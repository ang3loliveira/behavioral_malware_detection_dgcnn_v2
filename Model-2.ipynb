{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Graph Convolutional Neural Network (DGCNN)\n",
    "\n",
    "This code is part our research on malware detection and classification using Deep Learning and Deep Graph Convolutional Neural Networks.\n",
    "\n",
    "For more information or citation, please refer to our research paper:\n",
    "\n",
    "\"Oliveira, Angelo; Sassi, Renato José (2019): Behavioral Malware Detection Using Deep Graph Convolutional Neural Networks. TechRxiv. Preprint.\" at https://doi.org/10.36227/techrxiv.10043099.v1\n",
    "\n",
    "For the dataset, please refer to our repository:\n",
    "\n",
    "https://ieee-dataport.org/open-access/malware-analysis-datasets-api-call-sequences\n",
    "\n",
    "#### Model-2, Original (imbalanced) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "SEED = 137\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch.classifier import NeuralNetBinaryClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_91</th>\n",
       "      <th>t_92</th>\n",
       "      <th>t_93</th>\n",
       "      <th>t_94</th>\n",
       "      <th>t_95</th>\n",
       "      <th>t_96</th>\n",
       "      <th>t_97</th>\n",
       "      <th>t_98</th>\n",
       "      <th>t_99</th>\n",
       "      <th>malware</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>071e8c3f8922e186e57548cd4c703a5d</td>\n",
       "      <td>112</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>298</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "      <td>208</td>\n",
       "      <td>56</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33f8e6d08a6aae939f25a8e0d63dd523</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>71</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b68abd064e975e1c6d5f25e748663076</td>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>113</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>72049be7bd30ea61297ea624ae198067</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>302</td>\n",
       "      <td>208</td>\n",
       "      <td>302</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>302</td>\n",
       "      <td>228</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>c9b3700a77facf29172f32df6bc77f48</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>260</td>\n",
       "      <td>40</td>\n",
       "      <td>209</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               hash  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  \\\n",
       "0  071e8c3f8922e186e57548cd4c703a5d  112  274  158  215  274  158  215  298   \n",
       "1  33f8e6d08a6aae939f25a8e0d63dd523   82  208  187  208  172  117  172  117   \n",
       "2  b68abd064e975e1c6d5f25e748663076   16  110  240  117  240  117  240  117   \n",
       "3  72049be7bd30ea61297ea624ae198067   82  208  187  208  172  117  172  117   \n",
       "4  c9b3700a77facf29172f32df6bc77f48   82  240  117  240  117  240  117  240   \n",
       "\n",
       "   t_8  ...  t_91  t_92  t_93  t_94  t_95  t_96  t_97  t_98  t_99  malware  \n",
       "0   76  ...    71   297   135   171   215    35   208    56    71        1  \n",
       "1  172  ...    81   240   117    71   297   135   171   215    35        1  \n",
       "2  240  ...    65   112   123    65   112   123    65   113   112        1  \n",
       "3  172  ...   208   302   208   302   187   208   302   228   302        1  \n",
       "4  117  ...   209   260    40   209   260   141   260   141   260        1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dynamic_api_call_sequence_per_malware_100_0_306.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43876 entries, 0 to 43875\n",
      "Columns: 102 entries, hash to malware\n",
      "dtypes: int64(101), object(1)\n",
      "memory usage: 34.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43876, 100)\n",
      "(43876,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['hash', 'malware'], axis = 1).values.astype(int)\n",
    "y = df['malware'].values.astype(int)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "306\n"
     ]
    }
   ],
   "source": [
    "print(X.min())\n",
    "print(X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_imbalance(dataset):\n",
    "    count = sorted(Counter(dataset).items())\n",
    "    print(count)\n",
    "    print(count[1][1] / count[0][1])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1079), (1, 42797)]\n",
      "39.66357738646895\n"
     ]
    }
   ],
   "source": [
    "check_imbalance(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1 - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 42797), (1, 1079)]\n",
      "0.025212047573428042\n"
     ]
    }
   ],
   "source": [
    "check_imbalance(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 29982), (1, 731)]\n",
      "0.024381295443933027\n",
      "[(0, 12815), (1, 348)]\n",
      "0.027155676941084665\n"
     ]
    }
   ],
   "source": [
    "check_imbalance(y_train)\n",
    "check_imbalance(y_test)\n",
    "\n",
    "del df, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2_network(\n",
      "  (dgcnn_1): DGCNN_network()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (dgcnn_2): DGCNN_network()\n",
      "  (fc): Linear(in_features=27016, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Parameters: 35324\n"
     ]
    }
   ],
   "source": [
    "def norn_adj(X, input_dim_1):\n",
    "    \n",
    "    A = torch.zeros((X.size(0), input_dim_1, input_dim_1), dtype = torch.float).cuda()\n",
    "        \n",
    "    A_view = A.view(A.size(0), -1)\n",
    "    x_size = X.size(-1)\n",
    "    indices = X.narrow(-1, 0, x_size - 1) * A.stride(1) * A.stride(2) + X.narrow(-1, 1, x_size - 1) * A.stride(2)\n",
    "    A_view.scatter_(1, indices, 1)\n",
    "        \n",
    "    A_hat = A + torch.eye(input_dim_1, dtype = torch.float).cuda()\n",
    "    D_hat = A_hat.sum(dim = 1).pow(-1.0).diag_embed()\n",
    "    \n",
    "    return A_hat, D_hat\n",
    "\n",
    "def to_one_hot(X, input_dim_1):\n",
    "    \n",
    "    X = F.one_hot(X, num_classes = input_dim_1).float()    \n",
    "    X = X.permute(0, 2, 1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "class DGCNN_network(nn.Module):\n",
    "    \n",
    "    def __init__(self, weight_dim_1, weight_dim_2):\n",
    "\n",
    "        super(DGCNN_network, self).__init__()\n",
    "        self.weight_dim_1 = weight_dim_1\n",
    "        self.weight_dim_2 = weight_dim_2        \n",
    "        self.weights = nn.Parameter(torch.rand((self.weight_dim_1, weight_dim_2), dtype = torch.float, requires_grad = True))\n",
    "        \n",
    "    def forward(self, A_hat, D_hat, X):\n",
    "        return D_hat.matmul(A_hat).matmul(X).matmul(self.weights)\n",
    "\n",
    "class Model_2_network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim_1, input_dim_2, weight_dim_2, weight_dim_4, dropout_rate):\n",
    "    \n",
    "        super(Model_2_network, self).__init__()\n",
    "        \n",
    "        self.input_dim_1 = input_dim_1\n",
    "        self.input_dim_2 = input_dim_2\n",
    "        self.weight_dim_1 = input_dim_2\n",
    "        self.weight_dim_2 = weight_dim_2\n",
    "        self.weight_dim_3 = weight_dim_2\n",
    "        self.weight_dim_4 = weight_dim_4\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.dgcnn_1 = DGCNN_network(self.weight_dim_1, self.weight_dim_2)\n",
    "        self.dropout = nn.Dropout(p = self.dropout_rate)\n",
    "        self.dgcnn_2 = DGCNN_network(self.weight_dim_3, self.weight_dim_4)\n",
    "        self.fc = nn.Linear(self.input_dim_1 * (self.weight_dim_2 + self.weight_dim_4), 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        A_hat, D_hat = norn_adj(X, input_dim_1)\n",
    "        X = to_one_hot(X, input_dim_1)        \n",
    "\n",
    "        H_1 = self.dgcnn_1(A_hat, D_hat, X)\n",
    "        H_1 = self.dropout(H_1)\n",
    "        H_1 = torch.relu(H_1)\n",
    "        H_2 = self.dgcnn_2(A_hat, D_hat, H_1)\n",
    "        H_2 = self.dropout(H_2)\n",
    "        H_2 = torch.relu(H_2)\n",
    "        H_2 = torch.cat([H_1, H_2], 2)\n",
    "        H_2 = H_2.view(H_2.size(0), -1)\n",
    "        H_2 = self.fc(H_2)\n",
    "                \n",
    "        return H_2.squeeze()\n",
    "    \n",
    "model = Model_2_network(\n",
    "    input_dim_1 = 307,\n",
    "    input_dim_2 = 100,\n",
    "    weight_dim_2 = 71,    \n",
    "    weight_dim_4 = 17,\n",
    "    dropout_rate = 0.4\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(f'\\nParameters: {np.sum([param.numel() for param in model.parameters()])}')\n",
    "del model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.2480\u001b[0m  10.3494\n",
      "      2        \u001b[36m0.0555\u001b[0m  9.9352\n",
      "      3        \u001b[36m0.0490\u001b[0m  8.9526\n",
      "      4        \u001b[36m0.0454\u001b[0m  8.9836\n",
      "      5        \u001b[36m0.0422\u001b[0m  8.7842\n",
      "      6        \u001b[36m0.0412\u001b[0m  9.0131\n",
      "      7        \u001b[36m0.0401\u001b[0m  9.9701\n",
      "      8        \u001b[36m0.0380\u001b[0m  9.3848\n",
      "      9        0.0391  10.4051\n",
      "     10        \u001b[36m0.0358\u001b[0m  9.0398\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.2922\u001b[0m  10.0248\n",
      "      2        \u001b[36m0.0573\u001b[0m  10.0684\n",
      "      3        \u001b[36m0.0503\u001b[0m  9.6387\n",
      "      4        \u001b[36m0.0473\u001b[0m  9.4035\n",
      "      5        \u001b[36m0.0414\u001b[0m  9.2908\n",
      "      6        \u001b[36m0.0407\u001b[0m  10.9671\n",
      "      7        \u001b[36m0.0391\u001b[0m  8.8940\n",
      "      8        \u001b[36m0.0385\u001b[0m  8.8803\n",
      "      9        0.0388  9.2118\n",
      "     10        \u001b[36m0.0355\u001b[0m  10.0272\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3099\u001b[0m  9.4416\n",
      "      2        \u001b[36m0.0508\u001b[0m  9.6979\n",
      "      3        \u001b[36m0.0436\u001b[0m  9.7615\n",
      "      4        \u001b[36m0.0418\u001b[0m  9.7995\n",
      "      5        \u001b[36m0.0395\u001b[0m  9.8085\n",
      "      6        \u001b[36m0.0360\u001b[0m  10.9380\n",
      "      7        \u001b[36m0.0334\u001b[0m  9.7576\n",
      "      8        0.0341  11.0646\n",
      "      9        0.0346  9.4314\n",
      "     10        \u001b[36m0.0306\u001b[0m  10.5699\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2425\u001b[0m  9.0003\n",
      "      2        \u001b[36m0.0564\u001b[0m  8.8660\n",
      "      3        \u001b[36m0.0506\u001b[0m  9.2323\n",
      "      4        \u001b[36m0.0448\u001b[0m  8.9214\n",
      "      5        \u001b[36m0.0431\u001b[0m  9.2022\n",
      "      6        \u001b[36m0.0410\u001b[0m  9.6695\n",
      "      7        \u001b[36m0.0389\u001b[0m  9.3799\n",
      "      8        0.0392  8.8335\n",
      "      9        \u001b[36m0.0374\u001b[0m  8.7700\n",
      "     10        \u001b[36m0.0345\u001b[0m  8.7412\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2885\u001b[0m  8.7668\n",
      "      2        \u001b[36m0.0548\u001b[0m  8.7068\n",
      "      3        \u001b[36m0.0447\u001b[0m  8.6995\n",
      "      4        \u001b[36m0.0421\u001b[0m  8.6868\n",
      "      5        \u001b[36m0.0415\u001b[0m  8.6940\n",
      "      6        \u001b[36m0.0401\u001b[0m  8.7007\n",
      "      7        \u001b[36m0.0355\u001b[0m  8.7028\n",
      "      8        \u001b[36m0.0334\u001b[0m  8.7292\n",
      "      9        0.0381  8.7012\n",
      "     10        0.0353  8.7103\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6116\u001b[0m  8.8540\n",
      "      2        \u001b[36m0.0577\u001b[0m  8.8768\n",
      "      3        \u001b[36m0.0473\u001b[0m  8.8519\n",
      "      4        \u001b[36m0.0461\u001b[0m  9.0155\n",
      "      5        \u001b[36m0.0433\u001b[0m  9.0243\n",
      "      6        0.0465  9.0203\n",
      "      7        \u001b[36m0.0418\u001b[0m  8.9644\n",
      "      8        \u001b[36m0.0394\u001b[0m  8.8690\n",
      "      9        0.0407  8.8632\n",
      "     10        0.0395  9.0226\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8655\u001b[0m  8.8939\n",
      "      2        \u001b[36m0.0615\u001b[0m  8.9242\n",
      "      3        \u001b[36m0.0521\u001b[0m  8.8457\n",
      "      4        \u001b[36m0.0496\u001b[0m  8.8935\n",
      "      5        \u001b[36m0.0494\u001b[0m  8.9630\n",
      "      6        \u001b[36m0.0471\u001b[0m  8.9760\n",
      "      7        \u001b[36m0.0456\u001b[0m  8.9543\n",
      "      8        \u001b[36m0.0420\u001b[0m  8.9904\n",
      "      9        0.0438  9.0021\n",
      "     10        0.0454  8.9672\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6924\u001b[0m  8.9794\n",
      "      2        \u001b[36m0.0546\u001b[0m  8.8489\n",
      "      3        \u001b[36m0.0464\u001b[0m  8.8576\n",
      "      4        \u001b[36m0.0447\u001b[0m  8.8947\n",
      "      5        \u001b[36m0.0398\u001b[0m  8.8857\n",
      "      6        0.0434  8.8753\n",
      "      7        \u001b[36m0.0384\u001b[0m  8.8837\n",
      "      8        0.0389  8.8848\n",
      "      9        \u001b[36m0.0336\u001b[0m  8.8696\n",
      "     10        0.0363  8.8691\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6198\u001b[0m  8.9343\n",
      "      2        \u001b[36m0.0583\u001b[0m  8.8673\n",
      "      3        \u001b[36m0.0499\u001b[0m  8.8898\n",
      "      4        \u001b[36m0.0498\u001b[0m  8.8616\n",
      "      5        \u001b[36m0.0481\u001b[0m  8.8886\n",
      "      6        \u001b[36m0.0432\u001b[0m  8.8826\n",
      "      7        \u001b[36m0.0425\u001b[0m  8.8845\n",
      "      8        \u001b[36m0.0421\u001b[0m  8.9023\n",
      "      9        \u001b[36m0.0400\u001b[0m  8.8806\n",
      "     10        0.0429  8.8804\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0291\u001b[0m  8.8737\n",
      "      2        \u001b[36m0.0552\u001b[0m  8.8585\n",
      "      3        \u001b[36m0.0464\u001b[0m  8.8518\n",
      "      4        \u001b[36m0.0431\u001b[0m  8.9270\n",
      "      5        0.0475  8.8739\n",
      "      6        \u001b[36m0.0426\u001b[0m  8.8532\n",
      "      7        \u001b[36m0.0378\u001b[0m  8.8614\n",
      "      8        0.0394  8.8660\n",
      "      9        0.0393  8.8890\n",
      "     10        \u001b[36m0.0312\u001b[0m  8.8641\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5821\u001b[0m  8.9315\n",
      "      2        \u001b[36m0.0346\u001b[0m  8.8927\n",
      "      3        \u001b[36m0.0337\u001b[0m  8.9086\n",
      "      4        0.0348  8.8797\n",
      "      5        0.0349  8.9175\n",
      "      6        \u001b[36m0.0306\u001b[0m  8.8931\n",
      "      7        \u001b[36m0.0269\u001b[0m  8.9628\n",
      "      8        0.0294  8.9376\n",
      "      9        0.0314  8.9113\n",
      "     10        \u001b[36m0.0253\u001b[0m  8.9006\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8721\u001b[0m  8.9133\n",
      "      2        \u001b[36m0.0364\u001b[0m  8.8952\n",
      "      3        \u001b[36m0.0328\u001b[0m  8.9029\n",
      "      4        0.0341  8.9249\n",
      "      5        0.0351  8.9084\n",
      "      6        \u001b[36m0.0322\u001b[0m  8.9015\n",
      "      7        \u001b[36m0.0271\u001b[0m  8.9116\n",
      "      8        0.0283  8.9090\n",
      "      9        0.0320  8.9252\n",
      "     10        0.0289  8.9357\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9191\u001b[0m  8.9680\n",
      "      2        \u001b[36m0.0287\u001b[0m  8.9212\n",
      "      3        \u001b[36m0.0286\u001b[0m  8.9011\n",
      "      4        0.0298  8.9051\n",
      "      5        0.0318  8.9240\n",
      "      6        0.0287  8.9147\n",
      "      7        0.0302  8.9360\n",
      "      8        \u001b[36m0.0250\u001b[0m  8.9426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        0.0256  8.9115\n",
      "     10        \u001b[36m0.0240\u001b[0m  8.9104\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7515\u001b[0m  8.9065\n",
      "      2        \u001b[36m0.0350\u001b[0m  8.8949\n",
      "      3        \u001b[36m0.0316\u001b[0m  8.9177\n",
      "      4        0.0349  8.9735\n",
      "      5        0.0334  8.9225\n",
      "      6        0.0357  8.9070\n",
      "      7        \u001b[36m0.0284\u001b[0m  8.9039\n",
      "      8        0.0290  8.9193\n",
      "      9        \u001b[36m0.0273\u001b[0m  8.9099\n",
      "     10        0.0310  8.9129\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6345\u001b[0m  8.9367\n",
      "      2        \u001b[36m0.0313\u001b[0m  8.9119\n",
      "      3        \u001b[36m0.0294\u001b[0m  8.9047\n",
      "      4        0.0304  8.9061\n",
      "      5        0.0301  8.8994\n",
      "      6        0.0305  8.9149\n",
      "      7        \u001b[36m0.0286\u001b[0m  8.9707\n",
      "      8        \u001b[36m0.0259\u001b[0m  8.9360\n",
      "      9        \u001b[36m0.0243\u001b[0m  8.9106\n",
      "     10        0.0280  8.9055\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1945\u001b[0m  8.6449\n",
      "      2        \u001b[36m0.0372\u001b[0m  8.6905\n",
      "      3        \u001b[36m0.0295\u001b[0m  8.6457\n",
      "      4        0.0328  8.6871\n",
      "      5        0.0337  8.6591\n",
      "      6        0.0302  8.6597\n",
      "      7        0.0307  8.6445\n",
      "      8        0.0297  8.6522\n",
      "      9        0.0333  8.6548\n",
      "     10        0.0332  8.6662\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3188\u001b[0m  9.0339\n",
      "      2        \u001b[36m0.0348\u001b[0m  8.9975\n",
      "      3        \u001b[36m0.0319\u001b[0m  8.9889\n",
      "      4        0.0337  8.9948\n",
      "      5        0.0365  8.9896\n",
      "      6        0.0351  8.9942\n",
      "      7        \u001b[36m0.0283\u001b[0m  8.9955\n",
      "      8        0.0325  9.0285\n",
      "      9        0.0292  9.0161\n",
      "     10        0.0286  9.0558\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1640\u001b[0m  9.0525\n",
      "      2        \u001b[36m0.0313\u001b[0m  8.9801\n",
      "      3        \u001b[36m0.0259\u001b[0m  9.0688\n",
      "      4        0.0297  9.0545\n",
      "      5        0.0374  9.0205\n",
      "      6        0.0314  9.0321\n",
      "      7        0.0274  9.0507\n",
      "      8        \u001b[36m0.0259\u001b[0m  8.9826\n",
      "      9        0.0288  9.1201\n",
      "     10        \u001b[36m0.0251\u001b[0m  9.0051\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.7162\u001b[0m  9.0784\n",
      "      2        \u001b[36m0.0367\u001b[0m  9.0059\n",
      "      3        \u001b[36m0.0308\u001b[0m  9.0371\n",
      "      4        0.0349  9.0440\n",
      "      5        0.0332  9.1381\n",
      "      6        0.0329  9.0559\n",
      "      7        0.0325  9.0648\n",
      "      8        0.0330  9.0453\n",
      "      9        0.0356  9.0139\n",
      "     10        \u001b[36m0.0270\u001b[0m  9.0023\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.2121\u001b[0m  9.0062\n",
      "      2        \u001b[36m0.0334\u001b[0m  9.0407\n",
      "      3        \u001b[36m0.0285\u001b[0m  9.0159\n",
      "      4        0.0314  9.1196\n",
      "      5        0.0345  8.9877\n",
      "      6        0.0311  9.0709\n",
      "      7        0.0290  9.1290\n",
      "      8        0.0323  9.0269\n",
      "      9        0.0304  9.0153\n",
      "     10        0.0319  9.1277\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2646\u001b[0m  8.8167\n",
      "      2        \u001b[36m0.0718\u001b[0m  8.7204\n",
      "      3        \u001b[36m0.0629\u001b[0m  8.7238\n",
      "      4        \u001b[36m0.0611\u001b[0m  8.7932\n",
      "      5        \u001b[36m0.0569\u001b[0m  8.7496\n",
      "      6        0.0569  8.7513\n",
      "      7        \u001b[36m0.0551\u001b[0m  8.7991\n",
      "      8        \u001b[36m0.0489\u001b[0m  8.7811\n",
      "      9        \u001b[36m0.0479\u001b[0m  8.7915\n",
      "     10        \u001b[36m0.0463\u001b[0m  8.7576\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2677\u001b[0m  8.7447\n",
      "      2        \u001b[36m0.0724\u001b[0m  8.8093\n",
      "      3        \u001b[36m0.0631\u001b[0m  8.8322\n",
      "      4        \u001b[36m0.0597\u001b[0m  8.8264\n",
      "      5        \u001b[36m0.0597\u001b[0m  8.7932\n",
      "      6        \u001b[36m0.0545\u001b[0m  8.7322\n",
      "      7        \u001b[36m0.0526\u001b[0m  9.0042\n",
      "      8        \u001b[36m0.0513\u001b[0m  8.8986\n",
      "      9        \u001b[36m0.0496\u001b[0m  9.0140\n",
      "     10        0.0510  8.9308\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2745\u001b[0m  8.8506\n",
      "      2        \u001b[36m0.0671\u001b[0m  8.8675\n",
      "      3        \u001b[36m0.0582\u001b[0m  8.9018\n",
      "      4        \u001b[36m0.0558\u001b[0m  8.8431\n",
      "      5        \u001b[36m0.0521\u001b[0m  8.8242\n",
      "      6        0.0524  8.7820\n",
      "      7        \u001b[36m0.0472\u001b[0m  8.7954\n",
      "      8        \u001b[36m0.0468\u001b[0m  8.8537\n",
      "      9        \u001b[36m0.0442\u001b[0m  8.7697\n",
      "     10        \u001b[36m0.0426\u001b[0m  8.8227\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2443\u001b[0m  8.7449\n",
      "      2        \u001b[36m0.0698\u001b[0m  8.8987\n",
      "      3        \u001b[36m0.0618\u001b[0m  8.9380\n",
      "      4        \u001b[36m0.0577\u001b[0m  8.7266\n",
      "      5        \u001b[36m0.0557\u001b[0m  8.9541\n",
      "      6        0.0566  8.9592\n",
      "      7        \u001b[36m0.0516\u001b[0m  8.7614\n",
      "      8        \u001b[36m0.0511\u001b[0m  8.7699\n",
      "      9        \u001b[36m0.0508\u001b[0m  8.7332\n",
      "     10        \u001b[36m0.0472\u001b[0m  8.9192\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3104\u001b[0m  8.8640\n",
      "      2        \u001b[36m0.0707\u001b[0m  8.7899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m0.0571\u001b[0m  8.7534\n",
      "      4        0.0580  8.9216\n",
      "      5        \u001b[36m0.0531\u001b[0m  8.8828\n",
      "      6        \u001b[36m0.0529\u001b[0m  8.7861\n",
      "      7        \u001b[36m0.0494\u001b[0m  8.7465\n",
      "      8        \u001b[36m0.0487\u001b[0m  8.8249\n",
      "      9        0.0488  8.8272\n",
      "     10        \u001b[36m0.0480\u001b[0m  8.8508\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5530\u001b[0m  9.0047\n",
      "      2        \u001b[36m0.0731\u001b[0m  8.9471\n",
      "      3        \u001b[36m0.0627\u001b[0m  8.9833\n",
      "      4        0.0645  9.1466\n",
      "      5        0.0633  9.0923\n",
      "      6        \u001b[36m0.0621\u001b[0m  9.1150\n",
      "      7        \u001b[36m0.0558\u001b[0m  9.0958\n",
      "      8        0.0603  8.9875\n",
      "      9        \u001b[36m0.0554\u001b[0m  8.9178\n",
      "     10        \u001b[36m0.0524\u001b[0m  8.9677\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7007\u001b[0m  8.9234\n",
      "      2        \u001b[36m0.0746\u001b[0m  9.0438\n",
      "      3        \u001b[36m0.0659\u001b[0m  9.0331\n",
      "      4        \u001b[36m0.0637\u001b[0m  8.9833\n",
      "      5        0.0650  8.9901\n",
      "      6        \u001b[36m0.0632\u001b[0m  8.9798\n",
      "      7        \u001b[36m0.0607\u001b[0m  8.9593\n",
      "      8        \u001b[36m0.0581\u001b[0m  9.0003\n",
      "      9        \u001b[36m0.0559\u001b[0m  8.9607\n",
      "     10        \u001b[36m0.0538\u001b[0m  9.0383\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6924\u001b[0m  8.9909\n",
      "      2        \u001b[36m0.0689\u001b[0m  8.9040\n",
      "      3        \u001b[36m0.0605\u001b[0m  9.0548\n",
      "      4        \u001b[36m0.0605\u001b[0m  8.9305\n",
      "      5        \u001b[36m0.0584\u001b[0m  8.9209\n",
      "      6        \u001b[36m0.0568\u001b[0m  8.9475\n",
      "      7        \u001b[36m0.0539\u001b[0m  8.8840\n",
      "      8        \u001b[36m0.0488\u001b[0m  8.8960\n",
      "      9        0.0536  8.8948\n",
      "     10        0.0507  8.9405\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6454\u001b[0m  8.9182\n",
      "      2        \u001b[36m0.0744\u001b[0m  8.9097\n",
      "      3        \u001b[36m0.0677\u001b[0m  8.9208\n",
      "      4        \u001b[36m0.0649\u001b[0m  8.9180\n",
      "      5        0.0651  8.9246\n",
      "      6        \u001b[36m0.0609\u001b[0m  8.9114\n",
      "      7        \u001b[36m0.0597\u001b[0m  8.9466\n",
      "      8        \u001b[36m0.0567\u001b[0m  8.9272\n",
      "      9        0.0570  8.9131\n",
      "     10        \u001b[36m0.0545\u001b[0m  8.9126\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7084\u001b[0m  8.9063\n",
      "      2        \u001b[36m0.0697\u001b[0m  8.9360\n",
      "      3        \u001b[36m0.0614\u001b[0m  8.9742\n",
      "      4        0.0635  8.9321\n",
      "      5        0.0629  8.8929\n",
      "      6        \u001b[36m0.0560\u001b[0m  9.0364\n",
      "      7        0.0577  8.9422\n",
      "      8        \u001b[36m0.0517\u001b[0m  8.8741\n",
      "      9        \u001b[36m0.0514\u001b[0m  8.8771\n",
      "     10        \u001b[36m0.0475\u001b[0m  8.8947\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6943\u001b[0m  8.9254\n",
      "      2        \u001b[36m0.0415\u001b[0m  8.8966\n",
      "      3        \u001b[36m0.0383\u001b[0m  8.9157\n",
      "      4        0.0429  8.8992\n",
      "      5        0.0435  8.9284\n",
      "      6        \u001b[36m0.0380\u001b[0m  8.9498\n",
      "      7        \u001b[36m0.0380\u001b[0m  8.9680\n",
      "      8        \u001b[36m0.0375\u001b[0m  8.9061\n",
      "      9        \u001b[36m0.0369\u001b[0m  8.9242\n",
      "     10        \u001b[36m0.0358\u001b[0m  8.9179\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7425\u001b[0m  8.9203\n",
      "      2        \u001b[36m0.0402\u001b[0m  8.9026\n",
      "      3        0.0417  8.9417\n",
      "      4        0.0490  8.9063\n",
      "      5        0.0472  8.9291\n",
      "      6        0.0406  8.9295\n",
      "      7        \u001b[36m0.0381\u001b[0m  9.0074\n",
      "      8        0.0388  9.0783\n",
      "      9        \u001b[36m0.0353\u001b[0m  8.9997\n",
      "     10        \u001b[36m0.0343\u001b[0m  9.0224\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6157\u001b[0m  9.1847\n",
      "      2        \u001b[36m0.0353\u001b[0m  8.9387\n",
      "      3        0.0364  8.9193\n",
      "      4        0.0398  8.9207\n",
      "      5        0.0381  8.9281\n",
      "      6        0.0436  8.9234\n",
      "      7        0.0419  8.9350\n",
      "      8        0.0353  8.9319\n",
      "      9        \u001b[36m0.0337\u001b[0m  8.9285\n",
      "     10        \u001b[36m0.0337\u001b[0m  8.9258\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6605\u001b[0m  8.8874\n",
      "      2        \u001b[36m0.0419\u001b[0m  8.8959\n",
      "      3        0.0434  8.9500\n",
      "      4        0.0471  8.9164\n",
      "      5        \u001b[36m0.0389\u001b[0m  8.8972\n",
      "      6        0.0463  8.9009\n",
      "      7        0.0403  8.8972\n",
      "      8        \u001b[36m0.0383\u001b[0m  8.9072\n",
      "      9        \u001b[36m0.0371\u001b[0m  8.9085\n",
      "     10        0.0399  8.9296\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6448\u001b[0m  8.9261\n",
      "      2        \u001b[36m0.0379\u001b[0m  8.9249\n",
      "      3        0.0394  8.9181\n",
      "      4        \u001b[36m0.0374\u001b[0m  8.9234\n",
      "      5        0.0421  8.9285\n",
      "      6        0.0382  8.9569\n",
      "      7        \u001b[36m0.0333\u001b[0m  8.9352\n",
      "      8        0.0342  8.9217\n",
      "      9        0.0345  8.9245\n",
      "     10        0.0356  8.9182\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1965\u001b[0m  9.0034\n",
      "      2        \u001b[36m0.0440\u001b[0m  8.9970\n",
      "      3        \u001b[36m0.0362\u001b[0m  8.9867\n",
      "      4        0.0379  9.0062\n",
      "      5        0.0477  8.9804\n",
      "      6        0.0439  9.0002\n",
      "      7        0.0418  8.9891\n",
      "      8        0.0416  8.9881\n",
      "      9        0.0388  9.0229\n",
      "     10        0.0410  9.0139\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1634\u001b[0m  8.9876\n",
      "      2        \u001b[36m0.0466\u001b[0m  8.9977\n",
      "      3        \u001b[36m0.0386\u001b[0m  8.9963\n",
      "      4        0.0390  9.0035\n",
      "      5        0.0479  8.9980\n",
      "      6        0.0456  9.0209\n",
      "      7        0.0431  9.0059\n",
      "      8        0.0388  9.0095\n",
      "      9        0.0428  8.9952\n",
      "     10        \u001b[36m0.0374\u001b[0m  8.9971\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3101\u001b[0m  8.9856\n",
      "      2        \u001b[36m0.0402\u001b[0m  9.0061\n",
      "      3        \u001b[36m0.0331\u001b[0m  9.0167\n",
      "      4        0.0372  8.9824\n",
      "      5        0.0437  8.9734\n",
      "      6        0.0458  8.9893\n",
      "      7        0.0413  8.9927\n",
      "      8        0.0386  9.4713\n",
      "      9        0.0430  9.3367\n",
      "     10        0.0415  9.0949\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1777\u001b[0m  9.0687\n",
      "      2        \u001b[36m0.0486\u001b[0m  9.1344\n",
      "      3        \u001b[36m0.0371\u001b[0m  9.1059\n",
      "      4        0.0424  9.1494\n",
      "      5        0.0457  9.0628\n",
      "      6        0.0437  9.1128\n",
      "      7        0.0423  9.0595\n",
      "      8        0.0440  9.0171\n",
      "      9        0.0456  9.0200\n",
      "     10        0.0515  9.0062\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.4268\u001b[0m  8.9858\n",
      "      2        \u001b[36m0.0419\u001b[0m  8.9942\n",
      "      3        \u001b[36m0.0306\u001b[0m  8.9904\n",
      "      4        0.0353  8.9827\n",
      "      5        0.0444  8.9779\n",
      "      6        0.0419  8.9892\n",
      "      7        0.0396  8.9788\n",
      "      8        0.0417  8.9841\n",
      "      9        0.0367  9.0595\n",
      "     10        0.0398  8.9939\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3246\u001b[0m  8.7296\n",
      "      2        \u001b[36m0.0911\u001b[0m  8.7018\n",
      "      3        \u001b[36m0.0844\u001b[0m  8.7243\n",
      "      4        \u001b[36m0.0835\u001b[0m  8.6888\n",
      "      5        \u001b[36m0.0795\u001b[0m  8.7209\n",
      "      6        \u001b[36m0.0737\u001b[0m  8.8936\n",
      "      7        0.0756  8.7846\n",
      "      8        \u001b[36m0.0723\u001b[0m  8.8786\n",
      "      9        0.0765  8.8188\n",
      "     10        \u001b[36m0.0661\u001b[0m  8.7827\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3092\u001b[0m  9.0075\n",
      "      2        \u001b[36m0.0905\u001b[0m  8.8149\n",
      "      3        \u001b[36m0.0854\u001b[0m  8.8359\n",
      "      4        \u001b[36m0.0817\u001b[0m  8.8024\n",
      "      5        0.0828  8.8901\n",
      "      6        \u001b[36m0.0766\u001b[0m  8.8328\n",
      "      7        \u001b[36m0.0738\u001b[0m  8.8241\n",
      "      8        \u001b[36m0.0715\u001b[0m  8.8228\n",
      "      9        0.0717  8.8131\n",
      "     10        \u001b[36m0.0691\u001b[0m  8.7170\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3187\u001b[0m  9.0612\n",
      "      2        \u001b[36m0.0889\u001b[0m  8.7809\n",
      "      3        \u001b[36m0.0796\u001b[0m  8.8884\n",
      "      4        \u001b[36m0.0751\u001b[0m  9.0258\n",
      "      5        0.0801  8.8254\n",
      "      6        \u001b[36m0.0723\u001b[0m  8.8045\n",
      "      7        \u001b[36m0.0699\u001b[0m  8.8611\n",
      "      8        \u001b[36m0.0674\u001b[0m  8.7319\n",
      "      9        \u001b[36m0.0644\u001b[0m  8.7869\n",
      "     10        \u001b[36m0.0624\u001b[0m  8.7255\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3722\u001b[0m  8.8628\n",
      "      2        \u001b[36m0.0938\u001b[0m  8.7626\n",
      "      3        \u001b[36m0.0853\u001b[0m  8.8198\n",
      "      4        \u001b[36m0.0824\u001b[0m  8.9556\n",
      "      5        \u001b[36m0.0811\u001b[0m  8.9259\n",
      "      6        \u001b[36m0.0774\u001b[0m  8.8609\n",
      "      7        \u001b[36m0.0734\u001b[0m  8.8723\n",
      "      8        0.0743  8.7225\n",
      "      9        \u001b[36m0.0694\u001b[0m  8.9340\n",
      "     10        0.0715  8.8811\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3231\u001b[0m  8.8164\n",
      "      2        \u001b[36m0.0867\u001b[0m  8.8532\n",
      "      3        \u001b[36m0.0815\u001b[0m  8.8166\n",
      "      4        \u001b[36m0.0795\u001b[0m  8.7565\n",
      "      5        \u001b[36m0.0764\u001b[0m  8.7391\n",
      "      6        \u001b[36m0.0709\u001b[0m  8.8382\n",
      "      7        0.0730  8.7768\n",
      "      8        \u001b[36m0.0661\u001b[0m  8.7648\n",
      "      9        0.0681  8.7166\n",
      "     10        0.0669  8.7742\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7456\u001b[0m  9.0101\n",
      "      2        \u001b[36m0.0952\u001b[0m  9.0558\n",
      "      3        \u001b[36m0.0858\u001b[0m  8.9340\n",
      "      4        0.0897  8.9715\n",
      "      5        \u001b[36m0.0848\u001b[0m  8.9027\n",
      "      6        \u001b[36m0.0821\u001b[0m  8.8984\n",
      "      7        \u001b[36m0.0803\u001b[0m  8.9139\n",
      "      8        \u001b[36m0.0784\u001b[0m  8.9314\n",
      "      9        \u001b[36m0.0743\u001b[0m  8.9706\n",
      "     10        \u001b[36m0.0733\u001b[0m  8.9426\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7778\u001b[0m  8.8876\n",
      "      2        \u001b[36m0.0945\u001b[0m  8.8888\n",
      "      3        \u001b[36m0.0874\u001b[0m  8.9702\n",
      "      4        0.0878  9.0587\n",
      "      5        0.0890  8.9454\n",
      "      6        \u001b[36m0.0873\u001b[0m  8.9727\n",
      "      7        \u001b[36m0.0805\u001b[0m  8.9634\n",
      "      8        0.0837  9.0488\n",
      "      9        \u001b[36m0.0782\u001b[0m  8.9834\n",
      "     10        \u001b[36m0.0744\u001b[0m  8.9432\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0058\u001b[0m  8.8831\n",
      "      2        \u001b[36m0.0878\u001b[0m  8.9156\n",
      "      3        \u001b[36m0.0815\u001b[0m  8.9621\n",
      "      4        0.0836  8.9401\n",
      "      5        0.0823  8.9721\n",
      "      6        \u001b[36m0.0747\u001b[0m  8.9459\n",
      "      7        0.0760  8.9676\n",
      "      8        0.0749  8.9213\n",
      "      9        \u001b[36m0.0689\u001b[0m  9.0780\n",
      "     10        \u001b[36m0.0636\u001b[0m  9.0072\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7838\u001b[0m  9.0095\n",
      "      2        \u001b[36m0.0920\u001b[0m  9.0014\n",
      "      3        \u001b[36m0.0843\u001b[0m  8.9191\n",
      "      4        0.0891  8.8734\n",
      "      5        0.0854  9.0480\n",
      "      6        \u001b[36m0.0827\u001b[0m  8.9121\n",
      "      7        \u001b[36m0.0800\u001b[0m  9.1119\n",
      "      8        0.0800  9.0916\n",
      "      9        \u001b[36m0.0743\u001b[0m  8.8759\n",
      "     10        0.0773  9.1629\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8189\u001b[0m  9.1137\n",
      "      2        \u001b[36m0.0914\u001b[0m  9.0429\n",
      "      3        \u001b[36m0.0802\u001b[0m  9.1870\n",
      "      4        0.0893  9.1497\n",
      "      5        0.0857  8.8752\n",
      "      6        0.0806  8.8910\n",
      "      7        \u001b[36m0.0776\u001b[0m  8.8812\n",
      "      8        \u001b[36m0.0755\u001b[0m  8.9178\n",
      "      9        \u001b[36m0.0700\u001b[0m  8.9989\n",
      "     10        0.0707  8.9598\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6794\u001b[0m  9.1300\n",
      "      2        \u001b[36m0.0511\u001b[0m  8.9741\n",
      "      3        \u001b[36m0.0496\u001b[0m  8.9903\n",
      "      4        0.0506  9.0161\n",
      "      5        0.0569  9.1186\n",
      "      6        0.0533  8.9715\n",
      "      7        0.0525  8.9737\n",
      "      8        \u001b[36m0.0465\u001b[0m  8.9131\n",
      "      9        0.0549  9.0355\n",
      "     10        0.0495  8.8928\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7508\u001b[0m  9.0397\n",
      "      2        \u001b[36m0.0521\u001b[0m  9.0487\n",
      "      3        \u001b[36m0.0515\u001b[0m  8.9727\n",
      "      4        0.0587  8.9159\n",
      "      5        0.0547  8.9311\n",
      "      6        0.0572  9.1093\n",
      "      7        0.0607  9.0708\n",
      "      8        \u001b[36m0.0496\u001b[0m  9.0982\n",
      "      9        0.0540  9.0867\n",
      "     10        \u001b[36m0.0459\u001b[0m  8.8958\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7533\u001b[0m  9.0218\n",
      "      2        \u001b[36m0.0455\u001b[0m  9.0127\n",
      "      3        0.0500  9.0582\n",
      "      4        0.0483  8.9674\n",
      "      5        0.0536  9.1262\n",
      "      6        0.0486  9.0484\n",
      "      7        0.0503  8.9231\n",
      "      8        0.0504  9.0392\n",
      "      9        \u001b[36m0.0454\u001b[0m  8.9457\n",
      "     10        0.0464  9.0150\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7466\u001b[0m  8.9792\n",
      "      2        \u001b[36m0.0522\u001b[0m  8.9880\n",
      "      3        0.0532  9.0626\n",
      "      4        0.0537  9.0871\n",
      "      5        0.0579  9.0913\n",
      "      6        0.0559  9.0782\n",
      "      7        \u001b[36m0.0493\u001b[0m  9.0605\n",
      "      8        0.0573  8.9421\n",
      "      9        0.0499  9.0176\n",
      "     10        0.0523  9.1148\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7445\u001b[0m  8.9546\n",
      "      2        \u001b[36m0.0470\u001b[0m  9.1287\n",
      "      3        0.0497  9.0604\n",
      "      4        0.0490  9.1012\n",
      "      5        0.0539  9.0127\n",
      "      6        \u001b[36m0.0463\u001b[0m  8.9374\n",
      "      7        \u001b[36m0.0457\u001b[0m  9.0340\n",
      "      8        0.0502  8.9569\n",
      "      9        0.0461  9.0496\n",
      "     10        0.0490  9.1281\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.0584\u001b[0m  9.1404\n",
      "      2        \u001b[36m0.0548\u001b[0m  9.0531\n",
      "      3        \u001b[36m0.0466\u001b[0m  9.0142\n",
      "      4        0.0527  9.0048\n",
      "      5        0.0590  9.0109\n",
      "      6        0.0616  9.0155\n",
      "      7        0.0552  9.0397\n",
      "      8        0.0615  9.1357\n",
      "      9        0.0678  9.0731\n",
      "     10        0.0671  9.0193\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2056\u001b[0m  8.9812\n",
      "      2        \u001b[36m0.0689\u001b[0m  9.0025\n",
      "      3        \u001b[36m0.0502\u001b[0m  9.0103\n",
      "      4        0.0525  9.0697\n",
      "      5        0.0537  9.0966\n",
      "      6        0.0555  9.1819\n",
      "      7        0.0576  9.1303\n",
      "      8        0.0573  9.0471\n",
      "      9        0.0563  9.1139\n",
      "     10        \u001b[36m0.0485\u001b[0m  9.0849\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.7042\u001b[0m  9.3281\n",
      "      2        \u001b[36m0.0550\u001b[0m  9.0905\n",
      "      3        \u001b[36m0.0408\u001b[0m  9.0960\n",
      "      4        0.0455  9.2445\n",
      "      5        0.0529  9.0020\n",
      "      6        0.0547  9.0984\n",
      "      7        0.0568  9.1480\n",
      "      8        0.0538  9.2164\n",
      "      9        0.0543  9.1626\n",
      "     10        0.0535  9.0760\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2755\u001b[0m  9.0097\n",
      "      2        \u001b[36m0.0634\u001b[0m  8.9946\n",
      "      3        \u001b[36m0.0504\u001b[0m  9.0191\n",
      "      4        0.0515  9.0351\n",
      "      5        0.0606  9.0018\n",
      "      6        0.0570  9.0046\n",
      "      7        0.0617  9.0025\n",
      "      8        0.0599  9.0090\n",
      "      9        0.0544  9.0837\n",
      "     10        0.0606  9.0986\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.5443\u001b[0m  9.0085\n",
      "      2        \u001b[36m0.0556\u001b[0m  9.0406\n",
      "      3        \u001b[36m0.0444\u001b[0m  9.0019\n",
      "      4        0.0531  9.0077\n",
      "      5        0.0580  9.0429\n",
      "      6        0.0595  9.0091\n",
      "      7        0.0560  9.0399\n",
      "      8        0.0522  8.9802\n",
      "      9        0.0610  9.0068\n",
      "     10        0.0613  9.0389\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2812\u001b[0m  8.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.0578\u001b[0m  8.7113\n",
      "      3        \u001b[36m0.0506\u001b[0m  8.7783\n",
      "      4        \u001b[36m0.0449\u001b[0m  8.8099\n",
      "      5        \u001b[36m0.0436\u001b[0m  8.7312\n",
      "      6        \u001b[36m0.0390\u001b[0m  8.7269\n",
      "      7        0.0404  8.7676\n",
      "      8        \u001b[36m0.0348\u001b[0m  8.7617\n",
      "      9        \u001b[36m0.0346\u001b[0m  8.7884\n",
      "     10        0.0370  8.7944\n",
      "     11        0.0350  8.8083\n",
      "     12        0.0362  8.8169\n",
      "     13        \u001b[36m0.0330\u001b[0m  8.7205\n",
      "     14        0.0340  8.7687\n",
      "     15        \u001b[36m0.0324\u001b[0m  8.7545\n",
      "     16        0.0327  8.9527\n",
      "     17        0.0357  8.9216\n",
      "     18        0.0334  8.8504\n",
      "     19        0.0341  8.8890\n",
      "     20        0.0348  8.7723\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3335\u001b[0m  8.7521\n",
      "      2        \u001b[36m0.0606\u001b[0m  8.7690\n",
      "      3        \u001b[36m0.0490\u001b[0m  8.7729\n",
      "      4        \u001b[36m0.0476\u001b[0m  8.7688\n",
      "      5        \u001b[36m0.0413\u001b[0m  8.7321\n",
      "      6        0.0415  9.0263\n",
      "      7        \u001b[36m0.0403\u001b[0m  8.7571\n",
      "      8        \u001b[36m0.0397\u001b[0m  8.7904\n",
      "      9        \u001b[36m0.0386\u001b[0m  8.9054\n",
      "     10        \u001b[36m0.0337\u001b[0m  8.6737\n",
      "     11        0.0346  8.8007\n",
      "     12        0.0356  8.8025\n",
      "     13        \u001b[36m0.0336\u001b[0m  8.9132\n",
      "     14        \u001b[36m0.0331\u001b[0m  8.7125\n",
      "     15        0.0347  8.6848\n",
      "     16        \u001b[36m0.0325\u001b[0m  8.9448\n",
      "     17        \u001b[36m0.0319\u001b[0m  8.8696\n",
      "     18        0.0337  8.7504\n",
      "     19        0.0359  8.6847\n",
      "     20        0.0347  8.6676\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2492\u001b[0m  8.6842\n",
      "      2        \u001b[36m0.0530\u001b[0m  8.6822\n",
      "      3        \u001b[36m0.0442\u001b[0m  8.6840\n",
      "      4        \u001b[36m0.0400\u001b[0m  8.7119\n",
      "      5        \u001b[36m0.0399\u001b[0m  8.6901\n",
      "      6        \u001b[36m0.0356\u001b[0m  8.6786\n",
      "      7        \u001b[36m0.0340\u001b[0m  8.6867\n",
      "      8        \u001b[36m0.0308\u001b[0m  8.6909\n",
      "      9        0.0315  8.6868\n",
      "     10        0.0318  8.7089\n",
      "     11        0.0318  8.7285\n",
      "     12        0.0322  8.7044\n",
      "     13        \u001b[36m0.0302\u001b[0m  8.6807\n",
      "     14        \u001b[36m0.0295\u001b[0m  8.7009\n",
      "     15        \u001b[36m0.0272\u001b[0m  8.6906\n",
      "     16        \u001b[36m0.0262\u001b[0m  8.6897\n",
      "     17        0.0282  8.6904\n",
      "     18        0.0287  8.7163\n",
      "     19        0.0279  8.6870\n",
      "     20        0.0310  8.6834\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2550\u001b[0m  8.6831\n",
      "      2        \u001b[36m0.0575\u001b[0m  8.6744\n",
      "      3        \u001b[36m0.0474\u001b[0m  8.7053\n",
      "      4        \u001b[36m0.0460\u001b[0m  8.7217\n",
      "      5        \u001b[36m0.0446\u001b[0m  8.6998\n",
      "      6        \u001b[36m0.0396\u001b[0m  8.6898\n",
      "      7        0.0433  8.6785\n",
      "      8        \u001b[36m0.0375\u001b[0m  8.6927\n",
      "      9        \u001b[36m0.0331\u001b[0m  8.6787\n",
      "     10        0.0370  8.6763\n",
      "     11        0.0392  8.6959\n",
      "     12        0.0354  8.7065\n",
      "     13        0.0353  8.6775\n",
      "     14        0.0350  8.6946\n",
      "     15        0.0337  8.6857\n",
      "     16        0.0361  8.6922\n",
      "     17        0.0338  8.6947\n",
      "     18        0.0339  8.7403\n",
      "     19        0.0335  8.7021\n",
      "     20        0.0348  8.7445\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2681\u001b[0m  8.6970\n",
      "      2        \u001b[36m0.0540\u001b[0m  8.7471\n",
      "      3        \u001b[36m0.0478\u001b[0m  8.7837\n",
      "      4        \u001b[36m0.0423\u001b[0m  8.8364\n",
      "      5        \u001b[36m0.0399\u001b[0m  8.7576\n",
      "      6        \u001b[36m0.0374\u001b[0m  8.7794\n",
      "      7        \u001b[36m0.0363\u001b[0m  8.8108\n",
      "      8        0.0381  8.7068\n",
      "      9        \u001b[36m0.0341\u001b[0m  8.7520\n",
      "     10        0.0342  8.7948\n",
      "     11        \u001b[36m0.0323\u001b[0m  8.7280\n",
      "     12        0.0326  8.7712\n",
      "     13        \u001b[36m0.0313\u001b[0m  8.7185\n",
      "     14        \u001b[36m0.0302\u001b[0m  8.7250\n",
      "     15        0.0305  8.7064\n",
      "     16        \u001b[36m0.0292\u001b[0m  8.7555\n",
      "     17        0.0313  8.6916\n",
      "     18        0.0313  8.7641\n",
      "     19        0.0315  8.7145\n",
      "     20        0.0319  8.6912\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5594\u001b[0m  8.9138\n",
      "      2        \u001b[36m0.0570\u001b[0m  8.9075\n",
      "      3        \u001b[36m0.0505\u001b[0m  8.8982\n",
      "      4        \u001b[36m0.0460\u001b[0m  8.8937\n",
      "      5        0.0469  9.0093\n",
      "      6        \u001b[36m0.0459\u001b[0m  8.9363\n",
      "      7        \u001b[36m0.0397\u001b[0m  8.8349\n",
      "      8        0.0410  8.8931\n",
      "      9        \u001b[36m0.0394\u001b[0m  8.8744\n",
      "     10        \u001b[36m0.0390\u001b[0m  8.8921\n",
      "     11        \u001b[36m0.0355\u001b[0m  8.8445\n",
      "     12        0.0379  8.8749\n",
      "     13        \u001b[36m0.0346\u001b[0m  8.8811\n",
      "     14        \u001b[36m0.0329\u001b[0m  8.9117\n",
      "     15        0.0342  8.8522\n",
      "     16        0.0354  8.8799\n",
      "     17        0.0341  8.8710\n",
      "     18        0.0334  8.9034\n",
      "     19        \u001b[36m0.0327\u001b[0m  8.9295\n",
      "     20        0.0333  8.8694\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8861\u001b[0m  8.8710\n",
      "      2        \u001b[36m0.0621\u001b[0m  8.8792\n",
      "      3        \u001b[36m0.0515\u001b[0m  8.8706\n",
      "      4        \u001b[36m0.0501\u001b[0m  8.8725\n",
      "      5        \u001b[36m0.0469\u001b[0m  8.8920\n",
      "      6        \u001b[36m0.0452\u001b[0m  8.9094\n",
      "      7        \u001b[36m0.0449\u001b[0m  8.8622\n",
      "      8        \u001b[36m0.0405\u001b[0m  8.8890\n",
      "      9        \u001b[36m0.0398\u001b[0m  8.8559\n",
      "     10        \u001b[36m0.0392\u001b[0m  8.8777\n",
      "     11        \u001b[36m0.0383\u001b[0m  8.8784\n",
      "     12        \u001b[36m0.0383\u001b[0m  8.9609\n",
      "     13        \u001b[36m0.0372\u001b[0m  8.8764\n",
      "     14        0.0374  8.8862\n",
      "     15        0.0372  8.8640\n",
      "     16        \u001b[36m0.0333\u001b[0m  8.8885\n",
      "     17        0.0380  8.8772\n",
      "     18        0.0335  8.8958\n",
      "     19        0.0360  8.9054\n",
      "     20        \u001b[36m0.0332\u001b[0m  8.8908\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7342\u001b[0m  8.8670\n",
      "      2        \u001b[36m0.0531\u001b[0m  8.8623\n",
      "      3        \u001b[36m0.0442\u001b[0m  8.8777\n",
      "      4        \u001b[36m0.0432\u001b[0m  8.8761\n",
      "      5        \u001b[36m0.0427\u001b[0m  8.9245\n",
      "      6        \u001b[36m0.0401\u001b[0m  8.8915\n",
      "      7        \u001b[36m0.0382\u001b[0m  8.8672\n",
      "      8        \u001b[36m0.0379\u001b[0m  8.8785\n",
      "      9        \u001b[36m0.0346\u001b[0m  8.8711\n",
      "     10        \u001b[36m0.0339\u001b[0m  8.8777\n",
      "     11        0.0342  8.8914\n",
      "     12        0.0374  8.8865\n",
      "     13        \u001b[36m0.0288\u001b[0m  8.8902\n",
      "     14        0.0312  8.8913\n",
      "     15        0.0342  8.8647\n",
      "     16        0.0349  8.8739\n",
      "     17        0.0303  8.8624\n",
      "     18        0.0313  8.9021\n",
      "     19        0.0325  8.9061\n",
      "     20        0.0318  8.8809\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5614\u001b[0m  8.8991\n",
      "      2        \u001b[36m0.0543\u001b[0m  8.8990\n",
      "      3        \u001b[36m0.0491\u001b[0m  8.8915\n",
      "      4        \u001b[36m0.0458\u001b[0m  8.8816\n",
      "      5        \u001b[36m0.0443\u001b[0m  8.9069\n",
      "      6        0.0468  8.9022\n",
      "      7        \u001b[36m0.0431\u001b[0m  8.8868\n",
      "      8        \u001b[36m0.0406\u001b[0m  8.8927\n",
      "      9        \u001b[36m0.0381\u001b[0m  8.8902\n",
      "     10        0.0390  8.8825\n",
      "     11        \u001b[36m0.0373\u001b[0m  8.9040\n",
      "     12        0.0373  8.9637\n",
      "     13        \u001b[36m0.0371\u001b[0m  8.8909\n",
      "     14        \u001b[36m0.0347\u001b[0m  8.8945\n",
      "     15        \u001b[36m0.0343\u001b[0m  8.8858\n",
      "     16        \u001b[36m0.0314\u001b[0m  8.8892\n",
      "     17        0.0324  8.9018\n",
      "     18        0.0356  8.8850\n",
      "     19        \u001b[36m0.0311\u001b[0m  8.9039\n",
      "     20        0.0361  8.8849\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6542\u001b[0m  8.8843\n",
      "      2        \u001b[36m0.0557\u001b[0m  8.8670\n",
      "      3        \u001b[36m0.0456\u001b[0m  8.8802\n",
      "      4        0.0461  8.8610\n",
      "      5        \u001b[36m0.0400\u001b[0m  8.9181\n",
      "      6        0.0456  8.8886\n",
      "      7        \u001b[36m0.0394\u001b[0m  8.8668\n",
      "      8        \u001b[36m0.0369\u001b[0m  8.8647\n",
      "      9        \u001b[36m0.0351\u001b[0m  8.8727\n",
      "     10        \u001b[36m0.0321\u001b[0m  8.8726\n",
      "     11        0.0360  8.8833\n",
      "     12        0.0376  8.9061\n",
      "     13        0.0349  8.8782\n",
      "     14        0.0342  8.8702\n",
      "     15        \u001b[36m0.0296\u001b[0m  8.8748\n",
      "     16        0.0323  8.8740\n",
      "     17        0.0319  8.8710\n",
      "     18        0.0318  8.8894\n",
      "     19        0.0320  8.9209\n",
      "     20        0.0318  8.8708\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5579\u001b[0m  8.9117\n",
      "      2        \u001b[36m0.0350\u001b[0m  8.8957\n",
      "      3        \u001b[36m0.0316\u001b[0m  8.9255\n",
      "      4        0.0337  8.9150\n",
      "      5        \u001b[36m0.0300\u001b[0m  8.9413\n",
      "      6        0.0341  8.9199\n",
      "      7        \u001b[36m0.0296\u001b[0m  8.9119\n",
      "      8        \u001b[36m0.0287\u001b[0m  8.9074\n",
      "      9        \u001b[36m0.0284\u001b[0m  8.9086\n",
      "     10        \u001b[36m0.0281\u001b[0m  8.9139\n",
      "     11        0.0283  8.9160\n",
      "     12        \u001b[36m0.0258\u001b[0m  8.9749\n",
      "     13        0.0259  8.9250\n",
      "     14        0.0287  8.9001\n",
      "     15        0.0315  8.9182\n",
      "     16        \u001b[36m0.0249\u001b[0m  8.8960\n",
      "     17        \u001b[36m0.0243\u001b[0m  8.9509\n",
      "     18        0.0273  8.9321\n",
      "     19        0.0275  8.9558\n",
      "     20        \u001b[36m0.0225\u001b[0m  8.9463\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6283\u001b[0m  8.9332\n",
      "      2        \u001b[36m0.0359\u001b[0m  8.9716\n",
      "      3        \u001b[36m0.0350\u001b[0m  8.9125\n",
      "      4        0.0362  8.9089\n",
      "      5        \u001b[36m0.0320\u001b[0m  9.0168\n",
      "      6        \u001b[36m0.0310\u001b[0m  8.9762\n",
      "      7        \u001b[36m0.0288\u001b[0m  8.9658\n",
      "      8        \u001b[36m0.0286\u001b[0m  8.9061\n",
      "      9        0.0287  8.9126\n",
      "     10        0.0293  8.8955\n",
      "     11        \u001b[36m0.0252\u001b[0m  8.9174\n",
      "     12        0.0276  8.9384\n",
      "     13        0.0307  8.9222\n",
      "     14        \u001b[36m0.0244\u001b[0m  8.9072\n",
      "     15        0.0290  8.9389\n",
      "     16        0.0292  8.9093\n",
      "     17        0.0255  8.9140\n",
      "     18        0.0277  8.9206\n",
      "     19        \u001b[36m0.0215\u001b[0m  8.9775\n",
      "     20        0.0230  8.9018\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7544\u001b[0m  8.8732\n",
      "      2        \u001b[36m0.0306\u001b[0m  8.9068\n",
      "      3        0.0313  8.9071\n",
      "      4        0.0317  8.9142\n",
      "      5        \u001b[36m0.0306\u001b[0m  8.9535\n",
      "      6        \u001b[36m0.0292\u001b[0m  8.9239\n",
      "      7        \u001b[36m0.0259\u001b[0m  8.9085\n",
      "      8        0.0294  8.9120\n",
      "      9        0.0278  8.9203\n",
      "     10        0.0279  8.9415\n",
      "     11        0.0269  8.9300\n",
      "     12        0.0290  8.9969\n",
      "     13        0.0269  8.9246\n",
      "     14        \u001b[36m0.0247\u001b[0m  8.9145\n",
      "     15        0.0268  8.9026\n",
      "     16        \u001b[36m0.0223\u001b[0m  8.9239\n",
      "     17        0.0227  8.9258\n",
      "     18        0.0229  8.9233\n",
      "     19        0.0227  8.9598\n",
      "     20        \u001b[36m0.0215\u001b[0m  8.9215\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8628\u001b[0m  8.8928\n",
      "      2        \u001b[36m0.0364\u001b[0m  8.9027\n",
      "      3        \u001b[36m0.0331\u001b[0m  8.8921\n",
      "      4        0.0355  8.8988\n",
      "      5        0.0335  8.9707\n",
      "      6        \u001b[36m0.0317\u001b[0m  8.9282\n",
      "      7        0.0333  8.9103\n",
      "      8        \u001b[36m0.0266\u001b[0m  8.8984\n",
      "      9        0.0283  8.8998\n",
      "     10        \u001b[36m0.0260\u001b[0m  8.9114\n",
      "     11        0.0276  8.9093\n",
      "     12        0.0289  8.9421\n",
      "     13        0.0269  8.9100\n",
      "     14        0.0262  8.9001\n",
      "     15        0.0283  8.9045\n",
      "     16        \u001b[36m0.0253\u001b[0m  8.9138\n",
      "     17        0.0277  8.9095\n",
      "     18        \u001b[36m0.0234\u001b[0m  8.9546\n",
      "     19        0.0261  8.9298\n",
      "     20        0.0266  8.9089\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6930\u001b[0m  8.9149\n",
      "      2        \u001b[36m0.0331\u001b[0m  8.9010\n",
      "      3        \u001b[36m0.0287\u001b[0m  8.9137\n",
      "      4        0.0313  8.9279\n",
      "      5        0.0295  8.9414\n",
      "      6        0.0306  8.9177\n",
      "      7        0.0288  8.9152\n",
      "      8        0.0323  8.9227\n",
      "      9        \u001b[36m0.0250\u001b[0m  8.9189\n",
      "     10        0.0282  8.9354\n",
      "     11        0.0253  8.9237\n",
      "     12        0.0250  8.9755\n",
      "     13        \u001b[36m0.0219\u001b[0m  8.9196\n",
      "     14        0.0251  8.9294\n",
      "     15        0.0247  8.9223\n",
      "     16        0.0247  8.9035\n",
      "     17        0.0278  8.9095\n",
      "     18        \u001b[36m0.0218\u001b[0m  8.9261\n",
      "     19        0.0222  8.9400\n",
      "     20        0.0243  8.9306\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.5738\u001b[0m  8.9794\n",
      "      2        \u001b[36m0.0394\u001b[0m  9.0111\n",
      "      3        \u001b[36m0.0308\u001b[0m  9.1155\n",
      "      4        0.0333  9.0858\n",
      "      5        0.0378  9.1356\n",
      "      6        0.0335  9.0203\n",
      "      7        0.0340  9.0585\n",
      "      8        0.0330  9.0076\n",
      "      9        0.0318  9.0246\n",
      "     10        0.0380  9.0511\n",
      "     11        0.0327  9.0495\n",
      "     12        \u001b[36m0.0304\u001b[0m  9.0466\n",
      "     13        0.0341  9.0246\n",
      "     14        0.0311  9.0145\n",
      "     15        0.0329  9.0152\n",
      "     16        \u001b[36m0.0298\u001b[0m  9.0104\n",
      "     17        \u001b[36m0.0292\u001b[0m  8.9930\n",
      "     18        0.0302  9.0461\n",
      "     19        0.0319  9.0103\n",
      "     20        0.0298  9.0059\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2585\u001b[0m  8.9901\n",
      "      2        \u001b[36m0.0353\u001b[0m  9.0011\n",
      "      3        \u001b[36m0.0316\u001b[0m  9.0089\n",
      "      4        0.0340  9.0143\n",
      "      5        0.0382  9.0013\n",
      "      6        0.0387  9.0150\n",
      "      7        0.0317  9.0057\n",
      "      8        0.0339  9.0047\n",
      "      9        0.0335  8.9858\n",
      "     10        0.0356  9.0068\n",
      "     11        0.0350  9.0512\n",
      "     12        0.0319  9.0283\n",
      "     13        \u001b[36m0.0308\u001b[0m  8.9973\n",
      "     14        \u001b[36m0.0308\u001b[0m  9.0113\n",
      "     15        \u001b[36m0.0296\u001b[0m  8.9912\n",
      "     16        0.0341  9.0016\n",
      "     17        0.0324  8.9886\n",
      "     18        0.0299  9.0132\n",
      "     19        0.0323  8.9967\n",
      "     20        0.0333  9.0271\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.9549\u001b[0m  8.9796\n",
      "      2        \u001b[36m0.0304\u001b[0m  8.9943\n",
      "      3        \u001b[36m0.0271\u001b[0m  8.9998\n",
      "      4        0.0314  9.0322\n",
      "      5        0.0305  9.0038\n",
      "      6        0.0298  8.9970\n",
      "      7        0.0283  8.9851\n",
      "      8        0.0288  8.9890\n",
      "      9        0.0314  9.0139\n",
      "     10        \u001b[36m0.0253\u001b[0m  8.9952\n",
      "     11        0.0302  8.9965\n",
      "     12        \u001b[36m0.0247\u001b[0m  8.9982\n",
      "     13        0.0326  8.9917\n",
      "     14        0.0265  9.0142\n",
      "     15        0.0278  8.9954\n",
      "     16        0.0283  9.0112\n",
      "     17        0.0272  9.0214\n",
      "     18        \u001b[36m0.0235\u001b[0m  9.0180\n",
      "     19        0.0261  8.9992\n",
      "     20        0.0257  8.9989\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1355\u001b[0m  9.0145\n",
      "      2        \u001b[36m0.0363\u001b[0m  9.0098\n",
      "      3        \u001b[36m0.0315\u001b[0m  9.0166\n",
      "      4        0.0357  9.0045\n",
      "      5        0.0348  9.0113\n",
      "      6        0.0315  9.0072\n",
      "      7        0.0327  9.0015\n",
      "      8        0.0384  9.0007\n",
      "      9        0.0332  9.0005\n",
      "     10        \u001b[36m0.0314\u001b[0m  8.9997\n",
      "     11        \u001b[36m0.0312\u001b[0m  9.0545\n",
      "     12        \u001b[36m0.0274\u001b[0m  9.0139\n",
      "     13        0.0345  9.0036\n",
      "     14        0.0334  9.0099\n",
      "     15        0.0289  8.9969\n",
      "     16        0.0375  8.9993\n",
      "     17        0.0275  9.0184\n",
      "     18        0.0299  9.0148\n",
      "     19        0.0334  9.0202\n",
      "     20        0.0279  9.0074\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.6322\u001b[0m  8.9780\n",
      "      2        \u001b[36m0.0312\u001b[0m  9.0003\n",
      "      3        \u001b[36m0.0263\u001b[0m  8.9932\n",
      "      4        0.0339  9.0402\n",
      "      5        0.0323  9.0092\n",
      "      6        0.0310  8.9935\n",
      "      7        0.0330  8.9825\n",
      "      8        0.0316  8.9987\n",
      "      9        0.0359  8.9810\n",
      "     10        0.0286  8.9984\n",
      "     11        \u001b[36m0.0255\u001b[0m  9.0112\n",
      "     12        0.0388  9.0107\n",
      "     13        0.0303  8.9973\n",
      "     14        0.0338  8.9896\n",
      "     15        0.0318  9.0159\n",
      "     16        0.0299  8.9848\n",
      "     17        0.0302  9.0407\n",
      "     18        0.0312  9.0158\n",
      "     19        0.0283  8.9929\n",
      "     20        0.0299  8.9914\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2628\u001b[0m  8.7093\n",
      "      2        \u001b[36m0.0713\u001b[0m  8.6927\n",
      "      3        \u001b[36m0.0609\u001b[0m  8.7050\n",
      "      4        0.0625  8.7029\n",
      "      5        \u001b[36m0.0569\u001b[0m  8.7394\n",
      "      6        \u001b[36m0.0526\u001b[0m  8.6962\n",
      "      7        \u001b[36m0.0503\u001b[0m  8.7064\n",
      "      8        0.0534  8.7009\n",
      "      9        \u001b[36m0.0487\u001b[0m  8.7213\n",
      "     10        0.0494  8.7210\n",
      "     11        \u001b[36m0.0481\u001b[0m  8.7433\n",
      "     12        \u001b[36m0.0466\u001b[0m  8.7129\n",
      "     13        0.0494  8.7194\n",
      "     14        0.0470  8.7022\n",
      "     15        0.0467  8.7367\n",
      "     16        \u001b[36m0.0439\u001b[0m  8.6918\n",
      "     17        0.0440  8.7975\n",
      "     18        0.0489  8.7142\n",
      "     19        0.0456  8.7407\n",
      "     20        0.0482  8.7224\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3500\u001b[0m  8.7230\n",
      "      2        \u001b[36m0.0744\u001b[0m  8.7011\n",
      "      3        \u001b[36m0.0640\u001b[0m  8.7258\n",
      "      4        \u001b[36m0.0638\u001b[0m  8.7538\n",
      "      5        \u001b[36m0.0577\u001b[0m  8.7231\n",
      "      6        \u001b[36m0.0534\u001b[0m  8.7037\n",
      "      7        \u001b[36m0.0504\u001b[0m  8.7170\n",
      "      8        0.0509  8.6949\n",
      "      9        0.0504  8.7121\n",
      "     10        \u001b[36m0.0498\u001b[0m  8.7058\n",
      "     11        \u001b[36m0.0472\u001b[0m  8.7283\n",
      "     12        \u001b[36m0.0455\u001b[0m  8.7545\n",
      "     13        0.0473  8.8580\n",
      "     14        \u001b[36m0.0436\u001b[0m  8.7543\n",
      "     15        0.0450  8.8633\n",
      "     16        0.0458  8.8269\n",
      "     17        0.0457  8.8017\n",
      "     18        \u001b[36m0.0431\u001b[0m  8.8814\n",
      "     19        0.0471  8.8200\n",
      "     20        0.0438  8.9135\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2512\u001b[0m  8.8608\n",
      "      2        \u001b[36m0.0646\u001b[0m  8.7661\n",
      "      3        \u001b[36m0.0590\u001b[0m  8.7525\n",
      "      4        \u001b[36m0.0566\u001b[0m  8.8383\n",
      "      5        \u001b[36m0.0520\u001b[0m  8.8110\n",
      "      6        \u001b[36m0.0490\u001b[0m  8.9638\n",
      "      7        \u001b[36m0.0471\u001b[0m  8.9636\n",
      "      8        \u001b[36m0.0448\u001b[0m  8.7673\n",
      "      9        \u001b[36m0.0410\u001b[0m  8.7483\n",
      "     10        0.0417  8.7187\n",
      "     11        0.0424  8.7846\n",
      "     12        \u001b[36m0.0410\u001b[0m  8.7512\n",
      "     13        0.0425  8.7251\n",
      "     14        \u001b[36m0.0370\u001b[0m  8.7034\n",
      "     15        0.0403  8.7137\n",
      "     16        0.0403  8.7054\n",
      "     17        0.0409  8.7253\n",
      "     18        0.0383  8.7489\n",
      "     19        0.0401  8.7248\n",
      "     20        \u001b[36m0.0366\u001b[0m  8.7123\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2788\u001b[0m  8.6869\n",
      "      2        \u001b[36m0.0697\u001b[0m  8.6871\n",
      "      3        \u001b[36m0.0639\u001b[0m  8.6842\n",
      "      4        \u001b[36m0.0581\u001b[0m  8.6973\n",
      "      5        \u001b[36m0.0555\u001b[0m  8.7455\n",
      "      6        0.0567  8.6979\n",
      "      7        \u001b[36m0.0543\u001b[0m  8.7145\n",
      "      8        \u001b[36m0.0505\u001b[0m  8.6865\n",
      "      9        \u001b[36m0.0502\u001b[0m  8.6895\n",
      "     10        0.0524  8.6996\n",
      "     11        0.0523  8.6964\n",
      "     12        \u001b[36m0.0444\u001b[0m  8.7044\n",
      "     13        0.0495  8.7013\n",
      "     14        \u001b[36m0.0429\u001b[0m  8.6884\n",
      "     15        0.0432  8.6912\n",
      "     16        0.0469  8.6889\n",
      "     17        0.0505  8.7072\n",
      "     18        0.0449  8.7149\n",
      "     19        \u001b[36m0.0424\u001b[0m  8.7147\n",
      "     20        0.0430  8.6904\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2429\u001b[0m  8.7192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.0663\u001b[0m  8.7117\n",
      "      3        \u001b[36m0.0612\u001b[0m  8.7098\n",
      "      4        \u001b[36m0.0550\u001b[0m  8.6952\n",
      "      5        0.0561  8.7135\n",
      "      6        0.0557  8.7176\n",
      "      7        \u001b[36m0.0488\u001b[0m  8.7077\n",
      "      8        \u001b[36m0.0471\u001b[0m  8.6992\n",
      "      9        0.0490  8.7149\n",
      "     10        0.0480  8.7077\n",
      "     11        0.0482  8.7114\n",
      "     12        \u001b[36m0.0386\u001b[0m  8.7509\n",
      "     13        0.0447  8.7100\n",
      "     14        0.0450  8.6960\n",
      "     15        0.0402  8.7184\n",
      "     16        0.0423  8.7026\n",
      "     17        0.0432  8.7039\n",
      "     18        0.0414  8.7158\n",
      "     19        0.0411  8.7134\n",
      "     20        0.0402  8.7198\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5993\u001b[0m  8.8608\n",
      "      2        \u001b[36m0.0710\u001b[0m  8.8857\n",
      "      3        \u001b[36m0.0590\u001b[0m  8.8748\n",
      "      4        0.0616  8.8817\n",
      "      5        0.0611  8.8937\n",
      "      6        0.0591  8.9109\n",
      "      7        \u001b[36m0.0545\u001b[0m  8.8746\n",
      "      8        0.0567  8.8905\n",
      "      9        0.0550  8.8637\n",
      "     10        \u001b[36m0.0500\u001b[0m  8.8800\n",
      "     11        0.0516  8.8637\n",
      "     12        \u001b[36m0.0494\u001b[0m  8.9038\n",
      "     13        0.0494  8.8897\n",
      "     14        \u001b[36m0.0457\u001b[0m  8.8871\n",
      "     15        \u001b[36m0.0433\u001b[0m  8.8658\n",
      "     16        0.0455  8.8780\n",
      "     17        0.0468  8.8828\n",
      "     18        0.0442  8.9045\n",
      "     19        0.0437  8.9228\n",
      "     20        0.0445  8.9118\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6660\u001b[0m  8.8683\n",
      "      2        \u001b[36m0.0740\u001b[0m  8.8999\n",
      "      3        \u001b[36m0.0640\u001b[0m  8.8561\n",
      "      4        \u001b[36m0.0622\u001b[0m  8.8717\n",
      "      5        0.0652  8.8611\n",
      "      6        0.0623  8.8853\n",
      "      7        \u001b[36m0.0554\u001b[0m  8.8722\n",
      "      8        \u001b[36m0.0549\u001b[0m  8.8929\n",
      "      9        \u001b[36m0.0537\u001b[0m  8.8763\n",
      "     10        \u001b[36m0.0528\u001b[0m  8.8782\n",
      "     11        \u001b[36m0.0518\u001b[0m  8.8546\n",
      "     12        \u001b[36m0.0491\u001b[0m  8.9151\n",
      "     13        0.0504  8.8828\n",
      "     14        \u001b[36m0.0445\u001b[0m  8.8825\n",
      "     15        0.0484  8.8678\n",
      "     16        0.0454  8.8827\n",
      "     17        \u001b[36m0.0438\u001b[0m  8.8739\n",
      "     18        \u001b[36m0.0421\u001b[0m  8.8801\n",
      "     19        0.0440  8.8855\n",
      "     20        0.0453  8.8949\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5858\u001b[0m  8.8724\n",
      "      2        \u001b[36m0.0712\u001b[0m  8.8648\n",
      "      3        \u001b[36m0.0624\u001b[0m  8.8707\n",
      "      4        0.0626  8.8794\n",
      "      5        \u001b[36m0.0584\u001b[0m  8.8745\n",
      "      6        0.0585  8.9275\n",
      "      7        \u001b[36m0.0520\u001b[0m  8.8745\n",
      "      8        \u001b[36m0.0470\u001b[0m  8.8741\n",
      "      9        0.0499  8.8702\n",
      "     10        0.0487  8.8809\n",
      "     11        \u001b[36m0.0447\u001b[0m  8.8791\n",
      "     12        \u001b[36m0.0433\u001b[0m  8.8805\n",
      "     13        0.0450  8.8817\n",
      "     14        0.0456  8.8900\n",
      "     15        \u001b[36m0.0429\u001b[0m  8.9026\n",
      "     16        \u001b[36m0.0394\u001b[0m  8.8794\n",
      "     17        0.0428  8.8722\n",
      "     18        0.0412  8.8734\n",
      "     19        0.0395  8.9317\n",
      "     20        \u001b[36m0.0388\u001b[0m  8.8917\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7354\u001b[0m  8.8749\n",
      "      2        \u001b[36m0.0736\u001b[0m  8.8795\n",
      "      3        \u001b[36m0.0657\u001b[0m  8.8710\n",
      "      4        \u001b[36m0.0617\u001b[0m  8.8960\n",
      "      5        0.0629  8.8756\n",
      "      6        0.0620  8.8911\n",
      "      7        \u001b[36m0.0592\u001b[0m  8.8881\n",
      "      8        \u001b[36m0.0543\u001b[0m  8.8965\n",
      "      9        \u001b[36m0.0527\u001b[0m  8.8606\n",
      "     10        0.0546  8.8867\n",
      "     11        \u001b[36m0.0489\u001b[0m  8.8755\n",
      "     12        0.0495  8.9022\n",
      "     13        0.0516  8.9130\n",
      "     14        \u001b[36m0.0486\u001b[0m  8.8803\n",
      "     15        0.0494  8.8850\n",
      "     16        \u001b[36m0.0469\u001b[0m  8.8897\n",
      "     17        0.0487  8.8856\n",
      "     18        \u001b[36m0.0443\u001b[0m  8.8878\n",
      "     19        \u001b[36m0.0410\u001b[0m  8.8867\n",
      "     20        0.0461  8.8977\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7394\u001b[0m  8.8690\n",
      "      2        \u001b[36m0.0679\u001b[0m  8.8640\n",
      "      3        \u001b[36m0.0589\u001b[0m  8.8649\n",
      "      4        0.0628  8.8780\n",
      "      5        0.0600  8.8758\n",
      "      6        \u001b[36m0.0549\u001b[0m  8.9564\n",
      "      7        \u001b[36m0.0526\u001b[0m  8.8852\n",
      "      8        \u001b[36m0.0515\u001b[0m  8.8824\n",
      "      9        \u001b[36m0.0498\u001b[0m  8.8848\n",
      "     10        \u001b[36m0.0478\u001b[0m  8.8766\n",
      "     11        0.0490  8.8849\n",
      "     12        0.0501  8.8709\n",
      "     13        0.0487  8.9121\n",
      "     14        \u001b[36m0.0439\u001b[0m  8.8819\n",
      "     15        0.0463  8.8835\n",
      "     16        0.0441  8.8756\n",
      "     17        0.0446  8.8669\n",
      "     18        \u001b[36m0.0415\u001b[0m  8.8668\n",
      "     19        0.0418  8.9273\n",
      "     20        0.0455  8.8998\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0463\u001b[0m  8.9229\n",
      "      2        \u001b[36m0.0406\u001b[0m  8.9019\n",
      "      3        \u001b[36m0.0389\u001b[0m  8.9140\n",
      "      4        0.0453  8.8935\n",
      "      5        0.0410  9.0264\n",
      "      6        0.0401  9.0083\n",
      "      7        \u001b[36m0.0360\u001b[0m  9.8916\n",
      "      8        0.0399  12.2788\n",
      "      9        \u001b[36m0.0322\u001b[0m  9.8499\n",
      "     10        0.0369  9.4255\n",
      "     11        0.0337  9.0741\n",
      "     12        0.0340  9.0707\n",
      "     13        0.0368  9.1644\n",
      "     14        0.0383  9.0264\n",
      "     15        0.0376  8.9393\n",
      "     16        0.0367  9.0838\n",
      "     17        \u001b[36m0.0294\u001b[0m  8.9261\n",
      "     18        0.0374  9.0376\n",
      "     19        0.0334  8.9552\n",
      "     20        0.0310  8.9728\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.1min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7995\u001b[0m  9.1347\n",
      "      2        \u001b[36m0.0408\u001b[0m  8.9932\n",
      "      3        0.0409  8.9806\n",
      "      4        0.0422  9.1147\n",
      "      5        0.0458  9.1573\n",
      "      6        0.0431  9.1366\n",
      "      7        \u001b[36m0.0377\u001b[0m  9.1013\n",
      "      8        0.0396  9.0246\n",
      "      9        0.0378  9.0966\n",
      "     10        \u001b[36m0.0343\u001b[0m  8.9877\n",
      "     11        0.0355  8.9264\n",
      "     12        0.0363  9.2347\n",
      "     13        0.0417  9.0244\n",
      "     14        0.0346  9.0336\n",
      "     15        \u001b[36m0.0332\u001b[0m  8.9528\n",
      "     16        0.0377  8.9628\n",
      "     17        0.0362  9.0077\n",
      "     18        0.0368  9.1389\n",
      "     19        0.0356  9.1333\n",
      "     20        \u001b[36m0.0301\u001b[0m  8.9831\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.1min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7111\u001b[0m  8.9197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.0362\u001b[0m  8.9219\n",
      "      3        \u001b[36m0.0354\u001b[0m  9.1035\n",
      "      4        0.0410  9.0485\n",
      "      5        0.0378  9.1677\n",
      "      6        0.0378  9.0988\n",
      "      7        0.0383  9.1188\n",
      "      8        0.0363  8.9866\n",
      "      9        0.0373  9.0321\n",
      "     10        0.0356  9.1069\n",
      "     11        \u001b[36m0.0317\u001b[0m  9.0146\n",
      "     12        0.0379  8.9705\n",
      "     13        0.0332  8.9683\n",
      "     14        \u001b[36m0.0310\u001b[0m  9.0619\n",
      "     15        0.0333  9.0048\n",
      "     16        \u001b[36m0.0303\u001b[0m  8.9667\n",
      "     17        0.0353  8.9900\n",
      "     18        0.0353  8.9852\n",
      "     19        \u001b[36m0.0300\u001b[0m  9.0781\n",
      "     20        0.0316  8.9962\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6363\u001b[0m  8.9711\n",
      "      2        \u001b[36m0.0396\u001b[0m  8.9301\n",
      "      3        0.0396  8.9628\n",
      "      4        0.0459  9.0521\n",
      "      5        0.0426  8.9672\n",
      "      6        0.0436  9.0194\n",
      "      7        \u001b[36m0.0393\u001b[0m  8.9967\n",
      "      8        \u001b[36m0.0383\u001b[0m  9.0916\n",
      "      9        \u001b[36m0.0364\u001b[0m  8.9438\n",
      "     10        0.0400  8.9839\n",
      "     11        0.0405  8.9815\n",
      "     12        0.0364  9.0230\n",
      "     13        \u001b[36m0.0357\u001b[0m  8.9696\n",
      "     14        \u001b[36m0.0342\u001b[0m  9.0661\n",
      "     15        0.0384  9.1274\n",
      "     16        0.0351  8.9572\n",
      "     17        0.0374  8.9898\n",
      "     18        \u001b[36m0.0335\u001b[0m  9.1474\n",
      "     19        0.0361  9.0549\n",
      "     20        \u001b[36m0.0321\u001b[0m  8.9568\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7716\u001b[0m  8.9275\n",
      "      2        \u001b[36m0.0360\u001b[0m  9.1009\n",
      "      3        \u001b[36m0.0357\u001b[0m  8.9630\n",
      "      4        0.0362  8.9476\n",
      "      5        0.0438  8.9517\n",
      "      6        0.0419  9.0095\n",
      "      7        \u001b[36m0.0348\u001b[0m  9.0013\n",
      "      8        0.0354  8.9347\n",
      "      9        0.0368  9.0885\n",
      "     10        0.0378  8.9382\n",
      "     11        \u001b[36m0.0331\u001b[0m  9.1360\n",
      "     12        0.0382  8.9777\n",
      "     13        0.0352  9.1078\n",
      "     14        0.0362  9.0211\n",
      "     15        \u001b[36m0.0328\u001b[0m  8.9608\n",
      "     16        \u001b[36m0.0318\u001b[0m  9.1119\n",
      "     17        \u001b[36m0.0305\u001b[0m  9.0732\n",
      "     18        0.0322  9.0459\n",
      "     19        0.0325  8.9251\n",
      "     20        0.0341  8.9647\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.4008\u001b[0m  9.0183\n",
      "      2        \u001b[36m0.0430\u001b[0m  9.1401\n",
      "      3        \u001b[36m0.0368\u001b[0m  9.1848\n",
      "      4        0.0423  9.1153\n",
      "      5        0.0451  9.0139\n",
      "      6        0.0541  9.1671\n",
      "      7        0.0502  9.0686\n",
      "      8        0.0387  9.0576\n",
      "      9        0.0421  9.2527\n",
      "     10        0.0491  9.1094\n",
      "     11        0.0471  9.1344\n",
      "     12        0.0411  9.0695\n",
      "     13        0.0398  9.1097\n",
      "     14        0.0465  9.0803\n",
      "     15        0.0393  9.0267\n",
      "     16        0.0394  9.0519\n",
      "     17        0.0415  9.1356\n",
      "     18        \u001b[36m0.0366\u001b[0m  9.0516\n",
      "     19        0.0389  9.0376\n",
      "     20        0.0417  8.9990\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.1min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.0080\u001b[0m  9.0007\n",
      "      2        \u001b[36m0.0454\u001b[0m  9.0070\n",
      "      3        \u001b[36m0.0358\u001b[0m  9.0256\n",
      "      4        0.0401  9.2243\n",
      "      5        0.0498  9.1246\n",
      "      6        0.0444  9.0939\n",
      "      7        0.0428  8.9877\n",
      "      8        0.0441  9.1479\n",
      "      9        0.0388  9.0918\n",
      "     10        0.0433  9.1318\n",
      "     11        0.0389  9.0776\n",
      "     12        0.0409  9.0683\n",
      "     13        0.0387  8.9800\n",
      "     14        0.0383  9.0369\n",
      "     15        0.0421  8.9893\n",
      "     16        0.0380  9.0763\n",
      "     17        0.0373  9.2121\n",
      "     18        0.0380  9.0079\n",
      "     19        0.0400  9.0846\n",
      "     20        0.0385  9.0889\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.1min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1960\u001b[0m  9.0871\n",
      "      2        \u001b[36m0.0389\u001b[0m  9.0238\n",
      "      3        \u001b[36m0.0332\u001b[0m  9.0761\n",
      "      4        0.0363  9.0986\n",
      "      5        0.0412  9.0396\n",
      "      6        0.0422  9.0614\n",
      "      7        0.0424  9.2063\n",
      "      8        0.0387  9.0394\n",
      "      9        0.0422  9.0686\n",
      "     10        0.0437  9.0641\n",
      "     11        0.0393  8.9907\n",
      "     12        0.0357  9.0646\n",
      "     13        0.0368  9.0106\n",
      "     14        0.0352  9.1032\n",
      "     15        0.0427  8.9920\n",
      "     16        0.0359  9.1425\n",
      "     17        0.0389  9.0310\n",
      "     18        0.0400  9.0092\n",
      "     19        0.0359  9.1719\n",
      "     20        0.0389  9.0412\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.1min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.4512\u001b[0m  9.0185\n",
      "      2        \u001b[36m0.0433\u001b[0m  9.1651\n",
      "      3        \u001b[36m0.0360\u001b[0m  9.1084\n",
      "      4        0.0418  9.0271\n",
      "      5        0.0423  9.0128\n",
      "      6        0.0392  8.9895\n",
      "      7        0.0421  9.0833\n",
      "      8        0.0444  9.0032\n",
      "      9        0.0437  9.1954\n",
      "     10        0.0427  9.2305\n",
      "     11        0.0407  9.0921\n",
      "     12        0.0388  9.1532\n",
      "     13        0.0458  9.0600\n",
      "     14        0.0405  9.0771\n",
      "     15        0.0427  9.0311\n",
      "     16        0.0427  9.1277\n",
      "     17        0.0451  9.0640\n",
      "     18        0.0420  9.1474\n",
      "     19        0.0439  8.9982\n",
      "     20        0.0415  9.1723\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.1min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.8145\u001b[0m  9.0162\n",
      "      2        \u001b[36m0.0422\u001b[0m  9.1892\n",
      "      3        \u001b[36m0.0322\u001b[0m  9.0810\n",
      "      4        0.0417  9.3145\n",
      "      5        0.0414  9.0116\n",
      "      6        0.0458  9.0920\n",
      "      7        0.0436  9.0949\n",
      "      8        0.0437  9.0649\n",
      "      9        0.0425  9.1930\n",
      "     10        0.0440  9.0516\n",
      "     11        0.0446  8.9974\n",
      "     12        0.0391  9.2658\n",
      "     13        0.0467  9.0727\n",
      "     14        0.0442  8.9986\n",
      "     15        0.0431  9.0237\n",
      "     16        0.0398  9.2111\n",
      "     17        0.0438  9.0376\n",
      "     18        0.0452  9.1136\n",
      "     19        0.0395  9.0419\n",
      "     20        0.0407  9.2151\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.1min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3038\u001b[0m  8.9128\n",
      "      2        \u001b[36m0.0907\u001b[0m  8.8844\n",
      "      3        \u001b[36m0.0843\u001b[0m  8.7839\n",
      "      4        \u001b[36m0.0773\u001b[0m  8.7054\n",
      "      5        \u001b[36m0.0752\u001b[0m  8.9019\n",
      "      6        0.0780  8.7858\n",
      "      7        \u001b[36m0.0748\u001b[0m  8.7348\n",
      "      8        \u001b[36m0.0709\u001b[0m  8.8308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        0.0715  8.8646\n",
      "     10        \u001b[36m0.0684\u001b[0m  8.8589\n",
      "     11        \u001b[36m0.0656\u001b[0m  8.8161\n",
      "     12        0.0696  8.8014\n",
      "     13        0.0666  8.8390\n",
      "     14        \u001b[36m0.0634\u001b[0m  8.7246\n",
      "     15        0.0635  8.7762\n",
      "     16        \u001b[36m0.0606\u001b[0m  8.9894\n",
      "     17        0.0624  8.7828\n",
      "     18        0.0699  8.6894\n",
      "     19        0.0625  8.8005\n",
      "     20        0.0621  8.6952\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3281\u001b[0m  8.8592\n",
      "      2        \u001b[36m0.0946\u001b[0m  8.8140\n",
      "      3        \u001b[36m0.0907\u001b[0m  8.8808\n",
      "      4        \u001b[36m0.0837\u001b[0m  8.8032\n",
      "      5        \u001b[36m0.0804\u001b[0m  8.7072\n",
      "      6        \u001b[36m0.0776\u001b[0m  8.8008\n",
      "      7        \u001b[36m0.0748\u001b[0m  8.7864\n",
      "      8        \u001b[36m0.0695\u001b[0m  8.7624\n",
      "      9        \u001b[36m0.0657\u001b[0m  8.8788\n",
      "     10        0.0699  8.8304\n",
      "     11        0.0727  8.7126\n",
      "     12        0.0675  8.8627\n",
      "     13        0.0675  8.7257\n",
      "     14        \u001b[36m0.0618\u001b[0m  8.7231\n",
      "     15        0.0663  8.7435\n",
      "     16        0.0648  8.8498\n",
      "     17        \u001b[36m0.0613\u001b[0m  8.7409\n",
      "     18        0.0626  8.8504\n",
      "     19        \u001b[36m0.0591\u001b[0m  8.7592\n",
      "     20        0.0636  8.7426\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3050\u001b[0m  8.9587\n",
      "      2        \u001b[36m0.0883\u001b[0m  8.9881\n",
      "      3        \u001b[36m0.0813\u001b[0m  8.9332\n",
      "      4        \u001b[36m0.0758\u001b[0m  8.8970\n",
      "      5        \u001b[36m0.0746\u001b[0m  9.0045\n",
      "      6        \u001b[36m0.0705\u001b[0m  8.7441\n",
      "      7        \u001b[36m0.0694\u001b[0m  8.9713\n",
      "      8        \u001b[36m0.0646\u001b[0m  9.0237\n",
      "      9        0.0681  8.9244\n",
      "     10        \u001b[36m0.0640\u001b[0m  8.7210\n",
      "     11        \u001b[36m0.0599\u001b[0m  8.6979\n",
      "     12        0.0614  8.7065\n",
      "     13        0.0612  8.7096\n",
      "     14        \u001b[36m0.0561\u001b[0m  8.7016\n",
      "     15        0.0600  8.7090\n",
      "     16        0.0599  8.7168\n",
      "     17        0.0563  8.7133\n",
      "     18        0.0590  8.7039\n",
      "     19        \u001b[36m0.0560\u001b[0m  8.7131\n",
      "     20        \u001b[36m0.0546\u001b[0m  8.7064\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3111\u001b[0m  8.6842\n",
      "      2        \u001b[36m0.0924\u001b[0m  8.7127\n",
      "      3        \u001b[36m0.0849\u001b[0m  8.7292\n",
      "      4        \u001b[36m0.0808\u001b[0m  8.7002\n",
      "      5        \u001b[36m0.0797\u001b[0m  8.6915\n",
      "      6        \u001b[36m0.0778\u001b[0m  8.6903\n",
      "      7        \u001b[36m0.0725\u001b[0m  8.7025\n",
      "      8        0.0773  8.7015\n",
      "      9        \u001b[36m0.0708\u001b[0m  8.7055\n",
      "     10        \u001b[36m0.0696\u001b[0m  8.7075\n",
      "     11        0.0727  8.7015\n",
      "     12        \u001b[36m0.0670\u001b[0m  8.6967\n",
      "     13        \u001b[36m0.0644\u001b[0m  8.6928\n",
      "     14        0.0690  8.6961\n",
      "     15        0.0671  8.6998\n",
      "     16        0.0662  8.7442\n",
      "     17        \u001b[36m0.0626\u001b[0m  8.7109\n",
      "     18        0.0653  8.7036\n",
      "     19        0.0631  8.6886\n",
      "     20        0.0627  8.6843\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2677\u001b[0m  8.7186\n",
      "      2        \u001b[36m0.0889\u001b[0m  8.7142\n",
      "      3        \u001b[36m0.0808\u001b[0m  8.7104\n",
      "      4        \u001b[36m0.0765\u001b[0m  8.7226\n",
      "      5        \u001b[36m0.0710\u001b[0m  8.7234\n",
      "      6        0.0723  8.7378\n",
      "      7        \u001b[36m0.0681\u001b[0m  8.7142\n",
      "      8        \u001b[36m0.0661\u001b[0m  8.7035\n",
      "      9        0.0684  8.7164\n",
      "     10        \u001b[36m0.0633\u001b[0m  8.7607\n",
      "     11        0.0634  8.7192\n",
      "     12        0.0633  8.7135\n",
      "     13        \u001b[36m0.0604\u001b[0m  8.6987\n",
      "     14        \u001b[36m0.0603\u001b[0m  8.7001\n",
      "     15        0.0623  8.7018\n",
      "     16        0.0617  8.7030\n",
      "     17        \u001b[36m0.0583\u001b[0m  8.7106\n",
      "     18        0.0612  8.7150\n",
      "     19        \u001b[36m0.0575\u001b[0m  8.7138\n",
      "     20        \u001b[36m0.0568\u001b[0m  8.7186\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7874\u001b[0m  8.8708\n",
      "      2        \u001b[36m0.0938\u001b[0m  8.8720\n",
      "      3        \u001b[36m0.0891\u001b[0m  8.8919\n",
      "      4        \u001b[36m0.0864\u001b[0m  8.9087\n",
      "      5        \u001b[36m0.0807\u001b[0m  8.8856\n",
      "      6        0.0813  8.8893\n",
      "      7        \u001b[36m0.0763\u001b[0m  8.8748\n",
      "      8        0.0774  8.8927\n",
      "      9        \u001b[36m0.0759\u001b[0m  8.8837\n",
      "     10        \u001b[36m0.0750\u001b[0m  8.8948\n",
      "     11        \u001b[36m0.0712\u001b[0m  8.8982\n",
      "     12        \u001b[36m0.0686\u001b[0m  8.8790\n",
      "     13        \u001b[36m0.0676\u001b[0m  8.8669\n",
      "     14        \u001b[36m0.0675\u001b[0m  8.8831\n",
      "     15        \u001b[36m0.0655\u001b[0m  8.8796\n",
      "     16        \u001b[36m0.0609\u001b[0m  8.8843\n",
      "     17        0.0628  8.9261\n",
      "     18        0.0647  8.8868\n",
      "     19        \u001b[36m0.0582\u001b[0m  8.9337\n",
      "     20        0.0608  8.8809\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7321\u001b[0m  8.8759\n",
      "      2        \u001b[36m0.0991\u001b[0m  8.8872\n",
      "      3        \u001b[36m0.0875\u001b[0m  8.8711\n",
      "      4        0.0886  8.9215\n",
      "      5        0.0928  8.8835\n",
      "      6        \u001b[36m0.0825\u001b[0m  8.9034\n",
      "      7        \u001b[36m0.0825\u001b[0m  8.8770\n",
      "      8        \u001b[36m0.0724\u001b[0m  8.8806\n",
      "      9        \u001b[36m0.0710\u001b[0m  8.8895\n",
      "     10        0.0736  8.9515\n",
      "     11        \u001b[36m0.0668\u001b[0m  8.8821\n",
      "     12        \u001b[36m0.0664\u001b[0m  8.8826\n",
      "     13        0.0692  8.8756\n",
      "     14        0.0665  9.0451\n",
      "     15        \u001b[36m0.0644\u001b[0m  8.8800\n",
      "     16        0.0672  9.1326\n",
      "     17        0.0667  9.0710\n",
      "     18        \u001b[36m0.0632\u001b[0m  9.0597\n",
      "     19        \u001b[36m0.0601\u001b[0m  9.0418\n",
      "     20        0.0605  9.1502\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7392\u001b[0m  8.9357\n",
      "      2        \u001b[36m0.0879\u001b[0m  8.8860\n",
      "      3        \u001b[36m0.0788\u001b[0m  8.9144\n",
      "      4        0.0821  8.9032\n",
      "      5        0.0848  8.9790\n",
      "      6        \u001b[36m0.0787\u001b[0m  8.9454\n",
      "      7        \u001b[36m0.0754\u001b[0m  8.9230\n",
      "      8        \u001b[36m0.0737\u001b[0m  8.9983\n",
      "      9        \u001b[36m0.0690\u001b[0m  8.9163\n",
      "     10        0.0694  8.9101\n",
      "     11        \u001b[36m0.0677\u001b[0m  8.8796\n",
      "     12        \u001b[36m0.0641\u001b[0m  8.8720\n",
      "     13        \u001b[36m0.0637\u001b[0m  8.8748\n",
      "     14        \u001b[36m0.0619\u001b[0m  8.8831\n",
      "     15        \u001b[36m0.0586\u001b[0m  8.8724\n",
      "     16        0.0591  8.8670\n",
      "     17        0.0594  8.9365\n",
      "     18        \u001b[36m0.0576\u001b[0m  8.8927\n",
      "     19        0.0592  8.8890\n",
      "     20        \u001b[36m0.0545\u001b[0m  8.8771\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6928\u001b[0m  8.8713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.0951\u001b[0m  8.8857\n",
      "      3        \u001b[36m0.0858\u001b[0m  8.8950\n",
      "      4        0.0874  8.9029\n",
      "      5        0.0891  8.8975\n",
      "      6        0.0865  8.8954\n",
      "      7        \u001b[36m0.0823\u001b[0m  8.8868\n",
      "      8        0.0831  8.8967\n",
      "      9        \u001b[36m0.0744\u001b[0m  8.8949\n",
      "     10        0.0777  8.9498\n",
      "     11        \u001b[36m0.0738\u001b[0m  8.9176\n",
      "     12        \u001b[36m0.0693\u001b[0m  8.8855\n",
      "     13        0.0713  8.8850\n",
      "     14        \u001b[36m0.0658\u001b[0m  8.8820\n",
      "     15        0.0662  8.8881\n",
      "     16        \u001b[36m0.0635\u001b[0m  8.8954\n",
      "     17        \u001b[36m0.0584\u001b[0m  8.9419\n",
      "     18        0.0644  8.9078\n",
      "     19        0.0615  8.8925\n",
      "     20        0.0614  8.8925\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6936\u001b[0m  8.8786\n",
      "      2        \u001b[36m0.0945\u001b[0m  8.8670\n",
      "      3        \u001b[36m0.0827\u001b[0m  8.9204\n",
      "      4        0.0862  8.9012\n",
      "      5        \u001b[36m0.0814\u001b[0m  8.8832\n",
      "      6        0.0832  8.8631\n",
      "      7        \u001b[36m0.0780\u001b[0m  8.8726\n",
      "      8        \u001b[36m0.0728\u001b[0m  8.8694\n",
      "      9        \u001b[36m0.0693\u001b[0m  8.8836\n",
      "     10        0.0708  8.8993\n",
      "     11        \u001b[36m0.0682\u001b[0m  8.8811\n",
      "     12        \u001b[36m0.0645\u001b[0m  8.8868\n",
      "     13        \u001b[36m0.0620\u001b[0m  8.8857\n",
      "     14        0.0630  8.8810\n",
      "     15        \u001b[36m0.0613\u001b[0m  8.8667\n",
      "     16        \u001b[36m0.0604\u001b[0m  8.8721\n",
      "     17        \u001b[36m0.0596\u001b[0m  9.0076\n",
      "     18        \u001b[36m0.0561\u001b[0m  8.8927\n",
      "     19        \u001b[36m0.0556\u001b[0m  8.8768\n",
      "     20        \u001b[36m0.0545\u001b[0m  8.8759\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9225\u001b[0m  8.6002\n",
      "      2        \u001b[36m0.0502\u001b[0m  8.6691\n",
      "      3        0.0511  8.6823\n",
      "      4        0.0588  8.6495\n",
      "      5        0.0601  8.6093\n",
      "      6        0.0503  8.5801\n",
      "      7        0.0509  8.5972\n",
      "      8        \u001b[36m0.0469\u001b[0m  8.5788\n",
      "      9        0.0500  8.5856\n",
      "     10        0.0507  8.5980\n",
      "     11        0.0505  8.6217\n",
      "     12        \u001b[36m0.0468\u001b[0m  8.5756\n",
      "     13        \u001b[36m0.0412\u001b[0m  8.5844\n",
      "     14        0.0486  8.5773\n",
      "     15        0.0416  8.5991\n",
      "     16        0.0494  8.5843\n",
      "     17        0.0473  8.6022\n",
      "     18        0.0424  8.5992\n",
      "     19        0.0444  8.5916\n",
      "     20        \u001b[36m0.0401\u001b[0m  8.6029\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7473\u001b[0m  8.9263\n",
      "      2        \u001b[36m0.0515\u001b[0m  8.9431\n",
      "      3        0.0525  8.9318\n",
      "      4        0.0541  9.0847\n",
      "      5        0.0592  9.1246\n",
      "      6        0.0561  8.9187\n",
      "      7        0.0537  9.0421\n",
      "      8        \u001b[36m0.0485\u001b[0m  9.1178\n",
      "      9        0.0532  8.9703\n",
      "     10        0.0503  8.9682\n",
      "     11        0.0515  9.0816\n",
      "     12        0.0506  8.9019\n",
      "     13        \u001b[36m0.0473\u001b[0m  9.0102\n",
      "     14        \u001b[36m0.0459\u001b[0m  9.1246\n",
      "     15        0.0519  9.1771\n",
      "     16        0.0487  8.9237\n",
      "     17        0.0523  9.0215\n",
      "     18        \u001b[36m0.0446\u001b[0m  9.1439\n",
      "     19        0.0454  9.1902\n",
      "     20        0.0496  8.9127\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7177\u001b[0m  8.8993\n",
      "      2        \u001b[36m0.0465\u001b[0m  9.1566\n",
      "      3        \u001b[36m0.0456\u001b[0m  9.0446\n",
      "      4        0.0533  9.0548\n",
      "      5        0.0547  8.9435\n",
      "      6        0.0502  8.9404\n",
      "      7        0.0534  9.1849\n",
      "      8        \u001b[36m0.0419\u001b[0m  9.0393\n",
      "      9        0.0455  8.9947\n",
      "     10        0.0489  8.9614\n",
      "     11        0.0435  9.1340\n",
      "     12        0.0456  8.9647\n",
      "     13        0.0531  8.9814\n",
      "     14        0.0445  8.9186\n",
      "     15        0.0482  9.0134\n",
      "     16        \u001b[36m0.0364\u001b[0m  9.0685\n",
      "     17        0.0422  8.9733\n",
      "     18        0.0434  8.9601\n",
      "     19        0.0399  8.9100\n",
      "     20        0.0436  8.9008\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7897\u001b[0m  8.9283\n",
      "      2        \u001b[36m0.0499\u001b[0m  8.9431\n",
      "      3        0.0538  8.9536\n",
      "      4        0.0586  8.9879\n",
      "      5        0.0585  8.9342\n",
      "      6        0.0535  8.9916\n",
      "      7        0.0520  8.9189\n",
      "      8        0.0538  8.9006\n",
      "      9        0.0509  8.8937\n",
      "     10        0.0559  8.9087\n",
      "     11        \u001b[36m0.0484\u001b[0m  8.9587\n",
      "     12        0.0506  8.9563\n",
      "     13        0.0497  8.8848\n",
      "     14        \u001b[36m0.0482\u001b[0m  9.0067\n",
      "     15        \u001b[36m0.0469\u001b[0m  8.9045\n",
      "     16        \u001b[36m0.0460\u001b[0m  9.0102\n",
      "     17        0.0489  8.9743\n",
      "     18        0.0473  8.9218\n",
      "     19        0.0476  8.9264\n",
      "     20        \u001b[36m0.0375\u001b[0m  8.8926\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7793\u001b[0m  8.9837\n",
      "      2        \u001b[36m0.0493\u001b[0m  8.9209\n",
      "      3        0.0494  8.9248\n",
      "      4        0.0501  8.9622\n",
      "      5        0.0544  8.9525\n",
      "      6        0.0523  8.9243\n",
      "      7        0.0505  8.9218\n",
      "      8        0.0497  8.9108\n",
      "      9        0.0551  9.0131\n",
      "     10        0.0500  9.0366\n",
      "     11        \u001b[36m0.0469\u001b[0m  8.9808\n",
      "     12        0.0521  8.9648\n",
      "     13        0.0553  8.8901\n",
      "     14        0.0505  9.0103\n",
      "     15        0.0504  8.9716\n",
      "     16        \u001b[36m0.0426\u001b[0m  8.9582\n",
      "     17        0.0482  8.9386\n",
      "     18        0.0469  8.9935\n",
      "     19        0.0429  8.9973\n",
      "     20        \u001b[36m0.0422\u001b[0m  8.9443\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.4678\u001b[0m  8.9917\n",
      "      2        \u001b[36m0.0673\u001b[0m  9.0746\n",
      "      3        \u001b[36m0.0501\u001b[0m  9.0427\n",
      "      4        \u001b[36m0.0494\u001b[0m  9.1011\n",
      "      5        0.0531  9.0762\n",
      "      6        0.0565  9.0450\n",
      "      7        0.0669  8.9687\n",
      "      8        0.0529  8.9885\n",
      "      9        0.0533  8.9824\n",
      "     10        0.0543  8.9913\n",
      "     11        0.0513  9.0847\n",
      "     12        0.0566  8.9989\n",
      "     13        \u001b[36m0.0493\u001b[0m  9.0742\n",
      "     14        0.0567  9.0759\n",
      "     15        0.0495  9.0665\n",
      "     16        \u001b[36m0.0466\u001b[0m  9.0774\n",
      "     17        \u001b[36m0.0458\u001b[0m  9.0257\n",
      "     18        0.0478  8.9978\n",
      "     19        0.0487  9.0091\n",
      "     20        0.0497  9.0248\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3253\u001b[0m  9.0544\n",
      "      2        \u001b[36m0.0614\u001b[0m  9.0629\n",
      "      3        \u001b[36m0.0483\u001b[0m  9.0295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        0.0515  9.0375\n",
      "      5        0.0596  8.9624\n",
      "      6        0.0634  9.0480\n",
      "      7        0.0572  9.0705\n",
      "      8        0.0539  9.0167\n",
      "      9        0.0556  9.0010\n",
      "     10        0.0591  9.0962\n",
      "     11        0.0554  8.9959\n",
      "     12        \u001b[36m0.0478\u001b[0m  9.0259\n",
      "     13        0.0572  9.0028\n",
      "     14        0.0516  9.0293\n",
      "     15        0.0514  9.0284\n",
      "     16        0.0522  9.0247\n",
      "     17        0.0622  8.9960\n",
      "     18        0.0596  9.0560\n",
      "     19        0.0583  9.0148\n",
      "     20        0.0576  9.0286\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.8707\u001b[0m  9.0413\n",
      "      2        \u001b[36m0.0539\u001b[0m  8.9792\n",
      "      3        \u001b[36m0.0411\u001b[0m  9.0257\n",
      "      4        0.0476  9.0491\n",
      "      5        0.0534  8.9687\n",
      "      6        0.0569  8.9634\n",
      "      7        0.0571  9.0246\n",
      "      8        0.0591  8.9773\n",
      "      9        0.0590  9.0924\n",
      "     10        0.0582  8.9883\n",
      "     11        0.0508  8.9993\n",
      "     12        0.0539  8.9589\n",
      "     13        0.0608  9.0162\n",
      "     14        0.0539  8.9791\n",
      "     15        0.0499  8.9781\n",
      "     16        0.0547  9.0561\n",
      "     17        0.0553  9.0104\n",
      "     18        0.0498  8.9825\n",
      "     19        0.0496  8.9782\n",
      "     20        0.0475  9.0130\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.6041\u001b[0m  9.0452\n",
      "      2        \u001b[36m0.0651\u001b[0m  9.0423\n",
      "      3        \u001b[36m0.0487\u001b[0m  9.0093\n",
      "      4        0.0514  9.0578\n",
      "      5        0.0595  9.0128\n",
      "      6        0.0587  9.0179\n",
      "      7        0.0608  9.0014\n",
      "      8        0.0579  9.0227\n",
      "      9        0.0552  9.0795\n",
      "     10        0.0549  9.0505\n",
      "     11        0.0614  9.0372\n",
      "     12        0.0599  9.0016\n",
      "     13        0.0530  9.0414\n",
      "     14        0.0524  9.0723\n",
      "     15        0.0605  9.0490\n",
      "     16        0.0587  9.0629\n",
      "     17        0.0527  9.0380\n",
      "     18        0.0538  9.0610\n",
      "     19        0.0509  9.0008\n",
      "     20        0.0508  9.0267\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1175\u001b[0m  9.0043\n",
      "      2        \u001b[36m0.0614\u001b[0m  9.1608\n",
      "      3        \u001b[36m0.0463\u001b[0m  9.0547\n",
      "      4        0.0472  9.0107\n",
      "      5        0.0543  9.0276\n",
      "      6        0.0525  9.0760\n",
      "      7        0.0525  9.0776\n",
      "      8        0.0526  8.9938\n",
      "      9        0.0579  9.1028\n",
      "     10        0.0541  9.0054\n",
      "     11        0.0568  9.0147\n",
      "     12        0.0514  9.0986\n",
      "     13        0.0605  9.0240\n",
      "     14        0.0566  9.0808\n",
      "     15        0.0533  9.0180\n",
      "     16        0.0558  9.0723\n",
      "     17        0.0540  9.0194\n",
      "     18        0.0468  9.0555\n",
      "     19        0.0542  9.0492\n",
      "     20        0.0585  9.0455\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 3.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2814\u001b[0m  7.7240\n",
      "      2        \u001b[36m0.0639\u001b[0m  7.7136\n",
      "      3        \u001b[36m0.0471\u001b[0m  7.7213\n",
      "      4        \u001b[36m0.0395\u001b[0m  7.7227\n",
      "      5        \u001b[36m0.0369\u001b[0m  7.7856\n",
      "      6        \u001b[36m0.0358\u001b[0m  7.7309\n",
      "      7        \u001b[36m0.0331\u001b[0m  7.6939\n",
      "      8        0.0334  7.6988\n",
      "      9        0.0334  7.7206\n",
      "     10        0.0333  7.7546\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4753\u001b[0m  7.7105\n",
      "      2        \u001b[36m0.0682\u001b[0m  7.8276\n",
      "      3        \u001b[36m0.0505\u001b[0m  7.7011\n",
      "      4        \u001b[36m0.0416\u001b[0m  7.6863\n",
      "      5        \u001b[36m0.0372\u001b[0m  7.7057\n",
      "      6        \u001b[36m0.0346\u001b[0m  7.6871\n",
      "      7        \u001b[36m0.0333\u001b[0m  7.6986\n",
      "      8        0.0343  7.6990\n",
      "      9        0.0356  7.7798\n",
      "     10        \u001b[36m0.0322\u001b[0m  7.8050\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4231\u001b[0m  7.6884\n",
      "      2        \u001b[36m0.0622\u001b[0m  7.6901\n",
      "      3        \u001b[36m0.0426\u001b[0m  7.8274\n",
      "      4        \u001b[36m0.0383\u001b[0m  7.7110\n",
      "      5        \u001b[36m0.0337\u001b[0m  7.7419\n",
      "      6        \u001b[36m0.0306\u001b[0m  7.7437\n",
      "      7        0.0319  7.6980\n",
      "      8        \u001b[36m0.0306\u001b[0m  7.7987\n",
      "      9        \u001b[36m0.0290\u001b[0m  7.8376\n",
      "     10        \u001b[36m0.0282\u001b[0m  7.8388\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4052\u001b[0m  7.6967\n",
      "      2        \u001b[36m0.0646\u001b[0m  7.6850\n",
      "      3        \u001b[36m0.0478\u001b[0m  7.8365\n",
      "      4        \u001b[36m0.0396\u001b[0m  7.8261\n",
      "      5        \u001b[36m0.0364\u001b[0m  7.7481\n",
      "      6        \u001b[36m0.0343\u001b[0m  7.6765\n",
      "      7        0.0348  7.6786\n",
      "      8        \u001b[36m0.0319\u001b[0m  7.6926\n",
      "      9        0.0321  7.6958\n",
      "     10        0.0321  7.6948\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3345\u001b[0m  7.6971\n",
      "      2        \u001b[36m0.0608\u001b[0m  7.6809\n",
      "      3        \u001b[36m0.0430\u001b[0m  7.6761\n",
      "      4        \u001b[36m0.0382\u001b[0m  7.6837\n",
      "      5        \u001b[36m0.0331\u001b[0m  7.6938\n",
      "      6        \u001b[36m0.0330\u001b[0m  7.6978\n",
      "      7        \u001b[36m0.0322\u001b[0m  7.7021\n",
      "      8        0.0325  7.7369\n",
      "      9        \u001b[36m0.0311\u001b[0m  7.7672\n",
      "     10        \u001b[36m0.0295\u001b[0m  7.6852\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2961\u001b[0m  7.8406\n",
      "      2        \u001b[36m0.0738\u001b[0m  7.9156\n",
      "      3        \u001b[36m0.0509\u001b[0m  7.8879\n",
      "      4        \u001b[36m0.0431\u001b[0m  7.8700\n",
      "      5        \u001b[36m0.0395\u001b[0m  7.9197\n",
      "      6        \u001b[36m0.0353\u001b[0m  7.9960\n",
      "      7        0.0368  8.0133\n",
      "      8        0.0363  7.9986\n",
      "      9        \u001b[36m0.0326\u001b[0m  7.9251\n",
      "     10        \u001b[36m0.0317\u001b[0m  7.9294\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5075\u001b[0m  7.9541\n",
      "      2        \u001b[36m0.0780\u001b[0m  7.9452\n",
      "      3        \u001b[36m0.0541\u001b[0m  7.9323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.0436\u001b[0m  7.9377\n",
      "      5        \u001b[36m0.0381\u001b[0m  7.8681\n",
      "      6        \u001b[36m0.0359\u001b[0m  7.8506\n",
      "      7        0.0364  7.8395\n",
      "      8        0.0394  7.8600\n",
      "      9        0.0363  7.8453\n",
      "     10        \u001b[36m0.0318\u001b[0m  7.9808\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0522\u001b[0m  7.9268\n",
      "      2        \u001b[36m0.0652\u001b[0m  7.8654\n",
      "      3        \u001b[36m0.0449\u001b[0m  7.8454\n",
      "      4        \u001b[36m0.0384\u001b[0m  7.8903\n",
      "      5        \u001b[36m0.0327\u001b[0m  7.9082\n",
      "      6        \u001b[36m0.0322\u001b[0m  7.8539\n",
      "      7        \u001b[36m0.0309\u001b[0m  7.8425\n",
      "      8        0.0324  7.8510\n",
      "      9        0.0330  7.8688\n",
      "     10        0.0322  7.8437\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8795\u001b[0m  7.8476\n",
      "      2        \u001b[36m0.0705\u001b[0m  7.8238\n",
      "      3        \u001b[36m0.0483\u001b[0m  7.9708\n",
      "      4        \u001b[36m0.0416\u001b[0m  7.8415\n",
      "      5        \u001b[36m0.0380\u001b[0m  7.8472\n",
      "      6        \u001b[36m0.0372\u001b[0m  7.8732\n",
      "      7        0.0379  7.9077\n",
      "      8        \u001b[36m0.0344\u001b[0m  7.8192\n",
      "      9        0.0355  7.8406\n",
      "     10        0.0362  7.9045\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7539\u001b[0m  7.8351\n",
      "      2        \u001b[36m0.0623\u001b[0m  7.8328\n",
      "      3        \u001b[36m0.0433\u001b[0m  7.8339\n",
      "      4        \u001b[36m0.0351\u001b[0m  7.8437\n",
      "      5        \u001b[36m0.0326\u001b[0m  7.8269\n",
      "      6        0.0344  7.8355\n",
      "      7        0.0331  7.8312\n",
      "      8        \u001b[36m0.0308\u001b[0m  7.8321\n",
      "      9        \u001b[36m0.0298\u001b[0m  7.8475\n",
      "     10        0.0342  7.8484\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2189\u001b[0m  7.9122\n",
      "      2        \u001b[36m0.0382\u001b[0m  7.8811\n",
      "      3        \u001b[36m0.0260\u001b[0m  7.8776\n",
      "      4        \u001b[36m0.0240\u001b[0m  7.8746\n",
      "      5        \u001b[36m0.0226\u001b[0m  7.8806\n",
      "      6        0.0233  7.8716\n",
      "      7        \u001b[36m0.0216\u001b[0m  7.8812\n",
      "      8        0.0230  7.8787\n",
      "      9        \u001b[36m0.0206\u001b[0m  7.8877\n",
      "     10        0.0241  7.8771\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9475\u001b[0m  7.8823\n",
      "      2        \u001b[36m0.0366\u001b[0m  7.8763\n",
      "      3        \u001b[36m0.0264\u001b[0m  7.8837\n",
      "      4        \u001b[36m0.0223\u001b[0m  7.8751\n",
      "      5        0.0230  7.8873\n",
      "      6        0.0254  7.9200\n",
      "      7        0.0227  7.9001\n",
      "      8        0.0238  7.9292\n",
      "      9        \u001b[36m0.0210\u001b[0m  7.8955\n",
      "     10        0.0235  7.8706\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1712\u001b[0m  7.8736\n",
      "      2        \u001b[36m0.0337\u001b[0m  7.8787\n",
      "      3        \u001b[36m0.0206\u001b[0m  7.9440\n",
      "      4        \u001b[36m0.0192\u001b[0m  7.9182\n",
      "      5        \u001b[36m0.0182\u001b[0m  7.8747\n",
      "      6        0.0204  7.8994\n",
      "      7        0.0198  7.8710\n",
      "      8        0.0205  7.9974\n",
      "      9        0.0203  7.8926\n",
      "     10        0.0193  7.8816\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4902\u001b[0m  7.9315\n",
      "      2        \u001b[36m0.0425\u001b[0m  7.8779\n",
      "      3        \u001b[36m0.0271\u001b[0m  7.8796\n",
      "      4        \u001b[36m0.0234\u001b[0m  7.8783\n",
      "      5        \u001b[36m0.0233\u001b[0m  7.8810\n",
      "      6        0.0236  7.8835\n",
      "      7        \u001b[36m0.0210\u001b[0m  7.8872\n",
      "      8        0.0223  7.8948\n",
      "      9        0.0239  7.8980\n",
      "     10        0.0237  7.8871\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3584\u001b[0m  7.8742\n",
      "      2        \u001b[36m0.0353\u001b[0m  7.8788\n",
      "      3        \u001b[36m0.0236\u001b[0m  7.8739\n",
      "      4        \u001b[36m0.0205\u001b[0m  7.8775\n",
      "      5        \u001b[36m0.0188\u001b[0m  7.8712\n",
      "      6        0.0205  7.9343\n",
      "      7        0.0188  7.8826\n",
      "      8        0.0189  7.8768\n",
      "      9        0.0190  7.8757\n",
      "     10        0.0246  7.8765\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.2352\u001b[0m  8.0235\n",
      "      2        \u001b[36m0.0502\u001b[0m  8.0181\n",
      "      3        \u001b[36m0.0315\u001b[0m  8.0234\n",
      "      4        \u001b[36m0.0259\u001b[0m  8.0321\n",
      "      5        \u001b[36m0.0218\u001b[0m  8.0301\n",
      "      6        0.0226  8.0154\n",
      "      7        \u001b[36m0.0211\u001b[0m  8.0167\n",
      "      8        0.0231  8.0202\n",
      "      9        0.0241  8.0293\n",
      "     10        0.0241  8.0058\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.2981\u001b[0m  8.0506\n",
      "      2        \u001b[36m0.0470\u001b[0m  8.0094\n",
      "      3        \u001b[36m0.0303\u001b[0m  8.0144\n",
      "      4        \u001b[36m0.0247\u001b[0m  8.0153\n",
      "      5        \u001b[36m0.0226\u001b[0m  8.0248\n",
      "      6        \u001b[36m0.0210\u001b[0m  8.0590\n",
      "      7        0.0224  8.0282\n",
      "      8        0.0241  8.0816\n",
      "      9        0.0231  8.0806\n",
      "     10        0.0241  8.0285\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.0555\u001b[0m  7.9958\n",
      "      2        \u001b[36m0.0433\u001b[0m  8.0693\n",
      "      3        \u001b[36m0.0264\u001b[0m  8.0800\n",
      "      4        \u001b[36m0.0202\u001b[0m  8.1416\n",
      "      5        \u001b[36m0.0187\u001b[0m  8.0456\n",
      "      6        \u001b[36m0.0179\u001b[0m  8.0415\n",
      "      7        0.0183  8.0167\n",
      "      8        0.0182  8.0209\n",
      "      9        0.0211  8.0157\n",
      "     10        0.0205  8.0229\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.7319\u001b[0m  8.0245\n",
      "      2        \u001b[36m0.0479\u001b[0m  8.0112\n",
      "      3        \u001b[36m0.0305\u001b[0m  8.0392\n",
      "      4        \u001b[36m0.0255\u001b[0m  8.0169\n",
      "      5        \u001b[36m0.0243\u001b[0m  8.0274\n",
      "      6        \u001b[36m0.0209\u001b[0m  8.0208\n",
      "      7        0.0220  8.0242\n",
      "      8        0.0239  8.0155\n",
      "      9        0.0232  8.0241\n",
      "     10        0.0230  8.0649\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.4281\u001b[0m  8.0934\n",
      "      2        \u001b[36m0.0423\u001b[0m  8.0214\n",
      "      3        \u001b[36m0.0272\u001b[0m  8.0140\n",
      "      4        \u001b[36m0.0189\u001b[0m  8.0238\n",
      "      5        0.0205  8.0174\n",
      "      6        0.0201  8.0228\n",
      "      7        0.0192  8.0025\n",
      "      8        0.0214  8.0297\n",
      "      9        \u001b[36m0.0183\u001b[0m  8.0195\n",
      "     10        0.0218  8.0215\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3662\u001b[0m  7.6803\n",
      "      2        \u001b[36m0.0761\u001b[0m  7.6722\n",
      "      3        \u001b[36m0.0572\u001b[0m  7.6923\n",
      "      4        \u001b[36m0.0523\u001b[0m  7.6751\n",
      "      5        \u001b[36m0.0482\u001b[0m  7.7543\n",
      "      6        \u001b[36m0.0447\u001b[0m  7.6713\n",
      "      7        0.0449  7.6635\n",
      "      8        0.0461  7.6653\n",
      "      9        \u001b[36m0.0434\u001b[0m  7.6648\n",
      "     10        \u001b[36m0.0429\u001b[0m  7.6627\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3973\u001b[0m  7.6679\n",
      "      2        \u001b[36m0.0786\u001b[0m  7.6551\n",
      "      3        \u001b[36m0.0614\u001b[0m  7.6960\n",
      "      4        \u001b[36m0.0505\u001b[0m  7.6662\n",
      "      5        \u001b[36m0.0497\u001b[0m  7.6781\n",
      "      6        \u001b[36m0.0481\u001b[0m  7.6580\n",
      "      7        \u001b[36m0.0464\u001b[0m  7.6706\n",
      "      8        \u001b[36m0.0437\u001b[0m  7.6624\n",
      "      9        0.0457  7.6697\n",
      "     10        0.0442  7.6849\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3704\u001b[0m  7.6878\n",
      "      2        \u001b[36m0.0742\u001b[0m  7.6925\n",
      "      3        \u001b[36m0.0537\u001b[0m  7.6808\n",
      "      4        \u001b[36m0.0471\u001b[0m  7.6895\n",
      "      5        \u001b[36m0.0430\u001b[0m  7.6759\n",
      "      6        \u001b[36m0.0407\u001b[0m  7.6745\n",
      "      7        0.0440  7.7132\n",
      "      8        0.0410  7.7240\n",
      "      9        0.0409  7.7635\n",
      "     10        \u001b[36m0.0365\u001b[0m  7.6806\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3399\u001b[0m  7.6778\n",
      "      2        \u001b[36m0.0735\u001b[0m  7.7376\n",
      "      3        \u001b[36m0.0567\u001b[0m  7.6963\n",
      "      4        \u001b[36m0.0508\u001b[0m  7.7314\n",
      "      5        0.0509  7.7682\n",
      "      6        \u001b[36m0.0469\u001b[0m  7.7691\n",
      "      7        \u001b[36m0.0464\u001b[0m  7.7610\n",
      "      8        \u001b[36m0.0447\u001b[0m  7.8042\n",
      "      9        0.0448  7.7581\n",
      "     10        \u001b[36m0.0438\u001b[0m  7.6917\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3115\u001b[0m  7.7269\n",
      "      2        \u001b[36m0.0680\u001b[0m  7.7106\n",
      "      3        \u001b[36m0.0557\u001b[0m  7.6921\n",
      "      4        \u001b[36m0.0493\u001b[0m  7.8053\n",
      "      5        \u001b[36m0.0474\u001b[0m  7.7757\n",
      "      6        \u001b[36m0.0450\u001b[0m  7.7010\n",
      "      7        \u001b[36m0.0433\u001b[0m  7.7002\n",
      "      8        \u001b[36m0.0431\u001b[0m  7.6992\n",
      "      9        \u001b[36m0.0404\u001b[0m  7.8215\n",
      "     10        0.0415  7.8714\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5219\u001b[0m  7.9387\n",
      "      2        \u001b[36m0.0887\u001b[0m  7.8415\n",
      "      3        \u001b[36m0.0664\u001b[0m  7.9322\n",
      "      4        \u001b[36m0.0525\u001b[0m  7.8432\n",
      "      5        \u001b[36m0.0494\u001b[0m  7.8323\n",
      "      6        \u001b[36m0.0475\u001b[0m  7.8306\n",
      "      7        \u001b[36m0.0474\u001b[0m  7.8391\n",
      "      8        \u001b[36m0.0463\u001b[0m  7.8998\n",
      "      9        \u001b[36m0.0460\u001b[0m  7.8809\n",
      "     10        \u001b[36m0.0457\u001b[0m  7.8638\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4379\u001b[0m  7.8389\n",
      "      2        \u001b[36m0.0887\u001b[0m  7.9472\n",
      "      3        \u001b[36m0.0629\u001b[0m  7.8432\n",
      "      4        \u001b[36m0.0510\u001b[0m  7.8443\n",
      "      5        \u001b[36m0.0508\u001b[0m  7.8513\n",
      "      6        \u001b[36m0.0462\u001b[0m  7.9801\n",
      "      7        0.0496  7.8967\n",
      "      8        0.0472  7.8298\n",
      "      9        0.0465  7.9432\n",
      "     10        0.0483  7.8628\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2533\u001b[0m  7.8298\n",
      "      2        \u001b[36m0.0772\u001b[0m  7.8374\n",
      "      3        \u001b[36m0.0557\u001b[0m  7.8246\n",
      "      4        \u001b[36m0.0463\u001b[0m  7.8368\n",
      "      5        \u001b[36m0.0457\u001b[0m  7.8447\n",
      "      6        \u001b[36m0.0427\u001b[0m  7.8355\n",
      "      7        \u001b[36m0.0414\u001b[0m  7.8288\n",
      "      8        0.0447  7.8336\n",
      "      9        \u001b[36m0.0413\u001b[0m  7.8388\n",
      "     10        0.0415  7.8330\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5562\u001b[0m  7.8703\n",
      "      2        \u001b[36m0.0903\u001b[0m  7.8467\n",
      "      3        \u001b[36m0.0655\u001b[0m  7.8453\n",
      "      4        \u001b[36m0.0547\u001b[0m  7.8287\n",
      "      5        \u001b[36m0.0491\u001b[0m  7.8332\n",
      "      6        \u001b[36m0.0483\u001b[0m  7.8275\n",
      "      7        \u001b[36m0.0465\u001b[0m  7.8484\n",
      "      8        0.0482  7.8269\n",
      "      9        0.0470  7.8460\n",
      "     10        \u001b[36m0.0450\u001b[0m  7.8346\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9754\u001b[0m  7.8290\n",
      "      2        \u001b[36m0.0833\u001b[0m  7.8437\n",
      "      3        \u001b[36m0.0564\u001b[0m  7.8366\n",
      "      4        \u001b[36m0.0487\u001b[0m  7.8415\n",
      "      5        \u001b[36m0.0459\u001b[0m  7.8266\n",
      "      6        \u001b[36m0.0441\u001b[0m  7.8749\n",
      "      7        \u001b[36m0.0440\u001b[0m  7.8297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        0.0452  7.8487\n",
      "      9        \u001b[36m0.0424\u001b[0m  7.8346\n",
      "     10        0.0454  7.8348\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9797\u001b[0m  7.8721\n",
      "      2        \u001b[36m0.0433\u001b[0m  7.8578\n",
      "      3        \u001b[36m0.0312\u001b[0m  7.8675\n",
      "      4        \u001b[36m0.0277\u001b[0m  7.8691\n",
      "      5        0.0278  7.8691\n",
      "      6        \u001b[36m0.0275\u001b[0m  7.8577\n",
      "      7        0.0299  7.8711\n",
      "      8        \u001b[36m0.0264\u001b[0m  7.8602\n",
      "      9        \u001b[36m0.0238\u001b[0m  7.8716\n",
      "     10        0.0261  7.8632\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1878\u001b[0m  7.9143\n",
      "      2        \u001b[36m0.0434\u001b[0m  7.8779\n",
      "      3        \u001b[36m0.0313\u001b[0m  7.8848\n",
      "      4        \u001b[36m0.0276\u001b[0m  7.8717\n",
      "      5        \u001b[36m0.0257\u001b[0m  7.8814\n",
      "      6        0.0281  7.8745\n",
      "      7        0.0282  7.8901\n",
      "      8        0.0258  7.8770\n",
      "      9        0.0283  7.8980\n",
      "     10        0.0294  7.8834\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1313\u001b[0m  7.8713\n",
      "      2        \u001b[36m0.0389\u001b[0m  7.8814\n",
      "      3        \u001b[36m0.0266\u001b[0m  7.8701\n",
      "      4        \u001b[36m0.0228\u001b[0m  7.8814\n",
      "      5        \u001b[36m0.0226\u001b[0m  7.9249\n",
      "      6        0.0230  7.9681\n",
      "      7        \u001b[36m0.0211\u001b[0m  7.9364\n",
      "      8        0.0247  7.9906\n",
      "      9        0.0279  7.8851\n",
      "     10        0.0284  7.8952\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0496\u001b[0m  7.8891\n",
      "      2        \u001b[36m0.0427\u001b[0m  8.0058\n",
      "      3        \u001b[36m0.0308\u001b[0m  7.9968\n",
      "      4        \u001b[36m0.0277\u001b[0m  7.9305\n",
      "      5        0.0299  7.9490\n",
      "      6        0.0283  8.0103\n",
      "      7        0.0288  8.0445\n",
      "      8        0.0303  7.9010\n",
      "      9        0.0314  7.9537\n",
      "     10        0.0289  7.9307\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5390\u001b[0m  7.9495\n",
      "      2        \u001b[36m0.0415\u001b[0m  7.8879\n",
      "      3        \u001b[36m0.0290\u001b[0m  7.8716\n",
      "      4        \u001b[36m0.0235\u001b[0m  7.9302\n",
      "      5        0.0236  7.9203\n",
      "      6        \u001b[36m0.0231\u001b[0m  7.8834\n",
      "      7        0.0233  7.8732\n",
      "      8        0.0269  7.8787\n",
      "      9        0.0254  7.8799\n",
      "     10        0.0269  7.8876\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4237\u001b[0m  8.0121\n",
      "      2        \u001b[36m0.0582\u001b[0m  8.0091\n",
      "      3        \u001b[36m0.0365\u001b[0m  8.0112\n",
      "      4        \u001b[36m0.0286\u001b[0m  8.0747\n",
      "      5        \u001b[36m0.0248\u001b[0m  8.0195\n",
      "      6        0.0254  8.0579\n",
      "      7        0.0270  8.0978\n",
      "      8        0.0274  8.0381\n",
      "      9        0.0261  8.0110\n",
      "     10        0.0336  8.0055\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.8621\u001b[0m  8.0029\n",
      "      2        \u001b[36m0.0603\u001b[0m  7.9942\n",
      "      3        \u001b[36m0.0401\u001b[0m  8.0171\n",
      "      4        \u001b[36m0.0305\u001b[0m  8.0390\n",
      "      5        \u001b[36m0.0264\u001b[0m  8.0290\n",
      "      6        \u001b[36m0.0258\u001b[0m  8.0172\n",
      "      7        0.0266  8.0203\n",
      "      8        0.0282  8.0156\n",
      "      9        0.0312  8.0193\n",
      "     10        0.0308  8.0224\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.4239\u001b[0m  8.0701\n",
      "      2        \u001b[36m0.0546\u001b[0m  8.0203\n",
      "      3        \u001b[36m0.0330\u001b[0m  8.0192\n",
      "      4        \u001b[36m0.0252\u001b[0m  8.0253\n",
      "      5        \u001b[36m0.0234\u001b[0m  8.0165\n",
      "      6        \u001b[36m0.0224\u001b[0m  8.0245\n",
      "      7        \u001b[36m0.0219\u001b[0m  8.0147\n",
      "      8        0.0249  8.0249\n",
      "      9        0.0313  8.0307\n",
      "     10        0.0299  8.0249\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.3131\u001b[0m  8.0306\n",
      "      2        \u001b[36m0.0560\u001b[0m  7.9939\n",
      "      3        \u001b[36m0.0361\u001b[0m  8.0194\n",
      "      4        \u001b[36m0.0282\u001b[0m  8.0168\n",
      "      5        \u001b[36m0.0261\u001b[0m  8.0185\n",
      "      6        \u001b[36m0.0250\u001b[0m  8.0455\n",
      "      7        \u001b[36m0.0248\u001b[0m  8.0087\n",
      "      8        0.0280  7.9969\n",
      "      9        0.0314  8.0089\n",
      "     10        0.0300  8.0134\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.3421\u001b[0m  8.0275\n",
      "      2        \u001b[36m0.0496\u001b[0m  8.0275\n",
      "      3        \u001b[36m0.0308\u001b[0m  8.0395\n",
      "      4        \u001b[36m0.0240\u001b[0m  8.0251\n",
      "      5        \u001b[36m0.0219\u001b[0m  8.0090\n",
      "      6        0.0220  8.0213\n",
      "      7        0.0230  8.0182\n",
      "      8        0.0286  8.0093\n",
      "      9        0.0279  8.0030\n",
      "     10        0.0274  8.0363\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3522\u001b[0m  7.7109\n",
      "      2        \u001b[36m0.0918\u001b[0m  7.6845\n",
      "      3        \u001b[36m0.0741\u001b[0m  7.6765\n",
      "      4        \u001b[36m0.0661\u001b[0m  7.6711\n",
      "      5        0.0694  7.6825\n",
      "      6        \u001b[36m0.0649\u001b[0m  7.6685\n",
      "      7        \u001b[36m0.0628\u001b[0m  7.6871\n",
      "      8        0.0635  7.7067\n",
      "      9        \u001b[36m0.0613\u001b[0m  7.7012\n",
      "     10        \u001b[36m0.0567\u001b[0m  7.6724\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4075\u001b[0m  7.6909\n",
      "      2        \u001b[36m0.0988\u001b[0m  7.6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m0.0792\u001b[0m  7.6818\n",
      "      4        \u001b[36m0.0704\u001b[0m  7.6747\n",
      "      5        \u001b[36m0.0673\u001b[0m  7.6877\n",
      "      6        \u001b[36m0.0670\u001b[0m  7.7318\n",
      "      7        \u001b[36m0.0643\u001b[0m  7.6969\n",
      "      8        \u001b[36m0.0626\u001b[0m  7.6755\n",
      "      9        \u001b[36m0.0613\u001b[0m  7.6815\n",
      "     10        \u001b[36m0.0601\u001b[0m  7.6737\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3980\u001b[0m  7.6783\n",
      "      2        \u001b[36m0.0933\u001b[0m  7.6782\n",
      "      3        \u001b[36m0.0740\u001b[0m  7.6770\n",
      "      4        \u001b[36m0.0668\u001b[0m  7.6982\n",
      "      5        \u001b[36m0.0627\u001b[0m  7.6823\n",
      "      6        \u001b[36m0.0611\u001b[0m  7.6803\n",
      "      7        \u001b[36m0.0576\u001b[0m  7.6723\n",
      "      8        0.0603  7.6781\n",
      "      9        0.0578  7.6766\n",
      "     10        \u001b[36m0.0549\u001b[0m  7.6814\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4895\u001b[0m  7.7237\n",
      "      2        \u001b[36m0.0971\u001b[0m  7.6947\n",
      "      3        \u001b[36m0.0776\u001b[0m  7.6763\n",
      "      4        \u001b[36m0.0696\u001b[0m  7.6741\n",
      "      5        \u001b[36m0.0664\u001b[0m  7.6763\n",
      "      6        \u001b[36m0.0653\u001b[0m  7.6770\n",
      "      7        \u001b[36m0.0624\u001b[0m  7.6772\n",
      "      8        \u001b[36m0.0599\u001b[0m  7.6804\n",
      "      9        0.0616  7.8075\n",
      "     10        \u001b[36m0.0570\u001b[0m  7.7260\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3534\u001b[0m  7.8342\n",
      "      2        \u001b[36m0.0907\u001b[0m  7.7647\n",
      "      3        \u001b[36m0.0762\u001b[0m  7.6873\n",
      "      4        \u001b[36m0.0660\u001b[0m  7.6935\n",
      "      5        \u001b[36m0.0651\u001b[0m  7.6843\n",
      "      6        \u001b[36m0.0624\u001b[0m  7.7841\n",
      "      7        0.0629  7.8395\n",
      "      8        \u001b[36m0.0595\u001b[0m  7.8365\n",
      "      9        \u001b[36m0.0583\u001b[0m  7.7744\n",
      "     10        \u001b[36m0.0581\u001b[0m  7.7935\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1860\u001b[0m  8.0177\n",
      "      2        \u001b[36m0.1024\u001b[0m  8.0080\n",
      "      3        \u001b[36m0.0777\u001b[0m  7.8705\n",
      "      4        \u001b[36m0.0666\u001b[0m  7.8763\n",
      "      5        \u001b[36m0.0665\u001b[0m  7.8750\n",
      "      6        \u001b[36m0.0643\u001b[0m  7.8692\n",
      "      7        0.0671  7.8590\n",
      "      8        \u001b[36m0.0634\u001b[0m  7.8473\n",
      "      9        0.0644  7.9123\n",
      "     10        \u001b[36m0.0618\u001b[0m  7.9291\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4461\u001b[0m  7.9100\n",
      "      2        \u001b[36m0.1072\u001b[0m  7.9554\n",
      "      3        \u001b[36m0.0843\u001b[0m  7.9099\n",
      "      4        \u001b[36m0.0719\u001b[0m  7.9852\n",
      "      5        \u001b[36m0.0701\u001b[0m  7.8624\n",
      "      6        \u001b[36m0.0689\u001b[0m  7.8423\n",
      "      7        \u001b[36m0.0675\u001b[0m  7.8590\n",
      "      8        \u001b[36m0.0663\u001b[0m  7.8523\n",
      "      9        \u001b[36m0.0657\u001b[0m  7.9421\n",
      "     10        \u001b[36m0.0644\u001b[0m  7.8562\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8595\u001b[0m  7.8861\n",
      "      2        \u001b[36m0.1007\u001b[0m  7.9082\n",
      "      3        \u001b[36m0.0751\u001b[0m  7.8406\n",
      "      4        \u001b[36m0.0643\u001b[0m  7.8357\n",
      "      5        \u001b[36m0.0621\u001b[0m  7.9669\n",
      "      6        0.0637  7.8569\n",
      "      7        \u001b[36m0.0612\u001b[0m  7.8709\n",
      "      8        0.0640  7.8385\n",
      "      9        \u001b[36m0.0596\u001b[0m  7.8711\n",
      "     10        0.0604  7.8349\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8255\u001b[0m  7.8419\n",
      "      2        \u001b[36m0.1037\u001b[0m  7.8366\n",
      "      3        \u001b[36m0.0787\u001b[0m  7.9798\n",
      "      4        \u001b[36m0.0693\u001b[0m  7.8415\n",
      "      5        \u001b[36m0.0623\u001b[0m  7.8502\n",
      "      6        0.0681  7.9212\n",
      "      7        \u001b[36m0.0614\u001b[0m  8.0030\n",
      "      8        0.0638  7.8939\n",
      "      9        0.0619  7.8372\n",
      "     10        0.0621  7.8946\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8580\u001b[0m  7.8855\n",
      "      2        \u001b[36m0.1019\u001b[0m  7.9042\n",
      "      3        \u001b[36m0.0757\u001b[0m  7.8333\n",
      "      4        \u001b[36m0.0683\u001b[0m  7.8358\n",
      "      5        \u001b[36m0.0631\u001b[0m  7.8284\n",
      "      6        \u001b[36m0.0623\u001b[0m  7.8621\n",
      "      7        0.0641  7.8386\n",
      "      8        0.0657  7.8366\n",
      "      9        0.0666  7.8511\n",
      "     10        0.0625  7.8641\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0440\u001b[0m  7.8835\n",
      "      2        \u001b[36m0.0512\u001b[0m  7.8792\n",
      "      3        \u001b[36m0.0350\u001b[0m  7.8817\n",
      "      4        \u001b[36m0.0340\u001b[0m  7.8854\n",
      "      5        0.0356  7.8806\n",
      "      6        0.0347  7.8979\n",
      "      7        0.0361  7.9144\n",
      "      8        0.0377  7.8813\n",
      "      9        0.0365  7.8837\n",
      "     10        0.0361  7.8774\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9151\u001b[0m  7.8856\n",
      "      2        \u001b[36m0.0509\u001b[0m  7.8806\n",
      "      3        \u001b[36m0.0364\u001b[0m  7.8839\n",
      "      4        0.0370  7.8881\n",
      "      5        \u001b[36m0.0348\u001b[0m  7.9013\n",
      "      6        \u001b[36m0.0347\u001b[0m  7.8749\n",
      "      7        0.0363  7.8814\n",
      "      8        \u001b[36m0.0325\u001b[0m  7.8745\n",
      "      9        0.0336  7.8856\n",
      "     10        0.0417  7.8759\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0162\u001b[0m  7.8884\n",
      "      2        \u001b[36m0.0464\u001b[0m  7.9213\n",
      "      3        \u001b[36m0.0346\u001b[0m  7.8851\n",
      "      4        \u001b[36m0.0310\u001b[0m  7.8831\n",
      "      5        0.0310  7.8700\n",
      "      6        \u001b[36m0.0305\u001b[0m  7.8836\n",
      "      7        0.0323  7.8778\n",
      "      8        0.0323  7.8874\n",
      "      9        0.0342  7.8867\n",
      "     10        0.0327  7.8913\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3970\u001b[0m  7.8781\n",
      "      2        \u001b[36m0.0525\u001b[0m  7.8748\n",
      "      3        \u001b[36m0.0386\u001b[0m  7.8790\n",
      "      4        \u001b[36m0.0329\u001b[0m  7.8746\n",
      "      5        0.0335  7.8875\n",
      "      6        0.0369  7.8859\n",
      "      7        0.0382  7.9166\n",
      "      8        0.0358  7.8786\n",
      "      9        0.0381  7.8828\n",
      "     10        0.0374  7.8766\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.8087\u001b[0m  7.8789\n",
      "      2        \u001b[36m0.0528\u001b[0m  7.8889\n",
      "      3        \u001b[36m0.0371\u001b[0m  7.8729\n",
      "      4        \u001b[36m0.0318\u001b[0m  7.8979\n",
      "      5        \u001b[36m0.0290\u001b[0m  7.8924\n",
      "      6        0.0318  7.8822\n",
      "      7        0.0328  7.8789\n",
      "      8        0.0326  7.8823\n",
      "      9        0.0356  7.8809\n",
      "     10        0.0318  7.8803\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.1530\u001b[0m  8.0304\n",
      "      2        \u001b[36m0.0830\u001b[0m  8.0409\n",
      "      3        \u001b[36m0.0527\u001b[0m  8.0145\n",
      "      4        \u001b[36m0.0379\u001b[0m  8.0154\n",
      "      5        \u001b[36m0.0329\u001b[0m  8.0255\n",
      "      6        \u001b[36m0.0313\u001b[0m  8.0152\n",
      "      7        0.0323  8.0227\n",
      "      8        0.0340  8.0154\n",
      "      9        0.0370  8.0359\n",
      "     10        0.0377  8.0237\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.4229\u001b[0m  8.0108\n",
      "      2        \u001b[36m0.0739\u001b[0m  8.0034\n",
      "      3        \u001b[36m0.0440\u001b[0m  8.0097\n",
      "      4        \u001b[36m0.0349\u001b[0m  8.0083\n",
      "      5        \u001b[36m0.0326\u001b[0m  8.0107\n",
      "      6        \u001b[36m0.0309\u001b[0m  8.0298\n",
      "      7        0.0331  8.0391\n",
      "      8        0.0367  8.0084\n",
      "      9        0.0399  8.0111\n",
      "     10        0.0410  8.0026\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m6.0220\u001b[0m  8.0027\n",
      "      2        \u001b[36m0.0666\u001b[0m  8.0066\n",
      "      3        \u001b[36m0.0408\u001b[0m  8.0052\n",
      "      4        \u001b[36m0.0315\u001b[0m  8.0226\n",
      "      5        \u001b[36m0.0285\u001b[0m  8.0095\n",
      "      6        \u001b[36m0.0279\u001b[0m  8.0286\n",
      "      7        0.0315  8.1042\n",
      "      8        0.0326  7.9981\n",
      "      9        0.0362  8.0510\n",
      "     10        0.0339  7.9998\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.1804\u001b[0m  8.0576\n",
      "      2        \u001b[36m0.0710\u001b[0m  8.0290\n",
      "      3        \u001b[36m0.0460\u001b[0m  8.1083\n",
      "      4        \u001b[36m0.0352\u001b[0m  8.0195\n",
      "      5        \u001b[36m0.0333\u001b[0m  8.0240\n",
      "      6        0.0354  8.0667\n",
      "      7        0.0358  8.0276\n",
      "      8        0.0387  8.0989\n",
      "      9        0.0394  8.1014\n",
      "     10        0.0396  8.0241\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.5835\u001b[0m  8.0147\n",
      "      2        \u001b[36m0.0735\u001b[0m  8.1434\n",
      "      3        \u001b[36m0.0453\u001b[0m  8.1381\n",
      "      4        \u001b[36m0.0328\u001b[0m  7.9994\n",
      "      5        \u001b[36m0.0287\u001b[0m  8.0519\n",
      "      6        0.0297  8.0800\n",
      "      7        \u001b[36m0.0270\u001b[0m  8.0183\n",
      "      8        0.0345  8.0214\n",
      "      9        0.0378  8.1286\n",
      "     10        0.0356  8.0390\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4925\u001b[0m  7.6989\n",
      "      2        \u001b[36m0.0737\u001b[0m  7.7200\n",
      "      3        \u001b[36m0.0509\u001b[0m  7.7479\n",
      "      4        \u001b[36m0.0428\u001b[0m  7.7399\n",
      "      5        \u001b[36m0.0377\u001b[0m  7.7781\n",
      "      6        \u001b[36m0.0360\u001b[0m  7.6805\n",
      "      7        \u001b[36m0.0348\u001b[0m  7.6801\n",
      "      8        0.0351  7.6811\n",
      "      9        \u001b[36m0.0299\u001b[0m  7.7130\n",
      "     10        0.0315  7.6808\n",
      "     11        0.0323  7.7549\n",
      "     12        0.0323  7.7234\n",
      "     13        0.0313  7.7744\n",
      "     14        0.0302  7.8217\n",
      "     15        \u001b[36m0.0280\u001b[0m  7.7658\n",
      "     16        \u001b[36m0.0276\u001b[0m  7.8118\n",
      "     17        \u001b[36m0.0252\u001b[0m  7.7373\n",
      "     18        0.0298  7.7200\n",
      "     19        0.0273  7.7329\n",
      "     20        0.0266  7.7111\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3140\u001b[0m  7.8499\n",
      "      2        \u001b[36m0.0617\u001b[0m  7.7838\n",
      "      3        \u001b[36m0.0459\u001b[0m  7.7564\n",
      "      4        \u001b[36m0.0387\u001b[0m  7.7154\n",
      "      5        \u001b[36m0.0376\u001b[0m  7.6997\n",
      "      6        \u001b[36m0.0346\u001b[0m  7.8380\n",
      "      7        \u001b[36m0.0345\u001b[0m  7.7757\n",
      "      8        \u001b[36m0.0327\u001b[0m  7.7101\n",
      "      9        \u001b[36m0.0309\u001b[0m  7.7123\n",
      "     10        0.0315  7.7219\n",
      "     11        \u001b[36m0.0302\u001b[0m  7.7114\n",
      "     12        0.0302  7.7220\n",
      "     13        0.0313  7.7726\n",
      "     14        0.0311  7.7572\n",
      "     15        \u001b[36m0.0285\u001b[0m  7.7675\n",
      "     16        \u001b[36m0.0278\u001b[0m  7.7706\n",
      "     17        0.0296  7.8138\n",
      "     18        \u001b[36m0.0269\u001b[0m  7.7753\n",
      "     19        0.0282  7.8155\n",
      "     20        0.0291  7.7702\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3813\u001b[0m  7.7153\n",
      "      2        \u001b[36m0.0594\u001b[0m  7.7882\n",
      "      3        \u001b[36m0.0428\u001b[0m  7.7666\n",
      "      4        \u001b[36m0.0361\u001b[0m  7.6871\n",
      "      5        \u001b[36m0.0315\u001b[0m  7.7472\n",
      "      6        0.0319  7.7201\n",
      "      7        0.0329  7.6936\n",
      "      8        \u001b[36m0.0308\u001b[0m  7.6939\n",
      "      9        \u001b[36m0.0285\u001b[0m  7.6886\n",
      "     10        0.0298  7.7499\n",
      "     11        0.0292  7.6847\n",
      "     12        \u001b[36m0.0277\u001b[0m  7.6934\n",
      "     13        \u001b[36m0.0270\u001b[0m  7.7903\n",
      "     14        \u001b[36m0.0267\u001b[0m  7.7993\n",
      "     15        \u001b[36m0.0242\u001b[0m  7.7362\n",
      "     16        0.0254  7.7841\n",
      "     17        \u001b[36m0.0238\u001b[0m  7.7733\n",
      "     18        0.0249  7.7592\n",
      "     19        0.0251  7.6707\n",
      "     20        0.0246  7.7023\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4843\u001b[0m  7.7695\n",
      "      2        \u001b[36m0.0678\u001b[0m  7.6755\n",
      "      3        \u001b[36m0.0485\u001b[0m  7.6949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.0401\u001b[0m  7.6801\n",
      "      5        \u001b[36m0.0361\u001b[0m  7.6936\n",
      "      6        \u001b[36m0.0340\u001b[0m  7.6883\n",
      "      7        0.0361  7.6935\n",
      "      8        \u001b[36m0.0325\u001b[0m  7.6760\n",
      "      9        0.0342  7.6786\n",
      "     10        \u001b[36m0.0324\u001b[0m  7.6735\n",
      "     11        \u001b[36m0.0306\u001b[0m  7.6796\n",
      "     12        \u001b[36m0.0291\u001b[0m  7.6920\n",
      "     13        0.0326  7.7099\n",
      "     14        \u001b[36m0.0279\u001b[0m  7.6832\n",
      "     15        0.0300  7.6830\n",
      "     16        0.0281  7.6818\n",
      "     17        \u001b[36m0.0276\u001b[0m  7.6813\n",
      "     18        \u001b[36m0.0276\u001b[0m  7.6887\n",
      "     19        \u001b[36m0.0274\u001b[0m  7.6968\n",
      "     20        \u001b[36m0.0271\u001b[0m  7.6846\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3182\u001b[0m  7.6854\n",
      "      2        \u001b[36m0.0574\u001b[0m  7.8099\n",
      "      3        \u001b[36m0.0421\u001b[0m  7.7069\n",
      "      4        \u001b[36m0.0358\u001b[0m  7.7129\n",
      "      5        \u001b[36m0.0352\u001b[0m  7.7151\n",
      "      6        \u001b[36m0.0336\u001b[0m  7.6835\n",
      "      7        \u001b[36m0.0318\u001b[0m  7.6713\n",
      "      8        0.0329  7.7370\n",
      "      9        \u001b[36m0.0310\u001b[0m  7.7100\n",
      "     10        \u001b[36m0.0291\u001b[0m  7.7026\n",
      "     11        0.0292  7.6896\n",
      "     12        \u001b[36m0.0276\u001b[0m  7.6966\n",
      "     13        \u001b[36m0.0273\u001b[0m  7.7084\n",
      "     14        \u001b[36m0.0256\u001b[0m  7.7065\n",
      "     15        0.0271  7.6997\n",
      "     16        \u001b[36m0.0227\u001b[0m  7.7938\n",
      "     17        0.0262  7.7805\n",
      "     18        0.0243  7.7347\n",
      "     19        0.0257  7.7077\n",
      "     20        0.0252  7.7119\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0119\u001b[0m  7.8448\n",
      "      2        \u001b[36m0.0741\u001b[0m  7.8704\n",
      "      3        \u001b[36m0.0486\u001b[0m  8.0214\n",
      "      4        \u001b[36m0.0407\u001b[0m  7.8662\n",
      "      5        \u001b[36m0.0390\u001b[0m  7.8675\n",
      "      6        \u001b[36m0.0380\u001b[0m  7.8557\n",
      "      7        \u001b[36m0.0367\u001b[0m  7.9058\n",
      "      8        \u001b[36m0.0343\u001b[0m  7.8650\n",
      "      9        0.0354  7.9778\n",
      "     10        0.0356  7.8715\n",
      "     11        \u001b[36m0.0342\u001b[0m  7.9302\n",
      "     12        \u001b[36m0.0315\u001b[0m  7.9535\n",
      "     13        0.0343  7.9707\n",
      "     14        0.0326  7.8839\n",
      "     15        0.0322  8.0037\n",
      "     16        \u001b[36m0.0277\u001b[0m  7.9093\n",
      "     17        0.0303  7.8332\n",
      "     18        0.0312  7.8730\n",
      "     19        0.0315  7.9990\n",
      "     20        0.0304  7.9756\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1336\u001b[0m  7.9464\n",
      "      2        \u001b[36m0.0759\u001b[0m  7.9627\n",
      "      3        \u001b[36m0.0535\u001b[0m  7.8581\n",
      "      4        \u001b[36m0.0453\u001b[0m  7.8749\n",
      "      5        \u001b[36m0.0410\u001b[0m  7.9715\n",
      "      6        \u001b[36m0.0383\u001b[0m  7.9706\n",
      "      7        \u001b[36m0.0351\u001b[0m  7.9917\n",
      "      8        0.0369  7.9853\n",
      "      9        \u001b[36m0.0342\u001b[0m  8.0311\n",
      "     10        \u001b[36m0.0320\u001b[0m  7.9932\n",
      "     11        0.0346  8.0127\n",
      "     12        0.0321  8.0303\n",
      "     13        0.0352  7.9116\n",
      "     14        \u001b[36m0.0305\u001b[0m  7.8537\n",
      "     15        \u001b[36m0.0304\u001b[0m  7.9234\n",
      "     16        0.0308  7.8533\n",
      "     17        \u001b[36m0.0300\u001b[0m  7.9374\n",
      "     18        \u001b[36m0.0279\u001b[0m  7.8626\n",
      "     19        0.0314  7.9105\n",
      "     20        \u001b[36m0.0276\u001b[0m  7.8819\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6397\u001b[0m  7.8477\n",
      "      2        \u001b[36m0.0756\u001b[0m  7.8692\n",
      "      3        \u001b[36m0.0521\u001b[0m  8.0019\n",
      "      4        \u001b[36m0.0406\u001b[0m  7.8455\n",
      "      5        \u001b[36m0.0351\u001b[0m  7.9552\n",
      "      6        \u001b[36m0.0318\u001b[0m  7.8565\n",
      "      7        \u001b[36m0.0312\u001b[0m  7.9376\n",
      "      8        0.0325  7.9113\n",
      "      9        \u001b[36m0.0310\u001b[0m  7.8690\n",
      "     10        \u001b[36m0.0301\u001b[0m  7.9862\n",
      "     11        \u001b[36m0.0290\u001b[0m  7.9300\n",
      "     12        0.0291  7.9056\n",
      "     13        0.0298  7.9663\n",
      "     14        0.0291  7.8512\n",
      "     15        \u001b[36m0.0269\u001b[0m  7.9886\n",
      "     16        \u001b[36m0.0260\u001b[0m  7.9482\n",
      "     17        0.0270  7.9192\n",
      "     18        0.0266  7.9000\n",
      "     19        \u001b[36m0.0243\u001b[0m  7.8279\n",
      "     20        0.0267  7.9844\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9144\u001b[0m  7.8471\n",
      "      2        \u001b[36m0.0711\u001b[0m  7.9661\n",
      "      3        \u001b[36m0.0518\u001b[0m  7.9535\n",
      "      4        \u001b[36m0.0416\u001b[0m  7.9059\n",
      "      5        \u001b[36m0.0368\u001b[0m  7.9333\n",
      "      6        0.0379  8.0116\n",
      "      7        0.0374  7.8851\n",
      "      8        \u001b[36m0.0356\u001b[0m  7.8505\n",
      "      9        0.0356  7.9941\n",
      "     10        \u001b[36m0.0341\u001b[0m  7.8918\n",
      "     11        \u001b[36m0.0317\u001b[0m  7.9149\n",
      "     12        0.0320  7.8391\n",
      "     13        \u001b[36m0.0313\u001b[0m  7.8297\n",
      "     14        0.0339  7.8321\n",
      "     15        \u001b[36m0.0294\u001b[0m  7.8395\n",
      "     16        \u001b[36m0.0268\u001b[0m  7.8307\n",
      "     17        0.0304  7.9020\n",
      "     18        0.0303  7.8752\n",
      "     19        0.0288  7.9081\n",
      "     20        0.0278  7.9532\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2234\u001b[0m  8.0224\n",
      "      2        \u001b[36m0.0711\u001b[0m  7.9038\n",
      "      3        \u001b[36m0.0479\u001b[0m  7.8293\n",
      "      4        \u001b[36m0.0378\u001b[0m  7.8533\n",
      "      5        \u001b[36m0.0345\u001b[0m  7.9263\n",
      "      6        \u001b[36m0.0341\u001b[0m  7.9260\n",
      "      7        \u001b[36m0.0298\u001b[0m  7.9001\n",
      "      8        0.0320  7.8653\n",
      "      9        0.0307  7.9457\n",
      "     10        0.0325  7.8511\n",
      "     11        0.0335  7.9338\n",
      "     12        \u001b[36m0.0288\u001b[0m  7.8833\n",
      "     13        0.0312  7.9647\n",
      "     14        \u001b[36m0.0279\u001b[0m  8.0099\n",
      "     15        0.0291  7.9952\n",
      "     16        \u001b[36m0.0266\u001b[0m  7.9402\n",
      "     17        0.0282  7.8610\n",
      "     18        0.0275  7.8390\n",
      "     19        0.0270  7.8279\n",
      "     20        0.0276  7.8912\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1330\u001b[0m  7.9206\n",
      "      2        \u001b[36m0.0393\u001b[0m  7.8813\n",
      "      3        \u001b[36m0.0268\u001b[0m  7.8771\n",
      "      4        \u001b[36m0.0240\u001b[0m  7.9429\n",
      "      5        \u001b[36m0.0224\u001b[0m  7.8814\n",
      "      6        0.0234  7.8847\n",
      "      7        \u001b[36m0.0216\u001b[0m  7.8822\n",
      "      8        0.0226  7.9857\n",
      "      9        0.0217  7.9004\n",
      "     10        \u001b[36m0.0213\u001b[0m  7.8782\n",
      "     11        \u001b[36m0.0210\u001b[0m  7.8851\n",
      "     12        0.0213  7.8763\n",
      "     13        0.0225  7.8806\n",
      "     14        \u001b[36m0.0200\u001b[0m  7.8763\n",
      "     15        0.0218  7.8804\n",
      "     16        \u001b[36m0.0199\u001b[0m  7.8818\n",
      "     17        0.0209  7.8889\n",
      "     18        0.0218  7.8767\n",
      "     19        \u001b[36m0.0192\u001b[0m  7.8862\n",
      "     20        \u001b[36m0.0170\u001b[0m  7.8776\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.8625\u001b[0m  7.8819\n",
      "      2        \u001b[36m0.0433\u001b[0m  7.8746\n",
      "      3        \u001b[36m0.0289\u001b[0m  7.9028\n",
      "      4        \u001b[36m0.0249\u001b[0m  7.8986\n",
      "      5        \u001b[36m0.0244\u001b[0m  7.9609\n",
      "      6        \u001b[36m0.0233\u001b[0m  7.9881\n",
      "      7        \u001b[36m0.0228\u001b[0m  7.9114\n",
      "      8        0.0238  7.9120\n",
      "      9        0.0255  7.9161\n",
      "     10        \u001b[36m0.0207\u001b[0m  7.8871\n",
      "     11        0.0243  8.0571\n",
      "     12        0.0234  8.0271\n",
      "     13        \u001b[36m0.0206\u001b[0m  7.8980\n",
      "     14        \u001b[36m0.0197\u001b[0m  7.8859\n",
      "     15        0.0200  7.9868\n",
      "     16        0.0203  7.8787\n",
      "     17        0.0236  7.8877\n",
      "     18        0.0198  7.8892\n",
      "     19        \u001b[36m0.0185\u001b[0m  7.9223\n",
      "     20        0.0198  7.8793\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5279\u001b[0m  7.9046\n",
      "      2        \u001b[36m0.0354\u001b[0m  7.9065\n",
      "      3        \u001b[36m0.0229\u001b[0m  7.8997\n",
      "      4        \u001b[36m0.0185\u001b[0m  7.9199\n",
      "      5        \u001b[36m0.0172\u001b[0m  7.9073\n",
      "      6        0.0191  7.9215\n",
      "      7        0.0194  7.9110\n",
      "      8        0.0237  7.9417\n",
      "      9        0.0192  7.9064\n",
      "     10        0.0210  7.9057\n",
      "     11        0.0204  7.9317\n",
      "     12        0.0198  7.9156\n",
      "     13        0.0204  7.9261\n",
      "     14        0.0219  8.0938\n",
      "     15        \u001b[36m0.0170\u001b[0m  7.9485\n",
      "     16        \u001b[36m0.0162\u001b[0m  7.9141\n",
      "     17        \u001b[36m0.0160\u001b[0m  7.9157\n",
      "     18        0.0178  7.9239\n",
      "     19        0.0165  7.9139\n",
      "     20        0.0172  7.9446\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3193\u001b[0m  7.9147\n",
      "      2        \u001b[36m0.0383\u001b[0m  7.9095\n",
      "      3        \u001b[36m0.0271\u001b[0m  7.8833\n",
      "      4        \u001b[36m0.0237\u001b[0m  7.8846\n",
      "      5        \u001b[36m0.0225\u001b[0m  8.0321\n",
      "      6        0.0244  7.8838\n",
      "      7        0.0235  7.9551\n",
      "      8        \u001b[36m0.0220\u001b[0m  7.9988\n",
      "      9        0.0243  7.8999\n",
      "     10        \u001b[36m0.0195\u001b[0m  7.8735\n",
      "     11        0.0249  7.8829\n",
      "     12        0.0221  7.8730\n",
      "     13        0.0211  7.8833\n",
      "     14        \u001b[36m0.0191\u001b[0m  7.8976\n",
      "     15        0.0202  7.8835\n",
      "     16        0.0222  7.9915\n",
      "     17        \u001b[36m0.0186\u001b[0m  7.9531\n",
      "     18        0.0198  7.8698\n",
      "     19        \u001b[36m0.0183\u001b[0m  7.8844\n",
      "     20        \u001b[36m0.0178\u001b[0m  7.8725\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0263\u001b[0m  7.8788\n",
      "      2        \u001b[36m0.0356\u001b[0m  7.8834\n",
      "      3        \u001b[36m0.0228\u001b[0m  7.8920\n",
      "      4        \u001b[36m0.0213\u001b[0m  7.9114\n",
      "      5        \u001b[36m0.0205\u001b[0m  7.8780\n",
      "      6        \u001b[36m0.0188\u001b[0m  7.8855\n",
      "      7        0.0196  7.8785\n",
      "      8        0.0208  7.8837\n",
      "      9        0.0197  7.8756\n",
      "     10        0.0196  7.8891\n",
      "     11        0.0195  7.9939\n",
      "     12        \u001b[36m0.0176\u001b[0m  7.9067\n",
      "     13        0.0193  7.9028\n",
      "     14        \u001b[36m0.0159\u001b[0m  7.8906\n",
      "     15        \u001b[36m0.0156\u001b[0m  7.9039\n",
      "     16        \u001b[36m0.0150\u001b[0m  7.9862\n",
      "     17        0.0167  7.8752\n",
      "     18        0.0186  7.9524\n",
      "     19        0.0164  7.9080\n",
      "     20        0.0151  7.9662\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m6.4274\u001b[0m  8.0225\n",
      "      2        \u001b[36m0.0534\u001b[0m  8.1081\n",
      "      3        \u001b[36m0.0331\u001b[0m  8.0811\n",
      "      4        \u001b[36m0.0270\u001b[0m  8.0327\n",
      "      5        \u001b[36m0.0231\u001b[0m  8.1384\n",
      "      6        \u001b[36m0.0228\u001b[0m  8.0842\n",
      "      7        \u001b[36m0.0206\u001b[0m  8.0554\n",
      "      8        0.0225  8.0819\n",
      "      9        0.0256  8.1763\n",
      "     10        0.0253  8.1100\n",
      "     11        0.0237  8.0487\n",
      "     12        0.0243  8.0790\n",
      "     13        0.0216  8.0625\n",
      "     14        0.0207  8.1190\n",
      "     15        0.0246  8.1815\n",
      "     16        0.0247  8.0508\n",
      "     17        0.0229  8.1128\n",
      "     18        0.0239  8.0424\n",
      "     19        0.0264  8.1228\n",
      "     20        \u001b[36m0.0197\u001b[0m  8.0081\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.9431\u001b[0m  8.0793\n",
      "      2        \u001b[36m0.0452\u001b[0m  8.1169\n",
      "      3        \u001b[36m0.0321\u001b[0m  8.1146\n",
      "      4        \u001b[36m0.0240\u001b[0m  8.1031\n",
      "      5        \u001b[36m0.0219\u001b[0m  8.1743\n",
      "      6        0.0228  8.0348\n",
      "      7        0.0236  8.0315\n",
      "      8        0.0230  8.0558\n",
      "      9        0.0240  8.0247\n",
      "     10        0.0249  8.0836\n",
      "     11        0.0244  8.0650\n",
      "     12        0.0247  8.0592\n",
      "     13        0.0241  8.0405\n",
      "     14        0.0230  8.1198\n",
      "     15        \u001b[36m0.0208\u001b[0m  8.1079\n",
      "     16        \u001b[36m0.0207\u001b[0m  8.0272\n",
      "     17        \u001b[36m0.0205\u001b[0m  8.0385\n",
      "     18        0.0226  8.0310\n",
      "     19        0.0238  8.0604\n",
      "     20        0.0248  8.1318\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.7563\u001b[0m  8.0198\n",
      "      2        \u001b[36m0.0456\u001b[0m  8.0734\n",
      "      3        \u001b[36m0.0267\u001b[0m  8.0462\n",
      "      4        \u001b[36m0.0206\u001b[0m  8.0355\n",
      "      5        \u001b[36m0.0176\u001b[0m  8.0730\n",
      "      6        0.0193  8.0699\n",
      "      7        0.0176  8.1093\n",
      "      8        0.0193  8.0364\n",
      "      9        0.0198  8.0072\n",
      "     10        0.0200  8.0476\n",
      "     11        0.0203  8.1116\n",
      "     12        0.0233  8.0087\n",
      "     13        \u001b[36m0.0172\u001b[0m  8.0217\n",
      "     14        0.0220  8.0278\n",
      "     15        \u001b[36m0.0169\u001b[0m  8.0285\n",
      "     16        \u001b[36m0.0153\u001b[0m  8.0189\n",
      "     17        0.0191  8.0310\n",
      "     18        0.0193  8.0531\n",
      "     19        0.0189  8.0250\n",
      "     20        0.0183  8.0066\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.6994\u001b[0m  8.0189\n",
      "      2        \u001b[36m0.0473\u001b[0m  8.0121\n",
      "      3        \u001b[36m0.0312\u001b[0m  8.0286\n",
      "      4        \u001b[36m0.0242\u001b[0m  8.0122\n",
      "      5        \u001b[36m0.0218\u001b[0m  8.0404\n",
      "      6        \u001b[36m0.0217\u001b[0m  8.0248\n",
      "      7        0.0226  8.0204\n",
      "      8        0.0218  8.0029\n",
      "      9        0.0255  8.0105\n",
      "     10        0.0235  8.0157\n",
      "     11        0.0227  8.0205\n",
      "     12        0.0251  8.0356\n",
      "     13        0.0243  8.0491\n",
      "     14        \u001b[36m0.0209\u001b[0m  8.0171\n",
      "     15        0.0238  8.0277\n",
      "     16        \u001b[36m0.0205\u001b[0m  8.0084\n",
      "     17        0.0228  8.0126\n",
      "     18        0.0214  8.0175\n",
      "     19        \u001b[36m0.0179\u001b[0m  8.0337\n",
      "     20        0.0211  8.0266\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.9735\u001b[0m  8.0235\n",
      "      2        \u001b[36m0.0407\u001b[0m  8.0303\n",
      "      3        \u001b[36m0.0259\u001b[0m  8.0096\n",
      "      4        \u001b[36m0.0206\u001b[0m  8.0209\n",
      "      5        \u001b[36m0.0201\u001b[0m  8.0245\n",
      "      6        \u001b[36m0.0178\u001b[0m  8.0296\n",
      "      7        0.0191  8.0544\n",
      "      8        0.0226  8.0429\n",
      "      9        0.0215  8.0571\n",
      "     10        0.0227  8.0105\n",
      "     11        0.0206  8.1157\n",
      "     12        \u001b[36m0.0168\u001b[0m  8.1774\n",
      "     13        0.0213  8.1437\n",
      "     14        0.0189  8.0227\n",
      "     15        \u001b[36m0.0164\u001b[0m  8.0472\n",
      "     16        0.0190  8.0320\n",
      "     17        0.0197  8.0258\n",
      "     18        0.0199  8.0551\n",
      "     19        0.0188  8.1319\n",
      "     20        0.0183  8.0377\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3273\u001b[0m  7.8156\n",
      "      2        \u001b[36m0.0764\u001b[0m  7.8182\n",
      "      3        \u001b[36m0.0587\u001b[0m  7.8177\n",
      "      4        \u001b[36m0.0520\u001b[0m  7.6771\n",
      "      5        \u001b[36m0.0497\u001b[0m  7.6937\n",
      "      6        \u001b[36m0.0491\u001b[0m  7.6904\n",
      "      7        \u001b[36m0.0470\u001b[0m  7.6870\n",
      "      8        \u001b[36m0.0454\u001b[0m  7.6728\n",
      "      9        \u001b[36m0.0451\u001b[0m  7.7631\n",
      "     10        \u001b[36m0.0433\u001b[0m  7.7282\n",
      "     11        0.0435  7.7643\n",
      "     12        \u001b[36m0.0396\u001b[0m  7.8197\n",
      "     13        0.0401  7.7420\n",
      "     14        0.0396  7.7231\n",
      "     15        \u001b[36m0.0362\u001b[0m  7.6914\n",
      "     16        0.0390  7.6932\n",
      "     17        0.0405  7.7245\n",
      "     18        0.0399  7.7850\n",
      "     19        \u001b[36m0.0359\u001b[0m  7.6998\n",
      "     20        0.0373  7.6778\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3700\u001b[0m  7.6923\n",
      "      2        \u001b[36m0.0776\u001b[0m  7.6785\n",
      "      3        \u001b[36m0.0618\u001b[0m  7.6953\n",
      "      4        \u001b[36m0.0543\u001b[0m  7.6822\n",
      "      5        \u001b[36m0.0526\u001b[0m  7.6961\n",
      "      6        \u001b[36m0.0502\u001b[0m  7.7018\n",
      "      7        \u001b[36m0.0487\u001b[0m  7.6909\n",
      "      8        \u001b[36m0.0475\u001b[0m  7.6802\n",
      "      9        \u001b[36m0.0435\u001b[0m  7.6858\n",
      "     10        0.0446  7.6888\n",
      "     11        0.0435  7.6987\n",
      "     12        0.0444  7.6837\n",
      "     13        \u001b[36m0.0428\u001b[0m  7.7348\n",
      "     14        0.0442  7.6977\n",
      "     15        \u001b[36m0.0393\u001b[0m  7.7973\n",
      "     16        0.0407  7.6970\n",
      "     17        0.0395  7.6936\n",
      "     18        \u001b[36m0.0392\u001b[0m  7.6881\n",
      "     19        0.0397  7.6954\n",
      "     20        \u001b[36m0.0370\u001b[0m  7.6813\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4000\u001b[0m  7.7026\n",
      "      2        \u001b[36m0.0708\u001b[0m  7.6826\n",
      "      3        \u001b[36m0.0549\u001b[0m  7.6695\n",
      "      4        \u001b[36m0.0475\u001b[0m  7.6789\n",
      "      5        \u001b[36m0.0421\u001b[0m  7.6891\n",
      "      6        0.0426  7.8435\n",
      "      7        \u001b[36m0.0417\u001b[0m  7.6992\n",
      "      8        \u001b[36m0.0409\u001b[0m  7.7328\n",
      "      9        0.0423  7.7875\n",
      "     10        \u001b[36m0.0372\u001b[0m  7.6978\n",
      "     11        0.0375  7.6922\n",
      "     12        0.0380  7.7013\n",
      "     13        0.0377  7.6752\n",
      "     14        \u001b[36m0.0362\u001b[0m  7.6900\n",
      "     15        \u001b[36m0.0357\u001b[0m  7.6778\n",
      "     16        \u001b[36m0.0349\u001b[0m  7.7157\n",
      "     17        0.0350  7.6868\n",
      "     18        \u001b[36m0.0328\u001b[0m  7.6864\n",
      "     19        0.0339  7.6796\n",
      "     20        0.0340  7.6835\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3557\u001b[0m  7.6801\n",
      "      2        \u001b[36m0.0750\u001b[0m  7.6880\n",
      "      3        \u001b[36m0.0598\u001b[0m  7.6873\n",
      "      4        \u001b[36m0.0500\u001b[0m  7.7295\n",
      "      5        0.0503  7.6992\n",
      "      6        \u001b[36m0.0470\u001b[0m  7.6760\n",
      "      7        \u001b[36m0.0460\u001b[0m  7.6858\n",
      "      8        0.0464  7.6767\n",
      "      9        \u001b[36m0.0447\u001b[0m  7.6990\n",
      "     10        \u001b[36m0.0429\u001b[0m  7.6798\n",
      "     11        \u001b[36m0.0400\u001b[0m  7.7539\n",
      "     12        \u001b[36m0.0393\u001b[0m  7.6927\n",
      "     13        0.0396  7.6926\n",
      "     14        0.0415  7.6781\n",
      "     15        \u001b[36m0.0372\u001b[0m  7.7006\n",
      "     16        0.0386  7.6739\n",
      "     17        0.0400  7.6877\n",
      "     18        \u001b[36m0.0369\u001b[0m  7.6801\n",
      "     19        0.0380  7.7242\n",
      "     20        \u001b[36m0.0357\u001b[0m  7.6972\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3132\u001b[0m  7.6858\n",
      "      2        \u001b[36m0.0732\u001b[0m  7.6852\n",
      "      3        \u001b[36m0.0547\u001b[0m  7.6765\n",
      "      4        \u001b[36m0.0489\u001b[0m  7.6862\n",
      "      5        \u001b[36m0.0464\u001b[0m  7.6881\n",
      "      6        \u001b[36m0.0431\u001b[0m  7.6830\n",
      "      7        \u001b[36m0.0429\u001b[0m  7.7018\n",
      "      8        \u001b[36m0.0409\u001b[0m  7.6936\n",
      "      9        \u001b[36m0.0409\u001b[0m  7.6777\n",
      "     10        \u001b[36m0.0403\u001b[0m  7.6825\n",
      "     11        0.0427  7.6735\n",
      "     12        \u001b[36m0.0374\u001b[0m  7.6903\n",
      "     13        \u001b[36m0.0369\u001b[0m  7.6822\n",
      "     14        \u001b[36m0.0364\u001b[0m  7.6977\n",
      "     15        0.0379  7.7212\n",
      "     16        \u001b[36m0.0356\u001b[0m  7.6944\n",
      "     17        \u001b[36m0.0351\u001b[0m  7.6751\n",
      "     18        0.0372  7.6853\n",
      "     19        0.0352  7.6821\n",
      "     20        \u001b[36m0.0330\u001b[0m  7.7397\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.7554\u001b[0m  7.8690\n",
      "      2        \u001b[36m0.0951\u001b[0m  7.8334\n",
      "      3        \u001b[36m0.0676\u001b[0m  7.8483\n",
      "      4        \u001b[36m0.0545\u001b[0m  7.9442\n",
      "      5        \u001b[36m0.0506\u001b[0m  7.8372\n",
      "      6        \u001b[36m0.0482\u001b[0m  7.8474\n",
      "      7        \u001b[36m0.0450\u001b[0m  7.8588\n",
      "      8        0.0477  7.8642\n",
      "      9        0.0483  7.8416\n",
      "     10        0.0458  7.8871\n",
      "     11        0.0475  7.8475\n",
      "     12        \u001b[36m0.0434\u001b[0m  7.8269\n",
      "     13        0.0452  7.8436\n",
      "     14        0.0454  7.8402\n",
      "     15        \u001b[36m0.0423\u001b[0m  7.8369\n",
      "     16        0.0440  7.8258\n",
      "     17        \u001b[36m0.0397\u001b[0m  7.8467\n",
      "     18        \u001b[36m0.0382\u001b[0m  7.8582\n",
      "     19        \u001b[36m0.0378\u001b[0m  7.8565\n",
      "     20        0.0399  7.8275\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8404\u001b[0m  7.8398\n",
      "      2        \u001b[36m0.0823\u001b[0m  7.8227\n",
      "      3        \u001b[36m0.0590\u001b[0m  7.8375\n",
      "      4        \u001b[36m0.0542\u001b[0m  7.8263\n",
      "      5        \u001b[36m0.0488\u001b[0m  7.8926\n",
      "      6        \u001b[36m0.0477\u001b[0m  7.8366\n",
      "      7        \u001b[36m0.0437\u001b[0m  7.8371\n",
      "      8        0.0469  7.8260\n",
      "      9        0.0463  7.8369\n",
      "     10        0.0455  7.8326\n",
      "     11        \u001b[36m0.0436\u001b[0m  7.8372\n",
      "     12        \u001b[36m0.0435\u001b[0m  7.8340\n",
      "     13        \u001b[36m0.0422\u001b[0m  7.8729\n",
      "     14        \u001b[36m0.0400\u001b[0m  7.8411\n",
      "     15        \u001b[36m0.0399\u001b[0m  7.8377\n",
      "     16        0.0433  7.8277\n",
      "     17        0.0418  7.8359\n",
      "     18        0.0412  7.8405\n",
      "     19        \u001b[36m0.0374\u001b[0m  7.8451\n",
      "     20        0.0378  7.8809\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8091\u001b[0m  7.8436\n",
      "      2        \u001b[36m0.0766\u001b[0m  7.8465\n",
      "      3        \u001b[36m0.0552\u001b[0m  7.8475\n",
      "      4        \u001b[36m0.0469\u001b[0m  7.8341\n",
      "      5        \u001b[36m0.0426\u001b[0m  7.8256\n",
      "      6        0.0438  7.8492\n",
      "      7        \u001b[36m0.0410\u001b[0m  7.8315\n",
      "      8        0.0456  7.8589\n",
      "      9        0.0450  7.8320\n",
      "     10        0.0433  7.8375\n",
      "     11        0.0436  7.8299\n",
      "     12        0.0418  7.8414\n",
      "     13        \u001b[36m0.0396\u001b[0m  7.8304\n",
      "     14        \u001b[36m0.0379\u001b[0m  7.8978\n",
      "     15        0.0401  7.8977\n",
      "     16        \u001b[36m0.0371\u001b[0m  7.8644\n",
      "     17        0.0384  7.8326\n",
      "     18        0.0396  7.8590\n",
      "     19        \u001b[36m0.0341\u001b[0m  7.8316\n",
      "     20        0.0359  7.8395\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9271\u001b[0m  7.8373\n",
      "      2        \u001b[36m0.0807\u001b[0m  7.8263\n",
      "      3        \u001b[36m0.0608\u001b[0m  7.8815\n",
      "      4        \u001b[36m0.0508\u001b[0m  7.8457\n",
      "      5        \u001b[36m0.0482\u001b[0m  8.0028\n",
      "      6        \u001b[36m0.0475\u001b[0m  7.9647\n",
      "      7        \u001b[36m0.0475\u001b[0m  7.9949\n",
      "      8        0.0492  7.8474\n",
      "      9        \u001b[36m0.0466\u001b[0m  7.8469\n",
      "     10        \u001b[36m0.0458\u001b[0m  7.8588\n",
      "     11        \u001b[36m0.0444\u001b[0m  7.9756\n",
      "     12        0.0471  8.0182\n",
      "     13        \u001b[36m0.0437\u001b[0m  7.9338\n",
      "     14        \u001b[36m0.0420\u001b[0m  7.8794\n",
      "     15        \u001b[36m0.0411\u001b[0m  7.8389\n",
      "     16        \u001b[36m0.0388\u001b[0m  7.8353\n",
      "     17        0.0406  7.8355\n",
      "     18        0.0422  7.8955\n",
      "     19        \u001b[36m0.0379\u001b[0m  7.9506\n",
      "     20        0.0402  7.9380\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9174\u001b[0m  7.8867\n",
      "      2        \u001b[36m0.0767\u001b[0m  7.9761\n",
      "      3        \u001b[36m0.0547\u001b[0m  7.9438\n",
      "      4        \u001b[36m0.0481\u001b[0m  8.0008\n",
      "      5        \u001b[36m0.0446\u001b[0m  8.0150\n",
      "      6        0.0447  7.9654\n",
      "      7        \u001b[36m0.0418\u001b[0m  7.8843\n",
      "      8        0.0442  7.8878\n",
      "      9        0.0446  7.8426\n",
      "     10        0.0420  7.9329\n",
      "     11        0.0453  7.9276\n",
      "     12        \u001b[36m0.0393\u001b[0m  7.9011\n",
      "     13        \u001b[36m0.0390\u001b[0m  7.8298\n",
      "     14        0.0401  7.8618\n",
      "     15        0.0391  7.9075\n",
      "     16        \u001b[36m0.0356\u001b[0m  8.0255\n",
      "     17        0.0370  7.8855\n",
      "     18        0.0402  7.8758\n",
      "     19        0.0380  7.8481\n",
      "     20        \u001b[36m0.0351\u001b[0m  7.8767\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9485\u001b[0m  7.9380\n",
      "      2        \u001b[36m0.0432\u001b[0m  7.8916\n",
      "      3        \u001b[36m0.0323\u001b[0m  7.9713\n",
      "      4        \u001b[36m0.0280\u001b[0m  7.8741\n",
      "      5        \u001b[36m0.0261\u001b[0m  7.8867\n",
      "      6        0.0283  7.8900\n",
      "      7        0.0275  7.8893\n",
      "      8        0.0272  7.8867\n",
      "      9        0.0331  7.9141\n",
      "     10        0.0262  7.9583\n",
      "     11        \u001b[36m0.0251\u001b[0m  7.9415\n",
      "     12        0.0290  7.9049\n",
      "     13        0.0253  8.0408\n",
      "     14        0.0265  7.9304\n",
      "     15        0.0257  7.9986\n",
      "     16        0.0261  7.9818\n",
      "     17        \u001b[36m0.0246\u001b[0m  7.9058\n",
      "     18        0.0250  7.9954\n",
      "     19        \u001b[36m0.0219\u001b[0m  7.9261\n",
      "     20        \u001b[36m0.0217\u001b[0m  7.8815\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0144\u001b[0m  7.8993\n",
      "      2        \u001b[36m0.0441\u001b[0m  7.8814\n",
      "      3        \u001b[36m0.0306\u001b[0m  7.8886\n",
      "      4        \u001b[36m0.0280\u001b[0m  7.8872\n",
      "      5        \u001b[36m0.0279\u001b[0m  7.8900\n",
      "      6        0.0282  7.8821\n",
      "      7        0.0294  7.8872\n",
      "      8        0.0291  7.8785\n",
      "      9        0.0301  7.8895\n",
      "     10        0.0282  7.8963\n",
      "     11        \u001b[36m0.0265\u001b[0m  7.9062\n",
      "     12        \u001b[36m0.0255\u001b[0m  7.8933\n",
      "     13        0.0275  7.8877\n",
      "     14        0.0267  7.8850\n",
      "     15        0.0292  7.8896\n",
      "     16        0.0272  7.8863\n",
      "     17        0.0283  7.8932\n",
      "     18        \u001b[36m0.0234\u001b[0m  7.8852\n",
      "     19        \u001b[36m0.0230\u001b[0m  7.8965\n",
      "     20        \u001b[36m0.0230\u001b[0m  7.8765\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9975\u001b[0m  7.8748\n",
      "      2        \u001b[36m0.0377\u001b[0m  7.8814\n",
      "      3        \u001b[36m0.0253\u001b[0m  7.8754\n",
      "      4        \u001b[36m0.0234\u001b[0m  7.8861\n",
      "      5        \u001b[36m0.0213\u001b[0m  7.8858\n",
      "      6        0.0213  7.9069\n",
      "      7        0.0220  7.8785\n",
      "      8        0.0266  7.8843\n",
      "      9        0.0250  7.8757\n",
      "     10        0.0255  7.8818\n",
      "     11        \u001b[36m0.0195\u001b[0m  7.8749\n",
      "     12        0.0230  7.8848\n",
      "     13        0.0269  7.8780\n",
      "     14        0.0228  7.8900\n",
      "     15        0.0196  7.8797\n",
      "     16        0.0250  7.8876\n",
      "     17        0.0210  7.8777\n",
      "     18        0.0225  7.8932\n",
      "     19        0.0223  7.8875\n",
      "     20        0.0257  7.8843\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.8771\u001b[0m  7.9153\n",
      "      2        \u001b[36m0.0489\u001b[0m  7.8832\n",
      "      3        \u001b[36m0.0322\u001b[0m  7.8862\n",
      "      4        \u001b[36m0.0292\u001b[0m  7.9617\n",
      "      5        \u001b[36m0.0260\u001b[0m  7.8986\n",
      "      6        0.0277  7.8848\n",
      "      7        0.0275  7.8846\n",
      "      8        0.0306  7.8920\n",
      "      9        0.0303  7.9106\n",
      "     10        0.0281  7.8791\n",
      "     11        0.0299  7.8874\n",
      "     12        0.0282  7.8806\n",
      "     13        0.0299  7.8931\n",
      "     14        0.0273  7.8778\n",
      "     15        \u001b[36m0.0255\u001b[0m  7.8903\n",
      "     16        \u001b[36m0.0251\u001b[0m  7.9129\n",
      "     17        \u001b[36m0.0233\u001b[0m  7.8968\n",
      "     18        0.0242  7.9037\n",
      "     19        \u001b[36m0.0223\u001b[0m  7.8885\n",
      "     20        0.0280  7.8793\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1219\u001b[0m  7.8786\n",
      "      2        \u001b[36m0.0399\u001b[0m  7.8824\n",
      "      3        \u001b[36m0.0272\u001b[0m  7.8876\n",
      "      4        \u001b[36m0.0233\u001b[0m  7.8972\n",
      "      5        0.0242  7.8765\n",
      "      6        0.0252  7.8851\n",
      "      7        0.0263  7.8744\n",
      "      8        0.0242  7.8862\n",
      "      9        0.0256  7.8837\n",
      "     10        0.0269  7.8850\n",
      "     11        0.0243  7.9602\n",
      "     12        \u001b[36m0.0226\u001b[0m  7.8948\n",
      "     13        0.0233  7.8787\n",
      "     14        0.0232  7.8894\n",
      "     15        0.0231  7.8737\n",
      "     16        0.0252  7.8900\n",
      "     17        0.0226  7.8754\n",
      "     18        \u001b[36m0.0193\u001b[0m  7.8900\n",
      "     19        \u001b[36m0.0185\u001b[0m  7.8991\n",
      "     20        0.0236  7.8901\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.5258\u001b[0m  8.0320\n",
      "      2        \u001b[36m0.0571\u001b[0m  8.0171\n",
      "      3        \u001b[36m0.0362\u001b[0m  8.0139\n",
      "      4        \u001b[36m0.0277\u001b[0m  8.0109\n",
      "      5        0.0280  8.0338\n",
      "      6        \u001b[36m0.0257\u001b[0m  8.0598\n",
      "      7        0.0279  8.0279\n",
      "      8        0.0305  8.0200\n",
      "      9        0.0308  8.0263\n",
      "     10        0.0330  8.0211\n",
      "     11        0.0281  8.0278\n",
      "     12        0.0264  8.0111\n",
      "     13        0.0267  8.0418\n",
      "     14        0.0283  8.0341\n",
      "     15        0.0272  8.0309\n",
      "     16        0.0286  8.0228\n",
      "     17        0.0265  8.0223\n",
      "     18        0.0278  8.0192\n",
      "     19        0.0281  8.0088\n",
      "     20        0.0265  8.0151\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.8543\u001b[0m  8.0691\n",
      "      2        \u001b[36m0.0580\u001b[0m  8.0240\n",
      "      3        \u001b[36m0.0380\u001b[0m  8.0297\n",
      "      4        \u001b[36m0.0285\u001b[0m  8.0149\n",
      "      5        \u001b[36m0.0275\u001b[0m  8.0335\n",
      "      6        \u001b[36m0.0250\u001b[0m  8.0052\n",
      "      7        0.0257  8.0621\n",
      "      8        0.0259  8.0598\n",
      "      9        0.0288  8.0769\n",
      "     10        0.0300  7.9962\n",
      "     11        0.0335  8.0103\n",
      "     12        0.0299  8.0015\n",
      "     13        0.0272  8.0576\n",
      "     14        0.0257  8.1032\n",
      "     15        0.0273  8.0540\n",
      "     16        0.0286  8.0294\n",
      "     17        0.0278  8.0326\n",
      "     18        0.0265  8.0212\n",
      "     19        0.0276  8.0299\n",
      "     20        0.0256  8.0175\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.0598\u001b[0m  8.0104\n",
      "      2        \u001b[36m0.0505\u001b[0m  8.0163\n",
      "      3        \u001b[36m0.0306\u001b[0m  8.0274\n",
      "      4        \u001b[36m0.0232\u001b[0m  8.0273\n",
      "      5        \u001b[36m0.0223\u001b[0m  8.0143\n",
      "      6        \u001b[36m0.0206\u001b[0m  8.0140\n",
      "      7        0.0245  8.0173\n",
      "      8        0.0260  8.0260\n",
      "      9        0.0234  8.0162\n",
      "     10        0.0261  8.0660\n",
      "     11        0.0253  8.1142\n",
      "     12        0.0268  8.0969\n",
      "     13        0.0231  8.1280\n",
      "     14        0.0273  8.0746\n",
      "     15        0.0218  8.0594\n",
      "     16        0.0256  8.0321\n",
      "     17        0.0253  8.0686\n",
      "     18        0.0234  8.0369\n",
      "     19        0.0209  8.0791\n",
      "     20        0.0267  8.0259\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m6.7305\u001b[0m  8.0350\n",
      "      2        \u001b[36m0.0599\u001b[0m  8.0762\n",
      "      3        \u001b[36m0.0388\u001b[0m  8.0289\n",
      "      4        \u001b[36m0.0293\u001b[0m  8.0249\n",
      "      5        \u001b[36m0.0262\u001b[0m  8.0912\n",
      "      6        \u001b[36m0.0242\u001b[0m  8.0231\n",
      "      7        0.0261  8.0253\n",
      "      8        0.0261  8.1501\n",
      "      9        0.0280  8.1577\n",
      "     10        0.0319  8.0560\n",
      "     11        0.0301  8.0139\n",
      "     12        0.0293  8.0246\n",
      "     13        0.0288  8.0426\n",
      "     14        0.0305  8.0624\n",
      "     15        0.0299  8.0560\n",
      "     16        0.0286  8.1245\n",
      "     17        0.0311  8.1435\n",
      "     18        0.0344  8.0933\n",
      "     19        0.0276  8.0165\n",
      "     20        0.0253  8.0724\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.9091\u001b[0m  8.0839\n",
      "      2        \u001b[36m0.0528\u001b[0m  8.1383\n",
      "      3        \u001b[36m0.0332\u001b[0m  8.0712\n",
      "      4        \u001b[36m0.0251\u001b[0m  8.0341\n",
      "      5        \u001b[36m0.0217\u001b[0m  8.1422\n",
      "      6        \u001b[36m0.0208\u001b[0m  8.1309\n",
      "      7        0.0233  8.0498\n",
      "      8        0.0230  8.1017\n",
      "      9        0.0291  8.0502\n",
      "     10        0.0232  8.1677\n",
      "     11        0.0239  8.1547\n",
      "     12        0.0235  8.0172\n",
      "     13        0.0265  8.0001\n",
      "     14        0.0257  8.0286\n",
      "     15        0.0262  8.1134\n",
      "     16        0.0235  8.0197\n",
      "     17        0.0243  8.0002\n",
      "     18        0.0250  8.0592\n",
      "     19        0.0268  8.1035\n",
      "     20        0.0258  8.0614\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3657\u001b[0m  7.7667\n",
      "      2        \u001b[36m0.0936\u001b[0m  7.8462\n",
      "      3        \u001b[36m0.0786\u001b[0m  7.7706\n",
      "      4        \u001b[36m0.0723\u001b[0m  7.6835\n",
      "      5        \u001b[36m0.0693\u001b[0m  7.7667\n",
      "      6        \u001b[36m0.0659\u001b[0m  7.7060\n",
      "      7        \u001b[36m0.0642\u001b[0m  7.7760\n",
      "      8        \u001b[36m0.0627\u001b[0m  7.7264\n",
      "      9        \u001b[36m0.0625\u001b[0m  7.7130\n",
      "     10        \u001b[36m0.0607\u001b[0m  7.8121\n",
      "     11        \u001b[36m0.0572\u001b[0m  7.6904\n",
      "     12        \u001b[36m0.0547\u001b[0m  7.7011\n",
      "     13        0.0592  7.7684\n",
      "     14        \u001b[36m0.0541\u001b[0m  7.8360\n",
      "     15        0.0558  7.7044\n",
      "     16        0.0567  7.8273\n",
      "     17        \u001b[36m0.0519\u001b[0m  7.8448\n",
      "     18        \u001b[36m0.0513\u001b[0m  7.7351\n",
      "     19        \u001b[36m0.0499\u001b[0m  7.6959\n",
      "     20        0.0501  7.6814\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3441\u001b[0m  7.6855\n",
      "      2        \u001b[36m0.0972\u001b[0m  7.6988\n",
      "      3        \u001b[36m0.0780\u001b[0m  7.6912\n",
      "      4        \u001b[36m0.0696\u001b[0m  7.6907\n",
      "      5        \u001b[36m0.0684\u001b[0m  7.7438\n",
      "      6        0.0697  7.6945\n",
      "      7        \u001b[36m0.0665\u001b[0m  7.7046\n",
      "      8        \u001b[36m0.0630\u001b[0m  7.6888\n",
      "      9        \u001b[36m0.0599\u001b[0m  7.6872\n",
      "     10        \u001b[36m0.0586\u001b[0m  7.6806\n",
      "     11        \u001b[36m0.0575\u001b[0m  7.6917\n",
      "     12        \u001b[36m0.0563\u001b[0m  7.6878\n",
      "     13        \u001b[36m0.0549\u001b[0m  7.7179\n",
      "     14        0.0560  7.7607\n",
      "     15        0.0566  7.7985\n",
      "     16        \u001b[36m0.0525\u001b[0m  7.6918\n",
      "     17        \u001b[36m0.0517\u001b[0m  7.6899\n",
      "     18        0.0533  7.6858\n",
      "     19        0.0527  7.7056\n",
      "     20        \u001b[36m0.0500\u001b[0m  7.7078\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4333\u001b[0m  7.7024\n",
      "      2        \u001b[36m0.0910\u001b[0m  7.6915\n",
      "      3        \u001b[36m0.0731\u001b[0m  7.6854\n",
      "      4        \u001b[36m0.0666\u001b[0m  7.6928\n",
      "      5        \u001b[36m0.0640\u001b[0m  7.6757\n",
      "      6        \u001b[36m0.0618\u001b[0m  7.7029\n",
      "      7        \u001b[36m0.0606\u001b[0m  7.6774\n",
      "      8        \u001b[36m0.0595\u001b[0m  7.6928\n",
      "      9        0.0596  7.6961\n",
      "     10        \u001b[36m0.0580\u001b[0m  7.6884\n",
      "     11        \u001b[36m0.0550\u001b[0m  7.6746\n",
      "     12        \u001b[36m0.0548\u001b[0m  7.6867\n",
      "     13        \u001b[36m0.0511\u001b[0m  7.6917\n",
      "     14        0.0520  7.6863\n",
      "     15        \u001b[36m0.0499\u001b[0m  7.6860\n",
      "     16        0.0528  7.7409\n",
      "     17        0.0537  7.6846\n",
      "     18        \u001b[36m0.0485\u001b[0m  7.6944\n",
      "     19        0.0513  7.6749\n",
      "     20        \u001b[36m0.0471\u001b[0m  7.6904\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4753\u001b[0m  7.6859\n",
      "      2        \u001b[36m0.0961\u001b[0m  7.6659\n",
      "      3        \u001b[36m0.0779\u001b[0m  7.6855\n",
      "      4        \u001b[36m0.0709\u001b[0m  7.6951\n",
      "      5        \u001b[36m0.0658\u001b[0m  7.6900\n",
      "      6        0.0659  7.6881\n",
      "      7        \u001b[36m0.0638\u001b[0m  7.6857\n",
      "      8        \u001b[36m0.0631\u001b[0m  7.6777\n",
      "      9        \u001b[36m0.0607\u001b[0m  7.6940\n",
      "     10        0.0618  7.6763\n",
      "     11        0.0613  7.7285\n",
      "     12        \u001b[36m0.0582\u001b[0m  7.7013\n",
      "     13        \u001b[36m0.0566\u001b[0m  7.6946\n",
      "     14        0.0572  7.6801\n",
      "     15        \u001b[36m0.0551\u001b[0m  7.6892\n",
      "     16        \u001b[36m0.0548\u001b[0m  7.6997\n",
      "     17        0.0552  7.7070\n",
      "     18        \u001b[36m0.0524\u001b[0m  7.6814\n",
      "     19        0.0529  7.7103\n",
      "     20        \u001b[36m0.0524\u001b[0m  7.6945\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3533\u001b[0m  7.6829\n",
      "      2        \u001b[36m0.0907\u001b[0m  7.6994\n",
      "      3        \u001b[36m0.0754\u001b[0m  7.6885\n",
      "      4        \u001b[36m0.0673\u001b[0m  7.6926\n",
      "      5        \u001b[36m0.0618\u001b[0m  7.6762\n",
      "      6        \u001b[36m0.0605\u001b[0m  7.6897\n",
      "      7        \u001b[36m0.0564\u001b[0m  7.7309\n",
      "      8        0.0565  7.6927\n",
      "      9        0.0576  7.6860\n",
      "     10        0.0575  7.7017\n",
      "     11        \u001b[36m0.0540\u001b[0m  7.6785\n",
      "     12        \u001b[36m0.0524\u001b[0m  7.6911\n",
      "     13        \u001b[36m0.0508\u001b[0m  7.6932\n",
      "     14        0.0533  7.6870\n",
      "     15        0.0524  7.6898\n",
      "     16        \u001b[36m0.0488\u001b[0m  7.6942\n",
      "     17        0.0499  7.6769\n",
      "     18        0.0510  7.7021\n",
      "     19        \u001b[36m0.0479\u001b[0m  7.7135\n",
      "     20        0.0483  7.7036\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9163\u001b[0m  7.9160\n",
      "      2        \u001b[36m0.1028\u001b[0m  7.9719\n",
      "      3        \u001b[36m0.0757\u001b[0m  7.9428\n",
      "      4        \u001b[36m0.0686\u001b[0m  7.9423\n",
      "      5        0.0692  7.8550\n",
      "      6        0.0704  7.8916\n",
      "      7        \u001b[36m0.0667\u001b[0m  7.8383\n",
      "      8        \u001b[36m0.0667\u001b[0m  7.8276\n",
      "      9        \u001b[36m0.0648\u001b[0m  7.8510\n",
      "     10        \u001b[36m0.0643\u001b[0m  7.9539\n",
      "     11        \u001b[36m0.0611\u001b[0m  7.9115\n",
      "     12        0.0638  7.9649\n",
      "     13        \u001b[36m0.0608\u001b[0m  7.9351\n",
      "     14        \u001b[36m0.0591\u001b[0m  8.0085\n",
      "     15        \u001b[36m0.0570\u001b[0m  8.0138\n",
      "     16        0.0577  7.9687\n",
      "     17        \u001b[36m0.0528\u001b[0m  7.9302\n",
      "     18        0.0580  7.8398\n",
      "     19        0.0560  7.9013\n",
      "     20        0.0540  7.9829\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2389\u001b[0m  7.9475\n",
      "      2        \u001b[36m0.1085\u001b[0m  7.9008\n",
      "      3        \u001b[36m0.0824\u001b[0m  8.0219\n",
      "      4        \u001b[36m0.0694\u001b[0m  7.8498\n",
      "      5        \u001b[36m0.0679\u001b[0m  7.8852\n",
      "      6        \u001b[36m0.0629\u001b[0m  7.9210\n",
      "      7        0.0655  7.8993\n",
      "      8        0.0630  7.9176\n",
      "      9        0.0654  7.8901\n",
      "     10        \u001b[36m0.0621\u001b[0m  7.8366\n",
      "     11        0.0643  7.8618\n",
      "     12        0.0631  7.8951\n",
      "     13        \u001b[36m0.0608\u001b[0m  7.8495\n",
      "     14        \u001b[36m0.0596\u001b[0m  7.9473\n",
      "     15        \u001b[36m0.0579\u001b[0m  7.8507\n",
      "     16        \u001b[36m0.0554\u001b[0m  7.8380\n",
      "     17        0.0576  8.0006\n",
      "     18        0.0583  7.9552\n",
      "     19        \u001b[36m0.0508\u001b[0m  7.8709\n",
      "     20        0.0555  7.8901\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3523\u001b[0m  7.8943\n",
      "      2        \u001b[36m0.1006\u001b[0m  7.9913\n",
      "      3        \u001b[36m0.0767\u001b[0m  7.9096\n",
      "      4        \u001b[36m0.0635\u001b[0m  7.9038\n",
      "      5        \u001b[36m0.0624\u001b[0m  7.9004\n",
      "      6        \u001b[36m0.0618\u001b[0m  7.8571\n",
      "      7        \u001b[36m0.0606\u001b[0m  7.8673\n",
      "      8        0.0627  7.8680\n",
      "      9        \u001b[36m0.0605\u001b[0m  7.8569\n",
      "     10        \u001b[36m0.0589\u001b[0m  7.8743\n",
      "     11        0.0589  7.9114\n",
      "     12        0.0595  7.8432\n",
      "     13        \u001b[36m0.0566\u001b[0m  7.8280\n",
      "     14        0.0567  7.8521\n",
      "     15        0.0573  7.8593\n",
      "     16        \u001b[36m0.0524\u001b[0m  7.8813\n",
      "     17        0.0550  7.9404\n",
      "     18        \u001b[36m0.0505\u001b[0m  7.9871\n",
      "     19        \u001b[36m0.0498\u001b[0m  7.8666\n",
      "     20        0.0524  7.8819\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9598\u001b[0m  7.9864\n",
      "      2        \u001b[36m0.1021\u001b[0m  7.9816\n",
      "      3        \u001b[36m0.0786\u001b[0m  7.8647\n",
      "      4        \u001b[36m0.0712\u001b[0m  7.9220\n",
      "      5        \u001b[36m0.0650\u001b[0m  7.9262\n",
      "      6        \u001b[36m0.0634\u001b[0m  7.8751\n",
      "      7        0.0637  7.8389\n",
      "      8        0.0667  7.8386\n",
      "      9        0.0665  7.9084\n",
      "     10        0.0674  7.9053\n",
      "     11        \u001b[36m0.0618\u001b[0m  7.8517\n",
      "     12        0.0619  7.8352\n",
      "     13        \u001b[36m0.0611\u001b[0m  7.8716\n",
      "     14        \u001b[36m0.0605\u001b[0m  7.9841\n",
      "     15        0.0614  7.8803\n",
      "     16        \u001b[36m0.0570\u001b[0m  7.8813\n",
      "     17        0.0578  7.9488\n",
      "     18        0.0572  7.8477\n",
      "     19        \u001b[36m0.0540\u001b[0m  7.9202\n",
      "     20        0.0596  7.8281\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9316\u001b[0m  7.8256\n",
      "      2        \u001b[36m0.1036\u001b[0m  7.8381\n",
      "      3        \u001b[36m0.0778\u001b[0m  7.8299\n",
      "      4        \u001b[36m0.0643\u001b[0m  7.8444\n",
      "      5        \u001b[36m0.0591\u001b[0m  7.8619\n",
      "      6        0.0632  7.8534\n",
      "      7        0.0643  7.8434\n",
      "      8        0.0603  7.8559\n",
      "      9        0.0605  7.8296\n",
      "     10        \u001b[36m0.0584\u001b[0m  7.8547\n",
      "     11        0.0642  7.8389\n",
      "     12        0.0588  7.8644\n",
      "     13        0.0601  7.8733\n",
      "     14        \u001b[36m0.0553\u001b[0m  7.8523\n",
      "     15        \u001b[36m0.0531\u001b[0m  7.8315\n",
      "     16        0.0587  7.8596\n",
      "     17        0.0545  7.8252\n",
      "     18        0.0552  7.8526\n",
      "     19        \u001b[36m0.0528\u001b[0m  7.8290\n",
      "     20        \u001b[36m0.0519\u001b[0m  7.8582\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0154\u001b[0m  7.8966\n",
      "      2        \u001b[36m0.0502\u001b[0m  7.8736\n",
      "      3        \u001b[36m0.0364\u001b[0m  7.8913\n",
      "      4        \u001b[36m0.0357\u001b[0m  7.8737\n",
      "      5        \u001b[36m0.0348\u001b[0m  7.8927\n",
      "      6        0.0378  7.8768\n",
      "      7        0.0354  7.9061\n",
      "      8        0.0374  7.9179\n",
      "      9        0.0394  7.8894\n",
      "     10        0.0398  7.8792\n",
      "     11        \u001b[36m0.0337\u001b[0m  7.9282\n",
      "     12        0.0343  7.8723\n",
      "     13        0.0348  7.8838\n",
      "     14        0.0367  7.8808\n",
      "     15        0.0378  7.8994\n",
      "     16        0.0347  7.8870\n",
      "     17        \u001b[36m0.0302\u001b[0m  7.8927\n",
      "     18        0.0322  7.8743\n",
      "     19        0.0313  7.8924\n",
      "     20        0.0343  7.8776\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0640\u001b[0m  7.8846\n",
      "      2        \u001b[36m0.0538\u001b[0m  7.8940\n",
      "      3        \u001b[36m0.0389\u001b[0m  7.9294\n",
      "      4        \u001b[36m0.0350\u001b[0m  7.8806\n",
      "      5        0.0372  7.8871\n",
      "      6        0.0360  7.8800\n",
      "      7        0.0365  7.8889\n",
      "      8        0.0389  7.8796\n",
      "      9        \u001b[36m0.0336\u001b[0m  7.8896\n",
      "     10        0.0369  7.8907\n",
      "     11        0.0377  7.9049\n",
      "     12        0.0345  7.8808\n",
      "     13        0.0338  7.8921\n",
      "     14        0.0374  7.8791\n",
      "     15        0.0353  7.8940\n",
      "     16        0.0345  7.8950\n",
      "     17        0.0340  7.8937\n",
      "     18        \u001b[36m0.0312\u001b[0m  7.9750\n",
      "     19        0.0327  7.9017\n",
      "     20        0.0327  7.8789\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.9097\u001b[0m  7.8859\n",
      "      2        \u001b[36m0.0471\u001b[0m  7.8966\n",
      "      3        \u001b[36m0.0345\u001b[0m  7.8888\n",
      "      4        \u001b[36m0.0290\u001b[0m  7.8998\n",
      "      5        \u001b[36m0.0287\u001b[0m  7.8936\n",
      "      6        0.0324  7.9087\n",
      "      7        0.0351  7.8943\n",
      "      8        0.0325  7.8987\n",
      "      9        0.0326  7.8872\n",
      "     10        0.0367  7.9151\n",
      "     11        0.0327  7.8845\n",
      "     12        0.0305  7.9044\n",
      "     13        0.0334  7.9277\n",
      "     14        0.0351  7.9049\n",
      "     15        0.0340  7.9365\n",
      "     16        \u001b[36m0.0278\u001b[0m  7.9039\n",
      "     17        \u001b[36m0.0266\u001b[0m  7.8899\n",
      "     18        0.0298  7.9549\n",
      "     19        0.0283  7.8894\n",
      "     20        0.0316  7.9062\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3563\u001b[0m  7.9187\n",
      "      2        \u001b[36m0.0538\u001b[0m  7.9091\n",
      "      3        \u001b[36m0.0384\u001b[0m  7.9111\n",
      "      4        \u001b[36m0.0336\u001b[0m  7.9023\n",
      "      5        0.0355  7.9264\n",
      "      6        0.0369  7.9020\n",
      "      7        0.0386  7.9039\n",
      "      8        0.0367  7.9661\n",
      "      9        0.0362  8.0128\n",
      "     10        0.0371  7.9049\n",
      "     11        0.0348  7.9097\n",
      "     12        0.0378  7.8974\n",
      "     13        0.0362  7.9823\n",
      "     14        0.0347  7.9041\n",
      "     15        0.0355  7.9097\n",
      "     16        \u001b[36m0.0332\u001b[0m  7.9412\n",
      "     17        0.0333  7.9286\n",
      "     18        \u001b[36m0.0326\u001b[0m  8.0030\n",
      "     19        \u001b[36m0.0317\u001b[0m  7.9390\n",
      "     20        0.0336  7.9013\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6166\u001b[0m  7.8967\n",
      "      2        \u001b[36m0.0491\u001b[0m  7.9005\n",
      "      3        \u001b[36m0.0353\u001b[0m  7.9542\n",
      "      4        \u001b[36m0.0329\u001b[0m  7.9808\n",
      "      5        \u001b[36m0.0310\u001b[0m  8.0294\n",
      "      6        0.0330  7.9411\n",
      "      7        0.0340  7.9175\n",
      "      8        0.0341  7.9726\n",
      "      9        0.0332  7.9184\n",
      "     10        0.0369  7.9355\n",
      "     11        0.0352  7.9810\n",
      "     12        0.0343  7.9812\n",
      "     13        0.0357  7.9393\n",
      "     14        0.0335  7.9225\n",
      "     15        0.0359  7.9180\n",
      "     16        \u001b[36m0.0305\u001b[0m  7.9711\n",
      "     17        0.0306  7.9183\n",
      "     18        \u001b[36m0.0269\u001b[0m  8.0619\n",
      "     19        0.0320  7.9149\n",
      "     20        0.0314  7.9050\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m6.3242\u001b[0m  8.0531\n",
      "      2        \u001b[36m0.0749\u001b[0m  8.0275\n",
      "      3        \u001b[36m0.0472\u001b[0m  8.0474\n",
      "      4        \u001b[36m0.0356\u001b[0m  8.0790\n",
      "      5        \u001b[36m0.0325\u001b[0m  8.0621\n",
      "      6        0.0328  8.1292\n",
      "      7        \u001b[36m0.0318\u001b[0m  8.0990\n",
      "      8        0.0346  8.2015\n",
      "      9        0.0392  8.0573\n",
      "     10        0.0443  8.1433\n",
      "     11        0.0424  8.0951\n",
      "     12        0.0404  8.1206\n",
      "     13        0.0395  8.1190\n",
      "     14        0.0371  8.0735\n",
      "     15        0.0370  8.0641\n",
      "     16        0.0378  8.0992\n",
      "     17        0.0369  8.1266\n",
      "     18        0.0397  8.0536\n",
      "     19        0.0371  8.1047\n",
      "     20        0.0364  8.0465\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.2682\u001b[0m  8.0732\n",
      "      2        \u001b[36m0.0750\u001b[0m  8.0577\n",
      "      3        \u001b[36m0.0474\u001b[0m  8.0856\n",
      "      4        \u001b[36m0.0381\u001b[0m  8.1766\n",
      "      5        \u001b[36m0.0330\u001b[0m  8.1846\n",
      "      6        \u001b[36m0.0310\u001b[0m  8.0666\n",
      "      7        0.0347  8.1357\n",
      "      8        0.0354  8.0687\n",
      "      9        0.0358  8.1433\n",
      "     10        0.0424  8.0882\n",
      "     11        0.0397  8.0502\n",
      "     12        0.0351  8.0455\n",
      "     13        0.0348  8.0486\n",
      "     14        0.0368  8.0425\n",
      "     15        0.0359  8.0562\n",
      "     16        0.0359  8.0480\n",
      "     17        0.0365  8.0391\n",
      "     18        0.0387  8.0438\n",
      "     19        0.0336  8.0537\n",
      "     20        0.0348  8.0464\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.6316\u001b[0m  8.0349\n",
      "      2        \u001b[36m0.0661\u001b[0m  8.0730\n",
      "      3        \u001b[36m0.0414\u001b[0m  8.0409\n",
      "      4        \u001b[36m0.0303\u001b[0m  8.0429\n",
      "      5        \u001b[36m0.0278\u001b[0m  8.0427\n",
      "      6        0.0290  8.0466\n",
      "      7        0.0300  8.0609\n",
      "      8        0.0303  8.1694\n",
      "      9        0.0383  8.0401\n",
      "     10        0.0390  8.0498\n",
      "     11        0.0389  8.0478\n",
      "     12        0.0364  8.0468\n",
      "     13        0.0402  8.0338\n",
      "     14        0.0342  8.0533\n",
      "     15        0.0353  8.0424\n",
      "     16        0.0305  8.0505\n",
      "     17        0.0356  8.0608\n",
      "     18        0.0332  8.0462\n",
      "     19        0.0346  8.0210\n",
      "     20        0.0349  8.0446\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.5216\u001b[0m  8.0412\n",
      "      2        \u001b[36m0.0748\u001b[0m  8.0285\n",
      "      3        \u001b[36m0.0475\u001b[0m  8.0440\n",
      "      4        \u001b[36m0.0383\u001b[0m  8.0448\n",
      "      5        \u001b[36m0.0338\u001b[0m  8.0541\n",
      "      6        \u001b[36m0.0325\u001b[0m  8.0257\n",
      "      7        \u001b[36m0.0316\u001b[0m  8.0476\n",
      "      8        0.0342  8.0323\n",
      "      9        0.0375  8.0479\n",
      "     10        0.0396  8.0299\n",
      "     11        0.0359  8.0611\n",
      "     12        0.0385  8.0558\n",
      "     13        0.0370  8.0526\n",
      "     14        0.0400  8.0425\n",
      "     15        0.0321  8.0438\n",
      "     16        0.0366  8.0347\n",
      "     17        0.0332  8.0322\n",
      "     18        0.0350  8.0399\n",
      "     19        0.0378  8.0542\n",
      "     20        0.0323  8.0455\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.4027\u001b[0m  8.0396\n",
      "      2        \u001b[36m0.0747\u001b[0m  8.0496\n",
      "      3        \u001b[36m0.0460\u001b[0m  8.0402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.0355\u001b[0m  8.0536\n",
      "      5        \u001b[36m0.0296\u001b[0m  8.0375\n",
      "      6        0.0310  8.0692\n",
      "      7        0.0331  8.0462\n",
      "      8        0.0315  8.0504\n",
      "      9        0.0383  8.0350\n",
      "     10        0.0358  8.0306\n",
      "     11        0.0368  8.0305\n",
      "     12        0.0385  8.0476\n",
      "     13        0.0363  8.0428\n",
      "     14        0.0361  8.0534\n",
      "     15        0.0337  8.0487\n",
      "     16        0.0311  8.0467\n",
      "     17        0.0318  8.0294\n",
      "     18        0.0348  8.0419\n",
      "     19        0.0389  8.0248\n",
      "     20        0.0314  8.1536\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6003\u001b[0m  7.5807\n",
      "      2        \u001b[36m0.0899\u001b[0m  7.7253\n",
      "      3        \u001b[36m0.0610\u001b[0m  7.8159\n",
      "      4        \u001b[36m0.0489\u001b[0m  7.5289\n",
      "      5        \u001b[36m0.0418\u001b[0m  7.6470\n",
      "      6        \u001b[36m0.0380\u001b[0m  7.8423\n",
      "      7        \u001b[36m0.0334\u001b[0m  7.8159\n",
      "      8        \u001b[36m0.0325\u001b[0m  7.3548\n",
      "      9        \u001b[36m0.0296\u001b[0m  7.9678\n",
      "     10        \u001b[36m0.0292\u001b[0m  7.4726\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.8436\u001b[0m  7.3574\n",
      "      2        \u001b[36m0.1021\u001b[0m  7.6388\n",
      "      3        \u001b[36m0.0685\u001b[0m  7.3919\n",
      "      4        \u001b[36m0.0536\u001b[0m  7.3573\n",
      "      5        \u001b[36m0.0422\u001b[0m  7.3643\n",
      "      6        \u001b[36m0.0383\u001b[0m  7.5049\n",
      "      7        \u001b[36m0.0351\u001b[0m  7.7554\n",
      "      8        \u001b[36m0.0331\u001b[0m  7.6856\n",
      "      9        \u001b[36m0.0306\u001b[0m  7.3633\n",
      "     10        \u001b[36m0.0281\u001b[0m  7.3644\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4332\u001b[0m  7.3543\n",
      "      2        \u001b[36m0.0752\u001b[0m  7.3681\n",
      "      3        \u001b[36m0.0495\u001b[0m  7.3522\n",
      "      4        \u001b[36m0.0418\u001b[0m  7.3547\n",
      "      5        \u001b[36m0.0349\u001b[0m  7.3586\n",
      "      6        \u001b[36m0.0312\u001b[0m  7.3605\n",
      "      7        \u001b[36m0.0294\u001b[0m  7.3530\n",
      "      8        \u001b[36m0.0282\u001b[0m  7.3575\n",
      "      9        \u001b[36m0.0248\u001b[0m  7.3477\n",
      "     10        0.0275  7.3737\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4958\u001b[0m  7.3612\n",
      "      2        \u001b[36m0.0846\u001b[0m  7.3637\n",
      "      3        \u001b[36m0.0578\u001b[0m  7.3990\n",
      "      4        \u001b[36m0.0464\u001b[0m  7.3627\n",
      "      5        \u001b[36m0.0388\u001b[0m  7.4048\n",
      "      6        \u001b[36m0.0351\u001b[0m  7.3565\n",
      "      7        \u001b[36m0.0331\u001b[0m  7.3614\n",
      "      8        \u001b[36m0.0318\u001b[0m  7.3610\n",
      "      9        \u001b[36m0.0304\u001b[0m  7.6744\n",
      "     10        \u001b[36m0.0275\u001b[0m  7.6261\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5684\u001b[0m  7.4406\n",
      "      2        \u001b[36m0.0793\u001b[0m  7.3927\n",
      "      3        \u001b[36m0.0544\u001b[0m  7.5998\n",
      "      4        \u001b[36m0.0420\u001b[0m  7.3615\n",
      "      5        \u001b[36m0.0354\u001b[0m  7.4895\n",
      "      6        \u001b[36m0.0310\u001b[0m  7.6817\n",
      "      7        \u001b[36m0.0298\u001b[0m  7.3560\n",
      "      8        \u001b[36m0.0271\u001b[0m  7.6521\n",
      "      9        \u001b[36m0.0258\u001b[0m  7.4323\n",
      "     10        \u001b[36m0.0256\u001b[0m  7.6922\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3799\u001b[0m  7.5019\n",
      "      2        \u001b[36m0.0906\u001b[0m  7.5446\n",
      "      3        \u001b[36m0.0635\u001b[0m  7.6992\n",
      "      4        \u001b[36m0.0494\u001b[0m  7.9751\n",
      "      5        \u001b[36m0.0410\u001b[0m  7.7432\n",
      "      6        \u001b[36m0.0379\u001b[0m  7.5600\n",
      "      7        \u001b[36m0.0339\u001b[0m  7.5191\n",
      "      8        \u001b[36m0.0329\u001b[0m  7.5049\n",
      "      9        \u001b[36m0.0307\u001b[0m  7.4867\n",
      "     10        \u001b[36m0.0301\u001b[0m  7.4929\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.6210\u001b[0m  8.1143\n",
      "      2        \u001b[36m0.1069\u001b[0m  7.7376\n",
      "      3        \u001b[36m0.0783\u001b[0m  7.4897\n",
      "      4        \u001b[36m0.0621\u001b[0m  7.5537\n",
      "      5        \u001b[36m0.0505\u001b[0m  7.5034\n",
      "      6        \u001b[36m0.0435\u001b[0m  7.5409\n",
      "      7        \u001b[36m0.0373\u001b[0m  7.5884\n",
      "      8        \u001b[36m0.0343\u001b[0m  7.8553\n",
      "      9        \u001b[36m0.0313\u001b[0m  7.4986\n",
      "     10        \u001b[36m0.0301\u001b[0m  8.0896\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.8092\u001b[0m  7.5752\n",
      "      2        \u001b[36m0.0947\u001b[0m  7.5168\n",
      "      3        \u001b[36m0.0658\u001b[0m  7.8347\n",
      "      4        \u001b[36m0.0506\u001b[0m  7.5006\n",
      "      5        \u001b[36m0.0389\u001b[0m  8.0126\n",
      "      6        \u001b[36m0.0354\u001b[0m  7.6640\n",
      "      7        \u001b[36m0.0329\u001b[0m  7.4975\n",
      "      8        \u001b[36m0.0292\u001b[0m  7.4958\n",
      "      9        \u001b[36m0.0271\u001b[0m  7.5103\n",
      "     10        \u001b[36m0.0251\u001b[0m  7.5398\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.8380\u001b[0m  7.4998\n",
      "      2        \u001b[36m0.0984\u001b[0m  7.4930\n",
      "      3        \u001b[36m0.0709\u001b[0m  7.4967\n",
      "      4        \u001b[36m0.0546\u001b[0m  7.4963\n",
      "      5        \u001b[36m0.0460\u001b[0m  7.4926\n",
      "      6        \u001b[36m0.0397\u001b[0m  7.4923\n",
      "      7        \u001b[36m0.0362\u001b[0m  7.5876\n",
      "      8        \u001b[36m0.0336\u001b[0m  7.6108\n",
      "      9        \u001b[36m0.0305\u001b[0m  7.5347\n",
      "     10        \u001b[36m0.0274\u001b[0m  7.5629\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.3021\u001b[0m  7.5675\n",
      "      2        \u001b[36m0.1066\u001b[0m  7.4978\n",
      "      3        \u001b[36m0.0766\u001b[0m  7.6529\n",
      "      4        \u001b[36m0.0587\u001b[0m  7.5035\n",
      "      5        \u001b[36m0.0478\u001b[0m  7.6471\n",
      "      6        \u001b[36m0.0401\u001b[0m  7.6941\n",
      "      7        \u001b[36m0.0364\u001b[0m  7.5147\n",
      "      8        \u001b[36m0.0326\u001b[0m  7.4925\n",
      "      9        \u001b[36m0.0281\u001b[0m  7.6460\n",
      "     10        \u001b[36m0.0263\u001b[0m  7.4946\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3196\u001b[0m  7.5826\n",
      "      2        \u001b[36m0.0592\u001b[0m  7.5705\n",
      "      3        \u001b[36m0.0375\u001b[0m  7.5867\n",
      "      4        \u001b[36m0.0272\u001b[0m  7.5873\n",
      "      5        \u001b[36m0.0234\u001b[0m  7.5769\n",
      "      6        \u001b[36m0.0198\u001b[0m  7.9256\n",
      "      7        \u001b[36m0.0194\u001b[0m  7.6096\n",
      "      8        \u001b[36m0.0189\u001b[0m  7.5809\n",
      "      9        \u001b[36m0.0171\u001b[0m  7.5732\n",
      "     10        0.0174  7.5732\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2613\u001b[0m  7.6056\n",
      "      2        \u001b[36m0.0595\u001b[0m  7.6567\n",
      "      3        \u001b[36m0.0378\u001b[0m  7.5895\n",
      "      4        \u001b[36m0.0283\u001b[0m  7.5848\n",
      "      5        \u001b[36m0.0235\u001b[0m  7.5947\n",
      "      6        \u001b[36m0.0218\u001b[0m  7.7084\n",
      "      7        \u001b[36m0.0194\u001b[0m  7.5887\n",
      "      8        \u001b[36m0.0192\u001b[0m  7.5905\n",
      "      9        \u001b[36m0.0180\u001b[0m  7.5790\n",
      "     10        \u001b[36m0.0171\u001b[0m  7.8780\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1793\u001b[0m  7.8305\n",
      "      2        \u001b[36m0.0412\u001b[0m  7.5850\n",
      "      3        \u001b[36m0.0246\u001b[0m  7.5829\n",
      "      4        \u001b[36m0.0185\u001b[0m  7.7007\n",
      "      5        \u001b[36m0.0168\u001b[0m  7.5729\n",
      "      6        \u001b[36m0.0152\u001b[0m  7.6051\n",
      "      7        \u001b[36m0.0139\u001b[0m  7.5953\n",
      "      8        \u001b[36m0.0134\u001b[0m  7.5923\n",
      "      9        0.0137  7.5751\n",
      "     10        0.0141  7.5778\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3320\u001b[0m  7.5903\n",
      "      2        \u001b[36m0.0497\u001b[0m  7.5832\n",
      "      3        \u001b[36m0.0321\u001b[0m  7.5927\n",
      "      4        \u001b[36m0.0250\u001b[0m  7.5992\n",
      "      5        \u001b[36m0.0206\u001b[0m  7.5945\n",
      "      6        \u001b[36m0.0193\u001b[0m  7.6104\n",
      "      7        \u001b[36m0.0192\u001b[0m  7.5904\n",
      "      8        \u001b[36m0.0184\u001b[0m  7.5908\n",
      "      9        \u001b[36m0.0165\u001b[0m  7.5982\n",
      "     10        0.0176  7.5976\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4179\u001b[0m  7.6181\n",
      "      2        \u001b[36m0.0470\u001b[0m  7.6177\n",
      "      3        \u001b[36m0.0297\u001b[0m  7.6771\n",
      "      4        \u001b[36m0.0221\u001b[0m  7.5742\n",
      "      5        \u001b[36m0.0172\u001b[0m  7.5746\n",
      "      6        \u001b[36m0.0165\u001b[0m  7.5720\n",
      "      7        \u001b[36m0.0146\u001b[0m  7.5731\n",
      "      8        \u001b[36m0.0141\u001b[0m  7.5841\n",
      "      9        0.0151  7.5857\n",
      "     10        0.0146  7.6065\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m9.6738\u001b[0m  7.7594\n",
      "      2        \u001b[36m0.0853\u001b[0m  7.7531\n",
      "      3        \u001b[36m0.0501\u001b[0m  7.7611\n",
      "      4        \u001b[36m0.0368\u001b[0m  7.7661\n",
      "      5        \u001b[36m0.0303\u001b[0m  7.7726\n",
      "      6        \u001b[36m0.0260\u001b[0m  7.7652\n",
      "      7        \u001b[36m0.0227\u001b[0m  7.8019\n",
      "      8        \u001b[36m0.0201\u001b[0m  7.7832\n",
      "      9        \u001b[36m0.0191\u001b[0m  7.7694\n",
      "     10        \u001b[36m0.0177\u001b[0m  7.7623\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m4.5700\u001b[0m  7.7641\n",
      "      2        \u001b[36m0.0626\u001b[0m  7.7580\n",
      "      3        \u001b[36m0.0390\u001b[0m  7.7588\n",
      "      4        \u001b[36m0.0290\u001b[0m  7.7587\n",
      "      5        \u001b[36m0.0230\u001b[0m  7.7701\n",
      "      6        \u001b[36m0.0214\u001b[0m  7.7708\n",
      "      7        \u001b[36m0.0204\u001b[0m  7.7643\n",
      "      8        \u001b[36m0.0173\u001b[0m  7.7631\n",
      "      9        0.0189  7.7685\n",
      "     10        \u001b[36m0.0158\u001b[0m  7.7617\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m10.1224\u001b[0m  7.7800\n",
      "      2        \u001b[36m0.0707\u001b[0m  7.7824\n",
      "      3        \u001b[36m0.0422\u001b[0m  7.7800\n",
      "      4        \u001b[36m0.0305\u001b[0m  7.7651\n",
      "      5        \u001b[36m0.0231\u001b[0m  7.7584\n",
      "      6        \u001b[36m0.0196\u001b[0m  7.7591\n",
      "      7        \u001b[36m0.0172\u001b[0m  7.7599\n",
      "      8        \u001b[36m0.0150\u001b[0m  7.7844\n",
      "      9        \u001b[36m0.0141\u001b[0m  7.7585\n",
      "     10        \u001b[36m0.0128\u001b[0m  7.7673\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m9.3670\u001b[0m  7.7810\n",
      "      2        \u001b[36m0.0790\u001b[0m  7.7705\n",
      "      3        \u001b[36m0.0490\u001b[0m  7.7652\n",
      "      4        \u001b[36m0.0361\u001b[0m  7.7635\n",
      "      5        \u001b[36m0.0296\u001b[0m  7.7709\n",
      "      6        \u001b[36m0.0247\u001b[0m  7.7679\n",
      "      7        \u001b[36m0.0216\u001b[0m  7.7661\n",
      "      8        \u001b[36m0.0207\u001b[0m  7.8043\n",
      "      9        \u001b[36m0.0176\u001b[0m  7.8349\n",
      "     10        0.0178  7.7660\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m11.6379\u001b[0m  7.7617\n",
      "      2        \u001b[36m0.1191\u001b[0m  7.7658\n",
      "      3        \u001b[36m0.0555\u001b[0m  7.7676\n",
      "      4        \u001b[36m0.0378\u001b[0m  7.7626\n",
      "      5        \u001b[36m0.0287\u001b[0m  7.7605\n",
      "      6        \u001b[36m0.0236\u001b[0m  7.7687\n",
      "      7        \u001b[36m0.0196\u001b[0m  7.7648\n",
      "      8        \u001b[36m0.0180\u001b[0m  7.7718\n",
      "      9        \u001b[36m0.0163\u001b[0m  7.7685\n",
      "     10        \u001b[36m0.0151\u001b[0m  7.7682\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7589\u001b[0m  7.3546\n",
      "      2        \u001b[36m0.1100\u001b[0m  7.3607\n",
      "      3        \u001b[36m0.0782\u001b[0m  7.4003\n",
      "      4        \u001b[36m0.0659\u001b[0m  7.3723\n",
      "      5        \u001b[36m0.0539\u001b[0m  7.3610\n",
      "      6        \u001b[36m0.0478\u001b[0m  7.3544\n",
      "      7        \u001b[36m0.0452\u001b[0m  7.3637\n",
      "      8        \u001b[36m0.0409\u001b[0m  7.6565\n",
      "      9        \u001b[36m0.0400\u001b[0m  7.5554\n",
      "     10        \u001b[36m0.0379\u001b[0m  7.3637\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4404\u001b[0m  7.3769\n",
      "      2        \u001b[36m0.0914\u001b[0m  7.3671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m0.0659\u001b[0m  7.3696\n",
      "      4        \u001b[36m0.0558\u001b[0m  7.3601\n",
      "      5        \u001b[36m0.0487\u001b[0m  7.3604\n",
      "      6        \u001b[36m0.0452\u001b[0m  7.3677\n",
      "      7        \u001b[36m0.0415\u001b[0m  7.4362\n",
      "      8        \u001b[36m0.0412\u001b[0m  7.3707\n",
      "      9        \u001b[36m0.0384\u001b[0m  7.4019\n",
      "     10        \u001b[36m0.0362\u001b[0m  7.5003\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6619\u001b[0m  7.7705\n",
      "      2        \u001b[36m0.0971\u001b[0m  7.3682\n",
      "      3        \u001b[36m0.0665\u001b[0m  7.4349\n",
      "      4        \u001b[36m0.0568\u001b[0m  7.3678\n",
      "      5        \u001b[36m0.0459\u001b[0m  7.8743\n",
      "      6        \u001b[36m0.0423\u001b[0m  7.7622\n",
      "      7        \u001b[36m0.0400\u001b[0m  7.7804\n",
      "      8        \u001b[36m0.0362\u001b[0m  7.7716\n",
      "      9        \u001b[36m0.0351\u001b[0m  7.8898\n",
      "     10        \u001b[36m0.0346\u001b[0m  7.3651\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4313\u001b[0m  7.3646\n",
      "      2        \u001b[36m0.0931\u001b[0m  7.3629\n",
      "      3        \u001b[36m0.0656\u001b[0m  7.3641\n",
      "      4        \u001b[36m0.0547\u001b[0m  7.3630\n",
      "      5        \u001b[36m0.0502\u001b[0m  7.4512\n",
      "      6        \u001b[36m0.0449\u001b[0m  7.3656\n",
      "      7        \u001b[36m0.0412\u001b[0m  7.5882\n",
      "      8        \u001b[36m0.0407\u001b[0m  7.3465\n",
      "      9        \u001b[36m0.0378\u001b[0m  7.5288\n",
      "     10        0.0396  7.4262\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4746\u001b[0m  7.3580\n",
      "      2        \u001b[36m0.0914\u001b[0m  7.3602\n",
      "      3        \u001b[36m0.0636\u001b[0m  7.5271\n",
      "      4        \u001b[36m0.0522\u001b[0m  7.6236\n",
      "      5        \u001b[36m0.0469\u001b[0m  7.3510\n",
      "      6        \u001b[36m0.0421\u001b[0m  7.5128\n",
      "      7        \u001b[36m0.0394\u001b[0m  7.3568\n",
      "      8        \u001b[36m0.0375\u001b[0m  7.3588\n",
      "      9        \u001b[36m0.0365\u001b[0m  7.3621\n",
      "     10        \u001b[36m0.0365\u001b[0m  7.3565\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0788\u001b[0m  7.5279\n",
      "      2        \u001b[36m0.1039\u001b[0m  7.9053\n",
      "      3        \u001b[36m0.0719\u001b[0m  7.4907\n",
      "      4        \u001b[36m0.0592\u001b[0m  7.4883\n",
      "      5        \u001b[36m0.0492\u001b[0m  7.4928\n",
      "      6        \u001b[36m0.0459\u001b[0m  7.5562\n",
      "      7        \u001b[36m0.0430\u001b[0m  7.9514\n",
      "      8        \u001b[36m0.0402\u001b[0m  7.6028\n",
      "      9        \u001b[36m0.0387\u001b[0m  7.4973\n",
      "     10        0.0390  7.5504\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3240\u001b[0m  7.4935\n",
      "      2        \u001b[36m0.1020\u001b[0m  7.4893\n",
      "      3        \u001b[36m0.0717\u001b[0m  7.4896\n",
      "      4        \u001b[36m0.0582\u001b[0m  7.4858\n",
      "      5        \u001b[36m0.0506\u001b[0m  7.4843\n",
      "      6        \u001b[36m0.0448\u001b[0m  7.5710\n",
      "      7        \u001b[36m0.0412\u001b[0m  7.5666\n",
      "      8        \u001b[36m0.0401\u001b[0m  7.4893\n",
      "      9        \u001b[36m0.0367\u001b[0m  7.6850\n",
      "     10        0.0388  8.1113\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.9912\u001b[0m  7.4869\n",
      "      2        \u001b[36m0.1048\u001b[0m  7.6023\n",
      "      3        \u001b[36m0.0776\u001b[0m  7.5007\n",
      "      4        \u001b[36m0.0610\u001b[0m  7.4928\n",
      "      5        \u001b[36m0.0498\u001b[0m  7.5876\n",
      "      6        \u001b[36m0.0447\u001b[0m  7.4929\n",
      "      7        \u001b[36m0.0401\u001b[0m  7.8846\n",
      "      8        \u001b[36m0.0377\u001b[0m  7.5735\n",
      "      9        \u001b[36m0.0351\u001b[0m  7.4864\n",
      "     10        \u001b[36m0.0323\u001b[0m  7.8907\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0714\u001b[0m  7.7646\n",
      "      2        \u001b[36m0.0997\u001b[0m  7.6346\n",
      "      3        \u001b[36m0.0714\u001b[0m  8.1266\n",
      "      4        \u001b[36m0.0564\u001b[0m  7.9453\n",
      "      5        \u001b[36m0.0492\u001b[0m  7.7283\n",
      "      6        \u001b[36m0.0436\u001b[0m  7.4772\n",
      "      7        \u001b[36m0.0435\u001b[0m  7.4831\n",
      "      8        \u001b[36m0.0396\u001b[0m  7.4821\n",
      "      9        \u001b[36m0.0385\u001b[0m  7.4818\n",
      "     10        \u001b[36m0.0368\u001b[0m  7.6741\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5569\u001b[0m  7.7752\n",
      "      2        \u001b[36m0.1048\u001b[0m  7.4835\n",
      "      3        \u001b[36m0.0732\u001b[0m  7.4822\n",
      "      4        \u001b[36m0.0574\u001b[0m  7.6611\n",
      "      5        \u001b[36m0.0498\u001b[0m  7.5016\n",
      "      6        \u001b[36m0.0444\u001b[0m  7.7033\n",
      "      7        \u001b[36m0.0408\u001b[0m  7.5080\n",
      "      8        \u001b[36m0.0369\u001b[0m  7.6880\n",
      "      9        \u001b[36m0.0360\u001b[0m  7.7186\n",
      "     10        \u001b[36m0.0340\u001b[0m  7.4886\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3405\u001b[0m  7.7654\n",
      "      2        \u001b[36m0.0557\u001b[0m  7.5915\n",
      "      3        \u001b[36m0.0368\u001b[0m  7.5774\n",
      "      4        \u001b[36m0.0291\u001b[0m  7.5918\n",
      "      5        \u001b[36m0.0246\u001b[0m  7.5885\n",
      "      6        \u001b[36m0.0213\u001b[0m  7.5833\n",
      "      7        0.0215  7.5873\n",
      "      8        \u001b[36m0.0209\u001b[0m  7.5897\n",
      "      9        \u001b[36m0.0204\u001b[0m  7.5839\n",
      "     10        \u001b[36m0.0191\u001b[0m  7.5802\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.0131\u001b[0m  7.5847\n",
      "      2        \u001b[36m0.0637\u001b[0m  7.6721\n",
      "      3        \u001b[36m0.0403\u001b[0m  7.6507\n",
      "      4        \u001b[36m0.0306\u001b[0m  7.8786\n",
      "      5        \u001b[36m0.0263\u001b[0m  8.1839\n",
      "      6        \u001b[36m0.0233\u001b[0m  7.5885\n",
      "      7        \u001b[36m0.0219\u001b[0m  8.0116\n",
      "      8        \u001b[36m0.0212\u001b[0m  8.0655\n",
      "      9        \u001b[36m0.0185\u001b[0m  7.6009\n",
      "     10        0.0204  7.5939\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.8833\u001b[0m  7.5885\n",
      "      2        \u001b[36m0.0628\u001b[0m  7.5787\n",
      "      3        \u001b[36m0.0410\u001b[0m  7.6296\n",
      "      4        \u001b[36m0.0293\u001b[0m  7.5788\n",
      "      5        \u001b[36m0.0228\u001b[0m  7.5810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        \u001b[36m0.0193\u001b[0m  7.5782\n",
      "      7        \u001b[36m0.0188\u001b[0m  7.5839\n",
      "      8        \u001b[36m0.0164\u001b[0m  7.6006\n",
      "      9        0.0167  8.2833\n",
      "     10        \u001b[36m0.0144\u001b[0m  7.5889\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4851\u001b[0m  7.7014\n",
      "      2        \u001b[36m0.0542\u001b[0m  7.5852\n",
      "      3        \u001b[36m0.0364\u001b[0m  7.5763\n",
      "      4        \u001b[36m0.0287\u001b[0m  7.5798\n",
      "      5        \u001b[36m0.0246\u001b[0m  7.6767\n",
      "      6        \u001b[36m0.0222\u001b[0m  7.5884\n",
      "      7        \u001b[36m0.0212\u001b[0m  7.6565\n",
      "      8        \u001b[36m0.0198\u001b[0m  7.6208\n",
      "      9        0.0206  7.5881\n",
      "     10        0.0199  7.5778\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6885\u001b[0m  7.5834\n",
      "      2        \u001b[36m0.0544\u001b[0m  7.5815\n",
      "      3        \u001b[36m0.0339\u001b[0m  7.5829\n",
      "      4        \u001b[36m0.0252\u001b[0m  7.6117\n",
      "      5        \u001b[36m0.0211\u001b[0m  7.5773\n",
      "      6        \u001b[36m0.0186\u001b[0m  7.8258\n",
      "      7        \u001b[36m0.0178\u001b[0m  7.5832\n",
      "      8        \u001b[36m0.0171\u001b[0m  7.5864\n",
      "      9        \u001b[36m0.0169\u001b[0m  7.5810\n",
      "     10        \u001b[36m0.0163\u001b[0m  7.5821\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m10.1649\u001b[0m  8.0063\n",
      "      2        \u001b[36m0.0930\u001b[0m  7.7678\n",
      "      3        \u001b[36m0.0575\u001b[0m  7.7630\n",
      "      4        \u001b[36m0.0433\u001b[0m  7.7591\n",
      "      5        \u001b[36m0.0356\u001b[0m  7.7598\n",
      "      6        \u001b[36m0.0297\u001b[0m  7.7636\n",
      "      7        \u001b[36m0.0268\u001b[0m  7.7589\n",
      "      8        \u001b[36m0.0242\u001b[0m  7.7596\n",
      "      9        \u001b[36m0.0216\u001b[0m  7.7967\n",
      "     10        \u001b[36m0.0207\u001b[0m  7.7668\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.5188\u001b[0m  7.8759\n",
      "      2        \u001b[36m0.0750\u001b[0m  7.7704\n",
      "      3        \u001b[36m0.0490\u001b[0m  7.7749\n",
      "      4        \u001b[36m0.0367\u001b[0m  7.7693\n",
      "      5        \u001b[36m0.0287\u001b[0m  7.7842\n",
      "      6        \u001b[36m0.0256\u001b[0m  7.7575\n",
      "      7        \u001b[36m0.0223\u001b[0m  7.7728\n",
      "      8        \u001b[36m0.0216\u001b[0m  7.7588\n",
      "      9        \u001b[36m0.0208\u001b[0m  7.7697\n",
      "     10        \u001b[36m0.0200\u001b[0m  7.7857\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m8.4116\u001b[0m  7.7604\n",
      "      2        \u001b[36m0.0792\u001b[0m  7.7653\n",
      "      3        \u001b[36m0.0481\u001b[0m  7.7507\n",
      "      4        \u001b[36m0.0353\u001b[0m  7.8231\n",
      "      5        \u001b[36m0.0282\u001b[0m  7.7699\n",
      "      6        \u001b[36m0.0225\u001b[0m  7.7595\n",
      "      7        \u001b[36m0.0203\u001b[0m  7.7559\n",
      "      8        \u001b[36m0.0170\u001b[0m  7.9361\n",
      "      9        \u001b[36m0.0166\u001b[0m  7.8061\n",
      "     10        \u001b[36m0.0160\u001b[0m  7.7664\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m7.0500\u001b[0m  7.7969\n",
      "      2        \u001b[36m0.0808\u001b[0m  7.7616\n",
      "      3        \u001b[36m0.0508\u001b[0m  7.8803\n",
      "      4        \u001b[36m0.0384\u001b[0m  7.9913\n",
      "      5        \u001b[36m0.0301\u001b[0m  8.2247\n",
      "      6        \u001b[36m0.0261\u001b[0m  7.8628\n",
      "      7        \u001b[36m0.0231\u001b[0m  7.7633\n",
      "      8        \u001b[36m0.0216\u001b[0m  7.7558\n",
      "      9        \u001b[36m0.0200\u001b[0m  7.7735\n",
      "     10        \u001b[36m0.0196\u001b[0m  7.8819\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m10.2429\u001b[0m  7.7957\n",
      "      2        \u001b[36m0.0962\u001b[0m  8.1506\n",
      "      3        \u001b[36m0.0546\u001b[0m  7.9870\n",
      "      4        \u001b[36m0.0383\u001b[0m  7.7481\n",
      "      5        \u001b[36m0.0291\u001b[0m  7.7531\n",
      "      6        \u001b[36m0.0255\u001b[0m  7.7561\n",
      "      7        \u001b[36m0.0207\u001b[0m  7.7584\n",
      "      8        \u001b[36m0.0191\u001b[0m  7.9361\n",
      "      9        \u001b[36m0.0174\u001b[0m  8.0417\n",
      "     10        0.0179  7.7530\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4970\u001b[0m  7.8776\n",
      "      2        \u001b[36m0.1125\u001b[0m  7.4375\n",
      "      3        \u001b[36m0.0859\u001b[0m  7.4254\n",
      "      4        \u001b[36m0.0705\u001b[0m  7.3497\n",
      "      5        \u001b[36m0.0645\u001b[0m  7.8517\n",
      "      6        \u001b[36m0.0620\u001b[0m  7.9003\n",
      "      7        \u001b[36m0.0567\u001b[0m  7.3870\n",
      "      8        \u001b[36m0.0543\u001b[0m  7.3411\n",
      "      9        \u001b[36m0.0513\u001b[0m  7.5179\n",
      "     10        0.0529  7.8805\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4747\u001b[0m  7.9488\n",
      "      2        \u001b[36m0.1105\u001b[0m  7.4634\n",
      "      3        \u001b[36m0.0837\u001b[0m  7.4514\n",
      "      4        \u001b[36m0.0728\u001b[0m  7.7699\n",
      "      5        \u001b[36m0.0635\u001b[0m  7.3486\n",
      "      6        \u001b[36m0.0623\u001b[0m  7.3477\n",
      "      7        \u001b[36m0.0579\u001b[0m  7.3455\n",
      "      8        \u001b[36m0.0554\u001b[0m  7.3460\n",
      "      9        0.0555  7.3503\n",
      "     10        \u001b[36m0.0549\u001b[0m  7.4919\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4823\u001b[0m  7.4162\n",
      "      2        \u001b[36m0.1040\u001b[0m  7.3521\n",
      "      3        \u001b[36m0.0799\u001b[0m  7.5857\n",
      "      4        \u001b[36m0.0662\u001b[0m  7.8438\n",
      "      5        \u001b[36m0.0627\u001b[0m  7.3483\n",
      "      6        \u001b[36m0.0531\u001b[0m  7.3544\n",
      "      7        \u001b[36m0.0526\u001b[0m  7.8806\n",
      "      8        \u001b[36m0.0492\u001b[0m  7.3795\n",
      "      9        \u001b[36m0.0485\u001b[0m  7.3514\n",
      "     10        0.0489  7.3501\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5548\u001b[0m  7.3488\n",
      "      2        \u001b[36m0.1136\u001b[0m  7.3456\n",
      "      3        \u001b[36m0.0833\u001b[0m  7.6033\n",
      "      4        \u001b[36m0.0714\u001b[0m  7.8086\n",
      "      5        \u001b[36m0.0635\u001b[0m  7.3470\n",
      "      6        \u001b[36m0.0589\u001b[0m  7.3777\n",
      "      7        \u001b[36m0.0561\u001b[0m  7.3393\n",
      "      8        \u001b[36m0.0551\u001b[0m  7.6126\n",
      "      9        \u001b[36m0.0533\u001b[0m  7.7620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        \u001b[36m0.0523\u001b[0m  7.6796\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5105\u001b[0m  7.8208\n",
      "      2        \u001b[36m0.1063\u001b[0m  7.3359\n",
      "      3        \u001b[36m0.0808\u001b[0m  7.3370\n",
      "      4        \u001b[36m0.0692\u001b[0m  7.3446\n",
      "      5        \u001b[36m0.0616\u001b[0m  7.3479\n",
      "      6        \u001b[36m0.0572\u001b[0m  7.3417\n",
      "      7        \u001b[36m0.0541\u001b[0m  7.6149\n",
      "      8        \u001b[36m0.0509\u001b[0m  7.6386\n",
      "      9        0.0515  7.3411\n",
      "     10        \u001b[36m0.0491\u001b[0m  7.4466\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.0572\u001b[0m  7.4736\n",
      "      2        \u001b[36m0.1335\u001b[0m  7.7806\n",
      "      3        \u001b[36m0.0960\u001b[0m  7.6500\n",
      "      4        \u001b[36m0.0792\u001b[0m  8.0437\n",
      "      5        \u001b[36m0.0672\u001b[0m  7.8028\n",
      "      6        \u001b[36m0.0630\u001b[0m  7.4751\n",
      "      7        \u001b[36m0.0561\u001b[0m  7.5945\n",
      "      8        \u001b[36m0.0530\u001b[0m  7.6305\n",
      "      9        0.0541  7.6215\n",
      "     10        \u001b[36m0.0523\u001b[0m  7.5423\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3721\u001b[0m  7.4754\n",
      "      2        \u001b[36m0.1228\u001b[0m  7.4666\n",
      "      3        \u001b[36m0.0910\u001b[0m  7.6837\n",
      "      4        \u001b[36m0.0758\u001b[0m  8.0599\n",
      "      5        \u001b[36m0.0667\u001b[0m  8.1073\n",
      "      6        \u001b[36m0.0595\u001b[0m  7.6265\n",
      "      7        \u001b[36m0.0574\u001b[0m  7.4917\n",
      "      8        \u001b[36m0.0553\u001b[0m  7.6335\n",
      "      9        \u001b[36m0.0545\u001b[0m  7.5364\n",
      "     10        \u001b[36m0.0506\u001b[0m  7.4673\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5895\u001b[0m  7.4681\n",
      "      2        \u001b[36m0.1235\u001b[0m  7.4771\n",
      "      3        \u001b[36m0.0895\u001b[0m  7.4628\n",
      "      4        \u001b[36m0.0728\u001b[0m  7.5745\n",
      "      5        \u001b[36m0.0646\u001b[0m  7.5123\n",
      "      6        \u001b[36m0.0573\u001b[0m  7.4788\n",
      "      7        \u001b[36m0.0510\u001b[0m  7.5388\n",
      "      8        0.0531  7.9211\n",
      "      9        0.0524  7.9738\n",
      "     10        \u001b[36m0.0481\u001b[0m  7.7003\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.8705\u001b[0m  8.0122\n",
      "      2        \u001b[36m0.1307\u001b[0m  7.9336\n",
      "      3        \u001b[36m0.0962\u001b[0m  7.8927\n",
      "      4        \u001b[36m0.0784\u001b[0m  7.9116\n",
      "      5        \u001b[36m0.0707\u001b[0m  7.6429\n",
      "      6        \u001b[36m0.0617\u001b[0m  7.4898\n",
      "      7        \u001b[36m0.0568\u001b[0m  8.0643\n",
      "      8        \u001b[36m0.0541\u001b[0m  7.6177\n",
      "      9        0.0551  7.6194\n",
      "     10        \u001b[36m0.0538\u001b[0m  7.4814\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1782\u001b[0m  8.0395\n",
      "      2        \u001b[36m0.1270\u001b[0m  7.4895\n",
      "      3        \u001b[36m0.0969\u001b[0m  7.4787\n",
      "      4        \u001b[36m0.0758\u001b[0m  7.4805\n",
      "      5        \u001b[36m0.0649\u001b[0m  7.4832\n",
      "      6        \u001b[36m0.0606\u001b[0m  7.4788\n",
      "      7        \u001b[36m0.0536\u001b[0m  7.4840\n",
      "      8        \u001b[36m0.0529\u001b[0m  7.5079\n",
      "      9        \u001b[36m0.0517\u001b[0m  7.5087\n",
      "     10        \u001b[36m0.0491\u001b[0m  7.4846\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.6131\u001b[0m  7.5793\n",
      "      2        \u001b[36m0.0749\u001b[0m  7.5805\n",
      "      3        \u001b[36m0.0473\u001b[0m  7.5786\n",
      "      4        \u001b[36m0.0389\u001b[0m  7.6348\n",
      "      5        \u001b[36m0.0311\u001b[0m  7.5747\n",
      "      6        \u001b[36m0.0297\u001b[0m  7.5796\n",
      "      7        \u001b[36m0.0272\u001b[0m  7.6914\n",
      "      8        \u001b[36m0.0254\u001b[0m  7.5922\n",
      "      9        \u001b[36m0.0245\u001b[0m  7.5840\n",
      "     10        0.0252  7.5761\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3950\u001b[0m  7.5795\n",
      "      2        \u001b[36m0.0627\u001b[0m  7.5698\n",
      "      3        \u001b[36m0.0436\u001b[0m  7.5902\n",
      "      4        \u001b[36m0.0345\u001b[0m  7.7787\n",
      "      5        \u001b[36m0.0297\u001b[0m  7.5851\n",
      "      6        \u001b[36m0.0272\u001b[0m  7.5719\n",
      "      7        \u001b[36m0.0261\u001b[0m  7.5778\n",
      "      8        \u001b[36m0.0260\u001b[0m  7.5811\n",
      "      9        \u001b[36m0.0242\u001b[0m  7.5837\n",
      "     10        0.0276  7.5780\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6808\u001b[0m  7.6287\n",
      "      2        \u001b[36m0.0645\u001b[0m  7.5964\n",
      "      3        \u001b[36m0.0407\u001b[0m  7.5857\n",
      "      4        \u001b[36m0.0311\u001b[0m  7.5745\n",
      "      5        \u001b[36m0.0264\u001b[0m  7.5823\n",
      "      6        \u001b[36m0.0233\u001b[0m  7.5785\n",
      "      7        \u001b[36m0.0216\u001b[0m  7.5917\n",
      "      8        0.0216  7.5763\n",
      "      9        \u001b[36m0.0201\u001b[0m  7.5923\n",
      "     10        0.0215  7.7880\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.8412\u001b[0m  7.5797\n",
      "      2        \u001b[36m0.0799\u001b[0m  7.7027\n",
      "      3        \u001b[36m0.0507\u001b[0m  7.6767\n",
      "      4        \u001b[36m0.0381\u001b[0m  7.5720\n",
      "      5        \u001b[36m0.0321\u001b[0m  7.5866\n",
      "      6        \u001b[36m0.0283\u001b[0m  7.5844\n",
      "      7        \u001b[36m0.0270\u001b[0m  7.7143\n",
      "      8        \u001b[36m0.0243\u001b[0m  7.6094\n",
      "      9        \u001b[36m0.0231\u001b[0m  7.5915\n",
      "     10        0.0257  7.5939\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.0335\u001b[0m  7.6632\n",
      "      2        \u001b[36m0.0748\u001b[0m  7.7954\n",
      "      3        \u001b[36m0.0478\u001b[0m  7.5822\n",
      "      4        \u001b[36m0.0351\u001b[0m  7.5756\n",
      "      5        \u001b[36m0.0294\u001b[0m  7.6123\n",
      "      6        \u001b[36m0.0239\u001b[0m  7.5824\n",
      "      7        \u001b[36m0.0220\u001b[0m  7.5854\n",
      "      8        \u001b[36m0.0217\u001b[0m  7.7206\n",
      "      9        \u001b[36m0.0216\u001b[0m  7.7184\n",
      "     10        0.0223  7.5867\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m7.1742\u001b[0m  7.7779\n",
      "      2        \u001b[36m0.0988\u001b[0m  8.1367\n",
      "      3        \u001b[36m0.0592\u001b[0m  7.8651\n",
      "      4        \u001b[36m0.0445\u001b[0m  7.7600\n",
      "      5        \u001b[36m0.0369\u001b[0m  7.7970\n",
      "      6        \u001b[36m0.0309\u001b[0m  7.7571\n",
      "      7        \u001b[36m0.0293\u001b[0m  7.7596\n",
      "      8        \u001b[36m0.0254\u001b[0m  7.9879\n",
      "      9        \u001b[36m0.0246\u001b[0m  7.8200\n",
      "     10        \u001b[36m0.0228\u001b[0m  7.7770\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.6551\u001b[0m  7.9434\n",
      "      2        \u001b[36m0.0984\u001b[0m  7.9763\n",
      "      3        \u001b[36m0.0623\u001b[0m  7.8474\n",
      "      4        \u001b[36m0.0463\u001b[0m  7.8776\n",
      "      5        \u001b[36m0.0368\u001b[0m  7.7758\n",
      "      6        \u001b[36m0.0307\u001b[0m  8.1748\n",
      "      7        \u001b[36m0.0271\u001b[0m  8.0278\n",
      "      8        \u001b[36m0.0264\u001b[0m  7.9716\n",
      "      9        \u001b[36m0.0240\u001b[0m  7.7585\n",
      "     10        0.0243  7.7531\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.2198\u001b[0m  8.2130\n",
      "      2        \u001b[36m0.0876\u001b[0m  7.8388\n",
      "      3        \u001b[36m0.0531\u001b[0m  8.1940\n",
      "      4        \u001b[36m0.0389\u001b[0m  7.8672\n",
      "      5        \u001b[36m0.0287\u001b[0m  7.7910\n",
      "      6        \u001b[36m0.0253\u001b[0m  7.7564\n",
      "      7        \u001b[36m0.0216\u001b[0m  7.7596\n",
      "      8        \u001b[36m0.0199\u001b[0m  7.7490\n",
      "      9        0.0205  7.7508\n",
      "     10        \u001b[36m0.0198\u001b[0m  7.7491\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m6.3639\u001b[0m  7.7576\n",
      "      2        \u001b[36m0.0955\u001b[0m  7.7501\n",
      "      3        \u001b[36m0.0619\u001b[0m  7.7647\n",
      "      4        \u001b[36m0.0453\u001b[0m  7.7648\n",
      "      5        \u001b[36m0.0357\u001b[0m  7.7506\n",
      "      6        \u001b[36m0.0313\u001b[0m  7.7564\n",
      "      7        \u001b[36m0.0270\u001b[0m  7.9198\n",
      "      8        \u001b[36m0.0255\u001b[0m  7.8547\n",
      "      9        \u001b[36m0.0234\u001b[0m  7.7502\n",
      "     10        0.0242  7.7537\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.5459\u001b[0m  7.9103\n",
      "      2        \u001b[36m0.0960\u001b[0m  7.7581\n",
      "      3        \u001b[36m0.0574\u001b[0m  7.7527\n",
      "      4        \u001b[36m0.0413\u001b[0m  8.0447\n",
      "      5        \u001b[36m0.0325\u001b[0m  7.9529\n",
      "      6        \u001b[36m0.0266\u001b[0m  7.7539\n",
      "      7        \u001b[36m0.0241\u001b[0m  7.7571\n",
      "      8        \u001b[36m0.0214\u001b[0m  7.7596\n",
      "      9        \u001b[36m0.0198\u001b[0m  7.7691\n",
      "     10        \u001b[36m0.0197\u001b[0m  7.7503\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5512\u001b[0m  7.3487\n",
      "      2        \u001b[36m0.0902\u001b[0m  7.3485\n",
      "      3        \u001b[36m0.0612\u001b[0m  7.3496\n",
      "      4        \u001b[36m0.0498\u001b[0m  7.3495\n",
      "      5        \u001b[36m0.0414\u001b[0m  7.3431\n",
      "      6        \u001b[36m0.0364\u001b[0m  7.4892\n",
      "      7        \u001b[36m0.0351\u001b[0m  7.5347\n",
      "      8        \u001b[36m0.0322\u001b[0m  7.3289\n",
      "      9        \u001b[36m0.0305\u001b[0m  7.3345\n",
      "     10        \u001b[36m0.0293\u001b[0m  7.3348\n",
      "     11        0.0296  7.3384\n",
      "     12        \u001b[36m0.0286\u001b[0m  7.3403\n",
      "     13        \u001b[36m0.0277\u001b[0m  7.3394\n",
      "     14        \u001b[36m0.0248\u001b[0m  7.3433\n",
      "     15        0.0277  7.3344\n",
      "     16        0.0258  7.3360\n",
      "     17        0.0256  7.3346\n",
      "     18        0.0257  7.3364\n",
      "     19        0.0277  7.3443\n",
      "     20        0.0251  7.3343\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5085\u001b[0m  7.3354\n",
      "      2        \u001b[36m0.0879\u001b[0m  7.4616\n",
      "      3        \u001b[36m0.0585\u001b[0m  7.5666\n",
      "      4        \u001b[36m0.0473\u001b[0m  7.6591\n",
      "      5        \u001b[36m0.0409\u001b[0m  7.6963\n",
      "      6        \u001b[36m0.0368\u001b[0m  7.4771\n",
      "      7        \u001b[36m0.0340\u001b[0m  7.3770\n",
      "      8        \u001b[36m0.0326\u001b[0m  7.3388\n",
      "      9        \u001b[36m0.0283\u001b[0m  7.3454\n",
      "     10        0.0302  7.3390\n",
      "     11        \u001b[36m0.0277\u001b[0m  7.3751\n",
      "     12        \u001b[36m0.0260\u001b[0m  7.6748\n",
      "     13        0.0282  7.3366\n",
      "     14        \u001b[36m0.0257\u001b[0m  7.3298\n",
      "     15        0.0271  7.6656\n",
      "     16        0.0265  7.3415\n",
      "     17        0.0257  7.3344\n",
      "     18        \u001b[36m0.0254\u001b[0m  7.4670\n",
      "     19        0.0264  7.8074\n",
      "     20        0.0261  7.3472\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5412\u001b[0m  7.3329\n",
      "      2        \u001b[36m0.0831\u001b[0m  7.3338\n",
      "      3        \u001b[36m0.0550\u001b[0m  7.3299\n",
      "      4        \u001b[36m0.0432\u001b[0m  7.3488\n",
      "      5        \u001b[36m0.0356\u001b[0m  7.3358\n",
      "      6        \u001b[36m0.0323\u001b[0m  7.3474\n",
      "      7        \u001b[36m0.0286\u001b[0m  7.3466\n",
      "      8        0.0291  7.3408\n",
      "      9        \u001b[36m0.0250\u001b[0m  7.3309\n",
      "     10        \u001b[36m0.0234\u001b[0m  7.3399\n",
      "     11        0.0241  7.3387\n",
      "     12        0.0238  7.3364\n",
      "     13        0.0259  7.3347\n",
      "     14        \u001b[36m0.0209\u001b[0m  7.3657\n",
      "     15        0.0214  7.3531\n",
      "     16        0.0226  7.3445\n",
      "     17        0.0227  7.3315\n",
      "     18        0.0217  7.3301\n",
      "     19        0.0219  7.3325\n",
      "     20        0.0213  7.3380\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4761\u001b[0m  7.3406\n",
      "      2        \u001b[36m0.0810\u001b[0m  7.3314\n",
      "      3        \u001b[36m0.0577\u001b[0m  7.3493\n",
      "      4        \u001b[36m0.0451\u001b[0m  7.3363\n",
      "      5        \u001b[36m0.0387\u001b[0m  7.3251\n",
      "      6        \u001b[36m0.0341\u001b[0m  7.3442\n",
      "      7        \u001b[36m0.0328\u001b[0m  7.3393\n",
      "      8        \u001b[36m0.0307\u001b[0m  7.3554\n",
      "      9        \u001b[36m0.0304\u001b[0m  7.3312\n",
      "     10        \u001b[36m0.0280\u001b[0m  7.3442\n",
      "     11        \u001b[36m0.0279\u001b[0m  7.3518\n",
      "     12        \u001b[36m0.0277\u001b[0m  7.3341\n",
      "     13        \u001b[36m0.0266\u001b[0m  7.3254\n",
      "     14        \u001b[36m0.0259\u001b[0m  7.3240\n",
      "     15        \u001b[36m0.0258\u001b[0m  7.3302\n",
      "     16        0.0259  7.3302\n",
      "     17        \u001b[36m0.0244\u001b[0m  7.3268\n",
      "     18        0.0251  7.3292\n",
      "     19        \u001b[36m0.0238\u001b[0m  7.3549\n",
      "     20        0.0242  7.3364\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4710\u001b[0m  7.3324\n",
      "      2        \u001b[36m0.0787\u001b[0m  7.3302\n",
      "      3        \u001b[36m0.0521\u001b[0m  7.3257\n",
      "      4        \u001b[36m0.0418\u001b[0m  7.3521\n",
      "      5        \u001b[36m0.0365\u001b[0m  7.3374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        \u001b[36m0.0320\u001b[0m  7.3412\n",
      "      7        \u001b[36m0.0307\u001b[0m  7.3899\n",
      "      8        \u001b[36m0.0294\u001b[0m  7.3419\n",
      "      9        \u001b[36m0.0281\u001b[0m  7.3361\n",
      "     10        \u001b[36m0.0246\u001b[0m  7.3315\n",
      "     11        0.0264  7.3346\n",
      "     12        0.0263  7.3383\n",
      "     13        \u001b[36m0.0232\u001b[0m  7.3319\n",
      "     14        \u001b[36m0.0231\u001b[0m  7.3318\n",
      "     15        0.0259  7.3519\n",
      "     16        0.0245  7.3415\n",
      "     17        0.0239  7.3282\n",
      "     18        0.0263  7.3309\n",
      "     19        \u001b[36m0.0212\u001b[0m  7.3273\n",
      "     20        0.0213  7.3388\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4748\u001b[0m  7.4720\n",
      "      2        \u001b[36m0.0936\u001b[0m  7.4717\n",
      "      3        \u001b[36m0.0644\u001b[0m  7.5127\n",
      "      4        \u001b[36m0.0500\u001b[0m  7.4725\n",
      "      5        \u001b[36m0.0420\u001b[0m  7.4704\n",
      "      6        \u001b[36m0.0365\u001b[0m  7.4630\n",
      "      7        \u001b[36m0.0322\u001b[0m  7.4701\n",
      "      8        \u001b[36m0.0300\u001b[0m  7.4710\n",
      "      9        \u001b[36m0.0298\u001b[0m  7.4772\n",
      "     10        \u001b[36m0.0275\u001b[0m  7.4714\n",
      "     11        \u001b[36m0.0268\u001b[0m  7.4852\n",
      "     12        0.0271  7.4694\n",
      "     13        0.0273  7.4673\n",
      "     14        \u001b[36m0.0264\u001b[0m  7.4665\n",
      "     15        \u001b[36m0.0235\u001b[0m  7.4608\n",
      "     16        0.0252  7.4635\n",
      "     17        0.0259  7.4652\n",
      "     18        0.0267  7.4618\n",
      "     19        0.0273  7.5118\n",
      "     20        0.0255  7.5671\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.6252\u001b[0m  7.4696\n",
      "      2        \u001b[36m0.1125\u001b[0m  7.4658\n",
      "      3        \u001b[36m0.0802\u001b[0m  7.4665\n",
      "      4        \u001b[36m0.0585\u001b[0m  7.5134\n",
      "      5        \u001b[36m0.0514\u001b[0m  7.4754\n",
      "      6        \u001b[36m0.0442\u001b[0m  7.7761\n",
      "      7        \u001b[36m0.0362\u001b[0m  7.4758\n",
      "      8        0.0364  7.4718\n",
      "      9        \u001b[36m0.0331\u001b[0m  7.4664\n",
      "     10        \u001b[36m0.0308\u001b[0m  7.4643\n",
      "     11        \u001b[36m0.0276\u001b[0m  7.4652\n",
      "     12        \u001b[36m0.0269\u001b[0m  7.4658\n",
      "     13        0.0295  7.6389\n",
      "     14        0.0276  7.4898\n",
      "     15        0.0281  7.5936\n",
      "     16        0.0293  7.8778\n",
      "     17        \u001b[36m0.0254\u001b[0m  8.0839\n",
      "     18        0.0280  7.9185\n",
      "     19        0.0266  8.0350\n",
      "     20        0.0282  7.5843\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4317\u001b[0m  7.6415\n",
      "      2        \u001b[36m0.0928\u001b[0m  7.6523\n",
      "      3        \u001b[36m0.0630\u001b[0m  7.4745\n",
      "      4        \u001b[36m0.0485\u001b[0m  7.5740\n",
      "      5        \u001b[36m0.0392\u001b[0m  7.4719\n",
      "      6        \u001b[36m0.0336\u001b[0m  7.4690\n",
      "      7        \u001b[36m0.0288\u001b[0m  7.8331\n",
      "      8        \u001b[36m0.0264\u001b[0m  7.9689\n",
      "      9        \u001b[36m0.0260\u001b[0m  7.4703\n",
      "     10        \u001b[36m0.0232\u001b[0m  7.5038\n",
      "     11        \u001b[36m0.0232\u001b[0m  7.4775\n",
      "     12        0.0233  7.4817\n",
      "     13        \u001b[36m0.0230\u001b[0m  7.4993\n",
      "     14        \u001b[36m0.0207\u001b[0m  7.5199\n",
      "     15        0.0211  7.4726\n",
      "     16        0.0229  8.0660\n",
      "     17        0.0232  7.4717\n",
      "     18        0.0226  7.4774\n",
      "     19        \u001b[36m0.0202\u001b[0m  7.4751\n",
      "     20        \u001b[36m0.0198\u001b[0m  7.4782\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.5648\u001b[0m  7.7670\n",
      "      2        \u001b[36m0.1074\u001b[0m  7.7112\n",
      "      3        \u001b[36m0.0763\u001b[0m  7.6972\n",
      "      4        \u001b[36m0.0617\u001b[0m  7.7047\n",
      "      5        \u001b[36m0.0512\u001b[0m  8.0622\n",
      "      6        \u001b[36m0.0425\u001b[0m  8.1089\n",
      "      7        \u001b[36m0.0395\u001b[0m  8.0296\n",
      "      8        \u001b[36m0.0350\u001b[0m  7.5219\n",
      "      9        \u001b[36m0.0327\u001b[0m  7.4716\n",
      "     10        \u001b[36m0.0300\u001b[0m  7.4749\n",
      "     11        \u001b[36m0.0296\u001b[0m  7.4717\n",
      "     12        \u001b[36m0.0296\u001b[0m  7.4765\n",
      "     13        \u001b[36m0.0280\u001b[0m  7.8601\n",
      "     14        0.0294  7.4841\n",
      "     15        \u001b[36m0.0279\u001b[0m  7.4805\n",
      "     16        \u001b[36m0.0264\u001b[0m  7.4703\n",
      "     17        0.0283  7.4807\n",
      "     18        0.0271  7.8494\n",
      "     19        \u001b[36m0.0258\u001b[0m  7.8674\n",
      "     20        0.0269  7.4732\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3591\u001b[0m  7.7211\n",
      "      2        \u001b[36m0.0917\u001b[0m  7.8909\n",
      "      3        \u001b[36m0.0624\u001b[0m  7.5738\n",
      "      4        \u001b[36m0.0469\u001b[0m  7.4689\n",
      "      5        \u001b[36m0.0384\u001b[0m  7.4673\n",
      "      6        \u001b[36m0.0341\u001b[0m  7.5697\n",
      "      7        \u001b[36m0.0308\u001b[0m  7.4774\n",
      "      8        \u001b[36m0.0276\u001b[0m  7.4736\n",
      "      9        \u001b[36m0.0273\u001b[0m  7.5951\n",
      "     10        \u001b[36m0.0252\u001b[0m  7.5061\n",
      "     11        \u001b[36m0.0249\u001b[0m  7.7980\n",
      "     12        \u001b[36m0.0228\u001b[0m  7.4748\n",
      "     13        0.0252  7.4772\n",
      "     14        0.0246  7.4724\n",
      "     15        0.0238  7.4856\n",
      "     16        \u001b[36m0.0224\u001b[0m  7.6066\n",
      "     17        0.0231  7.5017\n",
      "     18        0.0255  7.6403\n",
      "     19        0.0242  7.4808\n",
      "     20        0.0229  7.4755\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2177\u001b[0m  7.5820\n",
      "      2        \u001b[36m0.0472\u001b[0m  7.5829\n",
      "      3        \u001b[36m0.0317\u001b[0m  7.5869\n",
      "      4        \u001b[36m0.0234\u001b[0m  7.5654\n",
      "      5        \u001b[36m0.0211\u001b[0m  7.5755\n",
      "      6        \u001b[36m0.0182\u001b[0m  7.5799\n",
      "      7        0.0195  7.5629\n",
      "      8        0.0189  7.5661\n",
      "      9        0.0185  7.8423\n",
      "     10        \u001b[36m0.0171\u001b[0m  7.7282\n",
      "     11        0.0179  7.5779\n",
      "     12        0.0176  7.5721\n",
      "     13        \u001b[36m0.0170\u001b[0m  7.6084\n",
      "     14        0.0179  7.6085\n",
      "     15        \u001b[36m0.0165\u001b[0m  7.5799\n",
      "     16        0.0170  7.5742\n",
      "     17        0.0168  7.5728\n",
      "     18        0.0170  7.5721\n",
      "     19        \u001b[36m0.0155\u001b[0m  7.5851\n",
      "     20        0.0156  7.6124\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6914\u001b[0m  7.5841\n",
      "      2        \u001b[36m0.0539\u001b[0m  7.5807\n",
      "      3        \u001b[36m0.0350\u001b[0m  7.5651\n",
      "      4        \u001b[36m0.0266\u001b[0m  7.5709\n",
      "      5        \u001b[36m0.0225\u001b[0m  7.5630\n",
      "      6        \u001b[36m0.0201\u001b[0m  7.5629\n",
      "      7        0.0205  7.5650\n",
      "      8        \u001b[36m0.0188\u001b[0m  7.5821\n",
      "      9        \u001b[36m0.0183\u001b[0m  7.5834\n",
      "     10        \u001b[36m0.0167\u001b[0m  7.5642\n",
      "     11        0.0168  7.5611\n",
      "     12        \u001b[36m0.0165\u001b[0m  7.5783\n",
      "     13        0.0178  7.5785\n",
      "     14        0.0165  7.5733\n",
      "     15        0.0175  7.5630\n",
      "     16        \u001b[36m0.0160\u001b[0m  7.5772\n",
      "     17        0.0163  7.5773\n",
      "     18        0.0185  7.5689\n",
      "     19        0.0182  7.5743\n",
      "     20        0.0183  7.5642\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.7532\u001b[0m  7.5727\n",
      "      2        \u001b[36m0.0475\u001b[0m  7.5790\n",
      "      3        \u001b[36m0.0293\u001b[0m  7.5620\n",
      "      4        \u001b[36m0.0219\u001b[0m  7.6790\n",
      "      5        \u001b[36m0.0166\u001b[0m  7.5684\n",
      "      6        \u001b[36m0.0157\u001b[0m  7.5706\n",
      "      7        \u001b[36m0.0145\u001b[0m  7.5543\n",
      "      8        \u001b[36m0.0131\u001b[0m  7.5622\n",
      "      9        \u001b[36m0.0127\u001b[0m  7.5516\n",
      "     10        0.0129  7.5528\n",
      "     11        0.0135  7.5508\n",
      "     12        0.0132  7.5580\n",
      "     13        0.0128  7.5591\n",
      "     14        0.0144  7.5611\n",
      "     15        0.0142  7.5600\n",
      "     16        0.0130  7.5572\n",
      "     17        0.0133  7.5686\n",
      "     18        0.0138  7.5658\n",
      "     19        0.0133  7.5610\n",
      "     20        \u001b[36m0.0126\u001b[0m  7.5880\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.3666\u001b[0m  7.5618\n",
      "      2        \u001b[36m0.0611\u001b[0m  7.5553\n",
      "      3        \u001b[36m0.0380\u001b[0m  7.5660\n",
      "      4        \u001b[36m0.0279\u001b[0m  7.5648\n",
      "      5        \u001b[36m0.0235\u001b[0m  7.5723\n",
      "      6        \u001b[36m0.0208\u001b[0m  7.5692\n",
      "      7        \u001b[36m0.0195\u001b[0m  7.5733\n",
      "      8        \u001b[36m0.0174\u001b[0m  7.5666\n",
      "      9        0.0185  7.5763\n",
      "     10        \u001b[36m0.0171\u001b[0m  7.5594\n",
      "     11        \u001b[36m0.0169\u001b[0m  7.5731\n",
      "     12        0.0172  7.5759\n",
      "     13        \u001b[36m0.0156\u001b[0m  7.5691\n",
      "     14        0.0167  7.5735\n",
      "     15        0.0157  7.5593\n",
      "     16        0.0164  7.5879\n",
      "     17        0.0166  7.5609\n",
      "     18        0.0161  7.5619\n",
      "     19        0.0178  7.5564\n",
      "     20        0.0160  7.5589\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.2438\u001b[0m  7.5762\n",
      "      2        \u001b[36m0.0536\u001b[0m  7.5528\n",
      "      3        \u001b[36m0.0331\u001b[0m  7.5708\n",
      "      4        \u001b[36m0.0235\u001b[0m  7.5745\n",
      "      5        \u001b[36m0.0185\u001b[0m  7.6113\n",
      "      6        \u001b[36m0.0173\u001b[0m  7.5597\n",
      "      7        \u001b[36m0.0167\u001b[0m  7.5665\n",
      "      8        \u001b[36m0.0149\u001b[0m  7.5695\n",
      "      9        \u001b[36m0.0135\u001b[0m  7.5586\n",
      "     10        0.0150  7.5839\n",
      "     11        0.0148  7.8037\n",
      "     12        0.0144  7.7335\n",
      "     13        0.0139  7.5586\n",
      "     14        0.0139  7.5458\n",
      "     15        \u001b[36m0.0135\u001b[0m  7.5462\n",
      "     16        0.0150  7.5487\n",
      "     17        0.0148  7.5487\n",
      "     18        0.0144  7.5611\n",
      "     19        0.0144  7.5632\n",
      "     20        \u001b[36m0.0132\u001b[0m  7.5637\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m8.7247\u001b[0m  7.7443\n",
      "      2        \u001b[36m0.0744\u001b[0m  7.7393\n",
      "      3        \u001b[36m0.0463\u001b[0m  7.7392\n",
      "      4        \u001b[36m0.0349\u001b[0m  7.7369\n",
      "      5        \u001b[36m0.0272\u001b[0m  7.7312\n",
      "      6        \u001b[36m0.0243\u001b[0m  7.7362\n",
      "      7        \u001b[36m0.0218\u001b[0m  7.7629\n",
      "      8        \u001b[36m0.0193\u001b[0m  7.7405\n",
      "      9        \u001b[36m0.0190\u001b[0m  7.7325\n",
      "     10        \u001b[36m0.0178\u001b[0m  7.7247\n",
      "     11        \u001b[36m0.0176\u001b[0m  7.7260\n",
      "     12        \u001b[36m0.0172\u001b[0m  7.7278\n",
      "     13        \u001b[36m0.0162\u001b[0m  7.7256\n",
      "     14        0.0169  7.7275\n",
      "     15        0.0170  7.7537\n",
      "     16        0.0168  7.7329\n",
      "     17        0.0175  7.7313\n",
      "     18        \u001b[36m0.0162\u001b[0m  7.7332\n",
      "     19        0.0166  7.7393\n",
      "     20        0.0182  7.7421\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m9.5860\u001b[0m  7.7332\n",
      "      2        \u001b[36m0.0857\u001b[0m  7.7502\n",
      "      3        \u001b[36m0.0480\u001b[0m  7.7535\n",
      "      4        \u001b[36m0.0364\u001b[0m  7.7247\n",
      "      5        \u001b[36m0.0292\u001b[0m  7.7261\n",
      "      6        \u001b[36m0.0253\u001b[0m  7.7371\n",
      "      7        \u001b[36m0.0236\u001b[0m  7.7314\n",
      "      8        \u001b[36m0.0208\u001b[0m  7.7252\n",
      "      9        \u001b[36m0.0200\u001b[0m  7.7293\n",
      "     10        \u001b[36m0.0185\u001b[0m  7.7388\n",
      "     11        \u001b[36m0.0177\u001b[0m  7.7407\n",
      "     12        \u001b[36m0.0173\u001b[0m  7.7351\n",
      "     13        0.0174  7.7272\n",
      "     14        0.0173  7.7213\n",
      "     15        \u001b[36m0.0172\u001b[0m  7.7315\n",
      "     16        0.0184  7.7295\n",
      "     17        0.0173  7.7340\n",
      "     18        0.0176  7.9143\n",
      "     19        \u001b[36m0.0170\u001b[0m  7.7393\n",
      "     20        \u001b[36m0.0165\u001b[0m  7.7374\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m11.3012\u001b[0m  7.7282\n",
      "      2        \u001b[36m0.0878\u001b[0m  7.7926\n",
      "      3        \u001b[36m0.0462\u001b[0m  7.9474\n",
      "      4        \u001b[36m0.0336\u001b[0m  7.7182\n",
      "      5        \u001b[36m0.0263\u001b[0m  7.7179\n",
      "      6        \u001b[36m0.0222\u001b[0m  7.7262\n",
      "      7        \u001b[36m0.0183\u001b[0m  7.7349\n",
      "      8        \u001b[36m0.0163\u001b[0m  7.7600\n",
      "      9        \u001b[36m0.0144\u001b[0m  7.7208\n",
      "     10        0.0156  7.7340\n",
      "     11        \u001b[36m0.0134\u001b[0m  7.7367\n",
      "     12        \u001b[36m0.0120\u001b[0m  7.7346\n",
      "     13        0.0128  7.9175\n",
      "     14        0.0133  7.7298\n",
      "     15        0.0123  7.7327\n",
      "     16        0.0122  7.7264\n",
      "     17        0.0127  7.7346\n",
      "     18        0.0134  7.7324\n",
      "     19        0.0134  7.7539\n",
      "     20        0.0141  7.7422\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m12.8296\u001b[0m  7.7630\n",
      "      2        \u001b[36m0.0976\u001b[0m  7.7504\n",
      "      3        \u001b[36m0.0578\u001b[0m  7.7514\n",
      "      4        \u001b[36m0.0404\u001b[0m  7.7479\n",
      "      5        \u001b[36m0.0315\u001b[0m  7.7465\n",
      "      6        \u001b[36m0.0273\u001b[0m  7.7499\n",
      "      7        \u001b[36m0.0232\u001b[0m  7.7412\n",
      "      8        \u001b[36m0.0209\u001b[0m  7.7709\n",
      "      9        \u001b[36m0.0198\u001b[0m  7.8613\n",
      "     10        \u001b[36m0.0194\u001b[0m  7.7542\n",
      "     11        \u001b[36m0.0186\u001b[0m  7.7516\n",
      "     12        \u001b[36m0.0168\u001b[0m  7.8418\n",
      "     13        0.0179  8.1844\n",
      "     14        \u001b[36m0.0166\u001b[0m  8.0081\n",
      "     15        0.0167  7.9175\n",
      "     16        \u001b[36m0.0156\u001b[0m  8.1559\n",
      "     17        0.0165  8.0602\n",
      "     18        0.0173  7.7546\n",
      "     19        0.0174  7.7504\n",
      "     20        0.0176  7.7456\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m11.4075\u001b[0m  7.7703\n",
      "      2        \u001b[36m0.0862\u001b[0m  7.7378\n",
      "      3        \u001b[36m0.0482\u001b[0m  7.7610\n",
      "      4        \u001b[36m0.0346\u001b[0m  7.8273\n",
      "      5        \u001b[36m0.0279\u001b[0m  7.7453\n",
      "      6        \u001b[36m0.0227\u001b[0m  7.7392\n",
      "      7        \u001b[36m0.0197\u001b[0m  7.7381\n",
      "      8        \u001b[36m0.0169\u001b[0m  7.7385\n",
      "      9        \u001b[36m0.0160\u001b[0m  7.7394\n",
      "     10        \u001b[36m0.0150\u001b[0m  7.7388\n",
      "     11        \u001b[36m0.0144\u001b[0m  7.7527\n",
      "     12        \u001b[36m0.0135\u001b[0m  7.9245\n",
      "     13        \u001b[36m0.0129\u001b[0m  7.7395\n",
      "     14        0.0143  7.7375\n",
      "     15        0.0148  7.7498\n",
      "     16        \u001b[36m0.0125\u001b[0m  7.7394\n",
      "     17        0.0130  7.7483\n",
      "     18        0.0147  7.7370\n",
      "     19        0.0145  7.7732\n",
      "     20        0.0145  7.7391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5379\u001b[0m  7.3326\n",
      "      2        \u001b[36m0.1001\u001b[0m  7.3209\n",
      "      3        \u001b[36m0.0713\u001b[0m  7.3259\n",
      "      4        \u001b[36m0.0590\u001b[0m  7.3242\n",
      "      5        \u001b[36m0.0526\u001b[0m  7.3264\n",
      "      6        \u001b[36m0.0462\u001b[0m  7.3310\n",
      "      7        \u001b[36m0.0431\u001b[0m  7.3353\n",
      "      8        \u001b[36m0.0416\u001b[0m  7.3331\n",
      "      9        \u001b[36m0.0394\u001b[0m  7.3189\n",
      "     10        0.0398  7.3205\n",
      "     11        \u001b[36m0.0393\u001b[0m  7.3194\n",
      "     12        \u001b[36m0.0378\u001b[0m  7.3163\n",
      "     13        0.0383  7.3319\n",
      "     14        \u001b[36m0.0375\u001b[0m  7.3258\n",
      "     15        \u001b[36m0.0364\u001b[0m  7.3591\n",
      "     16        \u001b[36m0.0358\u001b[0m  7.3343\n",
      "     17        0.0363  7.3357\n",
      "     18        0.0367  7.3330\n",
      "     19        \u001b[36m0.0336\u001b[0m  7.3273\n",
      "     20        0.0357  7.3239\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4882\u001b[0m  7.3206\n",
      "      2        \u001b[36m0.0972\u001b[0m  7.3280\n",
      "      3        \u001b[36m0.0697\u001b[0m  7.3342\n",
      "      4        \u001b[36m0.0571\u001b[0m  7.3367\n",
      "      5        \u001b[36m0.0506\u001b[0m  7.3265\n",
      "      6        \u001b[36m0.0471\u001b[0m  7.3232\n",
      "      7        \u001b[36m0.0454\u001b[0m  7.3338\n",
      "      8        \u001b[36m0.0398\u001b[0m  7.3222\n",
      "      9        \u001b[36m0.0396\u001b[0m  7.3537\n",
      "     10        \u001b[36m0.0373\u001b[0m  7.3294\n",
      "     11        \u001b[36m0.0372\u001b[0m  7.3589\n",
      "     12        \u001b[36m0.0357\u001b[0m  7.3507\n",
      "     13        0.0361  7.3350\n",
      "     14        0.0380  7.3337\n",
      "     15        0.0360  7.3339\n",
      "     16        \u001b[36m0.0347\u001b[0m  7.3288\n",
      "     17        \u001b[36m0.0336\u001b[0m  7.4471\n",
      "     18        \u001b[36m0.0325\u001b[0m  7.3231\n",
      "     19        0.0353  7.3216\n",
      "     20        \u001b[36m0.0317\u001b[0m  7.3381\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4778\u001b[0m  7.3287\n",
      "      2        \u001b[36m0.0908\u001b[0m  7.3312\n",
      "      3        \u001b[36m0.0661\u001b[0m  7.3251\n",
      "      4        \u001b[36m0.0536\u001b[0m  7.3247\n",
      "      5        \u001b[36m0.0459\u001b[0m  7.3301\n",
      "      6        \u001b[36m0.0427\u001b[0m  7.3257\n",
      "      7        \u001b[36m0.0397\u001b[0m  7.3477\n",
      "      8        \u001b[36m0.0380\u001b[0m  7.6717\n",
      "      9        \u001b[36m0.0361\u001b[0m  7.3194\n",
      "     10        \u001b[36m0.0331\u001b[0m  7.3214\n",
      "     11        \u001b[36m0.0324\u001b[0m  7.3151\n",
      "     12        0.0333  7.3174\n",
      "     13        \u001b[36m0.0320\u001b[0m  7.3190\n",
      "     14        \u001b[36m0.0304\u001b[0m  7.3152\n",
      "     15        0.0316  7.3171\n",
      "     16        \u001b[36m0.0290\u001b[0m  7.3406\n",
      "     17        \u001b[36m0.0288\u001b[0m  7.3207\n",
      "     18        \u001b[36m0.0285\u001b[0m  7.3185\n",
      "     19        0.0322  7.3202\n",
      "     20        0.0293  7.3241\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4757\u001b[0m  7.3171\n",
      "      2        \u001b[36m0.0949\u001b[0m  7.3120\n",
      "      3        \u001b[36m0.0687\u001b[0m  7.3145\n",
      "      4        \u001b[36m0.0587\u001b[0m  7.3624\n",
      "      5        \u001b[36m0.0517\u001b[0m  7.3251\n",
      "      6        \u001b[36m0.0462\u001b[0m  7.3208\n",
      "      7        \u001b[36m0.0415\u001b[0m  7.3120\n",
      "      8        \u001b[36m0.0402\u001b[0m  7.3147\n",
      "      9        \u001b[36m0.0400\u001b[0m  7.3223\n",
      "     10        \u001b[36m0.0387\u001b[0m  7.3269\n",
      "     11        \u001b[36m0.0379\u001b[0m  7.3146\n",
      "     12        0.0385  7.3365\n",
      "     13        \u001b[36m0.0374\u001b[0m  7.3422\n",
      "     14        \u001b[36m0.0372\u001b[0m  7.3238\n",
      "     15        \u001b[36m0.0357\u001b[0m  7.3177\n",
      "     16        \u001b[36m0.0335\u001b[0m  7.3181\n",
      "     17        0.0349  7.3196\n",
      "     18        \u001b[36m0.0334\u001b[0m  7.3235\n",
      "     19        0.0343  7.3127\n",
      "     20        \u001b[36m0.0332\u001b[0m  7.3596\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6724\u001b[0m  7.3341\n",
      "      2        \u001b[36m0.1052\u001b[0m  7.3122\n",
      "      3        \u001b[36m0.0733\u001b[0m  7.3212\n",
      "      4        \u001b[36m0.0575\u001b[0m  7.3185\n",
      "      5        \u001b[36m0.0477\u001b[0m  7.3197\n",
      "      6        \u001b[36m0.0443\u001b[0m  7.3173\n",
      "      7        \u001b[36m0.0412\u001b[0m  7.3222\n",
      "      8        \u001b[36m0.0366\u001b[0m  7.3270\n",
      "      9        0.0382  7.3291\n",
      "     10        \u001b[36m0.0348\u001b[0m  7.3337\n",
      "     11        \u001b[36m0.0340\u001b[0m  7.3161\n",
      "     12        0.0357  7.3187\n",
      "     13        0.0340  7.3217\n",
      "     14        \u001b[36m0.0331\u001b[0m  7.3154\n",
      "     15        0.0335  7.3165\n",
      "     16        0.0345  7.3514\n",
      "     17        \u001b[36m0.0318\u001b[0m  7.3415\n",
      "     18        \u001b[36m0.0318\u001b[0m  7.3247\n",
      "     19        \u001b[36m0.0298\u001b[0m  7.3278\n",
      "     20        \u001b[36m0.0282\u001b[0m  7.3242\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.8048\u001b[0m  7.4504\n",
      "      2        \u001b[36m0.1236\u001b[0m  7.4435\n",
      "      3        \u001b[36m0.0928\u001b[0m  7.4521\n",
      "      4        \u001b[36m0.0754\u001b[0m  7.4607\n",
      "      5        \u001b[36m0.0634\u001b[0m  7.4605\n",
      "      6        \u001b[36m0.0557\u001b[0m  7.4537\n",
      "      7        \u001b[36m0.0514\u001b[0m  7.4512\n",
      "      8        \u001b[36m0.0473\u001b[0m  7.4453\n",
      "      9        \u001b[36m0.0437\u001b[0m  7.4437\n",
      "     10        \u001b[36m0.0403\u001b[0m  7.4459\n",
      "     11        0.0409  7.7000\n",
      "     12        \u001b[36m0.0402\u001b[0m  7.8299\n",
      "     13        \u001b[36m0.0354\u001b[0m  7.7399\n",
      "     14        0.0380  7.8024\n",
      "     15        0.0364  7.4503\n",
      "     16        0.0388  7.4579\n",
      "     17        0.0412  7.4578\n",
      "     18        0.0360  7.4664\n",
      "     19        0.0385  7.4456\n",
      "     20        \u001b[36m0.0345\u001b[0m  7.5604\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3250\u001b[0m  7.4552\n",
      "      2        \u001b[36m0.1068\u001b[0m  7.6150\n",
      "      3        \u001b[36m0.0760\u001b[0m  7.4450\n",
      "      4        \u001b[36m0.0636\u001b[0m  7.4334\n",
      "      5        \u001b[36m0.0545\u001b[0m  7.4384\n",
      "      6        \u001b[36m0.0477\u001b[0m  7.4342\n",
      "      7        \u001b[36m0.0442\u001b[0m  7.4366\n",
      "      8        \u001b[36m0.0426\u001b[0m  7.4777\n",
      "      9        \u001b[36m0.0412\u001b[0m  7.4479\n",
      "     10        \u001b[36m0.0406\u001b[0m  7.4418\n",
      "     11        \u001b[36m0.0388\u001b[0m  7.4404\n",
      "     12        \u001b[36m0.0351\u001b[0m  7.4499\n",
      "     13        0.0365  7.4444\n",
      "     14        0.0369  7.4493\n",
      "     15        \u001b[36m0.0350\u001b[0m  7.4496\n",
      "     16        \u001b[36m0.0331\u001b[0m  7.4506\n",
      "     17        0.0361  7.4534\n",
      "     18        0.0369  7.4593\n",
      "     19        0.0361  7.4425\n",
      "     20        0.0375  7.4424\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4775\u001b[0m  7.4438\n",
      "      2        \u001b[36m0.1010\u001b[0m  7.4402\n",
      "      3        \u001b[36m0.0713\u001b[0m  7.4404\n",
      "      4        \u001b[36m0.0561\u001b[0m  7.4846\n",
      "      5        \u001b[36m0.0475\u001b[0m  7.4486\n",
      "      6        \u001b[36m0.0407\u001b[0m  7.4416\n",
      "      7        \u001b[36m0.0377\u001b[0m  7.4343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        \u001b[36m0.0369\u001b[0m  7.4358\n",
      "      9        \u001b[36m0.0360\u001b[0m  7.4391\n",
      "     10        \u001b[36m0.0344\u001b[0m  7.4369\n",
      "     11        \u001b[36m0.0321\u001b[0m  7.4309\n",
      "     12        0.0337  7.4471\n",
      "     13        \u001b[36m0.0315\u001b[0m  7.4454\n",
      "     14        0.0318  7.4390\n",
      "     15        \u001b[36m0.0296\u001b[0m  7.7042\n",
      "     16        0.0302  7.5444\n",
      "     17        0.0342  7.4766\n",
      "     18        0.0322  7.6237\n",
      "     19        0.0331  7.4438\n",
      "     20        0.0303  7.4573\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3406\u001b[0m  7.7175\n",
      "      2        \u001b[36m0.1058\u001b[0m  7.8623\n",
      "      3        \u001b[36m0.0740\u001b[0m  7.8896\n",
      "      4        \u001b[36m0.0587\u001b[0m  7.4438\n",
      "      5        \u001b[36m0.0507\u001b[0m  7.4439\n",
      "      6        \u001b[36m0.0459\u001b[0m  7.4396\n",
      "      7        \u001b[36m0.0419\u001b[0m  7.4692\n",
      "      8        \u001b[36m0.0396\u001b[0m  7.4748\n",
      "      9        \u001b[36m0.0390\u001b[0m  7.4441\n",
      "     10        \u001b[36m0.0380\u001b[0m  7.4329\n",
      "     11        \u001b[36m0.0369\u001b[0m  7.4320\n",
      "     12        \u001b[36m0.0342\u001b[0m  7.4320\n",
      "     13        0.0349  7.4348\n",
      "     14        0.0351  7.4426\n",
      "     15        0.0365  7.4387\n",
      "     16        0.0348  7.4622\n",
      "     17        0.0369  7.4353\n",
      "     18        \u001b[36m0.0335\u001b[0m  7.4303\n",
      "     19        0.0368  7.4410\n",
      "     20        0.0356  7.4364\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4134\u001b[0m  7.4364\n",
      "      2        \u001b[36m0.0996\u001b[0m  7.4391\n",
      "      3        \u001b[36m0.0712\u001b[0m  7.4360\n",
      "      4        \u001b[36m0.0563\u001b[0m  7.4418\n",
      "      5        \u001b[36m0.0464\u001b[0m  7.4382\n",
      "      6        \u001b[36m0.0435\u001b[0m  7.4297\n",
      "      7        \u001b[36m0.0393\u001b[0m  7.4327\n",
      "      8        \u001b[36m0.0363\u001b[0m  7.4472\n",
      "      9        0.0367  7.4344\n",
      "     10        \u001b[36m0.0361\u001b[0m  7.4352\n",
      "     11        \u001b[36m0.0345\u001b[0m  7.4351\n",
      "     12        0.0357  7.4649\n",
      "     13        \u001b[36m0.0336\u001b[0m  7.8744\n",
      "     14        \u001b[36m0.0335\u001b[0m  7.8895\n",
      "     15        0.0345  7.5471\n",
      "     16        \u001b[36m0.0309\u001b[0m  7.4613\n",
      "     17        0.0311  7.7464\n",
      "     18        0.0333  7.6590\n",
      "     19        0.0340  7.9839\n",
      "     20        0.0354  7.6228\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6439\u001b[0m  7.5255\n",
      "      2        \u001b[36m0.0573\u001b[0m  7.5207\n",
      "      3        \u001b[36m0.0378\u001b[0m  7.5932\n",
      "      4        \u001b[36m0.0305\u001b[0m  7.5652\n",
      "      5        \u001b[36m0.0252\u001b[0m  7.5324\n",
      "      6        \u001b[36m0.0232\u001b[0m  7.5434\n",
      "      7        \u001b[36m0.0221\u001b[0m  7.5538\n",
      "      8        \u001b[36m0.0209\u001b[0m  7.5584\n",
      "      9        0.0210  7.5265\n",
      "     10        \u001b[36m0.0200\u001b[0m  7.5172\n",
      "     11        0.0205  7.5208\n",
      "     12        0.0205  7.5260\n",
      "     13        0.0200  7.5318\n",
      "     14        0.0204  7.5225\n",
      "     15        0.0203  7.5350\n",
      "     16        \u001b[36m0.0196\u001b[0m  7.5388\n",
      "     17        \u001b[36m0.0186\u001b[0m  7.6005\n",
      "     18        0.0196  7.7851\n",
      "     19        0.0199  7.5382\n",
      "     20        0.0196  7.5455\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.5476\u001b[0m  7.5456\n",
      "      2        \u001b[36m0.0672\u001b[0m  7.5321\n",
      "      3        \u001b[36m0.0411\u001b[0m  7.5969\n",
      "      4        \u001b[36m0.0318\u001b[0m  8.0358\n",
      "      5        \u001b[36m0.0257\u001b[0m  7.9911\n",
      "      6        \u001b[36m0.0221\u001b[0m  7.9863\n",
      "      7        0.0222  7.5616\n",
      "      8        \u001b[36m0.0218\u001b[0m  7.5263\n",
      "      9        \u001b[36m0.0201\u001b[0m  7.5282\n",
      "     10        0.0201  7.5311\n",
      "     11        0.0203  7.5346\n",
      "     12        \u001b[36m0.0201\u001b[0m  7.5364\n",
      "     13        0.0203  7.5558\n",
      "     14        \u001b[36m0.0188\u001b[0m  8.1637\n",
      "     15        0.0199  7.8827\n",
      "     16        0.0203  7.5479\n",
      "     17        0.0214  7.5353\n",
      "     18        0.0216  7.6480\n",
      "     19        0.0205  7.6983\n",
      "     20        0.0217  7.6599\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.6833\u001b[0m  7.6787\n",
      "      2        \u001b[36m0.0630\u001b[0m  7.6380\n",
      "      3        \u001b[36m0.0395\u001b[0m  8.2573\n",
      "      4        \u001b[36m0.0271\u001b[0m  7.9063\n",
      "      5        \u001b[36m0.0224\u001b[0m  7.7004\n",
      "      6        \u001b[36m0.0194\u001b[0m  7.7653\n",
      "      7        \u001b[36m0.0180\u001b[0m  7.6384\n",
      "      8        \u001b[36m0.0169\u001b[0m  7.8172\n",
      "      9        0.0171  7.7640\n",
      "     10        \u001b[36m0.0163\u001b[0m  7.6404\n",
      "     11        \u001b[36m0.0144\u001b[0m  7.6294\n",
      "     12        0.0170  7.6400\n",
      "     13        0.0151  7.6344\n",
      "     14        0.0169  7.6835\n",
      "     15        0.0162  7.6423\n",
      "     16        0.0150  7.6472\n",
      "     17        0.0168  7.6349\n",
      "     18        0.0157  7.6359\n",
      "     19        0.0170  7.6399\n",
      "     20        0.0177  7.6372\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.1056\u001b[0m  7.6343\n",
      "      2        \u001b[36m0.0646\u001b[0m  7.6515\n",
      "      3        \u001b[36m0.0415\u001b[0m  7.6396\n",
      "      4        \u001b[36m0.0305\u001b[0m  7.8259\n",
      "      5        \u001b[36m0.0257\u001b[0m  7.6313\n",
      "      6        \u001b[36m0.0247\u001b[0m  7.6288\n",
      "      7        \u001b[36m0.0221\u001b[0m  7.7906\n",
      "      8        \u001b[36m0.0203\u001b[0m  7.6333\n",
      "      9        \u001b[36m0.0199\u001b[0m  7.6517\n",
      "     10        \u001b[36m0.0190\u001b[0m  7.6852\n",
      "     11        \u001b[36m0.0188\u001b[0m  7.7620\n",
      "     12        0.0213  7.7191\n",
      "     13        0.0193  7.6303\n",
      "     14        0.0208  7.6309\n",
      "     15        0.0198  7.7397\n",
      "     16        \u001b[36m0.0185\u001b[0m  8.3307\n",
      "     17        0.0197  7.9892\n",
      "     18        0.0190  7.6377\n",
      "     19        \u001b[36m0.0169\u001b[0m  7.6428\n",
      "     20        0.0192  7.6344\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.4969\u001b[0m  7.6284\n",
      "      2        \u001b[36m0.0631\u001b[0m  7.6354\n",
      "      3        \u001b[36m0.0395\u001b[0m  7.6295\n",
      "      4        \u001b[36m0.0285\u001b[0m  7.6295\n",
      "      5        \u001b[36m0.0231\u001b[0m  7.6709\n",
      "      6        \u001b[36m0.0201\u001b[0m  7.6316\n",
      "      7        \u001b[36m0.0186\u001b[0m  7.6215\n",
      "      8        \u001b[36m0.0176\u001b[0m  7.6224\n",
      "      9        \u001b[36m0.0172\u001b[0m  7.6413\n",
      "     10        \u001b[36m0.0170\u001b[0m  7.6231\n",
      "     11        \u001b[36m0.0164\u001b[0m  7.6220\n",
      "     12        \u001b[36m0.0162\u001b[0m  7.6320\n",
      "     13        0.0191  7.6355\n",
      "     14        \u001b[36m0.0155\u001b[0m  7.6302\n",
      "     15        0.0192  7.6237\n",
      "     16        0.0171  7.6231\n",
      "     17        0.0175  7.6228\n",
      "     18        0.0155  7.6228\n",
      "     19        0.0173  7.6248\n",
      "     20        0.0165  7.7197\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m9.9384\u001b[0m  7.8381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.0932\u001b[0m  7.8181\n",
      "      3        \u001b[36m0.0575\u001b[0m  7.8073\n",
      "      4        \u001b[36m0.0421\u001b[0m  7.8070\n",
      "      5        \u001b[36m0.0342\u001b[0m  7.8103\n",
      "      6        \u001b[36m0.0298\u001b[0m  7.8071\n",
      "      7        \u001b[36m0.0269\u001b[0m  7.8099\n",
      "      8        \u001b[36m0.0234\u001b[0m  7.8152\n",
      "      9        \u001b[36m0.0226\u001b[0m  7.8165\n",
      "     10        \u001b[36m0.0218\u001b[0m  7.8091\n",
      "     11        \u001b[36m0.0203\u001b[0m  7.8077\n",
      "     12        \u001b[36m0.0198\u001b[0m  7.8651\n",
      "     13        0.0207  7.8181\n",
      "     14        0.0202  7.8237\n",
      "     15        \u001b[36m0.0189\u001b[0m  7.8126\n",
      "     16        0.0201  8.1225\n",
      "     17        0.0191  7.8168\n",
      "     18        0.0194  7.9831\n",
      "     19        0.0217  7.9298\n",
      "     20        0.0199  7.8056\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m8.0924\u001b[0m  7.8070\n",
      "      2        \u001b[36m0.0780\u001b[0m  7.8018\n",
      "      3        \u001b[36m0.0514\u001b[0m  7.8126\n",
      "      4        \u001b[36m0.0396\u001b[0m  7.8164\n",
      "      5        \u001b[36m0.0320\u001b[0m  7.8106\n",
      "      6        \u001b[36m0.0271\u001b[0m  7.8053\n",
      "      7        \u001b[36m0.0232\u001b[0m  7.8050\n",
      "      8        \u001b[36m0.0221\u001b[0m  7.8041\n",
      "      9        \u001b[36m0.0207\u001b[0m  7.8036\n",
      "     10        0.0210  7.8136\n",
      "     11        \u001b[36m0.0205\u001b[0m  7.8533\n",
      "     12        0.0208  7.8524\n",
      "     13        \u001b[36m0.0194\u001b[0m  7.8087\n",
      "     14        \u001b[36m0.0191\u001b[0m  7.8128\n",
      "     15        0.0218  7.8130\n",
      "     16        0.0224  7.8087\n",
      "     17        0.0215  7.8031\n",
      "     18        0.0201  7.8200\n",
      "     19        0.0205  7.8293\n",
      "     20        0.0221  7.8190\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.6952\u001b[0m  7.8002\n",
      "      2        \u001b[36m0.0704\u001b[0m  7.8123\n",
      "      3        \u001b[36m0.0434\u001b[0m  7.8077\n",
      "      4        \u001b[36m0.0316\u001b[0m  7.8127\n",
      "      5        \u001b[36m0.0250\u001b[0m  7.8043\n",
      "      6        \u001b[36m0.0202\u001b[0m  7.8369\n",
      "      7        \u001b[36m0.0178\u001b[0m  7.8116\n",
      "      8        \u001b[36m0.0162\u001b[0m  7.8180\n",
      "      9        0.0165  7.8090\n",
      "     10        \u001b[36m0.0148\u001b[0m  7.8169\n",
      "     11        0.0155  7.8103\n",
      "     12        0.0161  7.8209\n",
      "     13        \u001b[36m0.0147\u001b[0m  7.8038\n",
      "     14        0.0150  7.8192\n",
      "     15        0.0158  7.8089\n",
      "     16        0.0175  7.8101\n",
      "     17        0.0182  7.8009\n",
      "     18        0.0162  7.8081\n",
      "     19        0.0171  7.8058\n",
      "     20        0.0183  7.8059\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m3.8524\u001b[0m  8.0633\n",
      "      2        \u001b[36m0.0779\u001b[0m  8.0953\n",
      "      3        \u001b[36m0.0486\u001b[0m  7.7987\n",
      "      4        \u001b[36m0.0355\u001b[0m  7.8015\n",
      "      5        \u001b[36m0.0290\u001b[0m  7.8081\n",
      "      6        \u001b[36m0.0247\u001b[0m  7.8019\n",
      "      7        \u001b[36m0.0221\u001b[0m  7.8619\n",
      "      8        \u001b[36m0.0212\u001b[0m  8.2727\n",
      "      9        \u001b[36m0.0199\u001b[0m  8.2699\n",
      "     10        0.0200  7.9472\n",
      "     11        \u001b[36m0.0184\u001b[0m  7.8008\n",
      "     12        0.0190  7.8005\n",
      "     13        0.0185  7.8037\n",
      "     14        0.0194  7.8089\n",
      "     15        0.0197  7.8566\n",
      "     16        0.0194  7.8213\n",
      "     17        0.0193  7.8312\n",
      "     18        0.0199  7.8031\n",
      "     19        0.0200  7.7975\n",
      "     20        0.0212  7.8038\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m6.0257\u001b[0m  7.8179\n",
      "      2        \u001b[36m0.0726\u001b[0m  7.8035\n",
      "      3        \u001b[36m0.0449\u001b[0m  8.2595\n",
      "      4        \u001b[36m0.0334\u001b[0m  7.8591\n",
      "      5        \u001b[36m0.0260\u001b[0m  7.8119\n",
      "      6        \u001b[36m0.0212\u001b[0m  7.7994\n",
      "      7        \u001b[36m0.0200\u001b[0m  7.7954\n",
      "      8        \u001b[36m0.0177\u001b[0m  7.7974\n",
      "      9        \u001b[36m0.0164\u001b[0m  7.7993\n",
      "     10        \u001b[36m0.0153\u001b[0m  7.8191\n",
      "     11        0.0173  7.8019\n",
      "     12        0.0154  8.0340\n",
      "     13        0.0159  7.8841\n",
      "     14        0.0171  7.7928\n",
      "     15        0.0167  7.7954\n",
      "     16        0.0183  7.8847\n",
      "     17        0.0183  7.9970\n",
      "     18        0.0169  7.9970\n",
      "     19        0.0167  7.8009\n",
      "     20        0.0184  7.8155\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6899\u001b[0m  7.3957\n",
      "      2        \u001b[36m0.1198\u001b[0m  7.3887\n",
      "      3        \u001b[36m0.0895\u001b[0m  7.3869\n",
      "      4        \u001b[36m0.0769\u001b[0m  7.5407\n",
      "      5        \u001b[36m0.0671\u001b[0m  7.3844\n",
      "      6        \u001b[36m0.0631\u001b[0m  7.3949\n",
      "      7        \u001b[36m0.0599\u001b[0m  7.4379\n",
      "      8        \u001b[36m0.0568\u001b[0m  7.8075\n",
      "      9        \u001b[36m0.0561\u001b[0m  7.3952\n",
      "     10        \u001b[36m0.0544\u001b[0m  7.3957\n",
      "     11        \u001b[36m0.0543\u001b[0m  7.3980\n",
      "     12        \u001b[36m0.0514\u001b[0m  7.3973\n",
      "     13        \u001b[36m0.0510\u001b[0m  7.3932\n",
      "     14        0.0520  7.5584\n",
      "     15        0.0520  7.6932\n",
      "     16        \u001b[36m0.0491\u001b[0m  7.4013\n",
      "     17        \u001b[36m0.0460\u001b[0m  7.3967\n",
      "     18        0.0521  7.3865\n",
      "     19        0.0462  7.3905\n",
      "     20        \u001b[36m0.0451\u001b[0m  7.3896\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4522\u001b[0m  7.4013\n",
      "      2        \u001b[36m0.1105\u001b[0m  7.3991\n",
      "      3        \u001b[36m0.0820\u001b[0m  7.4289\n",
      "      4        \u001b[36m0.0699\u001b[0m  7.3956\n",
      "      5        \u001b[36m0.0653\u001b[0m  7.3897\n",
      "      6        \u001b[36m0.0615\u001b[0m  7.3842\n",
      "      7        \u001b[36m0.0576\u001b[0m  7.3885\n",
      "      8        0.0578  7.3894\n",
      "      9        \u001b[36m0.0543\u001b[0m  7.3978\n",
      "     10        \u001b[36m0.0519\u001b[0m  7.3886\n",
      "     11        0.0540  7.3982\n",
      "     12        0.0526  7.4007\n",
      "     13        \u001b[36m0.0511\u001b[0m  7.4012\n",
      "     14        \u001b[36m0.0489\u001b[0m  7.3984\n",
      "     15        \u001b[36m0.0488\u001b[0m  7.3980\n",
      "     16        0.0505  7.3959\n",
      "     17        0.0491  7.3854\n",
      "     18        \u001b[36m0.0453\u001b[0m  7.3864\n",
      "     19        0.0484  7.4288\n",
      "     20        0.0478  7.4077\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6646\u001b[0m  7.4088\n",
      "      2        \u001b[36m0.1148\u001b[0m  7.3981\n",
      "      3        \u001b[36m0.0875\u001b[0m  7.3870\n",
      "      4        \u001b[36m0.0714\u001b[0m  7.3900\n",
      "      5        \u001b[36m0.0657\u001b[0m  7.3877\n",
      "      6        \u001b[36m0.0585\u001b[0m  7.4033\n",
      "      7        \u001b[36m0.0538\u001b[0m  7.4553\n",
      "      8        \u001b[36m0.0537\u001b[0m  7.3871\n",
      "      9        \u001b[36m0.0504\u001b[0m  7.3883\n",
      "     10        \u001b[36m0.0484\u001b[0m  7.3843\n",
      "     11        0.0497  7.3822\n",
      "     12        0.0496  7.3901\n",
      "     13        0.0492  7.3938\n",
      "     14        \u001b[36m0.0465\u001b[0m  7.3826\n",
      "     15        \u001b[36m0.0442\u001b[0m  7.4190\n",
      "     16        0.0457  7.3933\n",
      "     17        0.0475  7.3941\n",
      "     18        0.0459  7.3914\n",
      "     19        0.0456  7.4113\n",
      "     20        \u001b[36m0.0432\u001b[0m  7.3861\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6769\u001b[0m  7.3934\n",
      "      2        \u001b[36m0.1195\u001b[0m  7.3913\n",
      "      3        \u001b[36m0.0935\u001b[0m  7.3895\n",
      "      4        \u001b[36m0.0755\u001b[0m  7.5559\n",
      "      5        \u001b[36m0.0651\u001b[0m  7.6025\n",
      "      6        \u001b[36m0.0628\u001b[0m  7.7046\n",
      "      7        \u001b[36m0.0587\u001b[0m  7.9080\n",
      "      8        \u001b[36m0.0573\u001b[0m  7.5699\n",
      "      9        \u001b[36m0.0559\u001b[0m  7.4084\n",
      "     10        \u001b[36m0.0552\u001b[0m  7.3956\n",
      "     11        \u001b[36m0.0530\u001b[0m  7.4179\n",
      "     12        0.0535  7.3909\n",
      "     13        0.0554  7.3935\n",
      "     14        \u001b[36m0.0506\u001b[0m  7.3902\n",
      "     15        0.0517  7.3937\n",
      "     16        \u001b[36m0.0488\u001b[0m  7.3928\n",
      "     17        0.0511  7.3955\n",
      "     18        0.0513  7.3937\n",
      "     19        0.0499  7.4029\n",
      "     20        \u001b[36m0.0466\u001b[0m  7.3958\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4705\u001b[0m  7.4006\n",
      "      2        \u001b[36m0.1088\u001b[0m  7.3958\n",
      "      3        \u001b[36m0.0793\u001b[0m  7.3922\n",
      "      4        \u001b[36m0.0653\u001b[0m  7.3947\n",
      "      5        \u001b[36m0.0583\u001b[0m  7.3967\n",
      "      6        \u001b[36m0.0545\u001b[0m  7.3986\n",
      "      7        \u001b[36m0.0533\u001b[0m  7.4165\n",
      "      8        \u001b[36m0.0498\u001b[0m  7.3974\n",
      "      9        0.0511  7.3922\n",
      "     10        0.0500  7.3935\n",
      "     11        \u001b[36m0.0469\u001b[0m  7.3987\n",
      "     12        0.0484  7.4014\n",
      "     13        \u001b[36m0.0444\u001b[0m  7.3961\n",
      "     14        0.0447  7.6801\n",
      "     15        0.0460  7.3806\n",
      "     16        0.0480  7.3976\n",
      "     17        0.0450  7.3851\n",
      "     18        0.0468  7.3885\n",
      "     19        0.0454  7.3773\n",
      "     20        \u001b[36m0.0435\u001b[0m  7.3749\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=17, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3520\u001b[0m  7.5247\n",
      "      2        \u001b[36m0.1253\u001b[0m  7.6794\n",
      "      3        \u001b[36m0.0940\u001b[0m  7.5438\n",
      "      4        \u001b[36m0.0772\u001b[0m  7.5133\n",
      "      5        \u001b[36m0.0680\u001b[0m  7.5141\n",
      "      6        \u001b[36m0.0616\u001b[0m  7.5102\n",
      "      7        \u001b[36m0.0563\u001b[0m  7.5014\n",
      "      8        \u001b[36m0.0560\u001b[0m  7.5023\n",
      "      9        \u001b[36m0.0557\u001b[0m  7.5118\n",
      "     10        \u001b[36m0.0533\u001b[0m  7.5071\n",
      "     11        \u001b[36m0.0531\u001b[0m  7.5051\n",
      "     12        0.0532  7.5124\n",
      "     13        \u001b[36m0.0521\u001b[0m  7.4971\n",
      "     14        0.0557  7.5024\n",
      "     15        \u001b[36m0.0509\u001b[0m  7.5147\n",
      "     16        0.0536  7.6166\n",
      "     17        0.0529  8.1104\n",
      "     18        0.0522  7.6895\n",
      "     19        0.0517  7.6948\n",
      "     20        0.0523  7.5220\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3273\u001b[0m  7.5136\n",
      "      2        \u001b[36m0.1220\u001b[0m  7.8210\n",
      "      3        \u001b[36m0.0922\u001b[0m  7.7297\n",
      "      4        \u001b[36m0.0736\u001b[0m  7.4992\n",
      "      5        \u001b[36m0.0673\u001b[0m  7.4981\n",
      "      6        \u001b[36m0.0624\u001b[0m  7.5013\n",
      "      7        \u001b[36m0.0588\u001b[0m  7.5210\n",
      "      8        \u001b[36m0.0534\u001b[0m  7.5156\n",
      "      9        0.0549  7.5004\n",
      "     10        0.0536  7.4972\n",
      "     11        0.0558  7.5023\n",
      "     12        \u001b[36m0.0504\u001b[0m  7.5078\n",
      "     13        0.0530  7.5834\n",
      "     14        \u001b[36m0.0489\u001b[0m  7.8130\n",
      "     15        0.0536  7.5677\n",
      "     16        0.0543  7.5103\n",
      "     17        0.0525  7.5127\n",
      "     18        0.0552  7.5099\n",
      "     19        0.0509  7.5068\n",
      "     20        0.0489  7.5109\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.4287\u001b[0m  7.5121\n",
      "      2        \u001b[36m0.1286\u001b[0m  7.5048\n",
      "      3        \u001b[36m0.0947\u001b[0m  7.5249\n",
      "      4        \u001b[36m0.0775\u001b[0m  7.5078\n",
      "      5        \u001b[36m0.0690\u001b[0m  7.5112\n",
      "      6        \u001b[36m0.0620\u001b[0m  7.5050\n",
      "      7        \u001b[36m0.0587\u001b[0m  7.5045\n",
      "      8        \u001b[36m0.0499\u001b[0m  7.5872\n",
      "      9        \u001b[36m0.0489\u001b[0m  7.5157\n",
      "     10        \u001b[36m0.0465\u001b[0m  7.5071\n",
      "     11        0.0473  7.5351\n",
      "     12        \u001b[36m0.0449\u001b[0m  7.5087\n",
      "     13        0.0482  7.4989\n",
      "     14        0.0461  7.5023\n",
      "     15        0.0465  7.4992\n",
      "     16        \u001b[36m0.0441\u001b[0m  7.5072\n",
      "     17        0.0481  7.5002\n",
      "     18        0.0462  7.5002\n",
      "     19        0.0453  7.5028\n",
      "     20        0.0441  7.5055\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.4895\u001b[0m  7.5036\n",
      "      2        \u001b[36m0.1380\u001b[0m  7.5082\n",
      "      3        \u001b[36m0.1030\u001b[0m  7.5635\n",
      "      4        \u001b[36m0.0841\u001b[0m  7.4989\n",
      "      5        \u001b[36m0.0725\u001b[0m  7.4997\n",
      "      6        \u001b[36m0.0632\u001b[0m  7.5163\n",
      "      7        \u001b[36m0.0595\u001b[0m  7.5087\n",
      "      8        \u001b[36m0.0548\u001b[0m  7.5035\n",
      "      9        \u001b[36m0.0522\u001b[0m  7.4933\n",
      "     10        0.0527  7.4840\n",
      "     11        0.0523  7.4902\n",
      "     12        \u001b[36m0.0499\u001b[0m  7.4976\n",
      "     13        0.0515  7.4918\n",
      "     14        0.0505  7.4910\n",
      "     15        0.0504  7.5139\n",
      "     16        0.0514  7.4942\n",
      "     17        0.0511  7.4902\n",
      "     18        0.0502  7.4918\n",
      "     19        0.0512  7.4964\n",
      "     20        0.0500  7.5042\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.3246\u001b[0m  7.5235\n",
      "      2        \u001b[36m0.1221\u001b[0m  7.7317\n",
      "      3        \u001b[36m0.0867\u001b[0m  8.0616\n",
      "      4        \u001b[36m0.0691\u001b[0m  7.5298\n",
      "      5        \u001b[36m0.0597\u001b[0m  7.7827\n",
      "      6        \u001b[36m0.0572\u001b[0m  7.9274\n",
      "      7        \u001b[36m0.0514\u001b[0m  7.5149\n",
      "      8        \u001b[36m0.0510\u001b[0m  7.5128\n",
      "      9        \u001b[36m0.0496\u001b[0m  7.5574\n",
      "     10        \u001b[36m0.0496\u001b[0m  7.7702\n",
      "     11        0.0497  7.5077\n",
      "     12        \u001b[36m0.0461\u001b[0m  7.6734\n",
      "     13        0.0461  7.5033\n",
      "     14        0.0481  7.8455\n",
      "     15        \u001b[36m0.0460\u001b[0m  7.5151\n",
      "     16        \u001b[36m0.0458\u001b[0m  7.5074\n",
      "     17        0.0468  7.5071\n",
      "     18        \u001b[36m0.0458\u001b[0m  7.5389\n",
      "     19        \u001b[36m0.0438\u001b[0m  7.5029\n",
      "     20        0.0467  7.5065\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=17, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.8271\u001b[0m  7.5962\n",
      "      2        \u001b[36m0.0774\u001b[0m  7.5931\n",
      "      3        \u001b[36m0.0514\u001b[0m  7.5969\n",
      "      4        \u001b[36m0.0395\u001b[0m  7.5967\n",
      "      5        \u001b[36m0.0319\u001b[0m  7.6058\n",
      "      6        \u001b[36m0.0299\u001b[0m  7.5975\n",
      "      7        \u001b[36m0.0254\u001b[0m  7.7005\n",
      "      8        \u001b[36m0.0246\u001b[0m  7.5886\n",
      "      9        \u001b[36m0.0233\u001b[0m  7.5884\n",
      "     10        0.0247  7.6035\n",
      "     11        0.0247  7.6030\n",
      "     12        0.0257  7.8851\n",
      "     13        0.0264  8.0427\n",
      "     14        0.0260  7.6647\n",
      "     15        0.0263  7.5963\n",
      "     16        0.0261  7.5950\n",
      "     17        0.0240  7.9057\n",
      "     18        0.0248  7.8979\n",
      "     19        0.0250  7.5957\n",
      "     20        0.0252  7.5938\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4912\u001b[0m  7.6317\n",
      "      2        \u001b[36m0.0674\u001b[0m  7.5998\n",
      "      3        \u001b[36m0.0442\u001b[0m  7.6040\n",
      "      4        \u001b[36m0.0336\u001b[0m  7.5983\n",
      "      5        \u001b[36m0.0306\u001b[0m  7.6034\n",
      "      6        \u001b[36m0.0268\u001b[0m  7.6079\n",
      "      7        0.0273  7.6040\n",
      "      8        \u001b[36m0.0258\u001b[0m  7.6026\n",
      "      9        \u001b[36m0.0255\u001b[0m  7.6246\n",
      "     10        \u001b[36m0.0242\u001b[0m  7.5970\n",
      "     11        0.0248  7.5939\n",
      "     12        0.0267  7.5870\n",
      "     13        0.0262  7.5970\n",
      "     14        0.0262  7.6022\n",
      "     15        0.0246  7.5975\n",
      "     16        0.0251  7.6531\n",
      "     17        0.0250  7.5981\n",
      "     18        0.0251  7.5963\n",
      "     19        0.0260  7.6027\n",
      "     20        0.0244  7.6028\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.4627\u001b[0m  7.6018\n",
      "      2        \u001b[36m0.0612\u001b[0m  7.6534\n",
      "      3        \u001b[36m0.0385\u001b[0m  7.5985\n",
      "      4        \u001b[36m0.0290\u001b[0m  7.8501\n",
      "      5        \u001b[36m0.0251\u001b[0m  7.6416\n",
      "      6        \u001b[36m0.0224\u001b[0m  7.5922\n",
      "      7        \u001b[36m0.0210\u001b[0m  7.5865\n",
      "      8        \u001b[36m0.0202\u001b[0m  7.5895\n",
      "      9        \u001b[36m0.0193\u001b[0m  7.5925\n",
      "     10        0.0202  7.5931\n",
      "     11        0.0207  7.5901\n",
      "     12        0.0243  7.5929\n",
      "     13        0.0239  7.6004\n",
      "     14        0.0219  7.5947\n",
      "     15        0.0205  7.9507\n",
      "     16        0.0231  7.5931\n",
      "     17        0.0238  7.6011\n",
      "     18        0.0224  7.6045\n",
      "     19        0.0226  7.8327\n",
      "     20        0.0207  7.6340\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.5736\u001b[0m  7.6019\n",
      "      2        \u001b[36m0.0668\u001b[0m  7.7235\n",
      "      3        \u001b[36m0.0445\u001b[0m  7.5895\n",
      "      4        \u001b[36m0.0345\u001b[0m  7.5911\n",
      "      5        \u001b[36m0.0303\u001b[0m  7.5973\n",
      "      6        \u001b[36m0.0263\u001b[0m  7.6028\n",
      "      7        \u001b[36m0.0237\u001b[0m  7.5877\n",
      "      8        0.0249  7.6010\n",
      "      9        0.0246  7.5970\n",
      "     10        0.0257  7.6989\n",
      "     11        \u001b[36m0.0236\u001b[0m  7.6038\n",
      "     12        0.0264  7.6622\n",
      "     13        0.0281  7.6069\n",
      "     14        0.0276  7.5879\n",
      "     15        0.0261  7.5899\n",
      "     16        \u001b[36m0.0235\u001b[0m  7.6109\n",
      "     17        0.0244  7.5919\n",
      "     18        0.0255  7.5855\n",
      "     19        0.0254  7.5874\n",
      "     20        0.0253  7.5866\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m2.0889\u001b[0m  7.5909\n",
      "      2        \u001b[36m0.0657\u001b[0m  7.5906\n",
      "      3        \u001b[36m0.0434\u001b[0m  7.8198\n",
      "      4        \u001b[36m0.0321\u001b[0m  7.8167\n",
      "      5        \u001b[36m0.0277\u001b[0m  7.5935\n",
      "      6        \u001b[36m0.0244\u001b[0m  7.6002\n",
      "      7        \u001b[36m0.0219\u001b[0m  7.6860\n",
      "      8        \u001b[36m0.0205\u001b[0m  7.5911\n",
      "      9        0.0217  7.5962\n",
      "     10        0.0217  7.5939\n",
      "     11        0.0212  7.6215\n",
      "     12        0.0215  7.6159\n",
      "     13        0.0226  8.0034\n",
      "     14        0.0254  7.5937\n",
      "     15        0.0231  7.5981\n",
      "     16        0.0220  7.5940\n",
      "     17        0.0232  7.7235\n",
      "     18        0.0219  7.5985\n",
      "     19        0.0222  7.6006\n",
      "     20        0.0217  7.6163\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=17, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.4685\u001b[0m  7.7740\n",
      "      2        \u001b[36m0.1039\u001b[0m  7.7726\n",
      "      3        \u001b[36m0.0665\u001b[0m  7.7766\n",
      "      4        \u001b[36m0.0469\u001b[0m  7.7743\n",
      "      5        \u001b[36m0.0380\u001b[0m  7.7689\n",
      "      6        \u001b[36m0.0325\u001b[0m  7.7657\n",
      "      7        \u001b[36m0.0292\u001b[0m  7.8113\n",
      "      8        \u001b[36m0.0269\u001b[0m  7.7758\n",
      "      9        \u001b[36m0.0250\u001b[0m  7.7665\n",
      "     10        \u001b[36m0.0239\u001b[0m  7.7699\n",
      "     11        \u001b[36m0.0227\u001b[0m  7.7693\n",
      "     12        \u001b[36m0.0226\u001b[0m  7.7690\n",
      "     13        0.0230  7.7700\n",
      "     14        0.0243  7.7682\n",
      "     15        0.0247  7.7897\n",
      "     16        0.0246  7.7732\n",
      "     17        0.0250  8.1403\n",
      "     18        0.0268  7.9111\n",
      "     19        0.0269  7.8144\n",
      "     20        0.0305  8.0930\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1       \u001b[36m11.0515\u001b[0m  7.8254\n",
      "      2        \u001b[36m0.1160\u001b[0m  8.0033\n",
      "      3        \u001b[36m0.0696\u001b[0m  7.7843\n",
      "      4        \u001b[36m0.0513\u001b[0m  7.9364\n",
      "      5        \u001b[36m0.0416\u001b[0m  8.2957\n",
      "      6        \u001b[36m0.0356\u001b[0m  7.8260\n",
      "      7        \u001b[36m0.0316\u001b[0m  7.7778\n",
      "      8        \u001b[36m0.0280\u001b[0m  7.7707\n",
      "      9        \u001b[36m0.0262\u001b[0m  7.9123\n",
      "     10        \u001b[36m0.0246\u001b[0m  7.8601\n",
      "     11        \u001b[36m0.0239\u001b[0m  8.0873\n",
      "     12        0.0246  8.1478\n",
      "     13        \u001b[36m0.0225\u001b[0m  7.7850\n",
      "     14        0.0245  7.7930\n",
      "     15        0.0242  7.7798\n",
      "     16        0.0253  8.0484\n",
      "     17        0.0263  8.1208\n",
      "     18        0.0274  7.7855\n",
      "     19        0.0277  7.7934\n",
      "     20        0.0273  7.7852\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.1961\u001b[0m  7.7737\n",
      "      2        \u001b[36m0.0915\u001b[0m  7.7697\n",
      "      3        \u001b[36m0.0583\u001b[0m  7.9152\n",
      "      4        \u001b[36m0.0411\u001b[0m  7.7832\n",
      "      5        \u001b[36m0.0331\u001b[0m  7.7806\n",
      "      6        \u001b[36m0.0254\u001b[0m  7.8976\n",
      "      7        \u001b[36m0.0226\u001b[0m  8.0938\n",
      "      8        \u001b[36m0.0219\u001b[0m  7.7681\n",
      "      9        \u001b[36m0.0194\u001b[0m  7.7676\n",
      "     10        \u001b[36m0.0185\u001b[0m  7.7687\n",
      "     11        0.0193  7.7691\n",
      "     12        0.0195  7.7930\n",
      "     13        \u001b[36m0.0184\u001b[0m  7.7835\n",
      "     14        0.0192  7.9390\n",
      "     15        0.0218  7.7760\n",
      "     16        0.0208  7.7677\n",
      "     17        0.0207  7.9447\n",
      "     18        0.0238  8.2735\n",
      "     19        0.0227  7.7863\n",
      "     20        0.0227  7.7704\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m6.0183\u001b[0m  7.8472\n",
      "      2        \u001b[36m0.0907\u001b[0m  7.9110\n",
      "      3        \u001b[36m0.0558\u001b[0m  8.1089\n",
      "      4        \u001b[36m0.0431\u001b[0m  7.7654\n",
      "      5        \u001b[36m0.0350\u001b[0m  7.7590\n",
      "      6        \u001b[36m0.0298\u001b[0m  7.7591\n",
      "      7        \u001b[36m0.0269\u001b[0m  7.7857\n",
      "      8        \u001b[36m0.0254\u001b[0m  7.8548\n",
      "      9        \u001b[36m0.0235\u001b[0m  7.9237\n",
      "     10        0.0238  7.7642\n",
      "     11        \u001b[36m0.0234\u001b[0m  7.7672\n",
      "     12        0.0242  7.7641\n",
      "     13        0.0245  7.7612\n",
      "     14        0.0244  7.7659\n",
      "     15        0.0267  7.7673\n",
      "     16        0.0261  7.7733\n",
      "     17        0.0260  7.7636\n",
      "     18        0.0244  7.7663\n",
      "     19        0.0302  8.0014\n",
      "     20        0.0295  7.7615\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m5.9560\u001b[0m  7.7671\n",
      "      2        \u001b[36m0.0922\u001b[0m  7.7649\n",
      "      3        \u001b[36m0.0568\u001b[0m  8.0712\n",
      "      4        \u001b[36m0.0408\u001b[0m  8.0599\n",
      "      5        \u001b[36m0.0319\u001b[0m  7.8310\n",
      "      6        \u001b[36m0.0282\u001b[0m  7.7640\n",
      "      7        \u001b[36m0.0239\u001b[0m  7.7612\n",
      "      8        \u001b[36m0.0213\u001b[0m  7.7606\n",
      "      9        \u001b[36m0.0203\u001b[0m  7.7606\n",
      "     10        \u001b[36m0.0201\u001b[0m  7.9274\n",
      "     11        \u001b[36m0.0200\u001b[0m  7.7693\n",
      "     12        \u001b[36m0.0193\u001b[0m  8.1760\n",
      "     13        0.0210  8.1888\n",
      "     14        \u001b[36m0.0193\u001b[0m  8.2537\n",
      "     15        0.0202  7.7650\n",
      "     16        0.0237  8.1548\n",
      "     17        0.0237  8.2801\n",
      "     18        0.0244  7.9210\n",
      "     19        0.0256  7.9093\n",
      "     20        0.0259  7.8818\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=71, net__module__weight_dim_4=71, total= 2.7min\n",
      "0.9728036871750391 {'net__batch_size': 128, 'net__max_epochs': 10, 'net__module__dropout_rate': 0.6, 'net__module__weight_dim_2': 71, 'net__module__weight_dim_4': 17}\n",
      "\n",
      "Done! Time: 740.87 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed: 740.9min finished\n"
     ]
    }
   ],
   "source": [
    "start_training = time.time()\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "input_dim_1 = 307\n",
    "input_dim_2 = 100\n",
    "\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    Model_2_network,\n",
    "    module__input_dim_1 = input_dim_1,\n",
    "    module__input_dim_2 = input_dim_2,\n",
    "    module__weight_dim_2 = 17,\n",
    "    module__weight_dim_4 = 17,\n",
    "    module__dropout_rate = 0.4,\n",
    "    batch_size = 32,\n",
    "    max_epochs = 10,\n",
    "    train_split = None,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    iterator_train__shuffle = True,\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "ros = RandomOverSampler(random_state = SEED)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ros', ros),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "# LSTM(10) => 12771 => DGCNN(17, 17) => 12428\n",
    "# LSTM(40) => 55881 => DGCNN(71, 71) => 55736\n",
    "# LSTM(70) => 106191 => DGCNN(126, 126) => 105841\n",
    "# LSTM(100) => 163701 => DGCNN(182, 182) => 163073\n",
    "\n",
    "params = {\n",
    "    'net__module__weight_dim_2' : [17, 71],\n",
    "    'net__module__weight_dim_4' : [17, 71],\n",
    "    'net__module__dropout_rate' : [0.4, 0.5, 0.6],\n",
    "    'net__batch_size' : [32, 64, 128],\n",
    "    'net__max_epochs' : [10, 20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    refit = False,\n",
    "    cv = StratifiedKFold(n_splits = 5, random_state = SEED, shuffle = True),\n",
    "    scoring = lambda net_gs, X_gs, y_gs : roc_auc_score(y_gs, net_gs.predict_proba(X_gs)),\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train.astype(np.float))\n",
    "\n",
    "print(gs.best_score_, gs.best_params_)\n",
    "\n",
    "end_training = (time.time() - start_training) / 60\n",
    "\n",
    "print(f'\\nDone! Time: {end_training:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Configuration:\n",
    "\n",
    "0.9728036871750391 {'net__batch_size': 128, 'net__max_epochs': 10, 'net__module__dropout_rate': 0.6, 'net__module__weight_dim_2': 71, 'net__module__weight_dim_4': 17}\n",
    "\n",
    "Done! Time: 740.87 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.2932\u001b[0m  9.8777\n",
      "      2        \u001b[36m0.0638\u001b[0m  9.7536\n",
      "      3        \u001b[36m0.0418\u001b[0m  9.7425\n",
      "      4        \u001b[36m0.0343\u001b[0m  9.9549\n",
      "      5        \u001b[36m0.0310\u001b[0m  10.0712\n",
      "      6        \u001b[36m0.0297\u001b[0m  9.6284\n",
      "      7        \u001b[36m0.0290\u001b[0m  9.5052\n",
      "      8        \u001b[36m0.0279\u001b[0m  9.6408\n",
      "      9        \u001b[36m0.0266\u001b[0m  9.5245\n",
      "     10        0.0280  9.4950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ros',\n",
       "                 RandomOverSampler(random_state=137, ratio=None,\n",
       "                                   return_indices=False,\n",
       "                                   sampling_strategy='auto')),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetBinaryClassifier'>[initialized](\n",
       "  module_=Model_2_network(\n",
       "    (dgcnn_1): DGCNN_network()\n",
       "    (dropout): Dropout(p=0.6, inplace=False)\n",
       "    (dgcnn_2): DGCNN_network()\n",
       "    (fc): Linear(in_features=27016, out_features=1, bias=True)\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "\n",
    "# weight_dim_2 = gs.best_params_['net__module__weight_dim_2']\n",
    "# weight_dim_4 = gs.best_params_['net__module__weight_dim_4']\n",
    "# dropout_rate = gs.best_params_['net__module__dropout_rate']\n",
    "# batch_size = gs.best_params_['net__batch_size']\n",
    "# max_epochs = gs.best_params_['net__max_epochs']\n",
    "\n",
    "input_dim_1 = 307\n",
    "input_dim_2 = 100\n",
    "weight_dim_2 = 71\n",
    "weight_dim_4 = 17\n",
    "dropout_rate = 0.6\n",
    "batch_size = 128\n",
    "max_epochs = 10\n",
    "\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    Model_2_network,\n",
    "    module__input_dim_1 = input_dim_1,\n",
    "    module__input_dim_2 = input_dim_2,\n",
    "    module__weight_dim_2 = weight_dim_2,\n",
    "    module__weight_dim_4 = weight_dim_4,\n",
    "    module__dropout_rate = dropout_rate,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs,\n",
    "    train_split = None,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    iterator_train__shuffle = True,\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "ros = RandomOverSampler(random_state = SEED)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ros', ros),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train.astype(np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(y, pred):\n",
    "    print('Confusion matrix\\n[TN FP]\\n[FN TP]')\n",
    "    print(confusion_matrix(y >= 0.5, pred >= 0.5))\n",
    "    print(f'Precision: {precision_score(y >= 0.5, pred >= 0.5):.4f}')\n",
    "    print(f'Recall: {recall_score(y >= 0.5, pred >= 0.5):.4f}')    \n",
    "    print(f'F1-score: {f1_score(y >= 0.5, pred >= 0.5):.4f}')\n",
    "    print(f'ROC AUC: {roc_auc_score(y, pred):.4f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[TN FP]\n",
      "[FN TP]\n",
      "[[    0 12815]\n",
      " [    0   348]]\n",
      "Precision: 0.0264\n",
      "Recall: 1.0000\n",
      "F1-score: 0.0515\n",
      "ROC AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(y_test, np.ones(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[TN FP]\n",
      "[FN TP]\n",
      "[[12709   106]\n",
      " [   69   279]]\n",
      "Precision: 0.7247\n",
      "Recall: 0.8017\n",
      "F1-score: 0.7613\n",
      "ROC AUC: 0.9732\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(y_test, pipe.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
