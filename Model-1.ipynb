{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Graph Convolutional Neural Network (DGCNN)\n",
    "\n",
    "This code is part our research on malware detection and classification using Deep Learning and Deep Graph Convolutional Neural Networks.\n",
    "\n",
    "For more information or citation, please refer to our research paper:\n",
    "\n",
    "\"Oliveira, Angelo; Sassi, Renato José (2019): Behavioral Malware Detection Using Deep Graph Convolutional Neural Networks. TechRxiv. Preprint.\" at https://doi.org/10.36227/techrxiv.10043099.v1\n",
    "\n",
    "For the dataset, please refer to our repository:\n",
    "\n",
    "https://ieee-dataport.org/open-access/malware-analysis-datasets-api-call-sequences\n",
    "\n",
    "#### Model-1, Original (imbalanced) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "SEED = 137\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch.classifier import NeuralNetBinaryClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_91</th>\n",
       "      <th>t_92</th>\n",
       "      <th>t_93</th>\n",
       "      <th>t_94</th>\n",
       "      <th>t_95</th>\n",
       "      <th>t_96</th>\n",
       "      <th>t_97</th>\n",
       "      <th>t_98</th>\n",
       "      <th>t_99</th>\n",
       "      <th>malware</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>071e8c3f8922e186e57548cd4c703a5d</td>\n",
       "      <td>112</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>298</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "      <td>208</td>\n",
       "      <td>56</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33f8e6d08a6aae939f25a8e0d63dd523</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>71</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b68abd064e975e1c6d5f25e748663076</td>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>113</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>72049be7bd30ea61297ea624ae198067</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>302</td>\n",
       "      <td>208</td>\n",
       "      <td>302</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>302</td>\n",
       "      <td>228</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>c9b3700a77facf29172f32df6bc77f48</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>260</td>\n",
       "      <td>40</td>\n",
       "      <td>209</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               hash  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  \\\n",
       "0  071e8c3f8922e186e57548cd4c703a5d  112  274  158  215  274  158  215  298   \n",
       "1  33f8e6d08a6aae939f25a8e0d63dd523   82  208  187  208  172  117  172  117   \n",
       "2  b68abd064e975e1c6d5f25e748663076   16  110  240  117  240  117  240  117   \n",
       "3  72049be7bd30ea61297ea624ae198067   82  208  187  208  172  117  172  117   \n",
       "4  c9b3700a77facf29172f32df6bc77f48   82  240  117  240  117  240  117  240   \n",
       "\n",
       "   t_8  ...  t_91  t_92  t_93  t_94  t_95  t_96  t_97  t_98  t_99  malware  \n",
       "0   76  ...    71   297   135   171   215    35   208    56    71        1  \n",
       "1  172  ...    81   240   117    71   297   135   171   215    35        1  \n",
       "2  240  ...    65   112   123    65   112   123    65   113   112        1  \n",
       "3  172  ...   208   302   208   302   187   208   302   228   302        1  \n",
       "4  117  ...   209   260    40   209   260   141   260   141   260        1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dynamic_api_call_sequence_per_malware_100_0_306.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43876 entries, 0 to 43875\n",
      "Columns: 102 entries, hash to malware\n",
      "dtypes: int64(101), object(1)\n",
      "memory usage: 34.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43876, 100)\n",
      "(43876,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['hash', 'malware'], axis = 1).values.astype(int)\n",
    "y = df['malware'].values.astype(int)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "306\n"
     ]
    }
   ],
   "source": [
    "print(X.min())\n",
    "print(X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_imbalance(dataset):\n",
    "    count = sorted(Counter(dataset).items())\n",
    "    print(count)\n",
    "    print(count[1][1] / count[0][1])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1079), (1, 42797)]\n",
      "39.66357738646895\n"
     ]
    }
   ],
   "source": [
    "check_imbalance(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1 - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 42797), (1, 1079)]\n",
      "0.025212047573428042\n"
     ]
    }
   ],
   "source": [
    "check_imbalance(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 29982), (1, 731)]\n",
      "0.024381295443933027\n",
      "[(0, 12815), (1, 348)]\n",
      "0.027155676941084665\n"
     ]
    }
   ],
   "source": [
    "check_imbalance(y_train)\n",
    "check_imbalance(y_test)\n",
    "\n",
    "del df, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_network(\n",
      "  (dgcnn): DGCNN_network()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=42059, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Parameters: 55760\n"
     ]
    }
   ],
   "source": [
    "def norn_adj(X, input_dim_1):\n",
    "    \n",
    "    A = torch.zeros((X.size(0), input_dim_1, input_dim_1), dtype = torch.float).cuda()\n",
    "        \n",
    "    A_view = A.view(A.size(0), -1)\n",
    "    x_size = X.size(-1)\n",
    "    indices = X.narrow(-1, 0, x_size - 1) * A.stride(1) * A.stride(2) + X.narrow(-1, 1, x_size - 1) * A.stride(2)\n",
    "    A_view.scatter_(1, indices, 1)\n",
    "        \n",
    "    A_hat = A + torch.eye(input_dim_1, dtype = torch.float).cuda()\n",
    "    D_hat = A_hat.sum(dim = 1).pow(-1.0).diag_embed()\n",
    "    \n",
    "    return A_hat, D_hat\n",
    "\n",
    "def to_one_hot(X, input_dim_1):\n",
    "    \n",
    "    X = F.one_hot(X, num_classes = input_dim_1).float()    \n",
    "    X = X.permute(0, 2, 1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "class DGCNN_network(nn.Module):\n",
    "    \n",
    "    def __init__(self, weight_dim_1, weight_dim_2):\n",
    "\n",
    "        super(DGCNN_network, self).__init__()\n",
    "        self.weight_dim_1 = weight_dim_1\n",
    "        self.weight_dim_2 = weight_dim_2\n",
    "        self.weights = nn.Parameter(torch.rand((self.weight_dim_1, weight_dim_2), dtype = torch.float, requires_grad = True))\n",
    "        \n",
    "    def forward(self, A_hat, D_hat, X):\n",
    "        return D_hat.matmul(A_hat).matmul(X).matmul(self.weights)\n",
    "\n",
    "class Model_1_network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim_1, input_dim_2, weight_dim_2, dropout_rate):\n",
    "        \n",
    "        super(Model_1_network, self).__init__()\n",
    "        \n",
    "        self.input_dim_1 = input_dim_1\n",
    "        self.input_dim_2 = input_dim_2\n",
    "        self.weight_dim_1 = input_dim_2\n",
    "        self.weight_dim_2 = weight_dim_2\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.dgcnn = DGCNN_network(self.weight_dim_1, self.weight_dim_2)\n",
    "        self.dropout = nn.Dropout(p = self.dropout_rate)\n",
    "        self.fc = nn.Linear(self.input_dim_1 * self.weight_dim_2, 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        A_hat, D_hat = norn_adj(X, input_dim_1)\n",
    "        X = to_one_hot(X, input_dim_1)        \n",
    "\n",
    "        H = self.dgcnn(A_hat, D_hat, X)\n",
    "        H = self.dropout(H)\n",
    "        H = torch.relu(H)\n",
    "        H = H.view(H.size(0), -1)\n",
    "        H = self.fc(H)\n",
    "                \n",
    "        return H.squeeze()\n",
    "    \n",
    "model = Model_1_network(\n",
    "    input_dim_1 = 307,\n",
    "    input_dim_2 = 100,\n",
    "    weight_dim_2 = 137,\n",
    "    dropout_rate = 0.4\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(f'\\nParameters: {np.sum([param.numel() for param in model.parameters()])}')\n",
    "del model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0613\u001b[0m  8.4926\n",
      "      2        \u001b[36m0.0331\u001b[0m  8.3705\n",
      "      3        0.0344  8.4359\n",
      "      4        \u001b[36m0.0300\u001b[0m  8.5971\n",
      "      5        0.0356  8.2122\n",
      "      6        \u001b[36m0.0252\u001b[0m  8.1920\n",
      "      7        \u001b[36m0.0197\u001b[0m  9.2603\n",
      "      8        0.0198  8.1935\n",
      "      9        \u001b[36m0.0187\u001b[0m  8.2170\n",
      "     10        \u001b[36m0.0157\u001b[0m  8.1899\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0599\u001b[0m  8.2369\n",
      "      2        \u001b[36m0.0359\u001b[0m  8.1785\n",
      "      3        \u001b[36m0.0317\u001b[0m  8.1768\n",
      "      4        \u001b[36m0.0291\u001b[0m  8.6310\n",
      "      5        \u001b[36m0.0253\u001b[0m  9.3838\n",
      "      6        \u001b[36m0.0204\u001b[0m  8.2120\n",
      "      7        0.0205  8.2385\n",
      "      8        \u001b[36m0.0175\u001b[0m  8.2816\n",
      "      9        0.0180  8.1552\n",
      "     10        \u001b[36m0.0151\u001b[0m  8.1708\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0564\u001b[0m  8.1096\n",
      "      2        \u001b[36m0.0346\u001b[0m  8.1132\n",
      "      3        \u001b[36m0.0290\u001b[0m  8.1063\n",
      "      4        0.0336  8.1500\n",
      "      5        \u001b[36m0.0260\u001b[0m  8.1272\n",
      "      6        \u001b[36m0.0220\u001b[0m  8.1026\n",
      "      7        \u001b[36m0.0185\u001b[0m  8.1468\n",
      "      8        \u001b[36m0.0162\u001b[0m  8.1224\n",
      "      9        0.0175  8.1062\n",
      "     10        \u001b[36m0.0161\u001b[0m  8.0934\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0584\u001b[0m  8.1028\n",
      "      2        \u001b[36m0.0367\u001b[0m  8.1363\n",
      "      3        \u001b[36m0.0331\u001b[0m  8.0970\n",
      "      4        \u001b[36m0.0315\u001b[0m  8.0889\n",
      "      5        \u001b[36m0.0250\u001b[0m  8.0932\n",
      "      6        0.0259  8.0946\n",
      "      7        \u001b[36m0.0228\u001b[0m  8.0867\n",
      "      8        \u001b[36m0.0195\u001b[0m  8.1115\n",
      "      9        \u001b[36m0.0165\u001b[0m  8.1141\n",
      "     10        0.0186  8.0915\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0598\u001b[0m  8.0809\n",
      "      2        \u001b[36m0.0361\u001b[0m  8.0836\n",
      "      3        0.0385  8.0865\n",
      "      4        \u001b[36m0.0280\u001b[0m  8.0867\n",
      "      5        0.0293  8.0914\n",
      "      6        \u001b[36m0.0215\u001b[0m  8.1147\n",
      "      7        \u001b[36m0.0188\u001b[0m  8.1697\n",
      "      8        \u001b[36m0.0168\u001b[0m  8.1151\n",
      "      9        0.0170  8.1741\n",
      "     10        \u001b[36m0.0163\u001b[0m  8.0859\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1856\u001b[0m  8.3385\n",
      "      2        \u001b[36m0.0280\u001b[0m  8.4013\n",
      "      3        \u001b[36m0.0247\u001b[0m  8.3610\n",
      "      4        0.0268  8.3095\n",
      "      5        \u001b[36m0.0223\u001b[0m  8.3143\n",
      "      6        \u001b[36m0.0216\u001b[0m  8.3532\n",
      "      7        \u001b[36m0.0192\u001b[0m  8.2929\n",
      "      8        0.0283  8.3428\n",
      "      9        0.0203  8.3069\n",
      "     10        0.0271  8.3712\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1683\u001b[0m  8.3239\n",
      "      2        \u001b[36m0.0331\u001b[0m  8.2914\n",
      "      3        \u001b[36m0.0294\u001b[0m  8.2719\n",
      "      4        \u001b[36m0.0255\u001b[0m  8.2805\n",
      "      5        \u001b[36m0.0221\u001b[0m  8.2737\n",
      "      6        \u001b[36m0.0217\u001b[0m  8.2826\n",
      "      7        \u001b[36m0.0180\u001b[0m  8.3251\n",
      "      8        0.0212  8.3021\n",
      "      9        0.0255  8.2677\n",
      "     10        0.0287  8.2818\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1499\u001b[0m  8.3006\n",
      "      2        \u001b[36m0.0321\u001b[0m  8.2936\n",
      "      3        \u001b[36m0.0293\u001b[0m  8.2856\n",
      "      4        \u001b[36m0.0231\u001b[0m  8.3227\n",
      "      5        0.0356  8.3177\n",
      "      6        0.0258  8.2920\n",
      "      7        0.0281  8.3036\n",
      "      8        0.0239  8.2984\n",
      "      9        \u001b[36m0.0186\u001b[0m  8.2937\n",
      "     10        0.0204  8.2991\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1587\u001b[0m  8.3148\n",
      "      2        \u001b[36m0.0327\u001b[0m  8.3068\n",
      "      3        \u001b[36m0.0304\u001b[0m  8.2896\n",
      "      4        \u001b[36m0.0243\u001b[0m  8.2883\n",
      "      5        \u001b[36m0.0219\u001b[0m  8.3020\n",
      "      6        \u001b[36m0.0202\u001b[0m  8.3138\n",
      "      7        0.0223  8.3047\n",
      "      8        0.0228  8.3260\n",
      "      9        0.0238  8.3461\n",
      "     10        0.0232  8.3136\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1681\u001b[0m  8.2937\n",
      "      2        \u001b[36m0.0295\u001b[0m  8.2813\n",
      "      3        \u001b[36m0.0284\u001b[0m  8.2900\n",
      "      4        \u001b[36m0.0182\u001b[0m  8.2801\n",
      "      5        0.0193  8.3042\n",
      "      6        0.0230  8.3169\n",
      "      7        0.0202  8.3239\n",
      "      8        0.0188  8.2662\n",
      "      9        0.0186  8.2713\n",
      "     10        0.0202  8.2697\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0644\u001b[0m  8.0124\n",
      "      2        \u001b[36m0.0378\u001b[0m  8.0175\n",
      "      3        \u001b[36m0.0364\u001b[0m  8.0393\n",
      "      4        \u001b[36m0.0360\u001b[0m  8.0575\n",
      "      5        0.0431  8.0240\n",
      "      6        \u001b[36m0.0285\u001b[0m  8.0175\n",
      "      7        \u001b[36m0.0269\u001b[0m  8.0169\n",
      "      8        \u001b[36m0.0264\u001b[0m  8.0118\n",
      "      9        \u001b[36m0.0231\u001b[0m  8.0176\n",
      "     10        \u001b[36m0.0199\u001b[0m  8.0282\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0624\u001b[0m  8.0313\n",
      "      2        \u001b[36m0.0382\u001b[0m  8.0216\n",
      "      3        0.0429  8.0357\n",
      "      4        0.0383  8.0304\n",
      "      5        \u001b[36m0.0359\u001b[0m  8.0414\n",
      "      6        \u001b[36m0.0301\u001b[0m  8.0463\n",
      "      7        \u001b[36m0.0262\u001b[0m  8.0602\n",
      "      8        \u001b[36m0.0243\u001b[0m  8.0560\n",
      "      9        0.0254  8.0835\n",
      "     10        \u001b[36m0.0231\u001b[0m  8.0436\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0596\u001b[0m  8.0193\n",
      "      2        \u001b[36m0.0402\u001b[0m  8.0593\n",
      "      3        \u001b[36m0.0354\u001b[0m  8.0384\n",
      "      4        0.0458  8.0284\n",
      "      5        \u001b[36m0.0343\u001b[0m  8.0716\n",
      "      6        \u001b[36m0.0302\u001b[0m  8.0459\n",
      "      7        \u001b[36m0.0278\u001b[0m  8.0319\n",
      "      8        \u001b[36m0.0259\u001b[0m  8.0425\n",
      "      9        \u001b[36m0.0222\u001b[0m  8.0408\n",
      "     10        0.0224  8.0462\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0619\u001b[0m  8.0462\n",
      "      2        \u001b[36m0.0398\u001b[0m  8.0715\n",
      "      3        \u001b[36m0.0382\u001b[0m  8.0820\n",
      "      4        \u001b[36m0.0366\u001b[0m  8.0442\n",
      "      5        \u001b[36m0.0310\u001b[0m  8.0486\n",
      "      6        0.0329  8.0515\n",
      "      7        \u001b[36m0.0295\u001b[0m  8.0397\n",
      "      8        \u001b[36m0.0251\u001b[0m  8.0439\n",
      "      9        0.0277  8.0589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        \u001b[36m0.0235\u001b[0m  8.0702\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0613\u001b[0m  8.0305\n",
      "      2        \u001b[36m0.0403\u001b[0m  8.0387\n",
      "      3        0.0472  8.0397\n",
      "      4        \u001b[36m0.0384\u001b[0m  8.0375\n",
      "      5        \u001b[36m0.0359\u001b[0m  8.0439\n",
      "      6        \u001b[36m0.0310\u001b[0m  8.0546\n",
      "      7        \u001b[36m0.0253\u001b[0m  8.0670\n",
      "      8        \u001b[36m0.0239\u001b[0m  8.0869\n",
      "      9        \u001b[36m0.0221\u001b[0m  8.0352\n",
      "     10        \u001b[36m0.0216\u001b[0m  8.0402\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1908\u001b[0m  8.2913\n",
      "      2        \u001b[36m0.0295\u001b[0m  8.3053\n",
      "      3        \u001b[36m0.0289\u001b[0m  8.3030\n",
      "      4        0.0292  8.3424\n",
      "      5        \u001b[36m0.0280\u001b[0m  8.3056\n",
      "      6        0.0320  8.2965\n",
      "      7        \u001b[36m0.0271\u001b[0m  8.3055\n",
      "      8        0.0314  8.2952\n",
      "      9        0.0329  8.3037\n",
      "     10        0.0344  8.3114\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1791\u001b[0m  8.3241\n",
      "      2        \u001b[36m0.0339\u001b[0m  8.3369\n",
      "      3        \u001b[36m0.0322\u001b[0m  8.3087\n",
      "      4        \u001b[36m0.0305\u001b[0m  8.2994\n",
      "      5        \u001b[36m0.0286\u001b[0m  8.2867\n",
      "      6        \u001b[36m0.0257\u001b[0m  8.2996\n",
      "      7        \u001b[36m0.0255\u001b[0m  8.3011\n",
      "      8        0.0277  8.3230\n",
      "      9        0.0333  8.3173\n",
      "     10        0.0335  8.2974\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1638\u001b[0m  8.3074\n",
      "      2        \u001b[36m0.0307\u001b[0m  8.2991\n",
      "      3        0.0316  8.2925\n",
      "      4        0.0340  8.2954\n",
      "      5        \u001b[36m0.0302\u001b[0m  8.3134\n",
      "      6        0.0392  8.3322\n",
      "      7        0.0344  8.3201\n",
      "      8        \u001b[36m0.0278\u001b[0m  8.2935\n",
      "      9        0.0326  8.2907\n",
      "     10        0.0343  8.2975\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1734\u001b[0m  8.2939\n",
      "      2        \u001b[36m0.0317\u001b[0m  8.3086\n",
      "      3        0.0322  8.3145\n",
      "      4        \u001b[36m0.0315\u001b[0m  8.2948\n",
      "      5        \u001b[36m0.0278\u001b[0m  8.2906\n",
      "      6        0.0327  8.3053\n",
      "      7        0.0314  8.2965\n",
      "      8        \u001b[36m0.0251\u001b[0m  8.3046\n",
      "      9        0.0306  8.3039\n",
      "     10        0.0270  8.3333\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1833\u001b[0m  8.3362\n",
      "      2        \u001b[36m0.0320\u001b[0m  8.2966\n",
      "      3        0.0391  8.3028\n",
      "      4        \u001b[36m0.0228\u001b[0m  8.2989\n",
      "      5        0.0251  8.3071\n",
      "      6        0.0280  8.2932\n",
      "      7        0.0276  8.3245\n",
      "      8        0.0247  8.2999\n",
      "      9        0.0274  8.3012\n",
      "     10        0.0268  8.2954\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0706\u001b[0m  8.0453\n",
      "      2        \u001b[36m0.0434\u001b[0m  8.0439\n",
      "      3        0.0498  8.0525\n",
      "      4        0.0492  8.0686\n",
      "      5        \u001b[36m0.0408\u001b[0m  8.0908\n",
      "      6        \u001b[36m0.0358\u001b[0m  8.0334\n",
      "      7        0.0408  8.0565\n",
      "      8        \u001b[36m0.0341\u001b[0m  8.0386\n",
      "      9        \u001b[36m0.0318\u001b[0m  8.0447\n",
      "     10        \u001b[36m0.0295\u001b[0m  8.0405\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0685\u001b[0m  8.0583\n",
      "      2        \u001b[36m0.0474\u001b[0m  8.0575\n",
      "      3        0.0577  8.0234\n",
      "      4        \u001b[36m0.0463\u001b[0m  8.0394\n",
      "      5        0.0621  8.0300\n",
      "      6        \u001b[36m0.0395\u001b[0m  8.0290\n",
      "      7        \u001b[36m0.0349\u001b[0m  8.0450\n",
      "      8        0.0357  8.0456\n",
      "      9        \u001b[36m0.0324\u001b[0m  8.0757\n",
      "     10        0.0330  8.0832\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0632\u001b[0m  8.0485\n",
      "      2        \u001b[36m0.0426\u001b[0m  8.0413\n",
      "      3        0.0442  8.0447\n",
      "      4        0.0531  8.0497\n",
      "      5        \u001b[36m0.0404\u001b[0m  8.0412\n",
      "      6        \u001b[36m0.0355\u001b[0m  8.0736\n",
      "      7        0.0368  8.0390\n",
      "      8        \u001b[36m0.0297\u001b[0m  8.0452\n",
      "      9        0.0321  8.0431\n",
      "     10        \u001b[36m0.0266\u001b[0m  8.0508\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0679\u001b[0m  8.0422\n",
      "      2        \u001b[36m0.0402\u001b[0m  8.0316\n",
      "      3        0.0657  8.0470\n",
      "      4        \u001b[36m0.0395\u001b[0m  8.0484\n",
      "      5        0.0418  8.0493\n",
      "      6        0.0401  8.0378\n",
      "      7        0.0470  8.0406\n",
      "      8        \u001b[36m0.0371\u001b[0m  8.0338\n",
      "      9        \u001b[36m0.0362\u001b[0m  8.0365\n",
      "     10        \u001b[36m0.0341\u001b[0m  8.0370\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0682\u001b[0m  8.0628\n",
      "      2        \u001b[36m0.0453\u001b[0m  8.0349\n",
      "      3        0.0510  8.0179\n",
      "      4        \u001b[36m0.0447\u001b[0m  8.0240\n",
      "      5        \u001b[36m0.0444\u001b[0m  8.0321\n",
      "      6        \u001b[36m0.0396\u001b[0m  8.0299\n",
      "      7        \u001b[36m0.0395\u001b[0m  8.0211\n",
      "      8        \u001b[36m0.0341\u001b[0m  8.0597\n",
      "      9        \u001b[36m0.0310\u001b[0m  8.0691\n",
      "     10        \u001b[36m0.0294\u001b[0m  8.0468\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2064\u001b[0m  8.3085\n",
      "      2        \u001b[36m0.0358\u001b[0m  8.2947\n",
      "      3        \u001b[36m0.0323\u001b[0m  8.3043\n",
      "      4        0.0338  8.3218\n",
      "      5        0.0410  8.3350\n",
      "      6        0.0419  8.3198\n",
      "      7        0.0412  8.3071\n",
      "      8        0.0371  8.3131\n",
      "      9        0.0418  8.3000\n",
      "     10        0.0423  8.3098\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2005\u001b[0m  8.3492\n",
      "      2        \u001b[36m0.0356\u001b[0m  8.3430\n",
      "      3        0.0435  8.3536\n",
      "      4        \u001b[36m0.0327\u001b[0m  8.3411\n",
      "      5        0.0356  8.3129\n",
      "      6        0.0483  8.3479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        0.0423  8.3632\n",
      "      8        0.0436  8.3021\n",
      "      9        0.0344  8.3119\n",
      "     10        0.0498  8.3517\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1811\u001b[0m  8.3504\n",
      "      2        \u001b[36m0.0352\u001b[0m  8.3584\n",
      "      3        0.0361  8.3184\n",
      "      4        0.0378  8.3147\n",
      "      5        \u001b[36m0.0333\u001b[0m  8.3121\n",
      "      6        0.0368  8.3370\n",
      "      7        0.0340  8.3262\n",
      "      8        0.0404  8.3600\n",
      "      9        0.0402  8.3145\n",
      "     10        0.0419  8.3358\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1811\u001b[0m  8.2716\n",
      "      2        \u001b[36m0.0369\u001b[0m  8.3122\n",
      "      3        0.0379  8.2879\n",
      "      4        0.0382  8.2770\n",
      "      5        0.0525  8.2886\n",
      "      6        0.0412  8.2740\n",
      "      7        0.0373  8.2731\n",
      "      8        \u001b[36m0.0345\u001b[0m  8.2819\n",
      "      9        0.0349  8.2694\n",
      "     10        0.0436  8.2814\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1998\u001b[0m  8.3451\n",
      "      2        \u001b[36m0.0366\u001b[0m  8.3770\n",
      "      3        \u001b[36m0.0338\u001b[0m  8.3234\n",
      "      4        \u001b[36m0.0319\u001b[0m  8.3592\n",
      "      5        0.0343  8.3251\n",
      "      6        0.0339  8.3489\n",
      "      7        0.0323  8.3546\n",
      "      8        0.0350  8.3535\n",
      "      9        \u001b[36m0.0300\u001b[0m  8.3851\n",
      "     10        0.0322  8.4627\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0611\u001b[0m  8.1110\n",
      "      2        \u001b[36m0.0327\u001b[0m  8.0744\n",
      "      3        0.0467  8.1259\n",
      "      4        \u001b[36m0.0304\u001b[0m  8.0935\n",
      "      5        \u001b[36m0.0278\u001b[0m  8.1591\n",
      "      6        \u001b[36m0.0219\u001b[0m  8.1129\n",
      "      7        \u001b[36m0.0196\u001b[0m  8.1183\n",
      "      8        \u001b[36m0.0182\u001b[0m  8.0759\n",
      "      9        \u001b[36m0.0160\u001b[0m  8.0704\n",
      "     10        \u001b[36m0.0154\u001b[0m  8.0969\n",
      "     11        0.0173  8.1195\n",
      "     12        0.0172  8.0962\n",
      "     13        \u001b[36m0.0149\u001b[0m  8.0856\n",
      "     14        \u001b[36m0.0148\u001b[0m  8.0997\n",
      "     15        \u001b[36m0.0132\u001b[0m  8.1262\n",
      "     16        0.0149  8.0673\n",
      "     17        0.0138  8.1828\n",
      "     18        0.0165  8.0832\n",
      "     19        0.0140  8.1062\n",
      "     20        0.0146  8.1080\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0605\u001b[0m  8.1340\n",
      "      2        \u001b[36m0.0375\u001b[0m  8.0544\n",
      "      3        0.0377  8.0738\n",
      "      4        \u001b[36m0.0307\u001b[0m  8.0776\n",
      "      5        \u001b[36m0.0288\u001b[0m  8.0642\n",
      "      6        \u001b[36m0.0275\u001b[0m  8.0758\n",
      "      7        \u001b[36m0.0205\u001b[0m  8.1291\n",
      "      8        \u001b[36m0.0183\u001b[0m  8.0722\n",
      "      9        \u001b[36m0.0164\u001b[0m  8.0592\n",
      "     10        0.0172  8.0758\n",
      "     11        0.0181  8.0573\n",
      "     12        0.0178  8.0636\n",
      "     13        \u001b[36m0.0151\u001b[0m  8.1340\n",
      "     14        \u001b[36m0.0140\u001b[0m  8.0774\n",
      "     15        0.0168  8.1006\n",
      "     16        \u001b[36m0.0130\u001b[0m  8.1970\n",
      "     17        0.0164  8.0902\n",
      "     18        0.0134  8.0695\n",
      "     19        0.0159  8.0935\n",
      "     20        0.0163  8.0909\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0573\u001b[0m  8.0570\n",
      "      2        \u001b[36m0.0351\u001b[0m  8.0767\n",
      "      3        \u001b[36m0.0310\u001b[0m  8.1382\n",
      "      4        \u001b[36m0.0282\u001b[0m  8.0988\n",
      "      5        \u001b[36m0.0230\u001b[0m  8.0779\n",
      "      6        0.0232  8.0914\n",
      "      7        \u001b[36m0.0198\u001b[0m  8.0848\n",
      "      8        \u001b[36m0.0146\u001b[0m  8.1346\n",
      "      9        \u001b[36m0.0134\u001b[0m  8.0782\n",
      "     10        0.0147  8.1020\n",
      "     11        0.0166  8.0734\n",
      "     12        0.0140  8.1172\n",
      "     13        0.0134  8.0825\n",
      "     14        \u001b[36m0.0127\u001b[0m  8.1042\n",
      "     15        0.0150  8.0517\n",
      "     16        \u001b[36m0.0119\u001b[0m  8.1221\n",
      "     17        \u001b[36m0.0115\u001b[0m  8.0803\n",
      "     18        0.0118  8.0978\n",
      "     19        0.0128  8.0651\n",
      "     20        0.0119  8.0912\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0586\u001b[0m  8.0776\n",
      "      2        \u001b[36m0.0338\u001b[0m  8.0804\n",
      "      3        \u001b[36m0.0310\u001b[0m  8.0708\n",
      "      4        0.0364  8.1269\n",
      "      5        0.0422  8.1103\n",
      "      6        \u001b[36m0.0230\u001b[0m  8.1134\n",
      "      7        \u001b[36m0.0212\u001b[0m  8.1264\n",
      "      8        \u001b[36m0.0185\u001b[0m  8.1217\n",
      "      9        0.0208  8.1230\n",
      "     10        0.0194  8.0850\n",
      "     11        \u001b[36m0.0174\u001b[0m  8.1067\n",
      "     12        \u001b[36m0.0161\u001b[0m  8.1743\n",
      "     13        0.0170  8.0503\n",
      "     14        0.0171  8.0729\n",
      "     15        \u001b[36m0.0155\u001b[0m  8.0520\n",
      "     16        \u001b[36m0.0152\u001b[0m  8.1401\n",
      "     17        \u001b[36m0.0142\u001b[0m  8.0632\n",
      "     18        0.0162  8.1134\n",
      "     19        0.0157  8.0810\n",
      "     20        0.0152  8.0956\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0590\u001b[0m  8.1089\n",
      "      2        \u001b[36m0.0367\u001b[0m  8.0638\n",
      "      3        \u001b[36m0.0338\u001b[0m  8.0615\n",
      "      4        \u001b[36m0.0276\u001b[0m  8.0712\n",
      "      5        \u001b[36m0.0249\u001b[0m  8.0922\n",
      "      6        \u001b[36m0.0185\u001b[0m  8.0795\n",
      "      7        0.0186  8.0890\n",
      "      8        \u001b[36m0.0175\u001b[0m  8.0950\n",
      "      9        \u001b[36m0.0155\u001b[0m  8.0684\n",
      "     10        \u001b[36m0.0151\u001b[0m  8.0613\n",
      "     11        \u001b[36m0.0144\u001b[0m  8.0680\n",
      "     12        \u001b[36m0.0137\u001b[0m  8.0695\n",
      "     13        \u001b[36m0.0125\u001b[0m  8.1091\n",
      "     14        0.0141  8.1113\n",
      "     15        0.0137  8.0981\n",
      "     16        0.0137  8.0632\n",
      "     17        0.0148  8.0459\n",
      "     18        0.0136  8.0714\n",
      "     19        0.0136  8.0796\n",
      "     20        0.0148  8.0940\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1883\u001b[0m  8.2965\n",
      "      2        \u001b[36m0.0283\u001b[0m  8.3126\n",
      "      3        \u001b[36m0.0247\u001b[0m  8.3159\n",
      "      4        \u001b[36m0.0226\u001b[0m  8.3935\n",
      "      5        0.0247  8.3015\n",
      "      6        \u001b[36m0.0222\u001b[0m  8.3139\n",
      "      7        0.0266  8.2937\n",
      "      8        \u001b[36m0.0217\u001b[0m  8.2885\n",
      "      9        0.0247  8.3693\n",
      "     10        \u001b[36m0.0216\u001b[0m  8.2964\n",
      "     11        0.0221  8.2904\n",
      "     12        0.0246  8.3213\n",
      "     13        0.0228  8.2904\n",
      "     14        0.0230  8.2959\n",
      "     15        \u001b[36m0.0192\u001b[0m  8.3285\n",
      "     16        0.0226  8.3733\n",
      "     17        0.0240  8.2977\n",
      "     18        0.0228  8.3015\n",
      "     19        0.0206  8.2833\n",
      "     20        0.0203  8.2729\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1774\u001b[0m  8.4233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.0300\u001b[0m  8.3295\n",
      "      3        0.0311  8.3890\n",
      "      4        \u001b[36m0.0275\u001b[0m  8.3432\n",
      "      5        \u001b[36m0.0253\u001b[0m  8.3448\n",
      "      6        \u001b[36m0.0215\u001b[0m  8.3714\n",
      "      7        0.0234  8.3472\n",
      "      8        \u001b[36m0.0182\u001b[0m  8.4022\n",
      "      9        0.0189  8.3350\n",
      "     10        0.0214  8.3957\n",
      "     11        0.0194  8.3394\n",
      "     12        0.0205  8.4004\n",
      "     13        0.0203  8.3785\n",
      "     14        0.0215  8.4023\n",
      "     15        0.0191  8.3436\n",
      "     16        0.0202  8.3720\n",
      "     17        0.0194  8.4003\n",
      "     18        \u001b[36m0.0155\u001b[0m  8.3476\n",
      "     19        0.0237  8.4020\n",
      "     20        0.0216  8.4178\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1554\u001b[0m  8.3280\n",
      "      2        \u001b[36m0.0274\u001b[0m  8.3525\n",
      "      3        0.0282  8.3867\n",
      "      4        \u001b[36m0.0210\u001b[0m  8.4411\n",
      "      5        \u001b[36m0.0207\u001b[0m  8.3124\n",
      "      6        0.0254  8.3682\n",
      "      7        0.0256  8.3411\n",
      "      8        \u001b[36m0.0198\u001b[0m  8.3219\n",
      "      9        0.0247  8.2932\n",
      "     10        0.0217  8.3362\n",
      "     11        0.0239  8.3113\n",
      "     12        \u001b[36m0.0189\u001b[0m  8.3033\n",
      "     13        0.0232  8.3230\n",
      "     14        0.0254  8.2954\n",
      "     15        0.0206  8.2979\n",
      "     16        0.0211  8.2867\n",
      "     17        0.0217  8.3052\n",
      "     18        0.0209  8.3191\n",
      "     19        0.0193  8.2951\n",
      "     20        0.0213  8.2931\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1616\u001b[0m  8.2905\n",
      "      2        \u001b[36m0.0319\u001b[0m  8.2969\n",
      "      3        \u001b[36m0.0290\u001b[0m  8.2806\n",
      "      4        \u001b[36m0.0253\u001b[0m  8.2995\n",
      "      5        \u001b[36m0.0220\u001b[0m  8.3250\n",
      "      6        \u001b[36m0.0212\u001b[0m  8.3370\n",
      "      7        \u001b[36m0.0177\u001b[0m  8.3033\n",
      "      8        0.0207  8.2878\n",
      "      9        0.0212  8.2993\n",
      "     10        0.0255  8.2782\n",
      "     11        0.0303  8.3021\n",
      "     12        0.0308  8.4011\n",
      "     13        0.0304  8.3299\n",
      "     14        0.0253  8.3490\n",
      "     15        0.0218  8.3124\n",
      "     16        0.0195  8.3098\n",
      "     17        0.0227  8.2944\n",
      "     18        0.0203  8.2779\n",
      "     19        \u001b[36m0.0176\u001b[0m  8.3574\n",
      "     20        0.0188  8.4146\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1722\u001b[0m  8.2954\n",
      "      2        \u001b[36m0.0297\u001b[0m  8.3175\n",
      "      3        \u001b[36m0.0262\u001b[0m  8.2871\n",
      "      4        \u001b[36m0.0196\u001b[0m  8.3056\n",
      "      5        \u001b[36m0.0194\u001b[0m  8.3233\n",
      "      6        0.0209  8.3714\n",
      "      7        0.0218  8.3323\n",
      "      8        \u001b[36m0.0169\u001b[0m  8.3063\n",
      "      9        0.0194  8.2966\n",
      "     10        0.0220  8.3008\n",
      "     11        0.0209  8.3018\n",
      "     12        0.0222  8.2845\n",
      "     13        0.0199  8.3309\n",
      "     14        \u001b[36m0.0158\u001b[0m  8.3356\n",
      "     15        0.0207  8.2945\n",
      "     16        0.0166  8.3055\n",
      "     17        0.0170  8.2927\n",
      "     18        0.0194  8.3020\n",
      "     19        0.0178  8.2936\n",
      "     20        0.0177  8.3218\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0626\u001b[0m  8.0425\n",
      "      2        \u001b[36m0.0390\u001b[0m  8.0359\n",
      "      3        0.0395  8.0219\n",
      "      4        0.0419  8.0221\n",
      "      5        \u001b[36m0.0346\u001b[0m  8.0397\n",
      "      6        \u001b[36m0.0328\u001b[0m  8.0315\n",
      "      7        \u001b[36m0.0279\u001b[0m  8.0545\n",
      "      8        \u001b[36m0.0258\u001b[0m  8.0637\n",
      "      9        \u001b[36m0.0218\u001b[0m  8.0874\n",
      "     10        0.0223  8.0546\n",
      "     11        \u001b[36m0.0215\u001b[0m  8.0388\n",
      "     12        0.0216  8.0372\n",
      "     13        0.0239  8.0427\n",
      "     14        \u001b[36m0.0212\u001b[0m  8.0380\n",
      "     15        \u001b[36m0.0208\u001b[0m  8.0714\n",
      "     16        0.0209  8.0454\n",
      "     17        \u001b[36m0.0203\u001b[0m  8.0377\n",
      "     18        0.0214  8.0348\n",
      "     19        \u001b[36m0.0197\u001b[0m  8.0380\n",
      "     20        0.0254  8.0538\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0656\u001b[0m  8.0339\n",
      "      2        \u001b[36m0.0447\u001b[0m  8.0621\n",
      "      3        \u001b[36m0.0419\u001b[0m  8.0708\n",
      "      4        \u001b[36m0.0407\u001b[0m  8.0334\n",
      "      5        \u001b[36m0.0309\u001b[0m  8.0434\n",
      "      6        \u001b[36m0.0286\u001b[0m  8.0514\n",
      "      7        \u001b[36m0.0260\u001b[0m  8.0439\n",
      "      8        \u001b[36m0.0248\u001b[0m  8.0340\n",
      "      9        \u001b[36m0.0230\u001b[0m  8.0326\n",
      "     10        \u001b[36m0.0215\u001b[0m  8.0868\n",
      "     11        \u001b[36m0.0202\u001b[0m  8.0536\n",
      "     12        0.0211  8.0384\n",
      "     13        \u001b[36m0.0197\u001b[0m  8.1460\n",
      "     14        0.0209  8.9681\n",
      "     15        \u001b[36m0.0195\u001b[0m  9.9297\n",
      "     16        \u001b[36m0.0170\u001b[0m  8.6552\n",
      "     17        0.0192  8.4398\n",
      "     18        0.0208  8.2523\n",
      "     19        0.0177  8.2764\n",
      "     20        0.0187  8.1099\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0581\u001b[0m  8.0585\n",
      "      2        \u001b[36m0.0365\u001b[0m  8.0572\n",
      "      3        \u001b[36m0.0348\u001b[0m  8.0723\n",
      "      4        0.0367  8.0683\n",
      "      5        0.0600  8.0605\n",
      "      6        \u001b[36m0.0306\u001b[0m  8.0694\n",
      "      7        \u001b[36m0.0290\u001b[0m  8.0595\n",
      "      8        \u001b[36m0.0270\u001b[0m  8.0905\n",
      "      9        \u001b[36m0.0223\u001b[0m  8.0720\n",
      "     10        \u001b[36m0.0197\u001b[0m  8.0660\n",
      "     11        \u001b[36m0.0192\u001b[0m  8.0849\n",
      "     12        0.0212  8.1087\n",
      "     13        0.0213  8.0829\n",
      "     14        \u001b[36m0.0174\u001b[0m  8.0460\n",
      "     15        \u001b[36m0.0170\u001b[0m  8.0881\n",
      "     16        0.0182  8.1254\n",
      "     17        \u001b[36m0.0162\u001b[0m  8.0459\n",
      "     18        0.0189  8.0964\n",
      "     19        0.0173  8.0494\n",
      "     20        \u001b[36m0.0158\u001b[0m  8.0372\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0602\u001b[0m  8.0326\n",
      "      2        \u001b[36m0.0414\u001b[0m  8.0321\n",
      "      3        \u001b[36m0.0400\u001b[0m  8.0259\n",
      "      4        \u001b[36m0.0376\u001b[0m  8.0268\n",
      "      5        0.0449  8.0233\n",
      "      6        \u001b[36m0.0307\u001b[0m  8.0723\n",
      "      7        \u001b[36m0.0290\u001b[0m  8.0749\n",
      "      8        \u001b[36m0.0265\u001b[0m  8.0234\n",
      "      9        \u001b[36m0.0246\u001b[0m  8.0347\n",
      "     10        \u001b[36m0.0236\u001b[0m  8.0314\n",
      "     11        \u001b[36m0.0228\u001b[0m  8.0406\n",
      "     12        \u001b[36m0.0205\u001b[0m  8.0264\n",
      "     13        \u001b[36m0.0200\u001b[0m  8.1123\n",
      "     14        0.0201  8.0667\n",
      "     15        0.0202  8.0286\n",
      "     16        0.0211  8.0245\n",
      "     17        \u001b[36m0.0185\u001b[0m  8.0354\n",
      "     18        0.0189  8.0236\n",
      "     19        \u001b[36m0.0178\u001b[0m  8.0308\n",
      "     20        0.0186  8.0411\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0651\u001b[0m  8.0599\n",
      "      2        \u001b[36m0.0394\u001b[0m  8.0787\n",
      "      3        \u001b[36m0.0365\u001b[0m  8.0311\n",
      "      4        0.0380  8.0296\n",
      "      5        \u001b[36m0.0316\u001b[0m  8.0262\n",
      "      6        \u001b[36m0.0297\u001b[0m  8.0246\n",
      "      7        \u001b[36m0.0231\u001b[0m  8.0332\n",
      "      8        \u001b[36m0.0223\u001b[0m  8.0471\n",
      "      9        \u001b[36m0.0217\u001b[0m  8.0412\n",
      "     10        \u001b[36m0.0189\u001b[0m  8.0235\n",
      "     11        0.0202  8.0279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12        0.0191  8.0348\n",
      "     13        \u001b[36m0.0186\u001b[0m  8.0693\n",
      "     14        0.0196  8.0492\n",
      "     15        0.0196  8.0975\n",
      "     16        0.0191  8.0637\n",
      "     17        0.0193  8.1086\n",
      "     18        0.0198  8.0500\n",
      "     19        0.0188  8.0752\n",
      "     20        \u001b[36m0.0183\u001b[0m  8.0628\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1878\u001b[0m  8.3442\n",
      "      2        \u001b[36m0.0327\u001b[0m  8.3460\n",
      "      3        \u001b[36m0.0326\u001b[0m  8.3854\n",
      "      4        \u001b[36m0.0320\u001b[0m  8.3651\n",
      "      5        \u001b[36m0.0303\u001b[0m  8.3688\n",
      "      6        \u001b[36m0.0300\u001b[0m  8.3569\n",
      "      7        \u001b[36m0.0255\u001b[0m  8.3334\n",
      "      8        0.0283  8.3128\n",
      "      9        0.0280  8.3260\n",
      "     10        0.0281  8.3538\n",
      "     11        0.0311  8.3472\n",
      "     12        0.0341  8.3008\n",
      "     13        0.0279  8.2949\n",
      "     14        0.0308  8.3028\n",
      "     15        0.0298  8.3029\n",
      "     16        0.0305  8.2982\n",
      "     17        0.0368  8.3224\n",
      "     18        0.0319  8.3128\n",
      "     19        \u001b[36m0.0244\u001b[0m  8.3037\n",
      "     20        0.0284  8.3000\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1810\u001b[0m  8.2943\n",
      "      2        \u001b[36m0.0341\u001b[0m  8.2984\n",
      "      3        \u001b[36m0.0326\u001b[0m  8.2907\n",
      "      4        \u001b[36m0.0273\u001b[0m  8.3066\n",
      "      5        0.0324  8.3315\n",
      "      6        \u001b[36m0.0271\u001b[0m  8.3017\n",
      "      7        \u001b[36m0.0259\u001b[0m  8.2990\n",
      "      8        0.0261  8.2920\n",
      "      9        0.0267  8.3183\n",
      "     10        \u001b[36m0.0250\u001b[0m  8.2995\n",
      "     11        0.0349  8.3191\n",
      "     12        0.0294  8.3165\n",
      "     13        0.0308  8.2855\n",
      "     14        0.0329  8.2911\n",
      "     15        0.0260  8.2928\n",
      "     16        0.0299  8.2951\n",
      "     17        \u001b[36m0.0245\u001b[0m  8.2990\n",
      "     18        0.0304  8.3054\n",
      "     19        \u001b[36m0.0244\u001b[0m  8.3193\n",
      "     20        0.0270  8.3135\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1656\u001b[0m  8.2866\n",
      "      2        \u001b[36m0.0349\u001b[0m  8.2870\n",
      "      3        \u001b[36m0.0296\u001b[0m  8.2921\n",
      "      4        \u001b[36m0.0279\u001b[0m  8.2886\n",
      "      5        0.0309  8.3031\n",
      "      6        \u001b[36m0.0272\u001b[0m  8.3157\n",
      "      7        \u001b[36m0.0266\u001b[0m  8.2973\n",
      "      8        0.0383  8.2839\n",
      "      9        0.0294  8.2819\n",
      "     10        0.0276  8.2975\n",
      "     11        \u001b[36m0.0251\u001b[0m  8.2825\n",
      "     12        0.0256  8.3059\n",
      "     13        \u001b[36m0.0244\u001b[0m  8.3405\n",
      "     14        0.0261  8.3874\n",
      "     15        \u001b[36m0.0236\u001b[0m  8.3552\n",
      "     16        0.0277  8.3520\n",
      "     17        \u001b[36m0.0232\u001b[0m  8.3776\n",
      "     18        0.0267  8.3298\n",
      "     19        \u001b[36m0.0227\u001b[0m  8.3555\n",
      "     20        \u001b[36m0.0209\u001b[0m  8.3527\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1707\u001b[0m  8.3227\n",
      "      2        \u001b[36m0.0321\u001b[0m  8.3411\n",
      "      3        \u001b[36m0.0319\u001b[0m  8.3812\n",
      "      4        \u001b[36m0.0279\u001b[0m  8.3652\n",
      "      5        0.0306  8.3638\n",
      "      6        0.0292  8.3490\n",
      "      7        0.0306  8.3379\n",
      "      8        0.0285  8.4093\n",
      "      9        \u001b[36m0.0254\u001b[0m  8.3612\n",
      "     10        0.0255  8.3538\n",
      "     11        0.0272  8.3555\n",
      "     12        0.0304  8.3303\n",
      "     13        0.0292  8.3899\n",
      "     14        0.0265  8.3581\n",
      "     15        \u001b[36m0.0251\u001b[0m  8.3418\n",
      "     16        \u001b[36m0.0242\u001b[0m  8.3411\n",
      "     17        0.0248  8.3471\n",
      "     18        \u001b[36m0.0236\u001b[0m  8.3554\n",
      "     19        0.0276  8.3478\n",
      "     20        0.0280  8.3312\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1784\u001b[0m  8.3665\n",
      "      2        \u001b[36m0.0309\u001b[0m  8.3940\n",
      "      3        0.0418  8.3832\n",
      "      4        \u001b[36m0.0240\u001b[0m  8.3263\n",
      "      5        0.0242  8.3139\n",
      "      6        0.0294  8.3505\n",
      "      7        \u001b[36m0.0233\u001b[0m  8.3422\n",
      "      8        0.0244  8.3349\n",
      "      9        0.0282  8.3635\n",
      "     10        0.0239  8.4498\n",
      "     11        0.0258  8.3237\n",
      "     12        0.0258  8.3361\n",
      "     13        \u001b[36m0.0222\u001b[0m  8.3281\n",
      "     14        0.0288  8.3359\n",
      "     15        \u001b[36m0.0203\u001b[0m  8.3448\n",
      "     16        0.0267  8.3619\n",
      "     17        0.0259  8.3412\n",
      "     18        0.0251  8.3474\n",
      "     19        0.0215  8.3218\n",
      "     20        0.0292  8.3925\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0677\u001b[0m  8.1003\n",
      "      2        \u001b[36m0.0419\u001b[0m  8.0551\n",
      "      3        0.0494  8.0732\n",
      "      4        0.0513  8.0866\n",
      "      5        0.0491  8.0865\n",
      "      6        0.0466  8.0255\n",
      "      7        \u001b[36m0.0404\u001b[0m  8.0348\n",
      "      8        \u001b[36m0.0395\u001b[0m  8.0326\n",
      "      9        \u001b[36m0.0335\u001b[0m  8.0465\n",
      "     10        0.0343  8.0756\n",
      "     11        \u001b[36m0.0274\u001b[0m  8.0915\n",
      "     12        0.0338  8.0344\n",
      "     13        0.0297  8.0453\n",
      "     14        0.0277  8.0360\n",
      "     15        0.0296  8.0373\n",
      "     16        0.0279  8.0405\n",
      "     17        0.0291  8.0738\n",
      "     18        \u001b[36m0.0257\u001b[0m  8.0455\n",
      "     19        0.0264  8.0437\n",
      "     20        0.0269  8.0356\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0697\u001b[0m  8.0306\n",
      "      2        \u001b[36m0.0474\u001b[0m  8.0344\n",
      "      3        0.0717  8.0344\n",
      "      4        \u001b[36m0.0452\u001b[0m  8.0396\n",
      "      5        0.0468  8.0660\n",
      "      6        \u001b[36m0.0428\u001b[0m  8.0864\n",
      "      7        \u001b[36m0.0361\u001b[0m  8.0384\n",
      "      8        \u001b[36m0.0335\u001b[0m  8.0294\n",
      "      9        0.0351  8.0445\n",
      "     10        \u001b[36m0.0303\u001b[0m  8.0314\n",
      "     11        0.0309  8.0422\n",
      "     12        0.0309  8.0643\n",
      "     13        0.0308  8.0461\n",
      "     14        0.0307  8.0326\n",
      "     15        \u001b[36m0.0299\u001b[0m  8.0326\n",
      "     16        \u001b[36m0.0297\u001b[0m  8.0287\n",
      "     17        \u001b[36m0.0295\u001b[0m  8.0499\n",
      "     18        0.0314  8.0317\n",
      "     19        \u001b[36m0.0260\u001b[0m  8.0453\n",
      "     20        0.0293  8.0548\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0643\u001b[0m  8.0414\n",
      "      2        \u001b[36m0.0467\u001b[0m  8.0284\n",
      "      3        0.0477  8.0253\n",
      "      4        0.0498  8.0282\n",
      "      5        \u001b[36m0.0465\u001b[0m  8.0305\n",
      "      6        \u001b[36m0.0377\u001b[0m  8.0424\n",
      "      7        \u001b[36m0.0354\u001b[0m  8.0694\n",
      "      8        \u001b[36m0.0329\u001b[0m  8.0386\n",
      "      9        \u001b[36m0.0321\u001b[0m  8.0254\n",
      "     10        \u001b[36m0.0300\u001b[0m  8.0325\n",
      "     11        \u001b[36m0.0295\u001b[0m  8.0421\n",
      "     12        0.0301  8.0311\n",
      "     13        \u001b[36m0.0271\u001b[0m  8.0273\n",
      "     14        0.0281  8.0567\n",
      "     15        \u001b[36m0.0266\u001b[0m  8.0737\n",
      "     16        0.0285  8.0431\n",
      "     17        \u001b[36m0.0264\u001b[0m  8.0759\n",
      "     18        0.0271  8.0283\n",
      "     19        0.0282  8.0386\n",
      "     20        \u001b[36m0.0263\u001b[0m  8.0476\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0640\u001b[0m  8.0697\n",
      "      2        \u001b[36m0.0460\u001b[0m  8.0760\n",
      "      3        \u001b[36m0.0420\u001b[0m  8.0366\n",
      "      4        0.0438  8.0315\n",
      "      5        0.0423  8.0345\n",
      "      6        0.0495  8.0235\n",
      "      7        \u001b[36m0.0378\u001b[0m  8.0422\n",
      "      8        \u001b[36m0.0344\u001b[0m  8.0737\n",
      "      9        0.0345  8.0796\n",
      "     10        \u001b[36m0.0324\u001b[0m  8.1462\n",
      "     11        \u001b[36m0.0303\u001b[0m  8.0683\n",
      "     12        0.0311  8.0537\n",
      "     13        \u001b[36m0.0288\u001b[0m  8.0647\n",
      "     14        0.0322  8.0807\n",
      "     15        \u001b[36m0.0269\u001b[0m  8.0561\n",
      "     16        0.0288  8.0757\n",
      "     17        0.0290  8.0782\n",
      "     18        \u001b[36m0.0267\u001b[0m  8.0669\n",
      "     19        0.0296  8.0566\n",
      "     20        \u001b[36m0.0258\u001b[0m  8.0626\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0694\u001b[0m  8.0602\n",
      "      2        \u001b[36m0.0472\u001b[0m  8.0639\n",
      "      3        \u001b[36m0.0408\u001b[0m  8.0543\n",
      "      4        0.0477  8.0771\n",
      "      5        0.0442  8.1167\n",
      "      6        \u001b[36m0.0366\u001b[0m  8.0788\n",
      "      7        \u001b[36m0.0336\u001b[0m  8.0904\n",
      "      8        \u001b[36m0.0315\u001b[0m  8.0579\n",
      "      9        \u001b[36m0.0295\u001b[0m  8.0692\n",
      "     10        0.0308  8.0679\n",
      "     11        \u001b[36m0.0291\u001b[0m  8.0775\n",
      "     12        \u001b[36m0.0272\u001b[0m  8.0846\n",
      "     13        0.0301  8.0821\n",
      "     14        0.0286  8.0707\n",
      "     15        0.0274  8.0548\n",
      "     16        \u001b[36m0.0269\u001b[0m  8.0577\n",
      "     17        \u001b[36m0.0258\u001b[0m  8.0689\n",
      "     18        \u001b[36m0.0255\u001b[0m  8.0801\n",
      "     19        0.0284  8.0989\n",
      "     20        0.0257  8.0894\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2114\u001b[0m  8.3151\n",
      "      2        \u001b[36m0.0346\u001b[0m  8.2518\n",
      "      3        \u001b[36m0.0320\u001b[0m  8.2767\n",
      "      4        \u001b[36m0.0313\u001b[0m  8.2755\n",
      "      5        0.0397  8.2967\n",
      "      6        0.0470  8.3173\n",
      "      7        0.0389  8.3294\n",
      "      8        0.0392  8.2907\n",
      "      9        0.0416  8.3004\n",
      "     10        0.0446  8.3024\n",
      "     11        0.0431  8.2955\n",
      "     12        0.0399  8.2901\n",
      "     13        0.0382  8.3212\n",
      "     14        0.0394  8.3478\n",
      "     15        0.0379  8.3135\n",
      "     16        0.0317  8.2686\n",
      "     17        0.0386  8.3096\n",
      "     18        0.0385  8.2934\n",
      "     19        0.0329  8.2845\n",
      "     20        0.0348  8.3325\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1959\u001b[0m  8.3753\n",
      "      2        \u001b[36m0.0415\u001b[0m  8.3806\n",
      "      3        \u001b[36m0.0347\u001b[0m  8.3202\n",
      "      4        \u001b[36m0.0327\u001b[0m  8.3234\n",
      "      5        0.0364  8.3433\n",
      "      6        0.0369  8.3795\n",
      "      7        0.0339  8.3613\n",
      "      8        \u001b[36m0.0323\u001b[0m  8.3882\n",
      "      9        0.0384  8.3498\n",
      "     10        0.0423  8.3268\n",
      "     11        0.0343  8.3730\n",
      "     12        0.0368  8.3692\n",
      "     13        0.0407  8.3479\n",
      "     14        0.0392  8.3740\n",
      "     15        0.0378  8.3525\n",
      "     16        0.0352  8.3432\n",
      "     17        0.0349  8.3437\n",
      "     18        0.0372  8.3548\n",
      "     19        0.0332  8.3428\n",
      "     20        0.0343  8.3252\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1840\u001b[0m  8.3469\n",
      "      2        \u001b[36m0.0350\u001b[0m  8.4079\n",
      "      3        \u001b[36m0.0336\u001b[0m  8.3133\n",
      "      4        0.0434  8.3193\n",
      "      5        0.0360  8.3140\n",
      "      6        0.0375  8.3529\n",
      "      7        \u001b[36m0.0325\u001b[0m  8.3368\n",
      "      8        0.0395  8.3428\n",
      "      9        0.0410  8.3217\n",
      "     10        0.0390  8.3367\n",
      "     11        0.0375  8.3278\n",
      "     12        0.0351  8.3250\n",
      "     13        0.0342  8.3200\n",
      "     14        \u001b[36m0.0319\u001b[0m  8.3057\n",
      "     15        0.0400  8.3579\n",
      "     16        0.0386  8.3629\n",
      "     17        \u001b[36m0.0298\u001b[0m  8.3589\n",
      "     18        0.0365  8.3423\n",
      "     19        0.0317  8.3308\n",
      "     20        0.0334  8.3308\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1881\u001b[0m  8.3326\n",
      "      2        \u001b[36m0.0372\u001b[0m  8.3330\n",
      "      3        0.0407  8.3193\n",
      "      4        0.0462  8.3368\n",
      "      5        0.0514  8.3456\n",
      "      6        0.0443  8.3510\n",
      "      7        0.0452  8.3236\n",
      "      8        0.0440  8.3300\n",
      "      9        0.0447  8.3482\n",
      "     10        \u001b[36m0.0339\u001b[0m  8.3619\n",
      "     11        0.0345  8.4608\n",
      "     12        0.0344  8.3639\n",
      "     13        \u001b[36m0.0337\u001b[0m  8.3124\n",
      "     14        0.0401  8.4113\n",
      "     15        0.0378  8.3046\n",
      "     16        0.0369  8.3290\n",
      "     17        \u001b[36m0.0311\u001b[0m  8.3245\n",
      "     18        0.0352  8.3601\n",
      "     19        0.0321  8.3779\n",
      "     20        0.0331  8.3738\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1976\u001b[0m  8.3291\n",
      "      2        \u001b[36m0.0386\u001b[0m  8.3222\n",
      "      3        \u001b[36m0.0327\u001b[0m  8.3556\n",
      "      4        0.0342  8.3321\n",
      "      5        0.0362  8.3656\n",
      "      6        \u001b[36m0.0299\u001b[0m  8.3432\n",
      "      7        0.0412  8.3419\n",
      "      8        0.0390  8.3661\n",
      "      9        0.0365  8.3198\n",
      "     10        0.0333  8.3806\n",
      "     11        0.0340  8.3725\n",
      "     12        0.0374  8.3195\n",
      "     13        0.0370  8.3596\n",
      "     14        0.0329  8.3367\n",
      "     15        0.0369  8.3443\n",
      "     16        0.0328  8.3326\n",
      "     17        0.0310  8.2953\n",
      "     18        0.0354  8.3146\n",
      "     19        0.0326  8.3421\n",
      "     20        0.0339  8.3001\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.8min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0713\u001b[0m  7.3862\n",
      "      2        \u001b[36m0.0595\u001b[0m  7.3964\n",
      "      3        0.0829  7.3883\n",
      "      4        0.0846  7.3968\n",
      "      5        0.1047  7.3948\n",
      "      6        0.0696  7.4775\n",
      "      7        \u001b[36m0.0431\u001b[0m  7.5002\n",
      "      8        \u001b[36m0.0364\u001b[0m  7.3992\n",
      "      9        \u001b[36m0.0274\u001b[0m  7.4543\n",
      "     10        \u001b[36m0.0199\u001b[0m  7.4275\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0743\u001b[0m  7.4319\n",
      "      2        \u001b[36m0.0543\u001b[0m  7.3889\n",
      "      3        0.0630  7.3882\n",
      "      4        0.0618  7.4206\n",
      "      5        0.0609  7.5105\n",
      "      6        \u001b[36m0.0452\u001b[0m  7.3945\n",
      "      7        \u001b[36m0.0325\u001b[0m  7.3908\n",
      "      8        \u001b[36m0.0260\u001b[0m  7.3978\n",
      "      9        \u001b[36m0.0217\u001b[0m  7.4010\n",
      "     10        \u001b[36m0.0205\u001b[0m  7.4033\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0690\u001b[0m  7.4034\n",
      "      2        \u001b[36m0.0517\u001b[0m  7.3994\n",
      "      3        0.0592  7.4025\n",
      "      4        0.0603  7.3970\n",
      "      5        0.0633  7.3952\n",
      "      6        \u001b[36m0.0423\u001b[0m  7.3972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        \u001b[36m0.0320\u001b[0m  7.3959\n",
      "      8        \u001b[36m0.0245\u001b[0m  7.3925\n",
      "      9        \u001b[36m0.0191\u001b[0m  7.4008\n",
      "     10        \u001b[36m0.0153\u001b[0m  7.4041\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0781\u001b[0m  7.4218\n",
      "      2        \u001b[36m0.0519\u001b[0m  7.3914\n",
      "      3        0.0560  7.3901\n",
      "      4        0.0742  7.3856\n",
      "      5        0.0895  7.4106\n",
      "      6        0.0696  7.3978\n",
      "      7        \u001b[36m0.0468\u001b[0m  7.3973\n",
      "      8        \u001b[36m0.0425\u001b[0m  7.4013\n",
      "      9        \u001b[36m0.0275\u001b[0m  7.4009\n",
      "     10        \u001b[36m0.0234\u001b[0m  7.3966\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0713\u001b[0m  7.4813\n",
      "      2        \u001b[36m0.0596\u001b[0m  7.4087\n",
      "      3        0.0689  7.4068\n",
      "      4        \u001b[36m0.0554\u001b[0m  7.3907\n",
      "      5        0.0693  7.4031\n",
      "      6        \u001b[36m0.0448\u001b[0m  7.4071\n",
      "      7        0.0672  7.4315\n",
      "      8        \u001b[36m0.0312\u001b[0m  7.3958\n",
      "      9        \u001b[36m0.0220\u001b[0m  7.3954\n",
      "     10        \u001b[36m0.0162\u001b[0m  7.3948\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2180\u001b[0m  7.5908\n",
      "      2        \u001b[36m0.0417\u001b[0m  7.6005\n",
      "      3        0.0480  7.6089\n",
      "      4        \u001b[36m0.0340\u001b[0m  7.6092\n",
      "      5        0.0396  7.5990\n",
      "      6        \u001b[36m0.0247\u001b[0m  7.5978\n",
      "      7        \u001b[36m0.0219\u001b[0m  7.5901\n",
      "      8        0.0369  7.6037\n",
      "      9        0.0308  7.6061\n",
      "     10        0.0308  7.6033\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2158\u001b[0m  7.6116\n",
      "      2        \u001b[36m0.0421\u001b[0m  7.6250\n",
      "      3        0.0465  7.6094\n",
      "      4        \u001b[36m0.0358\u001b[0m  7.6030\n",
      "      5        \u001b[36m0.0349\u001b[0m  7.6011\n",
      "      6        \u001b[36m0.0259\u001b[0m  7.6782\n",
      "      7        \u001b[36m0.0211\u001b[0m  7.6065\n",
      "      8        0.0221  7.6183\n",
      "      9        0.0263  7.6256\n",
      "     10        \u001b[36m0.0205\u001b[0m  7.6078\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2444\u001b[0m  7.5721\n",
      "      2        \u001b[36m0.0321\u001b[0m  7.5754\n",
      "      3        \u001b[36m0.0238\u001b[0m  7.5737\n",
      "      4        0.0250  7.5775\n",
      "      5        \u001b[36m0.0233\u001b[0m  7.6096\n",
      "      6        0.0276  7.6213\n",
      "      7        \u001b[36m0.0199\u001b[0m  7.6141\n",
      "      8        \u001b[36m0.0132\u001b[0m  7.6748\n",
      "      9        0.0157  7.5926\n",
      "     10        0.0138  7.6364\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2178\u001b[0m  7.6396\n",
      "      2        \u001b[36m0.0402\u001b[0m  7.5681\n",
      "      3        \u001b[36m0.0321\u001b[0m  7.5796\n",
      "      4        0.0371  7.6006\n",
      "      5        0.0410  7.5881\n",
      "      6        \u001b[36m0.0315\u001b[0m  7.5734\n",
      "      7        \u001b[36m0.0282\u001b[0m  7.6241\n",
      "      8        \u001b[36m0.0256\u001b[0m  7.5867\n",
      "      9        0.0277  7.9579\n",
      "     10        0.0320  8.9817\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2459\u001b[0m  7.8501\n",
      "      2        \u001b[36m0.0401\u001b[0m  8.0093\n",
      "      3        \u001b[36m0.0307\u001b[0m  7.6947\n",
      "      4        \u001b[36m0.0227\u001b[0m  7.6401\n",
      "      5        \u001b[36m0.0169\u001b[0m  7.6488\n",
      "      6        \u001b[36m0.0136\u001b[0m  7.5674\n",
      "      7        \u001b[36m0.0116\u001b[0m  7.5767\n",
      "      8        \u001b[36m0.0095\u001b[0m  7.5692\n",
      "      9        0.0108  7.5714\n",
      "     10        0.0114  7.6014\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0732\u001b[0m  7.3704\n",
      "      2        \u001b[36m0.0572\u001b[0m  7.3635\n",
      "      3        0.0775  7.3720\n",
      "      4        0.0791  7.3695\n",
      "      5        0.0691  7.3639\n",
      "      6        0.0928  7.4180\n",
      "      7        0.0896  7.4288\n",
      "      8        \u001b[36m0.0495\u001b[0m  7.4024\n",
      "      9        \u001b[36m0.0327\u001b[0m  7.4302\n",
      "     10        \u001b[36m0.0282\u001b[0m  7.3811\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0749\u001b[0m  7.3700\n",
      "      2        \u001b[36m0.0557\u001b[0m  7.4767\n",
      "      3        0.0674  7.3721\n",
      "      4        0.0712  7.3801\n",
      "      5        0.0828  7.4024\n",
      "      6        0.0596  7.4094\n",
      "      7        \u001b[36m0.0444\u001b[0m  7.3879\n",
      "      8        \u001b[36m0.0352\u001b[0m  7.3897\n",
      "      9        \u001b[36m0.0306\u001b[0m  7.4174\n",
      "     10        \u001b[36m0.0244\u001b[0m  7.4325\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0749\u001b[0m  7.4475\n",
      "      2        \u001b[36m0.0554\u001b[0m  7.3853\n",
      "      3        0.0607  7.4310\n",
      "      4        \u001b[36m0.0520\u001b[0m  7.3981\n",
      "      5        0.0758  7.4396\n",
      "      6        \u001b[36m0.0498\u001b[0m  7.4227\n",
      "      7        \u001b[36m0.0471\u001b[0m  7.4030\n",
      "      8        \u001b[36m0.0360\u001b[0m  7.3756\n",
      "      9        \u001b[36m0.0285\u001b[0m  7.4260\n",
      "     10        \u001b[36m0.0247\u001b[0m  7.3938\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0732\u001b[0m  7.4093\n",
      "      2        \u001b[36m0.0574\u001b[0m  7.4383\n",
      "      3        0.0841  7.4094\n",
      "      4        0.0639  7.4215\n",
      "      5        0.1186  7.3718\n",
      "      6        0.1083  7.3734\n",
      "      7        0.0935  7.3938\n",
      "      8        0.0585  7.4479\n",
      "      9        \u001b[36m0.0374\u001b[0m  7.3819\n",
      "     10        \u001b[36m0.0304\u001b[0m  7.4264\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0761\u001b[0m  7.4724\n",
      "      2        \u001b[36m0.0589\u001b[0m  7.3693\n",
      "      3        0.0974  7.3630\n",
      "      4        0.0835  7.3635\n",
      "      5        0.0824  7.3624\n",
      "      6        0.0774  7.3670\n",
      "      7        \u001b[36m0.0477\u001b[0m  7.3640\n",
      "      8        \u001b[36m0.0303\u001b[0m  7.4003\n",
      "      9        \u001b[36m0.0290\u001b[0m  7.3834\n",
      "     10        \u001b[36m0.0223\u001b[0m  7.3694\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2426\u001b[0m  7.5678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.0443\u001b[0m  7.5663\n",
      "      3        \u001b[36m0.0413\u001b[0m  7.6106\n",
      "      4        0.0448  7.5640\n",
      "      5        \u001b[36m0.0312\u001b[0m  7.5795\n",
      "      6        0.0324  7.5808\n",
      "      7        \u001b[36m0.0282\u001b[0m  7.6935\n",
      "      8        \u001b[36m0.0242\u001b[0m  7.6316\n",
      "      9        \u001b[36m0.0236\u001b[0m  7.6187\n",
      "     10        \u001b[36m0.0213\u001b[0m  7.5996\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2207\u001b[0m  7.6482\n",
      "      2        \u001b[36m0.0400\u001b[0m  7.5692\n",
      "      3        0.0483  7.6512\n",
      "      4        \u001b[36m0.0329\u001b[0m  7.5765\n",
      "      5        0.0331  7.6365\n",
      "      6        \u001b[36m0.0235\u001b[0m  7.6463\n",
      "      7        0.0340  7.6231\n",
      "      8        0.0243  7.5714\n",
      "      9        0.0595  7.5902\n",
      "     10        0.0340  7.6094\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2120\u001b[0m  7.5628\n",
      "      2        \u001b[36m0.0387\u001b[0m  7.5682\n",
      "      3        \u001b[36m0.0301\u001b[0m  7.5668\n",
      "      4        0.0314  7.5433\n",
      "      5        0.0328  7.5502\n",
      "      6        0.0325  7.5569\n",
      "      7        \u001b[36m0.0232\u001b[0m  7.5515\n",
      "      8        \u001b[36m0.0166\u001b[0m  7.5421\n",
      "      9        \u001b[36m0.0161\u001b[0m  7.5639\n",
      "     10        \u001b[36m0.0154\u001b[0m  7.5505\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2424\u001b[0m  7.5535\n",
      "      2        \u001b[36m0.0385\u001b[0m  7.5550\n",
      "      3        \u001b[36m0.0342\u001b[0m  7.5563\n",
      "      4        0.0384  7.5528\n",
      "      5        \u001b[36m0.0275\u001b[0m  7.5567\n",
      "      6        \u001b[36m0.0233\u001b[0m  7.5948\n",
      "      7        \u001b[36m0.0211\u001b[0m  7.6231\n",
      "      8        \u001b[36m0.0207\u001b[0m  7.5858\n",
      "      9        0.0240  7.5554\n",
      "     10        0.0237  7.5559\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2401\u001b[0m  7.5479\n",
      "      2        \u001b[36m0.0388\u001b[0m  7.5485\n",
      "      3        \u001b[36m0.0320\u001b[0m  7.5441\n",
      "      4        \u001b[36m0.0277\u001b[0m  7.5623\n",
      "      5        \u001b[36m0.0224\u001b[0m  7.5706\n",
      "      6        \u001b[36m0.0181\u001b[0m  7.5585\n",
      "      7        \u001b[36m0.0147\u001b[0m  7.5504\n",
      "      8        \u001b[36m0.0142\u001b[0m  7.5536\n",
      "      9        \u001b[36m0.0127\u001b[0m  7.5522\n",
      "     10        0.0138  7.5571\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0815\u001b[0m  7.3460\n",
      "      2        \u001b[36m0.0584\u001b[0m  7.3562\n",
      "      3        0.0713  7.3625\n",
      "      4        0.0860  7.3933\n",
      "      5        0.0773  7.3705\n",
      "      6        0.0755  7.3400\n",
      "      7        0.0636  7.3447\n",
      "      8        \u001b[36m0.0467\u001b[0m  7.3498\n",
      "      9        \u001b[36m0.0463\u001b[0m  7.3529\n",
      "     10        \u001b[36m0.0358\u001b[0m  7.3507\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0841\u001b[0m  7.3942\n",
      "      2        \u001b[36m0.0595\u001b[0m  7.4128\n",
      "      3        0.0712  7.3630\n",
      "      4        0.0764  7.3415\n",
      "      5        0.1050  7.3464\n",
      "      6        \u001b[36m0.0575\u001b[0m  7.3544\n",
      "      7        \u001b[36m0.0502\u001b[0m  7.3488\n",
      "      8        \u001b[36m0.0440\u001b[0m  7.3502\n",
      "      9        \u001b[36m0.0402\u001b[0m  7.3610\n",
      "     10        \u001b[36m0.0379\u001b[0m  7.3800\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0753\u001b[0m  7.3563\n",
      "      2        \u001b[36m0.0573\u001b[0m  7.3500\n",
      "      3        0.0664  7.3476\n",
      "      4        0.0797  7.3922\n",
      "      5        0.1126  7.3414\n",
      "      6        0.1113  7.3488\n",
      "      7        0.0613  7.3667\n",
      "      8        \u001b[36m0.0536\u001b[0m  7.3530\n",
      "      9        \u001b[36m0.0405\u001b[0m  7.3780\n",
      "     10        \u001b[36m0.0344\u001b[0m  7.3540\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0771\u001b[0m  7.3948\n",
      "      2        \u001b[36m0.0629\u001b[0m  7.3516\n",
      "      3        0.0823  7.4079\n",
      "      4        0.1137  7.3464\n",
      "      5        0.0981  7.3563\n",
      "      6        0.0799  7.3829\n",
      "      7        0.1247  7.3459\n",
      "      8        0.0651  7.3443\n",
      "      9        \u001b[36m0.0473\u001b[0m  7.3564\n",
      "     10        \u001b[36m0.0407\u001b[0m  7.3475\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0789\u001b[0m  7.3539\n",
      "      2        \u001b[36m0.0605\u001b[0m  7.3477\n",
      "      3        0.0652  7.3570\n",
      "      4        0.0948  7.3545\n",
      "      5        0.1350  7.3658\n",
      "      6        0.0735  7.3507\n",
      "      7        0.0884  7.3440\n",
      "      8        \u001b[36m0.0519\u001b[0m  7.3557\n",
      "      9        \u001b[36m0.0436\u001b[0m  7.3660\n",
      "     10        \u001b[36m0.0381\u001b[0m  7.3862\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2383\u001b[0m  7.5780\n",
      "      2        \u001b[36m0.0641\u001b[0m  7.5980\n",
      "      3        \u001b[36m0.0493\u001b[0m  7.5716\n",
      "      4        0.0514  7.5675\n",
      "      5        \u001b[36m0.0471\u001b[0m  7.5587\n",
      "      6        \u001b[36m0.0354\u001b[0m  7.5728\n",
      "      7        \u001b[36m0.0288\u001b[0m  7.5673\n",
      "      8        0.0314  7.5720\n",
      "      9        \u001b[36m0.0258\u001b[0m  7.5841\n",
      "     10        \u001b[36m0.0233\u001b[0m  7.7429\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2337\u001b[0m  7.5788\n",
      "      2        \u001b[36m0.0539\u001b[0m  7.5672\n",
      "      3        \u001b[36m0.0434\u001b[0m  7.6607\n",
      "      4        \u001b[36m0.0401\u001b[0m  7.5658\n",
      "      5        \u001b[36m0.0322\u001b[0m  7.5671\n",
      "      6        \u001b[36m0.0313\u001b[0m  7.5906\n",
      "      7        0.0361  7.6573\n",
      "      8        \u001b[36m0.0284\u001b[0m  7.6490\n",
      "      9        \u001b[36m0.0245\u001b[0m  7.5668\n",
      "     10        0.0357  7.5670\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2247\u001b[0m  7.6160\n",
      "      2        \u001b[36m0.0431\u001b[0m  7.5484\n",
      "      3        \u001b[36m0.0397\u001b[0m  7.6232\n",
      "      4        \u001b[36m0.0341\u001b[0m  8.1486\n",
      "      5        \u001b[36m0.0276\u001b[0m  8.5224\n",
      "      6        0.0292  7.8085\n",
      "      7        \u001b[36m0.0270\u001b[0m  7.6630\n",
      "      8        \u001b[36m0.0253\u001b[0m  7.6205\n",
      "      9        \u001b[36m0.0232\u001b[0m  7.6173\n",
      "     10        \u001b[36m0.0215\u001b[0m  7.5449\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2265\u001b[0m  7.5450\n",
      "      2        \u001b[36m0.0514\u001b[0m  7.5539\n",
      "      3        \u001b[36m0.0456\u001b[0m  7.5743\n",
      "      4        \u001b[36m0.0412\u001b[0m  7.5308\n",
      "      5        \u001b[36m0.0366\u001b[0m  7.5329\n",
      "      6        0.0386  7.5337\n",
      "      7        \u001b[36m0.0364\u001b[0m  7.5365\n",
      "      8        \u001b[36m0.0321\u001b[0m  7.5314\n",
      "      9        0.0406  7.5437\n",
      "     10        0.0396  7.5524\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2548\u001b[0m  7.5455\n",
      "      2        \u001b[36m0.0523\u001b[0m  7.5369\n",
      "      3        \u001b[36m0.0403\u001b[0m  7.5352\n",
      "      4        \u001b[36m0.0323\u001b[0m  7.5354\n",
      "      5        0.0397  7.5492\n",
      "      6        \u001b[36m0.0245\u001b[0m  7.5333\n",
      "      7        0.0249  7.5481\n",
      "      8        \u001b[36m0.0197\u001b[0m  7.5411\n",
      "      9        0.0200  7.5854\n",
      "     10        \u001b[36m0.0190\u001b[0m  7.5545\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.3min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0702\u001b[0m  7.3941\n",
      "      2        \u001b[36m0.0544\u001b[0m  7.3368\n",
      "      3        0.0754  7.3453\n",
      "      4        0.1005  7.3430\n",
      "      5        0.1296  7.4279\n",
      "      6        0.1129  7.3616\n",
      "      7        0.0657  7.4227\n",
      "      8        \u001b[36m0.0372\u001b[0m  7.3342\n",
      "      9        \u001b[36m0.0305\u001b[0m  7.3415\n",
      "     10        \u001b[36m0.0232\u001b[0m  7.4443\n",
      "     11        \u001b[36m0.0174\u001b[0m  7.3444\n",
      "     12        \u001b[36m0.0171\u001b[0m  7.3653\n",
      "     13        \u001b[36m0.0147\u001b[0m  7.3485\n",
      "     14        0.0174  7.3479\n",
      "     15        \u001b[36m0.0142\u001b[0m  7.3842\n",
      "     16        \u001b[36m0.0129\u001b[0m  7.3903\n",
      "     17        0.0152  7.4352\n",
      "     18        0.0135  7.4200\n",
      "     19        0.0134  7.3424\n",
      "     20        0.0129  7.3680\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0768\u001b[0m  7.3656\n",
      "      2        \u001b[36m0.0548\u001b[0m  7.3360\n",
      "      3        \u001b[36m0.0535\u001b[0m  7.3577\n",
      "      4        0.0774  7.4219\n",
      "      5        0.0693  7.4006\n",
      "      6        0.1158  7.3617\n",
      "      7        0.0569  7.3509\n",
      "      8        \u001b[36m0.0383\u001b[0m  7.4142\n",
      "      9        \u001b[36m0.0258\u001b[0m  7.4013\n",
      "     10        \u001b[36m0.0200\u001b[0m  7.4161\n",
      "     11        \u001b[36m0.0177\u001b[0m  7.4117\n",
      "     12        \u001b[36m0.0162\u001b[0m  7.4283\n",
      "     13        0.0167  7.3607\n",
      "     14        \u001b[36m0.0144\u001b[0m  7.3353\n",
      "     15        \u001b[36m0.0136\u001b[0m  7.3559\n",
      "     16        \u001b[36m0.0131\u001b[0m  7.3366\n",
      "     17        \u001b[36m0.0131\u001b[0m  7.3469\n",
      "     18        \u001b[36m0.0130\u001b[0m  7.3960\n",
      "     19        \u001b[36m0.0129\u001b[0m  7.3984\n",
      "     20        \u001b[36m0.0121\u001b[0m  7.3507\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0704\u001b[0m  7.3341\n",
      "      2        \u001b[36m0.0467\u001b[0m  7.3807\n",
      "      3        0.0509  7.3352\n",
      "      4        0.0522  7.3280\n",
      "      5        0.0740  7.3405\n",
      "      6        \u001b[36m0.0467\u001b[0m  7.3619\n",
      "      7        \u001b[36m0.0352\u001b[0m  7.3759\n",
      "      8        \u001b[36m0.0258\u001b[0m  7.3308\n",
      "      9        \u001b[36m0.0206\u001b[0m  7.3341\n",
      "     10        \u001b[36m0.0167\u001b[0m  7.3711\n",
      "     11        \u001b[36m0.0159\u001b[0m  7.3340\n",
      "     12        \u001b[36m0.0137\u001b[0m  7.3275\n",
      "     13        0.0150  7.4072\n",
      "     14        \u001b[36m0.0127\u001b[0m  7.5048\n",
      "     15        \u001b[36m0.0124\u001b[0m  7.4125\n",
      "     16        \u001b[36m0.0116\u001b[0m  7.3810\n",
      "     17        \u001b[36m0.0113\u001b[0m  7.3641\n",
      "     18        \u001b[36m0.0112\u001b[0m  7.4490\n",
      "     19        0.0115  7.3271\n",
      "     20        0.0121  7.3264\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0795\u001b[0m  7.3454\n",
      "      2        \u001b[36m0.0514\u001b[0m  7.3424\n",
      "      3        0.0665  7.4461\n",
      "      4        0.0779  7.3833\n",
      "      5        0.0649  7.4865\n",
      "      6        0.0677  7.3271\n",
      "      7        \u001b[36m0.0412\u001b[0m  7.3360\n",
      "      8        \u001b[36m0.0311\u001b[0m  7.3345\n",
      "      9        \u001b[36m0.0242\u001b[0m  7.3726\n",
      "     10        \u001b[36m0.0206\u001b[0m  7.3636\n",
      "     11        \u001b[36m0.0180\u001b[0m  7.3671\n",
      "     12        \u001b[36m0.0161\u001b[0m  7.3951\n",
      "     13        \u001b[36m0.0146\u001b[0m  7.3674\n",
      "     14        0.0167  7.3734\n",
      "     15        0.0146  7.3401\n",
      "     16        \u001b[36m0.0123\u001b[0m  7.4001\n",
      "     17        0.0129  7.3857\n",
      "     18        0.0141  7.3608\n",
      "     19        0.0138  7.3715\n",
      "     20        0.0131  7.3363\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0774\u001b[0m  7.3585\n",
      "      2        \u001b[36m0.0561\u001b[0m  7.4123\n",
      "      3        0.0681  7.3296\n",
      "      4        0.0661  7.3707\n",
      "      5        0.0853  7.4206\n",
      "      6        0.1378  7.3814\n",
      "      7        \u001b[36m0.0420\u001b[0m  7.4102\n",
      "      8        \u001b[36m0.0284\u001b[0m  7.3868\n",
      "      9        \u001b[36m0.0228\u001b[0m  7.3300\n",
      "     10        \u001b[36m0.0185\u001b[0m  7.3518\n",
      "     11        \u001b[36m0.0164\u001b[0m  7.4503\n",
      "     12        \u001b[36m0.0150\u001b[0m  7.3433\n",
      "     13        \u001b[36m0.0144\u001b[0m  7.3389\n",
      "     14        \u001b[36m0.0125\u001b[0m  7.3577\n",
      "     15        0.0134  7.3636\n",
      "     16        0.0136  7.3620\n",
      "     17        0.0133  7.3967\n",
      "     18        \u001b[36m0.0118\u001b[0m  7.3387\n",
      "     19        0.0122  7.3341\n",
      "     20        0.0121  7.3316\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2476\u001b[0m  7.5295\n",
      "      2        \u001b[36m0.0361\u001b[0m  7.5902\n",
      "      3        \u001b[36m0.0345\u001b[0m  7.5402\n",
      "      4        \u001b[36m0.0308\u001b[0m  7.5893\n",
      "      5        0.0331  7.5382\n",
      "      6        0.0314  7.5585\n",
      "      7        0.0310  7.5334\n",
      "      8        \u001b[36m0.0247\u001b[0m  7.5478\n",
      "      9        \u001b[36m0.0189\u001b[0m  7.5424\n",
      "     10        0.0232  7.5503\n",
      "     11        \u001b[36m0.0169\u001b[0m  7.5958\n",
      "     12        \u001b[36m0.0158\u001b[0m  7.5737\n",
      "     13        0.0188  7.5472\n",
      "     14        \u001b[36m0.0155\u001b[0m  7.5372\n",
      "     15        0.0202  7.6281\n",
      "     16        0.0166  7.5378\n",
      "     17        \u001b[36m0.0145\u001b[0m  7.6217\n",
      "     18        \u001b[36m0.0140\u001b[0m  7.5595\n",
      "     19        0.0181  7.5442\n",
      "     20        0.0151  7.6648\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2230\u001b[0m  7.5322\n",
      "      2        \u001b[36m0.0404\u001b[0m  7.5291\n",
      "      3        \u001b[36m0.0308\u001b[0m  7.5321\n",
      "      4        \u001b[36m0.0297\u001b[0m  7.5756\n",
      "      5        \u001b[36m0.0225\u001b[0m  7.5906\n",
      "      6        \u001b[36m0.0220\u001b[0m  7.5323\n",
      "      7        0.0308  7.5772\n",
      "      8        \u001b[36m0.0203\u001b[0m  7.5361\n",
      "      9        \u001b[36m0.0202\u001b[0m  7.6059\n",
      "     10        0.0216  7.5283\n",
      "     11        \u001b[36m0.0202\u001b[0m  7.6039\n",
      "     12        \u001b[36m0.0182\u001b[0m  7.5357\n",
      "     13        \u001b[36m0.0165\u001b[0m  7.5441\n",
      "     14        \u001b[36m0.0156\u001b[0m  7.5848\n",
      "     15        0.0180  7.5908\n",
      "     16        \u001b[36m0.0141\u001b[0m  7.5775\n",
      "     17        0.0159  7.5339\n",
      "     18        0.0165  7.5314\n",
      "     19        \u001b[36m0.0127\u001b[0m  7.5399\n",
      "     20        0.0138  7.5307\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2239\u001b[0m  7.5467\n",
      "      2        \u001b[36m0.0334\u001b[0m  7.5551\n",
      "      3        \u001b[36m0.0282\u001b[0m  7.5505\n",
      "      4        \u001b[36m0.0241\u001b[0m  7.5328\n",
      "      5        0.0331  7.5374\n",
      "      6        0.0253  7.5326\n",
      "      7        \u001b[36m0.0205\u001b[0m  7.5437\n",
      "      8        \u001b[36m0.0131\u001b[0m  7.5332\n",
      "      9        \u001b[36m0.0107\u001b[0m  7.5471\n",
      "     10        0.0169  7.5434\n",
      "     11        0.0131  7.5394\n",
      "     12        \u001b[36m0.0107\u001b[0m  7.5388\n",
      "     13        0.0124  7.5407\n",
      "     14        0.0118  7.5304\n",
      "     15        0.0123  7.5579\n",
      "     16        0.0122  7.5393\n",
      "     17        0.0123  7.5513\n",
      "     18        0.0111  7.5779\n",
      "     19        0.0118  7.6651\n",
      "     20        \u001b[36m0.0096\u001b[0m  7.7356\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2332\u001b[0m  7.5987\n",
      "      2        \u001b[36m0.0382\u001b[0m  7.5828\n",
      "      3        \u001b[36m0.0332\u001b[0m  7.5958\n",
      "      4        \u001b[36m0.0293\u001b[0m  7.5836\n",
      "      5        0.0359  7.6134\n",
      "      6        \u001b[36m0.0251\u001b[0m  7.6236\n",
      "      7        0.0301  7.5950\n",
      "      8        \u001b[36m0.0227\u001b[0m  7.6125\n",
      "      9        0.0307  7.5712\n",
      "     10        0.0278  7.5867\n",
      "     11        0.0243  7.5575\n",
      "     12        \u001b[36m0.0176\u001b[0m  7.5967\n",
      "     13        \u001b[36m0.0171\u001b[0m  7.5856\n",
      "     14        0.0174  7.6411\n",
      "     15        \u001b[36m0.0149\u001b[0m  8.1532\n",
      "     16        0.0162  8.6248\n",
      "     17        \u001b[36m0.0131\u001b[0m  7.6295\n",
      "     18        0.0148  7.6133\n",
      "     19        0.0153  7.6451\n",
      "     20        0.0181  7.6382\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2475\u001b[0m  7.6127\n",
      "      2        \u001b[36m0.0353\u001b[0m  7.6414\n",
      "      3        \u001b[36m0.0297\u001b[0m  7.5809\n",
      "      4        \u001b[36m0.0287\u001b[0m  7.5699\n",
      "      5        \u001b[36m0.0185\u001b[0m  7.5512\n",
      "      6        \u001b[36m0.0160\u001b[0m  7.5503\n",
      "      7        \u001b[36m0.0129\u001b[0m  7.5398\n",
      "      8        0.0132  7.5632\n",
      "      9        \u001b[36m0.0118\u001b[0m  7.5751\n",
      "     10        \u001b[36m0.0113\u001b[0m  7.5568\n",
      "     11        \u001b[36m0.0100\u001b[0m  7.5457\n",
      "     12        0.0127  7.5530\n",
      "     13        \u001b[36m0.0091\u001b[0m  7.5442\n",
      "     14        0.0108  7.5562\n",
      "     15        0.0100  7.5501\n",
      "     16        0.0118  7.5594\n",
      "     17        0.0108  7.5471\n",
      "     18        0.0118  7.5518\n",
      "     19        0.0102  7.5454\n",
      "     20        0.0095  7.5503\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0786\u001b[0m  7.3347\n",
      "      2        \u001b[36m0.0524\u001b[0m  7.3399\n",
      "      3        0.0657  7.3335\n",
      "      4        0.0728  7.3452\n",
      "      5        0.0753  7.4101\n",
      "      6        0.1095  7.3445\n",
      "      7        0.0648  7.3395\n",
      "      8        \u001b[36m0.0388\u001b[0m  7.3363\n",
      "      9        \u001b[36m0.0336\u001b[0m  7.3313\n",
      "     10        \u001b[36m0.0279\u001b[0m  7.3421\n",
      "     11        \u001b[36m0.0242\u001b[0m  7.3396\n",
      "     12        \u001b[36m0.0216\u001b[0m  7.3600\n",
      "     13        \u001b[36m0.0213\u001b[0m  7.3472\n",
      "     14        \u001b[36m0.0197\u001b[0m  7.3414\n",
      "     15        \u001b[36m0.0193\u001b[0m  7.3394\n",
      "     16        0.0195  7.3422\n",
      "     17        0.0197  7.3884\n",
      "     18        \u001b[36m0.0178\u001b[0m  7.3519\n",
      "     19        \u001b[36m0.0178\u001b[0m  7.4849\n",
      "     20        0.0194  7.4427\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0677\u001b[0m  7.4591\n",
      "      2        \u001b[36m0.0623\u001b[0m  7.3529\n",
      "      3        0.0717  7.3814\n",
      "      4        0.0729  7.3432\n",
      "      5        0.0821  7.3627\n",
      "      6        0.1205  7.4265\n",
      "      7        0.0790  7.4624\n",
      "      8        \u001b[36m0.0458\u001b[0m  7.4084\n",
      "      9        \u001b[36m0.0353\u001b[0m  7.3743\n",
      "     10        \u001b[36m0.0283\u001b[0m  7.3821\n",
      "     11        \u001b[36m0.0268\u001b[0m  7.3383\n",
      "     12        \u001b[36m0.0242\u001b[0m  7.3432\n",
      "     13        \u001b[36m0.0214\u001b[0m  7.3408\n",
      "     14        \u001b[36m0.0212\u001b[0m  7.3575\n",
      "     15        \u001b[36m0.0207\u001b[0m  7.3406\n",
      "     16        0.0216  7.3502\n",
      "     17        \u001b[36m0.0196\u001b[0m  7.3472\n",
      "     18        \u001b[36m0.0194\u001b[0m  7.3558\n",
      "     19        \u001b[36m0.0192\u001b[0m  7.3431\n",
      "     20        \u001b[36m0.0183\u001b[0m  7.3405\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0804\u001b[0m  7.3447\n",
      "      2        \u001b[36m0.0509\u001b[0m  7.3336\n",
      "      3        0.0558  7.3357\n",
      "      4        0.0619  7.3394\n",
      "      5        0.0860  7.3406\n",
      "      6        0.0802  7.3456\n",
      "      7        \u001b[36m0.0493\u001b[0m  7.3348\n",
      "      8        \u001b[36m0.0372\u001b[0m  7.3358\n",
      "      9        \u001b[36m0.0306\u001b[0m  7.3351\n",
      "     10        \u001b[36m0.0256\u001b[0m  7.3388\n",
      "     11        \u001b[36m0.0220\u001b[0m  7.3817\n",
      "     12        \u001b[36m0.0203\u001b[0m  7.3458\n",
      "     13        \u001b[36m0.0188\u001b[0m  7.3567\n",
      "     14        \u001b[36m0.0184\u001b[0m  7.3965\n",
      "     15        \u001b[36m0.0176\u001b[0m  7.3403\n",
      "     16        \u001b[36m0.0168\u001b[0m  7.3402\n",
      "     17        0.0174  7.3403\n",
      "     18        \u001b[36m0.0157\u001b[0m  7.3388\n",
      "     19        0.0168  7.3413\n",
      "     20        \u001b[36m0.0155\u001b[0m  7.3444\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0739\u001b[0m  7.3607\n",
      "      2        \u001b[36m0.0575\u001b[0m  7.3943\n",
      "      3        0.0732  7.3544\n",
      "      4        0.0769  7.3599\n",
      "      5        0.1679  7.3648\n",
      "      6        0.0856  7.4427\n",
      "      7        \u001b[36m0.0534\u001b[0m  7.3621\n",
      "      8        0.0535  7.3591\n",
      "      9        \u001b[36m0.0376\u001b[0m  7.3954\n",
      "     10        \u001b[36m0.0295\u001b[0m  7.4102\n",
      "     11        \u001b[36m0.0263\u001b[0m  7.3733\n",
      "     12        \u001b[36m0.0229\u001b[0m  7.4687\n",
      "     13        0.0238  7.3913\n",
      "     14        \u001b[36m0.0206\u001b[0m  7.3726\n",
      "     15        0.0213  7.3724\n",
      "     16        \u001b[36m0.0194\u001b[0m  7.3643\n",
      "     17        0.0202  7.4122\n",
      "     18        \u001b[36m0.0182\u001b[0m  7.3607\n",
      "     19        \u001b[36m0.0182\u001b[0m  7.3612\n",
      "     20        0.0188  7.4457\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0786\u001b[0m  7.3550\n",
      "      2        \u001b[36m0.0592\u001b[0m  7.3635\n",
      "      3        0.1001  7.4309\n",
      "      4        0.0734  7.4037\n",
      "      5        0.0810  7.3855\n",
      "      6        0.0825  7.4513\n",
      "      7        \u001b[36m0.0583\u001b[0m  7.4277\n",
      "      8        \u001b[36m0.0351\u001b[0m  7.3646\n",
      "      9        \u001b[36m0.0297\u001b[0m  7.3571\n",
      "     10        \u001b[36m0.0251\u001b[0m  7.3514\n",
      "     11        \u001b[36m0.0224\u001b[0m  7.3773\n",
      "     12        \u001b[36m0.0199\u001b[0m  7.3933\n",
      "     13        \u001b[36m0.0184\u001b[0m  7.4186\n",
      "     14        \u001b[36m0.0184\u001b[0m  7.4594\n",
      "     15        0.0187  7.3651\n",
      "     16        \u001b[36m0.0168\u001b[0m  7.3930\n",
      "     17        0.0171  7.4217\n",
      "     18        0.0172  7.3585\n",
      "     19        0.0174  7.4256\n",
      "     20        0.0181  7.3782\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2460\u001b[0m  7.5516\n",
      "      2        \u001b[36m0.0409\u001b[0m  7.5786\n",
      "      3        0.0410  7.5517\n",
      "      4        0.0504  7.5425\n",
      "      5        \u001b[36m0.0371\u001b[0m  7.5426\n",
      "      6        \u001b[36m0.0343\u001b[0m  7.5456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        \u001b[36m0.0289\u001b[0m  7.5366\n",
      "      8        \u001b[36m0.0264\u001b[0m  7.5521\n",
      "      9        \u001b[36m0.0199\u001b[0m  7.5441\n",
      "     10        0.0206  7.5528\n",
      "     11        0.0287  7.5383\n",
      "     12        0.0259  7.5461\n",
      "     13        0.0288  7.5399\n",
      "     14        0.0266  7.5522\n",
      "     15        0.0210  7.5404\n",
      "     16        0.0202  7.5538\n",
      "     17        \u001b[36m0.0190\u001b[0m  7.5652\n",
      "     18        0.0200  7.5785\n",
      "     19        \u001b[36m0.0167\u001b[0m  7.5431\n",
      "     20        0.0177  7.5433\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2402\u001b[0m  7.5382\n",
      "      2        \u001b[36m0.0378\u001b[0m  7.5464\n",
      "      3        \u001b[36m0.0337\u001b[0m  7.5397\n",
      "      4        \u001b[36m0.0327\u001b[0m  7.5593\n",
      "      5        \u001b[36m0.0255\u001b[0m  7.5522\n",
      "      6        0.0292  7.5482\n",
      "      7        0.0257  7.6449\n",
      "      8        0.0288  7.5466\n",
      "      9        \u001b[36m0.0252\u001b[0m  7.5469\n",
      "     10        \u001b[36m0.0233\u001b[0m  7.6112\n",
      "     11        0.0298  7.5489\n",
      "     12        0.0265  7.6290\n",
      "     13        0.0295  7.5745\n",
      "     14        0.0235  7.5560\n",
      "     15        \u001b[36m0.0214\u001b[0m  7.5468\n",
      "     16        \u001b[36m0.0189\u001b[0m  7.5471\n",
      "     17        \u001b[36m0.0168\u001b[0m  7.5499\n",
      "     18        \u001b[36m0.0141\u001b[0m  7.5812\n",
      "     19        0.0143  7.5593\n",
      "     20        0.0163  7.6628\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2258\u001b[0m  7.5500\n",
      "      2        \u001b[36m0.0384\u001b[0m  7.5410\n",
      "      3        \u001b[36m0.0298\u001b[0m  7.5487\n",
      "      4        0.0351  7.5460\n",
      "      5        \u001b[36m0.0291\u001b[0m  7.6060\n",
      "      6        \u001b[36m0.0228\u001b[0m  7.5555\n",
      "      7        0.0422  7.5444\n",
      "      8        0.0316  7.6005\n",
      "      9        0.0250  7.6255\n",
      "     10        \u001b[36m0.0199\u001b[0m  7.5527\n",
      "     11        0.0244  7.5509\n",
      "     12        \u001b[36m0.0177\u001b[0m  7.5891\n",
      "     13        \u001b[36m0.0143\u001b[0m  7.5911\n",
      "     14        0.0145  7.5560\n",
      "     15        0.0156  7.5546\n",
      "     16        \u001b[36m0.0134\u001b[0m  7.5853\n",
      "     17        0.0148  7.5931\n",
      "     18        \u001b[36m0.0133\u001b[0m  7.5530\n",
      "     19        0.0180  7.5577\n",
      "     20        0.0155  7.6378\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2227\u001b[0m  7.5358\n",
      "      2        \u001b[36m0.0415\u001b[0m  7.5508\n",
      "      3        0.0424  7.5505\n",
      "      4        \u001b[36m0.0364\u001b[0m  7.6572\n",
      "      5        \u001b[36m0.0309\u001b[0m  7.6214\n",
      "      6        \u001b[36m0.0243\u001b[0m  7.5482\n",
      "      7        0.0408  7.6542\n",
      "      8        0.0304  7.5491\n",
      "      9        \u001b[36m0.0222\u001b[0m  7.5456\n",
      "     10        0.0233  7.6324\n",
      "     11        0.0236  7.5694\n",
      "     12        \u001b[36m0.0188\u001b[0m  7.6071\n",
      "     13        0.0277  7.5830\n",
      "     14        0.0274  7.5405\n",
      "     15        0.0255  7.5404\n",
      "     16        0.0206  7.5369\n",
      "     17        0.0203  7.5495\n",
      "     18        0.0248  7.6170\n",
      "     19        0.0202  7.6154\n",
      "     20        0.0205  7.5514\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2404\u001b[0m  7.5519\n",
      "      2        \u001b[36m0.0426\u001b[0m  7.5392\n",
      "      3        \u001b[36m0.0363\u001b[0m  7.5740\n",
      "      4        \u001b[36m0.0336\u001b[0m  7.5704\n",
      "      5        \u001b[36m0.0242\u001b[0m  7.5947\n",
      "      6        \u001b[36m0.0213\u001b[0m  7.5702\n",
      "      7        \u001b[36m0.0171\u001b[0m  7.6467\n",
      "      8        \u001b[36m0.0149\u001b[0m  7.5467\n",
      "      9        \u001b[36m0.0129\u001b[0m  7.6278\n",
      "     10        \u001b[36m0.0126\u001b[0m  7.5404\n",
      "     11        0.0132  7.5469\n",
      "     12        0.0154  7.5921\n",
      "     13        0.0158  7.6119\n",
      "     14        0.0168  7.6835\n",
      "     15        0.0127  7.5836\n",
      "     16        0.0154  7.6079\n",
      "     17        0.0156  7.5508\n",
      "     18        0.0151  7.5472\n",
      "     19        0.0169  7.5761\n",
      "     20        \u001b[36m0.0124\u001b[0m  7.6036\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0815\u001b[0m  7.3470\n",
      "      2        \u001b[36m0.0588\u001b[0m  7.3448\n",
      "      3        0.0781  7.3807\n",
      "      4        0.0875  7.3522\n",
      "      5        0.0994  7.3468\n",
      "      6        0.0924  7.3495\n",
      "      7        0.0731  7.3851\n",
      "      8        \u001b[36m0.0580\u001b[0m  7.3480\n",
      "      9        \u001b[36m0.0439\u001b[0m  7.3817\n",
      "     10        \u001b[36m0.0361\u001b[0m  7.3560\n",
      "     11        \u001b[36m0.0327\u001b[0m  7.3588\n",
      "     12        \u001b[36m0.0316\u001b[0m  7.4393\n",
      "     13        \u001b[36m0.0300\u001b[0m  7.3801\n",
      "     14        \u001b[36m0.0292\u001b[0m  7.3746\n",
      "     15        \u001b[36m0.0253\u001b[0m  7.3773\n",
      "     16        \u001b[36m0.0246\u001b[0m  7.3336\n",
      "     17        0.0271  7.3698\n",
      "     18        0.0253  7.3419\n",
      "     19        0.0264  7.3567\n",
      "     20        \u001b[36m0.0240\u001b[0m  7.3450\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0783\u001b[0m  7.3396\n",
      "      2        \u001b[36m0.0625\u001b[0m  7.3351\n",
      "      3        0.0712  7.3358\n",
      "      4        0.0858  7.3331\n",
      "      5        0.1029  7.3397\n",
      "      6        0.0658  7.3309\n",
      "      7        \u001b[36m0.0553\u001b[0m  7.3879\n",
      "      8        \u001b[36m0.0496\u001b[0m  7.4229\n",
      "      9        \u001b[36m0.0387\u001b[0m  7.3870\n",
      "     10        \u001b[36m0.0375\u001b[0m  7.3360\n",
      "     11        \u001b[36m0.0305\u001b[0m  7.3355\n",
      "     12        0.0336  7.3344\n",
      "     13        \u001b[36m0.0297\u001b[0m  7.4094\n",
      "     14        \u001b[36m0.0281\u001b[0m  7.3433\n",
      "     15        0.0282  7.4345\n",
      "     16        0.0287  7.3722\n",
      "     17        \u001b[36m0.0262\u001b[0m  7.3531\n",
      "     18        \u001b[36m0.0246\u001b[0m  7.3429\n",
      "     19        0.0278  7.3419\n",
      "     20        0.0272  7.3876\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0816\u001b[0m  7.3423\n",
      "      2        \u001b[36m0.0562\u001b[0m  7.3399\n",
      "      3        \u001b[36m0.0536\u001b[0m  7.3599\n",
      "      4        0.0676  7.3725\n",
      "      5        0.0635  7.3884\n",
      "      6        0.0683  7.3350\n",
      "      7        0.0564  7.3392\n",
      "      8        \u001b[36m0.0459\u001b[0m  7.3961\n",
      "      9        \u001b[36m0.0398\u001b[0m  7.4076\n",
      "     10        \u001b[36m0.0329\u001b[0m  7.4428\n",
      "     11        \u001b[36m0.0301\u001b[0m  7.4079\n",
      "     12        \u001b[36m0.0276\u001b[0m  7.3751\n",
      "     13        0.0276  7.4248\n",
      "     14        \u001b[36m0.0271\u001b[0m  7.3425\n",
      "     15        \u001b[36m0.0249\u001b[0m  7.3827\n",
      "     16        \u001b[36m0.0244\u001b[0m  7.4582\n",
      "     17        \u001b[36m0.0234\u001b[0m  7.3505\n",
      "     18        \u001b[36m0.0226\u001b[0m  7.3436\n",
      "     19        0.0233  7.3966\n",
      "     20        \u001b[36m0.0219\u001b[0m  7.4154\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0796\u001b[0m  7.4370\n",
      "      2        \u001b[36m0.0611\u001b[0m  7.4009\n",
      "      3        0.0820  7.3341\n",
      "      4        0.0993  7.3437\n",
      "      5        0.0888  7.4398\n",
      "      6        0.1671  7.4387\n",
      "      7        0.0681  7.4395\n",
      "      8        0.0726  7.3573\n",
      "      9        \u001b[36m0.0587\u001b[0m  7.3870\n",
      "     10        \u001b[36m0.0439\u001b[0m  7.3372\n",
      "     11        \u001b[36m0.0371\u001b[0m  7.3978\n",
      "     12        \u001b[36m0.0340\u001b[0m  7.3317\n",
      "     13        \u001b[36m0.0327\u001b[0m  7.3486\n",
      "     14        0.0349  7.3406\n",
      "     15        \u001b[36m0.0316\u001b[0m  7.3522\n",
      "     16        0.0317  7.3880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17        \u001b[36m0.0289\u001b[0m  7.4251\n",
      "     18        0.0295  7.3900\n",
      "     19        \u001b[36m0.0270\u001b[0m  7.3459\n",
      "     20        0.0285  7.3688\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0816\u001b[0m  7.3325\n",
      "      2        \u001b[36m0.0702\u001b[0m  7.3355\n",
      "      3        0.0735  7.3484\n",
      "      4        \u001b[36m0.0691\u001b[0m  7.3488\n",
      "      5        0.1540  7.3525\n",
      "      6        0.1556  7.3322\n",
      "      7        0.0865  7.3642\n",
      "      8        \u001b[36m0.0561\u001b[0m  7.3564\n",
      "      9        \u001b[36m0.0446\u001b[0m  7.4094\n",
      "     10        \u001b[36m0.0368\u001b[0m  7.3758\n",
      "     11        \u001b[36m0.0353\u001b[0m  7.3654\n",
      "     12        \u001b[36m0.0319\u001b[0m  7.3792\n",
      "     13        \u001b[36m0.0294\u001b[0m  7.3838\n",
      "     14        \u001b[36m0.0287\u001b[0m  7.3781\n",
      "     15        \u001b[36m0.0278\u001b[0m  7.3963\n",
      "     16        \u001b[36m0.0271\u001b[0m  7.3383\n",
      "     17        \u001b[36m0.0269\u001b[0m  7.3338\n",
      "     18        \u001b[36m0.0267\u001b[0m  7.3407\n",
      "     19        0.0281  7.3401\n",
      "     20        \u001b[36m0.0265\u001b[0m  7.3599\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2689\u001b[0m  7.5471\n",
      "      2        \u001b[36m0.0499\u001b[0m  7.5381\n",
      "      3        \u001b[36m0.0483\u001b[0m  7.5472\n",
      "      4        \u001b[36m0.0419\u001b[0m  7.5467\n",
      "      5        0.0471  7.5427\n",
      "      6        \u001b[36m0.0380\u001b[0m  7.5400\n",
      "      7        0.0407  7.5535\n",
      "      8        \u001b[36m0.0334\u001b[0m  7.5599\n",
      "      9        \u001b[36m0.0319\u001b[0m  7.5887\n",
      "     10        \u001b[36m0.0283\u001b[0m  7.5579\n",
      "     11        \u001b[36m0.0235\u001b[0m  7.5780\n",
      "     12        \u001b[36m0.0224\u001b[0m  7.5710\n",
      "     13        0.0228  7.6290\n",
      "     14        0.0239  7.5618\n",
      "     15        0.0233  7.6066\n",
      "     16        \u001b[36m0.0213\u001b[0m  7.5666\n",
      "     17        \u001b[36m0.0204\u001b[0m  7.5638\n",
      "     18        0.0213  7.6120\n",
      "     19        0.0227  7.5880\n",
      "     20        \u001b[36m0.0192\u001b[0m  7.5449\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2461\u001b[0m  7.5369\n",
      "      2        \u001b[36m0.0491\u001b[0m  7.5370\n",
      "      3        \u001b[36m0.0421\u001b[0m  7.5906\n",
      "      4        \u001b[36m0.0402\u001b[0m  7.5602\n",
      "      5        0.0416  7.5622\n",
      "      6        \u001b[36m0.0334\u001b[0m  7.5706\n",
      "      7        \u001b[36m0.0267\u001b[0m  7.7101\n",
      "      8        0.0274  7.5348\n",
      "      9        0.0268  7.5387\n",
      "     10        \u001b[36m0.0266\u001b[0m  7.5392\n",
      "     11        \u001b[36m0.0240\u001b[0m  7.5790\n",
      "     12        \u001b[36m0.0239\u001b[0m  7.5557\n",
      "     13        0.0241  7.5839\n",
      "     14        \u001b[36m0.0224\u001b[0m  7.5404\n",
      "     15        \u001b[36m0.0205\u001b[0m  7.5448\n",
      "     16        0.0222  7.5337\n",
      "     17        0.0246  7.5489\n",
      "     18        0.0211  7.5426\n",
      "     19        0.0216  7.5586\n",
      "     20        0.0222  7.5731\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2409\u001b[0m  7.5205\n",
      "      2        \u001b[36m0.0413\u001b[0m  7.5178\n",
      "      3        \u001b[36m0.0388\u001b[0m  7.5151\n",
      "      4        \u001b[36m0.0379\u001b[0m  7.5087\n",
      "      5        0.0417  7.5200\n",
      "      6        \u001b[36m0.0313\u001b[0m  7.5155\n",
      "      7        \u001b[36m0.0299\u001b[0m  7.5279\n",
      "      8        \u001b[36m0.0289\u001b[0m  7.5654\n",
      "      9        \u001b[36m0.0217\u001b[0m  7.5492\n",
      "     10        \u001b[36m0.0214\u001b[0m  7.5230\n",
      "     11        0.0228  7.5483\n",
      "     12        \u001b[36m0.0204\u001b[0m  7.5308\n",
      "     13        0.0213  7.5828\n",
      "     14        0.0223  7.6099\n",
      "     15        \u001b[36m0.0182\u001b[0m  7.6392\n",
      "     16        \u001b[36m0.0173\u001b[0m  7.5563\n",
      "     17        0.0189  7.5929\n",
      "     18        0.0230  7.5617\n",
      "     19        0.0193  7.5200\n",
      "     20        \u001b[36m0.0148\u001b[0m  7.5206\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2462\u001b[0m  7.5604\n",
      "      2        \u001b[36m0.0446\u001b[0m  7.5849\n",
      "      3        \u001b[36m0.0395\u001b[0m  7.5673\n",
      "      4        0.0398  7.6567\n",
      "      5        0.0458  7.5778\n",
      "      6        \u001b[36m0.0337\u001b[0m  7.6135\n",
      "      7        \u001b[36m0.0288\u001b[0m  7.5631\n",
      "      8        \u001b[36m0.0265\u001b[0m  7.5644\n",
      "      9        0.0318  7.5811\n",
      "     10        0.0290  7.6795\n",
      "     11        \u001b[36m0.0237\u001b[0m  7.6906\n",
      "     12        \u001b[36m0.0223\u001b[0m  7.6030\n",
      "     13        0.0243  7.5618\n",
      "     14        0.0267  7.6332\n",
      "     15        0.0289  7.5781\n",
      "     16        0.0300  7.7200\n",
      "     17        0.0259  7.7269\n",
      "     18        0.0274  7.6672\n",
      "     19        0.0241  7.5769\n",
      "     20        \u001b[36m0.0208\u001b[0m  7.5731\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2585\u001b[0m  7.6190\n",
      "      2        \u001b[36m0.0522\u001b[0m  7.5594\n",
      "      3        \u001b[36m0.0380\u001b[0m  7.5598\n",
      "      4        0.0476  7.5939\n",
      "      5        \u001b[36m0.0276\u001b[0m  7.5621\n",
      "      6        \u001b[36m0.0214\u001b[0m  7.5986\n",
      "      7        0.0293  7.6814\n",
      "      8        0.0229  7.5597\n",
      "      9        \u001b[36m0.0193\u001b[0m  7.5703\n",
      "     10        \u001b[36m0.0176\u001b[0m  7.5663\n",
      "     11        \u001b[36m0.0173\u001b[0m  7.6272\n",
      "     12        \u001b[36m0.0172\u001b[0m  7.5654\n",
      "     13        0.0195  7.6480\n",
      "     14        0.0194  7.5951\n",
      "     15        0.0212  7.6402\n",
      "     16        0.0191  7.6687\n",
      "     17        0.0210  7.6195\n",
      "     18        0.0210  7.5637\n",
      "     19        0.0204  7.6195\n",
      "     20        0.0190  7.5661\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.6min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0924\u001b[0m  7.0371\n",
      "      2        0.1430  7.0296\n",
      "      3        0.1905  7.0565\n",
      "      4        0.2939  7.0652\n",
      "      5        0.3497  7.2684\n",
      "      6        0.4476  7.0322\n",
      "      7        0.1538  7.0299\n",
      "      8        0.1560  7.0376\n",
      "      9        \u001b[36m0.0819\u001b[0m  7.0342\n",
      "     10        \u001b[36m0.0516\u001b[0m  7.0493\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1005\u001b[0m  7.0482\n",
      "      2        0.1055  7.0468\n",
      "      3        0.2263  7.0439\n",
      "      4        0.3376  7.0364\n",
      "      5        0.3466  7.0579\n",
      "      6        0.5070  7.0578\n",
      "      7        0.4317  7.0654\n",
      "      8        0.3128  7.0324\n",
      "      9        0.1767  7.0341\n",
      "     10        \u001b[36m0.0711\u001b[0m  7.0598\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1151\u001b[0m  7.0348\n",
      "      2        \u001b[36m0.0953\u001b[0m  7.0303\n",
      "      3        0.1335  7.0269\n",
      "      4        0.1561  7.0303\n",
      "      5        0.2201  7.0373\n",
      "      6        0.2465  7.0412\n",
      "      7        0.3235  7.0558\n",
      "      8        0.3948  7.0457\n",
      "      9        0.3831  7.0338\n",
      "     10        \u001b[36m0.0861\u001b[0m  7.0348\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1119\u001b[0m  7.1091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.1025\u001b[0m  7.0390\n",
      "      3        0.1516  7.0583\n",
      "      4        0.3540  7.0262\n",
      "      5        0.2657  7.0479\n",
      "      6        0.2226  7.0833\n",
      "      7        0.3473  7.0898\n",
      "      8        0.3862  7.0513\n",
      "      9        0.3748  7.0592\n",
      "     10        0.1091  7.1086\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0955\u001b[0m  7.1251\n",
      "      2        0.1062  7.0462\n",
      "      3        0.2044  7.1777\n",
      "      4        0.2973  7.0427\n",
      "      5        0.2739  7.0452\n",
      "      6        0.4702  7.0439\n",
      "      7        0.6690  7.0397\n",
      "      8        0.2167  7.0419\n",
      "      9        \u001b[36m0.0786\u001b[0m  7.0387\n",
      "     10        \u001b[36m0.0516\u001b[0m  7.0484\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4205\u001b[0m  7.2444\n",
      "      2        \u001b[36m0.0715\u001b[0m  7.2547\n",
      "      3        \u001b[36m0.0709\u001b[0m  7.2789\n",
      "      4        \u001b[36m0.0689\u001b[0m  7.2487\n",
      "      5        0.0942  7.2532\n",
      "      6        0.1095  7.2542\n",
      "      7        0.0845  7.2505\n",
      "      8        0.2118  7.2510\n",
      "      9        0.1599  7.2462\n",
      "     10        \u001b[36m0.0626\u001b[0m  7.2521\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3834\u001b[0m  7.2917\n",
      "      2        \u001b[36m0.0678\u001b[0m  7.2591\n",
      "      3        \u001b[36m0.0624\u001b[0m  7.2888\n",
      "      4        0.0725  7.3256\n",
      "      5        0.0629  7.3298\n",
      "      6        \u001b[36m0.0608\u001b[0m  7.2588\n",
      "      7        0.1003  7.2526\n",
      "      8        0.1137  7.3006\n",
      "      9        0.0773  7.2482\n",
      "     10        \u001b[36m0.0546\u001b[0m  7.3630\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3603\u001b[0m  7.3101\n",
      "      2        \u001b[36m0.0619\u001b[0m  7.2482\n",
      "      3        0.0680  7.3217\n",
      "      4        0.0627  7.2753\n",
      "      5        0.0853  7.2521\n",
      "      6        0.0836  7.2704\n",
      "      7        0.1193  7.2709\n",
      "      8        0.1564  7.8357\n",
      "      9        0.1306  7.2620\n",
      "     10        0.1871  7.2598\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3943\u001b[0m  7.2607\n",
      "      2        \u001b[36m0.0744\u001b[0m  7.2534\n",
      "      3        0.0807  7.2545\n",
      "      4        \u001b[36m0.0685\u001b[0m  7.2714\n",
      "      5        0.1042  7.2729\n",
      "      6        0.0872  7.2983\n",
      "      7        0.1344  7.2564\n",
      "      8        0.1208  7.2521\n",
      "      9        0.0875  7.2629\n",
      "     10        \u001b[36m0.0545\u001b[0m  7.2654\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3881\u001b[0m  7.2604\n",
      "      2        \u001b[36m0.0673\u001b[0m  7.2597\n",
      "      3        0.0759  7.2650\n",
      "      4        \u001b[36m0.0547\u001b[0m  7.3621\n",
      "      5        0.0635  7.9052\n",
      "      6        \u001b[36m0.0508\u001b[0m  7.2652\n",
      "      7        \u001b[36m0.0412\u001b[0m  7.2617\n",
      "      8        \u001b[36m0.0249\u001b[0m  7.7032\n",
      "      9        \u001b[36m0.0182\u001b[0m  7.2602\n",
      "     10        \u001b[36m0.0140\u001b[0m  7.2671\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1219\u001b[0m  7.0619\n",
      "      2        \u001b[36m0.1018\u001b[0m  7.0810\n",
      "      3        0.1692  7.0452\n",
      "      4        0.2085  7.0453\n",
      "      5        0.2415  7.0760\n",
      "      6        0.1383  7.0709\n",
      "      7        0.1295  7.0656\n",
      "      8        0.1714  7.0536\n",
      "      9        0.1040  7.0647\n",
      "     10        \u001b[36m0.0633\u001b[0m  7.0554\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1144\u001b[0m  7.0531\n",
      "      2        \u001b[36m0.1008\u001b[0m  7.0471\n",
      "      3        0.1651  7.0489\n",
      "      4        0.1741  7.0574\n",
      "      5        0.3332  7.0597\n",
      "      6        0.3931  7.0681\n",
      "      7        0.3647  7.0816\n",
      "      8        0.1703  7.0803\n",
      "      9        \u001b[36m0.0954\u001b[0m  7.0960\n",
      "     10        \u001b[36m0.0644\u001b[0m  7.0845\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1058\u001b[0m  7.0625\n",
      "      2        \u001b[36m0.1044\u001b[0m  7.0643\n",
      "      3        0.1778  7.0477\n",
      "      4        0.1939  7.0915\n",
      "      5        0.3113  7.0634\n",
      "      6        0.3130  7.0790\n",
      "      7        0.3262  7.0616\n",
      "      8        0.1689  7.0573\n",
      "      9        0.1443  7.0620\n",
      "     10        \u001b[36m0.0660\u001b[0m  7.0504\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1172\u001b[0m  7.0478\n",
      "      2        \u001b[36m0.1068\u001b[0m  7.0501\n",
      "      3        0.2202  7.0499\n",
      "      4        0.2202  7.0839\n",
      "      5        0.3418  7.1678\n",
      "      6        0.2562  7.5111\n",
      "      7        0.1444  7.0713\n",
      "      8        0.1091  7.0665\n",
      "      9        0.1874  7.0603\n",
      "     10        \u001b[36m0.0995\u001b[0m  7.0666\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0948\u001b[0m  7.0532\n",
      "      2        0.1268  7.1667\n",
      "      3        0.2423  7.2831\n",
      "      4        0.2164  7.0633\n",
      "      5        0.3172  7.0605\n",
      "      6        0.4966  7.1240\n",
      "      7        0.2504  7.0491\n",
      "      8        0.1378  7.0498\n",
      "      9        \u001b[36m0.0708\u001b[0m  7.1345\n",
      "     10        \u001b[36m0.0490\u001b[0m  7.2397\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3529\u001b[0m  7.2769\n",
      "      2        \u001b[36m0.1042\u001b[0m  7.2954\n",
      "      3        0.1395  7.2714\n",
      "      4        0.1296  7.2595\n",
      "      5        0.1832  7.2645\n",
      "      6        0.2799  7.2753\n",
      "      7        0.3867  7.2593\n",
      "      8        0.5995  7.2619\n",
      "      9        0.2761  7.2736\n",
      "     10        \u001b[36m0.1037\u001b[0m  7.2807\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3199\u001b[0m  7.2999\n",
      "      2        \u001b[36m0.0879\u001b[0m  7.2583\n",
      "      3        0.1264  7.2572\n",
      "      4        0.1446  7.2705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        0.1162  7.2589\n",
      "      6        0.1334  7.2568\n",
      "      7        0.1902  7.2753\n",
      "      8        0.1446  7.2794\n",
      "      9        \u001b[36m0.0670\u001b[0m  7.2818\n",
      "     10        \u001b[36m0.0439\u001b[0m  7.2558\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3806\u001b[0m  7.2624\n",
      "      2        \u001b[36m0.0700\u001b[0m  7.2628\n",
      "      3        \u001b[36m0.0485\u001b[0m  7.2650\n",
      "      4        0.0501  7.2588\n",
      "      5        0.0535  7.2781\n",
      "      6        0.0494  7.2666\n",
      "      7        0.0666  7.2654\n",
      "      8        0.0502  7.2634\n",
      "      9        \u001b[36m0.0345\u001b[0m  7.2649\n",
      "     10        \u001b[36m0.0204\u001b[0m  7.3072\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3680\u001b[0m  7.2683\n",
      "      2        \u001b[36m0.0765\u001b[0m  7.4446\n",
      "      3        0.0935  7.6526\n",
      "      4        0.1001  7.2812\n",
      "      5        0.1297  7.2694\n",
      "      6        0.1394  7.2686\n",
      "      7        0.2468  7.2672\n",
      "      8        0.2613  7.5029\n",
      "      9        0.2535  7.3037\n",
      "     10        0.2178  7.2797\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3917\u001b[0m  7.2776\n",
      "      2        \u001b[36m0.0727\u001b[0m  7.2792\n",
      "      3        \u001b[36m0.0695\u001b[0m  7.3037\n",
      "      4        0.0736  7.2709\n",
      "      5        0.0750  7.2622\n",
      "      6        0.0894  7.2695\n",
      "      7        \u001b[36m0.0567\u001b[0m  7.2854\n",
      "      8        \u001b[36m0.0260\u001b[0m  7.2628\n",
      "      9        \u001b[36m0.0201\u001b[0m  7.2721\n",
      "     10        \u001b[36m0.0149\u001b[0m  7.2785\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1131\u001b[0m  7.2279\n",
      "      2        0.1297  7.1313\n",
      "      3        0.2780  7.0659\n",
      "      4        0.2142  7.0670\n",
      "      5        0.2492  7.1130\n",
      "      6        0.4585  7.0827\n",
      "      7        0.3863  7.1217\n",
      "      8        0.1574  7.1168\n",
      "      9        0.1664  7.2252\n",
      "     10        \u001b[36m0.0814\u001b[0m  7.1500\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1300\u001b[0m  7.0660\n",
      "      2        \u001b[36m0.1095\u001b[0m  7.0668\n",
      "      3        0.1497  7.1902\n",
      "      4        0.2141  7.0613\n",
      "      5        0.2294  7.0500\n",
      "      6        0.3010  7.1406\n",
      "      7        0.2045  7.2655\n",
      "      8        0.1195  7.0901\n",
      "      9        \u001b[36m0.0909\u001b[0m  7.0591\n",
      "     10        \u001b[36m0.0724\u001b[0m  7.0585\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1261\u001b[0m  7.0661\n",
      "      2        \u001b[36m0.1043\u001b[0m  7.0583\n",
      "      3        \u001b[36m0.0918\u001b[0m  7.0532\n",
      "      4        0.1335  7.0737\n",
      "      5        0.2350  7.0648\n",
      "      6        0.3143  7.0747\n",
      "      7        0.2231  7.0629\n",
      "      8        0.1153  7.0569\n",
      "      9        \u001b[36m0.0801\u001b[0m  7.0584\n",
      "     10        \u001b[36m0.0630\u001b[0m  7.0675\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1253\u001b[0m  7.0698\n",
      "      2        \u001b[36m0.1197\u001b[0m  7.0738\n",
      "      3        0.1800  7.0919\n",
      "      4        0.2202  7.1333\n",
      "      5        0.2584  7.0530\n",
      "      6        0.2048  7.0711\n",
      "      7        0.2057  7.0742\n",
      "      8        0.2508  7.0798\n",
      "      9        0.1287  7.0768\n",
      "     10        \u001b[36m0.0886\u001b[0m  7.0720\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1195\u001b[0m  7.0864\n",
      "      2        \u001b[36m0.1042\u001b[0m  7.0735\n",
      "      3        0.1714  7.0636\n",
      "      4        0.1929  7.0520\n",
      "      5        0.2460  7.0563\n",
      "      6        0.1868  7.0610\n",
      "      7        0.2227  7.0530\n",
      "      8        \u001b[36m0.1012\u001b[0m  7.0631\n",
      "      9        \u001b[36m0.0794\u001b[0m  7.0762\n",
      "     10        \u001b[36m0.0604\u001b[0m  7.0685\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4209\u001b[0m  7.2987\n",
      "      2        \u001b[36m0.0923\u001b[0m  7.2685\n",
      "      3        \u001b[36m0.0853\u001b[0m  7.2702\n",
      "      4        0.0936  7.2659\n",
      "      5        0.1341  7.2648\n",
      "      6        0.1026  7.2674\n",
      "      7        0.1253  7.2722\n",
      "      8        0.0905  7.2888\n",
      "      9        \u001b[36m0.0445\u001b[0m  7.2750\n",
      "     10        \u001b[36m0.0341\u001b[0m  7.2953\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3553\u001b[0m  7.4143\n",
      "      2        \u001b[36m0.1011\u001b[0m  7.4499\n",
      "      3        0.1174  7.2792\n",
      "      4        0.1077  7.2700\n",
      "      5        0.1179  7.2739\n",
      "      6        0.1709  7.2839\n",
      "      7        \u001b[36m0.0971\u001b[0m  7.2995\n",
      "      8        \u001b[36m0.0655\u001b[0m  7.2682\n",
      "      9        \u001b[36m0.0517\u001b[0m  7.2713\n",
      "     10        \u001b[36m0.0412\u001b[0m  7.2679\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3917\u001b[0m  7.2546\n",
      "      2        \u001b[36m0.0762\u001b[0m  7.2603\n",
      "      3        \u001b[36m0.0673\u001b[0m  7.2548\n",
      "      4        \u001b[36m0.0661\u001b[0m  7.2729\n",
      "      5        0.0812  7.2665\n",
      "      6        0.0794  7.2618\n",
      "      7        0.0753  7.2573\n",
      "      8        \u001b[36m0.0450\u001b[0m  7.2633\n",
      "      9        0.0737  7.2764\n",
      "     10        \u001b[36m0.0347\u001b[0m  7.2657\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3710\u001b[0m  7.2693\n",
      "      2        \u001b[36m0.0915\u001b[0m  7.2985\n",
      "      3        0.1384  7.4650\n",
      "      4        0.1279  7.2796\n",
      "      5        0.1965  7.2582\n",
      "      6        0.1802  7.2630\n",
      "      7        0.1988  7.2634\n",
      "      8        0.2225  7.2689\n",
      "      9        0.1884  7.2727\n",
      "     10        0.1517  7.2705\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3864\u001b[0m  7.2673\n",
      "      2        \u001b[36m0.0952\u001b[0m  7.2687\n",
      "      3        \u001b[36m0.0911\u001b[0m  7.2606\n",
      "      4        \u001b[36m0.0796\u001b[0m  7.2690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        0.0961  7.2610\n",
      "      6        0.0851  7.2665\n",
      "      7        0.1004  7.2617\n",
      "      8        \u001b[36m0.0661\u001b[0m  7.2726\n",
      "      9        \u001b[36m0.0359\u001b[0m  7.2658\n",
      "     10        \u001b[36m0.0265\u001b[0m  7.3278\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 1.2min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1026\u001b[0m  7.0589\n",
      "      2        0.1148  7.0663\n",
      "      3        0.2610  7.0533\n",
      "      4        0.3149  7.0528\n",
      "      5        0.2917  7.0657\n",
      "      6        0.2115  7.0564\n",
      "      7        0.2118  7.0631\n",
      "      8        \u001b[36m0.0959\u001b[0m  7.0631\n",
      "      9        \u001b[36m0.0622\u001b[0m  7.0565\n",
      "     10        \u001b[36m0.0445\u001b[0m  7.0688\n",
      "     11        \u001b[36m0.0357\u001b[0m  7.0661\n",
      "     12        \u001b[36m0.0293\u001b[0m  7.0643\n",
      "     13        \u001b[36m0.0240\u001b[0m  7.0813\n",
      "     14        \u001b[36m0.0220\u001b[0m  7.0493\n",
      "     15        \u001b[36m0.0205\u001b[0m  7.0562\n",
      "     16        \u001b[36m0.0201\u001b[0m  7.0714\n",
      "     17        \u001b[36m0.0188\u001b[0m  7.0555\n",
      "     18        \u001b[36m0.0174\u001b[0m  7.0492\n",
      "     19        \u001b[36m0.0166\u001b[0m  7.1142\n",
      "     20        \u001b[36m0.0161\u001b[0m  7.1018\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0883\u001b[0m  7.2474\n",
      "      2        0.1032  7.0856\n",
      "      3        0.1702  7.0536\n",
      "      4        0.2395  7.0506\n",
      "      5        0.3404  7.0850\n",
      "      6        0.3655  7.0648\n",
      "      7        0.2718  7.0649\n",
      "      8        0.1283  7.0529\n",
      "      9        \u001b[36m0.0705\u001b[0m  7.0504\n",
      "     10        \u001b[36m0.0450\u001b[0m  7.0505\n",
      "     11        \u001b[36m0.0381\u001b[0m  7.0516\n",
      "     12        \u001b[36m0.0308\u001b[0m  7.0770\n",
      "     13        \u001b[36m0.0279\u001b[0m  7.1027\n",
      "     14        \u001b[36m0.0235\u001b[0m  7.0592\n",
      "     15        0.0256  7.0620\n",
      "     16        \u001b[36m0.0198\u001b[0m  7.0772\n",
      "     17        \u001b[36m0.0190\u001b[0m  7.0524\n",
      "     18        \u001b[36m0.0177\u001b[0m  7.0574\n",
      "     19        \u001b[36m0.0173\u001b[0m  7.0595\n",
      "     20        \u001b[36m0.0162\u001b[0m  7.0701\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1112\u001b[0m  7.0751\n",
      "      2        \u001b[36m0.0891\u001b[0m  7.0664\n",
      "      3        0.1406  7.0560\n",
      "      4        0.1918  7.0540\n",
      "      5        0.2622  7.0750\n",
      "      6        0.2424  7.0867\n",
      "      7        0.4581  7.0852\n",
      "      8        0.2770  7.0841\n",
      "      9        \u001b[36m0.0816\u001b[0m  7.0737\n",
      "     10        0.0954  7.1336\n",
      "     11        \u001b[36m0.0473\u001b[0m  7.0627\n",
      "     12        \u001b[36m0.0356\u001b[0m  7.0635\n",
      "     13        \u001b[36m0.0298\u001b[0m  7.0673\n",
      "     14        \u001b[36m0.0238\u001b[0m  7.1273\n",
      "     15        \u001b[36m0.0230\u001b[0m  7.0557\n",
      "     16        \u001b[36m0.0185\u001b[0m  7.0626\n",
      "     17        \u001b[36m0.0178\u001b[0m  7.0702\n",
      "     18        \u001b[36m0.0161\u001b[0m  7.0764\n",
      "     19        \u001b[36m0.0143\u001b[0m  7.0671\n",
      "     20        0.0154  7.0650\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1102\u001b[0m  7.0506\n",
      "      2        \u001b[36m0.1032\u001b[0m  7.0529\n",
      "      3        0.1841  7.0649\n",
      "      4        0.2968  7.0582\n",
      "      5        0.2624  7.0686\n",
      "      6        0.2441  7.0670\n",
      "      7        0.1425  7.0924\n",
      "      8        0.1190  7.0697\n",
      "      9        \u001b[36m0.0639\u001b[0m  7.0527\n",
      "     10        \u001b[36m0.0575\u001b[0m  7.0573\n",
      "     11        \u001b[36m0.0432\u001b[0m  7.0536\n",
      "     12        \u001b[36m0.0354\u001b[0m  7.0630\n",
      "     13        \u001b[36m0.0299\u001b[0m  7.0650\n",
      "     14        \u001b[36m0.0257\u001b[0m  7.0849\n",
      "     15        \u001b[36m0.0222\u001b[0m  7.0539\n",
      "     16        \u001b[36m0.0205\u001b[0m  7.0514\n",
      "     17        0.0210  7.0565\n",
      "     18        \u001b[36m0.0191\u001b[0m  7.0656\n",
      "     19        \u001b[36m0.0175\u001b[0m  7.0577\n",
      "     20        0.0176  7.0646\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1010\u001b[0m  7.0656\n",
      "      2        0.1043  7.0704\n",
      "      3        0.1985  7.0504\n",
      "      4        0.2952  7.0804\n",
      "      5        0.3011  7.0518\n",
      "      6        0.1818  7.0486\n",
      "      7        \u001b[36m0.0932\u001b[0m  7.0701\n",
      "      8        \u001b[36m0.0627\u001b[0m  7.0485\n",
      "      9        \u001b[36m0.0516\u001b[0m  7.0470\n",
      "     10        \u001b[36m0.0414\u001b[0m  7.0562\n",
      "     11        \u001b[36m0.0337\u001b[0m  7.0774\n",
      "     12        \u001b[36m0.0272\u001b[0m  7.0561\n",
      "     13        \u001b[36m0.0249\u001b[0m  7.0508\n",
      "     14        \u001b[36m0.0202\u001b[0m  7.0588\n",
      "     15        \u001b[36m0.0186\u001b[0m  7.0559\n",
      "     16        \u001b[36m0.0178\u001b[0m  7.0651\n",
      "     17        \u001b[36m0.0156\u001b[0m  7.0787\n",
      "     18        \u001b[36m0.0154\u001b[0m  7.0571\n",
      "     19        \u001b[36m0.0150\u001b[0m  7.0804\n",
      "     20        \u001b[36m0.0138\u001b[0m  7.0778\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4306\u001b[0m  7.2823\n",
      "      2        \u001b[36m0.0672\u001b[0m  7.2568\n",
      "      3        0.0861  7.2666\n",
      "      4        \u001b[36m0.0588\u001b[0m  7.2645\n",
      "      5        0.0693  7.2758\n",
      "      6        0.1120  7.2612\n",
      "      7        0.1426  7.2745\n",
      "      8        0.1703  7.2679\n",
      "      9        0.1862  7.2971\n",
      "     10        0.4687  7.5579\n",
      "     11        0.1449  7.3123\n",
      "     12        0.0596  7.2656\n",
      "     13        \u001b[36m0.0421\u001b[0m  7.2626\n",
      "     14        \u001b[36m0.0295\u001b[0m  7.2646\n",
      "     15        \u001b[36m0.0216\u001b[0m  7.2738\n",
      "     16        0.0257  7.2743\n",
      "     17        0.0221  7.2854\n",
      "     18        \u001b[36m0.0187\u001b[0m  7.2780\n",
      "     19        \u001b[36m0.0142\u001b[0m  7.2836\n",
      "     20        0.0202  7.2819\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4241\u001b[0m  7.2814\n",
      "      2        \u001b[36m0.0655\u001b[0m  7.2823\n",
      "      3        \u001b[36m0.0610\u001b[0m  7.2742\n",
      "      4        \u001b[36m0.0473\u001b[0m  7.2908\n",
      "      5        0.0556  7.2776\n",
      "      6        0.0728  7.2650\n",
      "      7        0.0748  7.2638\n",
      "      8        0.0734  7.2631\n",
      "      9        0.0564  7.2638\n",
      "     10        \u001b[36m0.0389\u001b[0m  7.2626\n",
      "     11        \u001b[36m0.0214\u001b[0m  7.2607\n",
      "     12        \u001b[36m0.0152\u001b[0m  7.2782\n",
      "     13        \u001b[36m0.0125\u001b[0m  7.2840\n",
      "     14        \u001b[36m0.0107\u001b[0m  7.2684\n",
      "     15        0.0120  7.2574\n",
      "     16        0.0109  7.2606\n",
      "     17        \u001b[36m0.0102\u001b[0m  7.2594\n",
      "     18        \u001b[36m0.0101\u001b[0m  7.2636\n",
      "     19        0.0106  7.2764\n",
      "     20        \u001b[36m0.0095\u001b[0m  7.2887\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3638\u001b[0m  7.3016\n",
      "      2        \u001b[36m0.0661\u001b[0m  7.3920\n",
      "      3        \u001b[36m0.0571\u001b[0m  7.2638\n",
      "      4        0.0603  7.2631\n",
      "      5        0.0804  7.2611\n",
      "      6        0.0792  7.3142\n",
      "      7        0.0780  7.2578\n",
      "      8        \u001b[36m0.0531\u001b[0m  7.2719\n",
      "      9        0.0717  7.2707\n",
      "     10        0.0611  7.3235\n",
      "     11        \u001b[36m0.0451\u001b[0m  7.2599\n",
      "     12        \u001b[36m0.0267\u001b[0m  7.2670\n",
      "     13        \u001b[36m0.0169\u001b[0m  7.2654\n",
      "     14        \u001b[36m0.0155\u001b[0m  7.2589\n",
      "     15        \u001b[36m0.0100\u001b[0m  7.2648\n",
      "     16        0.0101  7.5534\n",
      "     17        0.0104  7.2862\n",
      "     18        \u001b[36m0.0094\u001b[0m  7.2787\n",
      "     19        \u001b[36m0.0078\u001b[0m  7.2689\n",
      "     20        0.0081  7.4154\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3999\u001b[0m  7.2678\n",
      "      2        \u001b[36m0.0710\u001b[0m  7.2670\n",
      "      3        0.0774  7.2663\n",
      "      4        \u001b[36m0.0662\u001b[0m  7.2677\n",
      "      5        \u001b[36m0.0603\u001b[0m  7.2878\n",
      "      6        0.0846  7.4812\n",
      "      7        0.0912  7.4204\n",
      "      8        0.0820  7.3019\n",
      "      9        0.1025  7.2691\n",
      "     10        0.1496  7.2752\n",
      "     11        0.2453  7.2715\n",
      "     12        0.0871  7.2709\n",
      "     13        0.0649  7.2751\n",
      "     14        \u001b[36m0.0470\u001b[0m  7.2737\n",
      "     15        \u001b[36m0.0298\u001b[0m  7.2646\n",
      "     16        \u001b[36m0.0295\u001b[0m  7.2662\n",
      "     17        \u001b[36m0.0246\u001b[0m  7.2669\n",
      "     18        \u001b[36m0.0235\u001b[0m  7.2617\n",
      "     19        0.0249  7.2761\n",
      "     20        \u001b[36m0.0138\u001b[0m  7.2700\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3906\u001b[0m  7.3048\n",
      "      2        \u001b[36m0.0680\u001b[0m  7.5377\n",
      "      3        0.0694  7.3471\n",
      "      4        \u001b[36m0.0620\u001b[0m  7.2655\n",
      "      5        \u001b[36m0.0606\u001b[0m  7.2648\n",
      "      6        \u001b[36m0.0389\u001b[0m  7.2800\n",
      "      7        0.0906  7.2605\n",
      "      8        0.0597  7.2606\n",
      "      9        \u001b[36m0.0343\u001b[0m  7.2730\n",
      "     10        \u001b[36m0.0202\u001b[0m  7.2688\n",
      "     11        \u001b[36m0.0128\u001b[0m  7.2622\n",
      "     12        \u001b[36m0.0101\u001b[0m  7.3982\n",
      "     13        \u001b[36m0.0094\u001b[0m  7.2599\n",
      "     14        \u001b[36m0.0089\u001b[0m  7.2550\n",
      "     15        \u001b[36m0.0076\u001b[0m  7.2608\n",
      "     16        0.0077  7.3837\n",
      "     17        \u001b[36m0.0076\u001b[0m  7.2712\n",
      "     18        \u001b[36m0.0071\u001b[0m  7.3287\n",
      "     19        \u001b[36m0.0071\u001b[0m  7.2985\n",
      "     20        \u001b[36m0.0070\u001b[0m  7.2587\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1018\u001b[0m  7.0761\n",
      "      2        0.1195  7.0722\n",
      "      3        0.2729  7.0772\n",
      "      4        0.2682  7.0577\n",
      "      5        0.3218  7.0633\n",
      "      6        0.1286  7.0617\n",
      "      7        \u001b[36m0.0942\u001b[0m  7.0779\n",
      "      8        \u001b[36m0.0765\u001b[0m  7.0568\n",
      "      9        \u001b[36m0.0558\u001b[0m  7.0668\n",
      "     10        \u001b[36m0.0493\u001b[0m  7.0612\n",
      "     11        \u001b[36m0.0420\u001b[0m  7.0587\n",
      "     12        \u001b[36m0.0358\u001b[0m  7.0628\n",
      "     13        \u001b[36m0.0336\u001b[0m  7.0585\n",
      "     14        \u001b[36m0.0300\u001b[0m  7.0823\n",
      "     15        \u001b[36m0.0279\u001b[0m  7.1370\n",
      "     16        \u001b[36m0.0250\u001b[0m  7.1536\n",
      "     17        \u001b[36m0.0236\u001b[0m  7.2579\n",
      "     18        \u001b[36m0.0236\u001b[0m  7.0675\n",
      "     19        0.0245  7.0608\n",
      "     20        \u001b[36m0.0204\u001b[0m  7.0690\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1144\u001b[0m  7.0550\n",
      "      2        \u001b[36m0.0967\u001b[0m  7.0641\n",
      "      3        0.1409  7.0573\n",
      "      4        0.2329  7.1054\n",
      "      5        0.3008  7.0561\n",
      "      6        0.1789  7.0592\n",
      "      7        0.1640  7.0611\n",
      "      8        \u001b[36m0.0859\u001b[0m  7.0824\n",
      "      9        \u001b[36m0.0658\u001b[0m  7.0753\n",
      "     10        \u001b[36m0.0517\u001b[0m  7.0628\n",
      "     11        \u001b[36m0.0413\u001b[0m  7.0682\n",
      "     12        \u001b[36m0.0361\u001b[0m  7.0956\n",
      "     13        \u001b[36m0.0323\u001b[0m  7.5082\n",
      "     14        \u001b[36m0.0305\u001b[0m  7.0698\n",
      "     15        \u001b[36m0.0284\u001b[0m  7.0702\n",
      "     16        \u001b[36m0.0268\u001b[0m  7.3569\n",
      "     17        \u001b[36m0.0229\u001b[0m  7.0639\n",
      "     18        \u001b[36m0.0215\u001b[0m  7.0704\n",
      "     19        \u001b[36m0.0212\u001b[0m  7.0715\n",
      "     20        0.0215  7.0788\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1103\u001b[0m  7.0708\n",
      "      2        \u001b[36m0.1027\u001b[0m  7.0586\n",
      "      3        0.1414  7.0683\n",
      "      4        0.2218  7.0715\n",
      "      5        0.3172  7.0710\n",
      "      6        0.2696  7.0834\n",
      "      7        0.2442  7.0788\n",
      "      8        0.2207  7.1313\n",
      "      9        0.1482  7.2248\n",
      "     10        \u001b[36m0.0752\u001b[0m  7.0639\n",
      "     11        \u001b[36m0.0575\u001b[0m  7.1663\n",
      "     12        \u001b[36m0.0428\u001b[0m  7.1176\n",
      "     13        \u001b[36m0.0378\u001b[0m  7.6134\n",
      "     14        \u001b[36m0.0320\u001b[0m  7.1162\n",
      "     15        \u001b[36m0.0309\u001b[0m  7.0715\n",
      "     16        \u001b[36m0.0269\u001b[0m  7.0814\n",
      "     17        \u001b[36m0.0228\u001b[0m  7.0703\n",
      "     18        \u001b[36m0.0211\u001b[0m  7.0686\n",
      "     19        0.0212  7.0610\n",
      "     20        \u001b[36m0.0198\u001b[0m  7.0662\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1100\u001b[0m  7.0977\n",
      "      2        0.1111  7.0910\n",
      "      3        0.2382  7.1770\n",
      "      4        0.2588  7.0597\n",
      "      5        0.3018  7.0840\n",
      "      6        0.3596  7.0706\n",
      "      7        0.2587  7.0522\n",
      "      8        0.4300  7.0561\n",
      "      9        0.1449  7.0564\n",
      "     10        \u001b[36m0.0807\u001b[0m  7.0768\n",
      "     11        \u001b[36m0.0612\u001b[0m  7.0651\n",
      "     12        \u001b[36m0.0538\u001b[0m  7.0713\n",
      "     13        \u001b[36m0.0393\u001b[0m  7.0806\n",
      "     14        \u001b[36m0.0352\u001b[0m  7.1471\n",
      "     15        \u001b[36m0.0331\u001b[0m  7.0782\n",
      "     16        \u001b[36m0.0308\u001b[0m  7.0676\n",
      "     17        \u001b[36m0.0269\u001b[0m  7.0662\n",
      "     18        0.0271  7.0716\n",
      "     19        \u001b[36m0.0229\u001b[0m  7.1048\n",
      "     20        0.0239  7.0600\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1227\u001b[0m  7.0753\n",
      "      2        \u001b[36m0.1028\u001b[0m  7.0808\n",
      "      3        \u001b[36m0.1027\u001b[0m  7.0678\n",
      "      4        0.1663  7.0511\n",
      "      5        0.1843  7.0588\n",
      "      6        0.1909  7.0496\n",
      "      7        0.1139  7.0658\n",
      "      8        \u001b[36m0.0715\u001b[0m  7.0531\n",
      "      9        \u001b[36m0.0693\u001b[0m  7.0585\n",
      "     10        \u001b[36m0.0543\u001b[0m  7.0660\n",
      "     11        \u001b[36m0.0433\u001b[0m  7.0564\n",
      "     12        \u001b[36m0.0361\u001b[0m  7.0517\n",
      "     13        \u001b[36m0.0319\u001b[0m  7.0500\n",
      "     14        \u001b[36m0.0295\u001b[0m  7.0644\n",
      "     15        \u001b[36m0.0267\u001b[0m  7.0866\n",
      "     16        \u001b[36m0.0251\u001b[0m  7.0548\n",
      "     17        \u001b[36m0.0245\u001b[0m  7.1279\n",
      "     18        \u001b[36m0.0209\u001b[0m  7.0735\n",
      "     19        0.0224  7.1134\n",
      "     20        \u001b[36m0.0200\u001b[0m  7.0688\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4056\u001b[0m  7.5251\n",
      "      2        \u001b[36m0.0749\u001b[0m  7.2740\n",
      "      3        \u001b[36m0.0733\u001b[0m  7.2656\n",
      "      4        0.0794  7.2710\n",
      "      5        0.0984  7.2685\n",
      "      6        0.1192  7.2909\n",
      "      7        0.0951  7.5216\n",
      "      8        0.1169  8.3608\n",
      "      9        0.1431  8.2361\n",
      "     10        \u001b[36m0.0552\u001b[0m  7.8069\n",
      "     11        \u001b[36m0.0361\u001b[0m  7.4678\n",
      "     12        0.0363  7.5276\n",
      "     13        \u001b[36m0.0220\u001b[0m  7.3277\n",
      "     14        \u001b[36m0.0169\u001b[0m  7.2864\n",
      "     15        0.0178  7.3653\n",
      "     16        \u001b[36m0.0153\u001b[0m  7.2676\n",
      "     17        \u001b[36m0.0139\u001b[0m  7.2670\n",
      "     18        \u001b[36m0.0131\u001b[0m  7.2647\n",
      "     19        \u001b[36m0.0127\u001b[0m  7.2604\n",
      "     20        \u001b[36m0.0121\u001b[0m  7.3436\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3541\u001b[0m  7.2774\n",
      "      2        \u001b[36m0.0793\u001b[0m  7.3619\n",
      "      3        0.0945  7.3580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m0.0704\u001b[0m  7.2742\n",
      "      5        0.1065  7.2727\n",
      "      6        0.1129  7.2715\n",
      "      7        0.1499  7.2693\n",
      "      8        0.1716  7.8068\n",
      "      9        \u001b[36m0.0694\u001b[0m  7.4215\n",
      "     10        \u001b[36m0.0413\u001b[0m  7.2854\n",
      "     11        \u001b[36m0.0266\u001b[0m  7.2923\n",
      "     12        \u001b[36m0.0206\u001b[0m  7.2873\n",
      "     13        \u001b[36m0.0179\u001b[0m  7.5236\n",
      "     14        \u001b[36m0.0146\u001b[0m  7.3030\n",
      "     15        \u001b[36m0.0129\u001b[0m  7.2693\n",
      "     16        0.0136  7.2719\n",
      "     17        \u001b[36m0.0128\u001b[0m  7.2631\n",
      "     18        \u001b[36m0.0115\u001b[0m  7.2742\n",
      "     19        \u001b[36m0.0113\u001b[0m  7.2794\n",
      "     20        0.0129  7.5123\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3636\u001b[0m  7.8459\n",
      "      2        \u001b[36m0.0677\u001b[0m  7.3031\n",
      "      3        0.0774  7.2728\n",
      "      4        \u001b[36m0.0666\u001b[0m  7.2979\n",
      "      5        0.0749  7.4128\n",
      "      6        0.0990  7.4533\n",
      "      7        0.0751  7.2862\n",
      "      8        \u001b[36m0.0478\u001b[0m  7.2727\n",
      "      9        0.0630  7.2633\n",
      "     10        \u001b[36m0.0295\u001b[0m  7.2697\n",
      "     11        \u001b[36m0.0184\u001b[0m  7.3485\n",
      "     12        \u001b[36m0.0160\u001b[0m  7.3410\n",
      "     13        \u001b[36m0.0118\u001b[0m  7.3178\n",
      "     14        \u001b[36m0.0108\u001b[0m  7.3266\n",
      "     15        \u001b[36m0.0104\u001b[0m  7.3273\n",
      "     16        \u001b[36m0.0096\u001b[0m  7.3180\n",
      "     17        0.0096  7.3081\n",
      "     18        \u001b[36m0.0087\u001b[0m  7.3106\n",
      "     19        0.0087  7.3913\n",
      "     20        \u001b[36m0.0081\u001b[0m  7.4172\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4312\u001b[0m  7.3195\n",
      "      2        \u001b[36m0.0781\u001b[0m  7.3261\n",
      "      3        \u001b[36m0.0712\u001b[0m  7.5432\n",
      "      4        \u001b[36m0.0678\u001b[0m  7.4006\n",
      "      5        0.0694  7.3210\n",
      "      6        0.0787  7.3159\n",
      "      7        0.0716  7.3176\n",
      "      8        0.0756  7.3783\n",
      "      9        0.0868  7.3198\n",
      "     10        0.0681  7.3284\n",
      "     11        \u001b[36m0.0499\u001b[0m  7.3228\n",
      "     12        \u001b[36m0.0329\u001b[0m  7.3200\n",
      "     13        \u001b[36m0.0221\u001b[0m  7.3149\n",
      "     14        \u001b[36m0.0203\u001b[0m  7.3196\n",
      "     15        \u001b[36m0.0154\u001b[0m  7.3189\n",
      "     16        \u001b[36m0.0134\u001b[0m  7.3225\n",
      "     17        0.0226  7.3587\n",
      "     18        0.0150  7.5447\n",
      "     19        0.0187  7.3227\n",
      "     20        0.0213  7.3619\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3798\u001b[0m  7.3154\n",
      "      2        \u001b[36m0.0719\u001b[0m  7.3291\n",
      "      3        0.0801  7.3133\n",
      "      4        \u001b[36m0.0648\u001b[0m  7.3222\n",
      "      5        0.1000  7.3190\n",
      "      6        0.0962  7.3164\n",
      "      7        0.1245  7.3423\n",
      "      8        0.1040  7.3918\n",
      "      9        \u001b[36m0.0531\u001b[0m  7.3134\n",
      "     10        \u001b[36m0.0281\u001b[0m  7.3217\n",
      "     11        \u001b[36m0.0216\u001b[0m  7.3432\n",
      "     12        \u001b[36m0.0172\u001b[0m  7.6497\n",
      "     13        \u001b[36m0.0122\u001b[0m  8.4285\n",
      "     14        \u001b[36m0.0106\u001b[0m  8.0211\n",
      "     15        \u001b[36m0.0099\u001b[0m  7.6447\n",
      "     16        0.0100  7.4684\n",
      "     17        0.0100  7.5384\n",
      "     18        \u001b[36m0.0094\u001b[0m  7.3529\n",
      "     19        \u001b[36m0.0089\u001b[0m  7.3223\n",
      "     20        0.0092  7.3162\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1070\u001b[0m  7.1226\n",
      "      2        0.1216  7.1240\n",
      "      3        0.1948  7.1198\n",
      "      4        0.2593  7.2405\n",
      "      5        0.3087  7.1169\n",
      "      6        0.5087  7.4665\n",
      "      7        0.3739  7.0996\n",
      "      8        0.1607  7.1882\n",
      "      9        0.1143  7.1110\n",
      "     10        \u001b[36m0.0766\u001b[0m  7.1114\n",
      "     11        \u001b[36m0.0607\u001b[0m  7.1202\n",
      "     12        \u001b[36m0.0530\u001b[0m  7.3257\n",
      "     13        \u001b[36m0.0492\u001b[0m  7.1897\n",
      "     14        \u001b[36m0.0430\u001b[0m  7.0980\n",
      "     15        \u001b[36m0.0420\u001b[0m  7.0989\n",
      "     16        \u001b[36m0.0391\u001b[0m  7.2298\n",
      "     17        \u001b[36m0.0365\u001b[0m  7.1177\n",
      "     18        \u001b[36m0.0330\u001b[0m  7.1160\n",
      "     19        0.0345  7.3537\n",
      "     20        \u001b[36m0.0305\u001b[0m  7.1102\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1251\u001b[0m  7.1197\n",
      "      2        \u001b[36m0.1114\u001b[0m  7.1027\n",
      "      3        0.1255  7.2601\n",
      "      4        0.1951  7.1013\n",
      "      5        0.3073  7.1866\n",
      "      6        0.3816  7.1863\n",
      "      7        0.1460  7.1131\n",
      "      8        \u001b[36m0.1101\u001b[0m  7.1125\n",
      "      9        \u001b[36m0.0872\u001b[0m  7.1454\n",
      "     10        \u001b[36m0.0772\u001b[0m  7.1180\n",
      "     11        \u001b[36m0.0594\u001b[0m  7.1096\n",
      "     12        \u001b[36m0.0561\u001b[0m  7.1144\n",
      "     13        \u001b[36m0.0513\u001b[0m  7.2589\n",
      "     14        \u001b[36m0.0459\u001b[0m  7.2420\n",
      "     15        \u001b[36m0.0421\u001b[0m  7.4172\n",
      "     16        \u001b[36m0.0418\u001b[0m  7.2702\n",
      "     17        \u001b[36m0.0376\u001b[0m  7.1420\n",
      "     18        \u001b[36m0.0368\u001b[0m  7.1126\n",
      "     19        \u001b[36m0.0357\u001b[0m  7.1107\n",
      "     20        \u001b[36m0.0340\u001b[0m  7.1176\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.0995\u001b[0m  7.1056\n",
      "      2        0.1214  7.2307\n",
      "      3        0.1809  7.1158\n",
      "      4        0.2190  7.1194\n",
      "      5        0.2875  7.1356\n",
      "      6        0.1639  7.1177\n",
      "      7        0.1301  7.1020\n",
      "      8        0.1012  7.1633\n",
      "      9        \u001b[36m0.0738\u001b[0m  7.1100\n",
      "     10        \u001b[36m0.0590\u001b[0m  7.1780\n",
      "     11        \u001b[36m0.0544\u001b[0m  7.1061\n",
      "     12        \u001b[36m0.0475\u001b[0m  7.1081\n",
      "     13        \u001b[36m0.0414\u001b[0m  7.1361\n",
      "     14        \u001b[36m0.0394\u001b[0m  7.3067\n",
      "     15        \u001b[36m0.0364\u001b[0m  7.1143\n",
      "     16        \u001b[36m0.0337\u001b[0m  7.0961\n",
      "     17        \u001b[36m0.0308\u001b[0m  7.0959\n",
      "     18        \u001b[36m0.0298\u001b[0m  7.0958\n",
      "     19        0.0299  7.0970\n",
      "     20        \u001b[36m0.0289\u001b[0m  7.0999\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1065\u001b[0m  7.1118\n",
      "      2        0.1232  7.1407\n",
      "      3        0.1839  7.1090\n",
      "      4        0.3387  7.0943\n",
      "      5        0.3107  7.0964\n",
      "      6        0.1684  7.1008\n",
      "      7        0.1359  7.0988\n",
      "      8        0.1100  7.0927\n",
      "      9        \u001b[36m0.0904\u001b[0m  7.1275\n",
      "     10        \u001b[36m0.0703\u001b[0m  7.1178\n",
      "     11        \u001b[36m0.0664\u001b[0m  7.1231\n",
      "     12        \u001b[36m0.0590\u001b[0m  7.2239\n",
      "     13        \u001b[36m0.0507\u001b[0m  7.0996\n",
      "     14        \u001b[36m0.0486\u001b[0m  7.1009\n",
      "     15        \u001b[36m0.0435\u001b[0m  7.1196\n",
      "     16        \u001b[36m0.0412\u001b[0m  7.1008\n",
      "     17        \u001b[36m0.0397\u001b[0m  7.1115\n",
      "     18        \u001b[36m0.0358\u001b[0m  7.1290\n",
      "     19        \u001b[36m0.0346\u001b[0m  7.1671\n",
      "     20        0.0363  7.0972\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.1075\u001b[0m  7.1989\n",
      "      2        0.1147  7.1013\n",
      "      3        0.1881  7.1106\n",
      "      4        0.2376  7.1091\n",
      "      5        0.2045  7.1057\n",
      "      6        0.2012  7.1101\n",
      "      7        0.1200  7.1114\n",
      "      8        \u001b[36m0.1053\u001b[0m  7.1096\n",
      "      9        \u001b[36m0.0857\u001b[0m  7.1038\n",
      "     10        \u001b[36m0.0712\u001b[0m  7.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11        \u001b[36m0.0658\u001b[0m  7.1084\n",
      "     12        \u001b[36m0.0584\u001b[0m  7.1052\n",
      "     13        \u001b[36m0.0498\u001b[0m  7.1068\n",
      "     14        \u001b[36m0.0451\u001b[0m  7.1126\n",
      "     15        \u001b[36m0.0421\u001b[0m  7.1041\n",
      "     16        \u001b[36m0.0362\u001b[0m  7.1410\n",
      "     17        \u001b[36m0.0358\u001b[0m  7.0941\n",
      "     18        \u001b[36m0.0335\u001b[0m  7.1019\n",
      "     19        \u001b[36m0.0315\u001b[0m  7.1130\n",
      "     20        \u001b[36m0.0308\u001b[0m  7.1042\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=31, total= 2.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3683\u001b[0m  7.3211\n",
      "      2        \u001b[36m0.1171\u001b[0m  7.3153\n",
      "      3        0.1507  7.3111\n",
      "      4        0.1391  7.3288\n",
      "      5        0.1621  7.3212\n",
      "      6        0.1940  7.3155\n",
      "      7        \u001b[36m0.1144\u001b[0m  7.3138\n",
      "      8        \u001b[36m0.0764\u001b[0m  7.3180\n",
      "      9        \u001b[36m0.0373\u001b[0m  7.3128\n",
      "     10        \u001b[36m0.0282\u001b[0m  7.3111\n",
      "     11        \u001b[36m0.0229\u001b[0m  7.3144\n",
      "     12        \u001b[36m0.0194\u001b[0m  7.3496\n",
      "     13        \u001b[36m0.0181\u001b[0m  7.3082\n",
      "     14        \u001b[36m0.0162\u001b[0m  7.3103\n",
      "     15        0.0164  7.3099\n",
      "     16        0.0173  7.3167\n",
      "     17        0.0178  7.3066\n",
      "     18        \u001b[36m0.0141\u001b[0m  7.3093\n",
      "     19        0.0146  7.3127\n",
      "     20        0.0188  7.3178\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3757\u001b[0m  7.3053\n",
      "      2        \u001b[36m0.0891\u001b[0m  7.3084\n",
      "      3        \u001b[36m0.0884\u001b[0m  7.3997\n",
      "      4        \u001b[36m0.0727\u001b[0m  7.3082\n",
      "      5        0.0846  7.2978\n",
      "      6        0.1096  7.3601\n",
      "      7        0.1376  7.3044\n",
      "      8        0.1297  7.3203\n",
      "      9        \u001b[36m0.0663\u001b[0m  7.2922\n",
      "     10        \u001b[36m0.0498\u001b[0m  7.2827\n",
      "     11        \u001b[36m0.0297\u001b[0m  7.2888\n",
      "     12        \u001b[36m0.0243\u001b[0m  7.2874\n",
      "     13        \u001b[36m0.0232\u001b[0m  7.2884\n",
      "     14        \u001b[36m0.0168\u001b[0m  7.3025\n",
      "     15        0.0183  7.2989\n",
      "     16        \u001b[36m0.0165\u001b[0m  7.2962\n",
      "     17        \u001b[36m0.0157\u001b[0m  7.2873\n",
      "     18        \u001b[36m0.0153\u001b[0m  7.2872\n",
      "     19        \u001b[36m0.0149\u001b[0m  7.2876\n",
      "     20        \u001b[36m0.0142\u001b[0m  7.2949\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3961\u001b[0m  7.2892\n",
      "      2        \u001b[36m0.0701\u001b[0m  7.2883\n",
      "      3        \u001b[36m0.0608\u001b[0m  7.3043\n",
      "      4        0.0716  7.2941\n",
      "      5        0.0775  7.3161\n",
      "      6        0.0696  7.2936\n",
      "      7        0.0855  7.2897\n",
      "      8        \u001b[36m0.0550\u001b[0m  7.2886\n",
      "      9        \u001b[36m0.0431\u001b[0m  7.2931\n",
      "     10        \u001b[36m0.0226\u001b[0m  7.2917\n",
      "     11        \u001b[36m0.0185\u001b[0m  7.2999\n",
      "     12        \u001b[36m0.0157\u001b[0m  7.3040\n",
      "     13        0.0159  7.3035\n",
      "     14        \u001b[36m0.0137\u001b[0m  7.2873\n",
      "     15        \u001b[36m0.0119\u001b[0m  7.2899\n",
      "     16        0.0132  7.2961\n",
      "     17        0.0126  7.3038\n",
      "     18        \u001b[36m0.0109\u001b[0m  7.2892\n",
      "     19        0.0135  7.2910\n",
      "     20        \u001b[36m0.0103\u001b[0m  7.3112\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4114\u001b[0m  7.3358\n",
      "      2        \u001b[36m0.0839\u001b[0m  7.3323\n",
      "      3        0.1109  7.2836\n",
      "      4        0.1115  7.2894\n",
      "      5        0.1006  7.2868\n",
      "      6        0.1658  7.2880\n",
      "      7        0.1537  7.3680\n",
      "      8        0.1080  7.6675\n",
      "      9        0.0881  8.2169\n",
      "     10        \u001b[36m0.0518\u001b[0m  7.5617\n",
      "     11        \u001b[36m0.0479\u001b[0m  7.9117\n",
      "     12        \u001b[36m0.0284\u001b[0m  7.8183\n",
      "     13        \u001b[36m0.0234\u001b[0m  7.3388\n",
      "     14        \u001b[36m0.0217\u001b[0m  7.3533\n",
      "     15        \u001b[36m0.0187\u001b[0m  7.4785\n",
      "     16        \u001b[36m0.0166\u001b[0m  7.2985\n",
      "     17        \u001b[36m0.0147\u001b[0m  7.3474\n",
      "     18        0.0157  7.3873\n",
      "     19        \u001b[36m0.0138\u001b[0m  7.3687\n",
      "     20        0.0140  7.2907\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.5min\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3477\u001b[0m  7.2895\n",
      "      2        \u001b[36m0.1062\u001b[0m  7.2865\n",
      "      3        0.1210  7.2965\n",
      "      4        0.1180  7.4307\n",
      "      5        0.1890  7.4681\n",
      "      6        0.2393  7.2984\n",
      "      7        0.1230  7.3005\n",
      "      8        \u001b[36m0.0450\u001b[0m  7.2963\n",
      "      9        \u001b[36m0.0310\u001b[0m  7.2966\n",
      "     10        \u001b[36m0.0221\u001b[0m  7.5741\n",
      "     11        \u001b[36m0.0189\u001b[0m  7.3571\n",
      "     12        \u001b[36m0.0162\u001b[0m  7.3052\n",
      "     13        \u001b[36m0.0149\u001b[0m  7.3697\n",
      "     14        \u001b[36m0.0143\u001b[0m  7.2934\n",
      "     15        \u001b[36m0.0140\u001b[0m  7.2932\n",
      "     16        \u001b[36m0.0126\u001b[0m  7.2938\n",
      "     17        0.0127  7.3088\n",
      "     18        0.0138  7.3082\n",
      "     19        0.0137  7.4332\n",
      "     20        \u001b[36m0.0115\u001b[0m  7.3103\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__weight_dim_2=137, total= 2.5min\n",
      "0.9666045248949673 {'net__batch_size': 128, 'net__max_epochs': 20, 'net__module__dropout_rate': 0.6, 'net__module__weight_dim_2': 137}\n",
      "\n",
      "Done! Time: 347.35 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed: 347.3min finished\n"
     ]
    }
   ],
   "source": [
    "start_training = time.time()\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "input_dim_1 = 307\n",
    "input_dim_2 = 100\n",
    "\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    Model_1_network,\n",
    "    module__input_dim_1 = input_dim_1,\n",
    "    module__input_dim_2 = input_dim_2,\n",
    "    module__weight_dim_2 = 31,\n",
    "    module__dropout_rate = 0.4,\n",
    "    batch_size = 32,\n",
    "    max_epochs = 10,\n",
    "    train_split = None,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "ros = RandomOverSampler(random_state = SEED)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ros', ros),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "# LSTM(10) => 12771 => DGCNN(31) => 12618\n",
    "# LSTM(40) => 55881 => DGCNN(137) => 55760\n",
    "# LSTM(70) => 106191 => DGCNN(261) => 106228 \n",
    "# LSTM(100) => 163701 => DGCNN(402) => 163615\n",
    "\n",
    "params = {\n",
    "    'net__module__weight_dim_2' : [31, 137],\n",
    "    'net__module__dropout_rate' : [0.4, 0.5, 0.6],\n",
    "    'net__batch_size' : [32, 64, 128],\n",
    "    'net__max_epochs' : [10, 20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    refit = False,\n",
    "    cv = StratifiedKFold(n_splits = 5, random_state = SEED, shuffle = True),\n",
    "    scoring = lambda net_gs, X_gs, y_gs : roc_auc_score(y_gs, net_gs.predict_proba(X_gs)),\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train.astype(np.float))\n",
    "\n",
    "print(gs.best_score_, gs.best_params_)\n",
    "\n",
    "end_training = (time.time() - start_training) / 60\n",
    "\n",
    "print(f'\\nDone! Time: {end_training:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Configuration:\n",
    "\n",
    "0.9666045248949673 {'net__batch_size': 128, 'net__max_epochs': 20, 'net__module__dropout_rate': 0.6, 'net__module__weight_dim_2': 137}\n",
    "\n",
    "Done! Time: 347.35 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4958\u001b[0m  8.4902\n",
      "      2        \u001b[36m0.0431\u001b[0m  8.9065\n",
      "      3        \u001b[36m0.0310\u001b[0m  8.7450\n",
      "      4        \u001b[36m0.0272\u001b[0m  9.3222\n",
      "      5        \u001b[36m0.0247\u001b[0m  8.8353\n",
      "      6        0.0252  9.1269\n",
      "      7        0.0257  9.1642\n",
      "      8        0.0261  8.8960\n",
      "      9        0.0266  8.6250\n",
      "     10        0.0280  8.6909\n",
      "     11        0.0283  8.6181\n",
      "     12        0.0280  8.8735\n",
      "     13        0.0282  8.5925\n",
      "     14        0.0283  8.5858\n",
      "     15        \u001b[36m0.0247\u001b[0m  8.5840\n",
      "     16        0.0274  8.6559\n",
      "     17        0.0285  8.5802\n",
      "     18        0.0253  8.6467\n",
      "     19        0.0296  8.6375\n",
      "     20        0.0287  8.7618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ros',\n",
       "                 RandomOverSampler(random_state=137, ratio=None,\n",
       "                                   return_indices=False,\n",
       "                                   sampling_strategy='auto')),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetBinaryClassifier'>[initialized](\n",
       "  module_=Model_1_network(\n",
       "    (dgcnn): DGCNN_network()\n",
       "    (dropout): Dropout(p=0.6, inplace=False)\n",
       "    (fc): Linear(in_features=42059, out_features=1, bias=True)\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "\n",
    "# weight_dim_2 = gs.best_params_['net__module__weight_dim_2']\n",
    "# dropout_rate = gs.best_params_['net__module__dropout_rate']\n",
    "# batch_size = gs.best_params_['net__batch_size']\n",
    "# max_epochs = gs.best_params_['net__max_epochs']\n",
    "\n",
    "input_dim_1 = 307\n",
    "input_dim_2 = 100\n",
    "weight_dim_2 = 137\n",
    "dropout_rate = 0.6\n",
    "batch_size = 128\n",
    "max_epochs = 20\n",
    "\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    Model_1_network,\n",
    "    module__input_dim_1 = input_dim_1,\n",
    "    module__input_dim_2 = input_dim_2,\n",
    "    module__weight_dim_2 = weight_dim_2,\n",
    "    module__dropout_rate = dropout_rate,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs,\n",
    "    train_split = None,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    iterator_train__shuffle = True,\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "ros = RandomOverSampler(random_state = SEED)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ros', ros),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train.astype(np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(y, pred):\n",
    "    print('Confusion matrix\\n[TN FP]\\n[FN TP]')\n",
    "    print(confusion_matrix(y >= 0.5, pred >= 0.5))\n",
    "    print(f'Precision: {precision_score(y >= 0.5, pred >= 0.5):.4f}')\n",
    "    print(f'Recall: {recall_score(y >= 0.5, pred >= 0.5):.4f}')    \n",
    "    print(f'F1-score: {f1_score(y >= 0.5, pred >= 0.5):.4f}')\n",
    "    print(f'ROC AUC: {roc_auc_score(y, pred):.4f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[TN FP]\n",
      "[FN TP]\n",
      "[[    0 12815]\n",
      " [    0   348]]\n",
      "Precision: 0.0264\n",
      "Recall: 1.0000\n",
      "F1-score: 0.0515\n",
      "ROC AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(y_test, np.ones(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[TN FP]\n",
      "[FN TP]\n",
      "[[12755    60]\n",
      " [  102   246]]\n",
      "Precision: 0.8039\n",
      "Recall: 0.7069\n",
      "F1-score: 0.7523\n",
      "ROC AUC: 0.9613\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(y_test, pipe.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
