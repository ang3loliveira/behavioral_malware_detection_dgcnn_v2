{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long-Short Term Memory (LSTM) Network\n",
    "\n",
    "This code is part our research on malware detection and classification using Deep Learning and Deep Graph Convolutional Neural Networks.\n",
    "\n",
    "For more information or citation, please refer to our research paper:\n",
    "\n",
    "\"Oliveira, Angelo; Sassi, Renato José (2019): Behavioral Malware Detection Using Deep Graph Convolutional Neural Networks. TechRxiv. Preprint.\" at https://doi.org/10.36227/techrxiv.10043099.v1\n",
    "\n",
    "For the dataset, please refer to our repository:\n",
    "\n",
    "https://ieee-dataport.org/open-access/malware-analysis-datasets-api-call-sequences\n",
    "\n",
    "#### Original (imbalanced) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "SEED = 137\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch.classifier import NeuralNetBinaryClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>...</th>\n",
       "      <th>t_91</th>\n",
       "      <th>t_92</th>\n",
       "      <th>t_93</th>\n",
       "      <th>t_94</th>\n",
       "      <th>t_95</th>\n",
       "      <th>t_96</th>\n",
       "      <th>t_97</th>\n",
       "      <th>t_98</th>\n",
       "      <th>t_99</th>\n",
       "      <th>malware</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>071e8c3f8922e186e57548cd4c703a5d</td>\n",
       "      <td>112</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>274</td>\n",
       "      <td>158</td>\n",
       "      <td>215</td>\n",
       "      <td>298</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "      <td>208</td>\n",
       "      <td>56</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33f8e6d08a6aae939f25a8e0d63dd523</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>71</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "      <td>171</td>\n",
       "      <td>215</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b68abd064e975e1c6d5f25e748663076</td>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>65</td>\n",
       "      <td>113</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>72049be7bd30ea61297ea624ae198067</td>\n",
       "      <td>82</td>\n",
       "      <td>208</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>117</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>302</td>\n",
       "      <td>208</td>\n",
       "      <td>302</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>302</td>\n",
       "      <td>228</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>c9b3700a77facf29172f32df6bc77f48</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>240</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>260</td>\n",
       "      <td>40</td>\n",
       "      <td>209</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>141</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               hash  t_0  t_1  t_2  t_3  t_4  t_5  t_6  t_7  \\\n",
       "0  071e8c3f8922e186e57548cd4c703a5d  112  274  158  215  274  158  215  298   \n",
       "1  33f8e6d08a6aae939f25a8e0d63dd523   82  208  187  208  172  117  172  117   \n",
       "2  b68abd064e975e1c6d5f25e748663076   16  110  240  117  240  117  240  117   \n",
       "3  72049be7bd30ea61297ea624ae198067   82  208  187  208  172  117  172  117   \n",
       "4  c9b3700a77facf29172f32df6bc77f48   82  240  117  240  117  240  117  240   \n",
       "\n",
       "   t_8  ...  t_91  t_92  t_93  t_94  t_95  t_96  t_97  t_98  t_99  malware  \n",
       "0   76  ...    71   297   135   171   215    35   208    56    71        1  \n",
       "1  172  ...    81   240   117    71   297   135   171   215    35        1  \n",
       "2  240  ...    65   112   123    65   112   123    65   113   112        1  \n",
       "3  172  ...   208   302   208   302   187   208   302   228   302        1  \n",
       "4  117  ...   209   260    40   209   260   141   260   141   260        1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dynamic_api_call_sequence_per_malware_100_0_306.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43876 entries, 0 to 43875\n",
      "Columns: 102 entries, hash to malware\n",
      "dtypes: int64(101), object(1)\n",
      "memory usage: 34.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43876, 100)\n",
      "(43876,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['hash', 'malware'], axis = 1).values.astype(int)\n",
    "y = df['malware'].values.astype(int)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "306\n"
     ]
    }
   ],
   "source": [
    "print(X.min())\n",
    "print(X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_imbalance(dataset):\n",
    "    count = sorted(Counter(dataset).items())\n",
    "    print(count)\n",
    "    print(count[1][1] / count[0][1])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1079), (1, 42797)]\n",
      "39.66357738646895\n"
     ]
    }
   ],
   "source": [
    "check_imbalance(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1 - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 42797), (1, 1079)]\n",
      "0.025212047573428042\n"
     ]
    }
   ],
   "source": [
    "check_imbalance(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 29982), (1, 731)]\n",
      "0.024381295443933027\n",
      "[(0, 12815), (1, 348)]\n",
      "0.027155676941084665\n"
     ]
    }
   ],
   "source": [
    "check_imbalance(y_train)\n",
    "check_imbalance(y_test)\n",
    "\n",
    "del df, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_network(\n",
      "  (lstm): LSTM(307, 10, batch_first=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Parameters: 12771\n"
     ]
    }
   ],
   "source": [
    "class LSTM_network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate):\n",
    "        \n",
    "        super(LSTM_network, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, batch_first = True)\n",
    "        self.dropout = nn.Dropout(p = self.dropout_rate)\n",
    "        self.fc = nn.Linear(self.hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = F.one_hot(X, num_classes = self.input_dim).float().cuda()\n",
    "        \n",
    "        # Hidden layer shape: (num_layers, batch_size, hidden_dim)\n",
    "        hidden_0 = (torch.zeros(1, X.size(0), self.hidden_dim).float().cuda(),\n",
    "                    torch.zeros(1, X.size(0), self.hidden_dim).float().cuda())\n",
    "        \n",
    "        # Input/Output shape: (batch_size, seq_len, input_dim)\n",
    "        _, self.hidden = self.lstm(X, hidden_0)\n",
    "                \n",
    "        H = self.hidden[0].squeeze()\n",
    "        H = self.dropout(H)\n",
    "        H = self.fc(H)\n",
    "                \n",
    "        return H.squeeze()\n",
    "\n",
    "model = LSTM_network(\n",
    "    input_dim = 307,\n",
    "    hidden_dim = 10,\n",
    "    dropout_rate = 0.4\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(f'\\nParameters: {np.sum([param.numel() for param in model.parameters()])}')\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3071\u001b[0m  5.2808\n",
      "      2        \u001b[36m0.2025\u001b[0m  5.6263\n",
      "      3        \u001b[36m0.1091\u001b[0m  5.4592\n",
      "      4        \u001b[36m0.0737\u001b[0m  5.8417\n",
      "      5        \u001b[36m0.0667\u001b[0m  5.2525\n",
      "      6        \u001b[36m0.0476\u001b[0m  5.3720\n",
      "      7        0.0535  5.5915\n",
      "      8        \u001b[36m0.0375\u001b[0m  5.6889\n",
      "      9        0.0383  5.1440\n",
      "     10        0.0496  5.8559\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  55.7s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   58.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3052\u001b[0m  5.1651\n",
      "      2        \u001b[36m0.1964\u001b[0m  5.2356\n",
      "      3        \u001b[36m0.1325\u001b[0m  5.2545\n",
      "      4        \u001b[36m0.0982\u001b[0m  5.3721\n",
      "      5        \u001b[36m0.0691\u001b[0m  5.3434\n",
      "      6        0.0788  5.3410\n",
      "      7        \u001b[36m0.0592\u001b[0m  5.2691\n",
      "      8        \u001b[36m0.0522\u001b[0m  5.5044\n",
      "      9        \u001b[36m0.0482\u001b[0m  5.2922\n",
      "     10        \u001b[36m0.0376\u001b[0m  5.2926\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  53.6s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2674\u001b[0m  5.3703\n",
      "      2        \u001b[36m0.1092\u001b[0m  5.4750\n",
      "      3        \u001b[36m0.0762\u001b[0m  5.3841\n",
      "      4        0.0873  5.3044\n",
      "      5        \u001b[36m0.0608\u001b[0m  5.3595\n",
      "      6        \u001b[36m0.0598\u001b[0m  5.4157\n",
      "      7        0.1032  5.9886\n",
      "      8        0.0777  6.7430\n",
      "      9        \u001b[36m0.0505\u001b[0m  5.7015\n",
      "     10        0.0561  5.4525\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  56.9s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2839\u001b[0m  5.4451\n",
      "      2        \u001b[36m0.1597\u001b[0m  5.3956\n",
      "      3        \u001b[36m0.0968\u001b[0m  5.6328\n",
      "      4        \u001b[36m0.0716\u001b[0m  5.4910\n",
      "      5        \u001b[36m0.0712\u001b[0m  5.7116\n",
      "      6        \u001b[36m0.0625\u001b[0m  5.2986\n",
      "      7        \u001b[36m0.0484\u001b[0m  5.3613\n",
      "      8        0.0527  5.2088\n",
      "      9        \u001b[36m0.0385\u001b[0m  5.3694\n",
      "     10        0.0533  5.1728\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  54.7s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2663\u001b[0m  5.2014\n",
      "      2        \u001b[36m0.1748\u001b[0m  5.1663\n",
      "      3        \u001b[36m0.1083\u001b[0m  5.1000\n",
      "      4        \u001b[36m0.0840\u001b[0m  5.1491\n",
      "      5        \u001b[36m0.0601\u001b[0m  5.1967\n",
      "      6        \u001b[36m0.0559\u001b[0m  5.2527\n",
      "      7        \u001b[36m0.0549\u001b[0m  5.1620\n",
      "      8        \u001b[36m0.0422\u001b[0m  5.1662\n",
      "      9        0.0522  5.1156\n",
      "     10        \u001b[36m0.0400\u001b[0m  5.1656\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  52.3s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2568\u001b[0m  5.7757\n",
      "      2        \u001b[36m0.1581\u001b[0m  5.6936\n",
      "      3        \u001b[36m0.0677\u001b[0m  5.6270\n",
      "      4        \u001b[36m0.0478\u001b[0m  5.7224\n",
      "      5        \u001b[36m0.0443\u001b[0m  5.7091\n",
      "      6        0.0526  5.7690\n",
      "      7        0.3769  5.7245\n",
      "      8        0.5705  5.7222\n",
      "      9        0.4989  5.7456\n",
      "     10        0.4349  5.7212\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  57.8s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2600\u001b[0m  5.8348\n",
      "      2        \u001b[36m0.1728\u001b[0m  5.7416\n",
      "      3        \u001b[36m0.0925\u001b[0m  5.6977\n",
      "      4        \u001b[36m0.0502\u001b[0m  5.7276\n",
      "      5        \u001b[36m0.0448\u001b[0m  5.6926\n",
      "      6        \u001b[36m0.0353\u001b[0m  5.7418\n",
      "      7        \u001b[36m0.0293\u001b[0m  5.8929\n",
      "      8        \u001b[36m0.0285\u001b[0m  5.7654\n",
      "      9        \u001b[36m0.0267\u001b[0m  5.7882\n",
      "     10        0.0302  5.6873\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  58.2s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2787\u001b[0m  5.7574\n",
      "      2        \u001b[36m0.1036\u001b[0m  5.6852\n",
      "      3        \u001b[36m0.0649\u001b[0m  5.7221\n",
      "      4        0.0768  5.6618\n",
      "      5        \u001b[36m0.0500\u001b[0m  5.7330\n",
      "      6        \u001b[36m0.0451\u001b[0m  5.6691\n",
      "      7        0.0736  5.7825\n",
      "      8        \u001b[36m0.0410\u001b[0m  5.7013\n",
      "      9        0.3283  5.7207\n",
      "     10        0.6365  5.7492\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  57.8s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2489\u001b[0m  5.7520\n",
      "      2        \u001b[36m0.1190\u001b[0m  5.6244\n",
      "      3        \u001b[36m0.0681\u001b[0m  5.6761\n",
      "      4        \u001b[36m0.0546\u001b[0m  5.7179\n",
      "      5        \u001b[36m0.0398\u001b[0m  5.7066\n",
      "      6        \u001b[36m0.0360\u001b[0m  5.7846\n",
      "      7        \u001b[36m0.0358\u001b[0m  5.7939\n",
      "      8        0.0524  5.8445\n",
      "      9        0.0366  6.5420\n",
      "     10        \u001b[36m0.0275\u001b[0m  6.1676\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  59.2s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2342\u001b[0m  6.2640\n",
      "      2        \u001b[36m0.1201\u001b[0m  7.4350\n",
      "      3        \u001b[36m0.0750\u001b[0m  6.1237\n",
      "      4        0.4297  5.6942\n",
      "      5        0.5575  5.7562\n",
      "      6        0.5343  5.6901\n",
      "      7        0.4267  5.7604\n",
      "      8        0.3304  5.7158\n",
      "      9        0.4711  5.8644\n",
      "     10        0.3687  6.0881\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2553\u001b[0m  8.7830\n",
      "      2        \u001b[36m0.1020\u001b[0m  8.7557\n",
      "      3        \u001b[36m0.0487\u001b[0m  8.7874\n",
      "      4        \u001b[36m0.0451\u001b[0m  8.7038\n",
      "      5        \u001b[36m0.0403\u001b[0m  8.7467\n",
      "      6        0.2599  8.7102\n",
      "      7        0.5087  8.6730\n",
      "      8        0.4317  8.7365\n",
      "      9        0.4412  8.6803\n",
      "     10        0.2154  8.7197\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3058\u001b[0m  8.7042\n",
      "      2        \u001b[36m0.0798\u001b[0m  8.7225\n",
      "      3        0.0945  8.7230\n",
      "      4        0.0906  8.7144\n",
      "      5        \u001b[36m0.0461\u001b[0m  8.7171\n",
      "      6        \u001b[36m0.0411\u001b[0m  8.7227\n",
      "      7        0.0506  8.7246\n",
      "      8        \u001b[36m0.0316\u001b[0m  8.6717\n",
      "      9        0.0332  8.7228\n",
      "     10        0.0440  8.7266\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2964\u001b[0m  8.7248\n",
      "      2        0.3363  8.7145\n",
      "      3        \u001b[36m0.1474\u001b[0m  8.7115\n",
      "      4        0.1520  8.7240\n",
      "      5        0.2472  8.6897\n",
      "      6        0.1571  8.7271\n",
      "      7        \u001b[36m0.0933\u001b[0m  8.6750\n",
      "      8        \u001b[36m0.0833\u001b[0m  8.7168\n",
      "      9        0.0900  8.6998\n",
      "     10        \u001b[36m0.0701\u001b[0m  8.7145\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3498\u001b[0m  8.7160\n",
      "      2        \u001b[36m0.0792\u001b[0m  8.7349\n",
      "      3        \u001b[36m0.0512\u001b[0m  8.6786\n",
      "      4        \u001b[36m0.0379\u001b[0m  8.7699\n",
      "      5        \u001b[36m0.0293\u001b[0m  8.8286\n",
      "      6        0.0301  8.7260\n",
      "      7        \u001b[36m0.0263\u001b[0m  8.7303\n",
      "      8        0.0366  8.7301\n",
      "      9        0.4866  8.6598\n",
      "     10        0.5096  8.6915\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2478\u001b[0m  8.7236\n",
      "      2        \u001b[36m0.0940\u001b[0m  8.7113\n",
      "      3        0.3346  8.7256\n",
      "      4        0.3201  8.7179\n",
      "      5        0.1515  8.7171\n",
      "      6        0.0961  8.7108\n",
      "      7        0.0982  8.7062\n",
      "      8        \u001b[36m0.0592\u001b[0m  8.7115\n",
      "      9        \u001b[36m0.0503\u001b[0m  8.6994\n",
      "     10        \u001b[36m0.0419\u001b[0m  8.7296\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3086\u001b[0m  7.0151\n",
      "      2        \u001b[36m0.0994\u001b[0m  6.9964\n",
      "      3        \u001b[36m0.0540\u001b[0m  7.0335\n",
      "      4        \u001b[36m0.0334\u001b[0m  7.0227\n",
      "      5        \u001b[36m0.0321\u001b[0m  7.0234\n",
      "      6        \u001b[36m0.0290\u001b[0m  7.0245\n",
      "      7        0.0649  7.0155\n",
      "      8        0.3781  7.0093\n",
      "      9        0.1701  7.0198\n",
      "     10        0.0664  7.0751\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2388\u001b[0m  7.0437\n",
      "      2        \u001b[36m0.0618\u001b[0m  7.0962\n",
      "      3        \u001b[36m0.0317\u001b[0m  7.0598\n",
      "      4        0.2995  7.0680\n",
      "      5        0.1343  7.0426\n",
      "      6        0.0958  7.0508\n",
      "      7        0.0810  7.0475\n",
      "      8        0.0419  7.0599\n",
      "      9        0.0360  7.0655\n",
      "     10        0.5875  7.0423\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3677\u001b[0m  7.0549\n",
      "      2        \u001b[36m0.1893\u001b[0m  7.0446\n",
      "      3        \u001b[36m0.1043\u001b[0m  7.0156\n",
      "      4        \u001b[36m0.0742\u001b[0m  7.0569\n",
      "      5        \u001b[36m0.0469\u001b[0m  7.0612\n",
      "      6        \u001b[36m0.0321\u001b[0m  7.0653\n",
      "      7        0.0369  7.0365\n",
      "      8        \u001b[36m0.0244\u001b[0m  7.0855\n",
      "      9        \u001b[36m0.0196\u001b[0m  7.1008\n",
      "     10        \u001b[36m0.0180\u001b[0m  7.0635\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3299\u001b[0m  7.0160\n",
      "      2        \u001b[36m0.1619\u001b[0m  7.0747\n",
      "      3        \u001b[36m0.0855\u001b[0m  7.0480\n",
      "      4        \u001b[36m0.0494\u001b[0m  7.0322\n",
      "      5        0.0636  7.0735\n",
      "      6        \u001b[36m0.0493\u001b[0m  7.0641\n",
      "      7        \u001b[36m0.0235\u001b[0m  7.0604\n",
      "      8        0.0250  7.0682\n",
      "      9        0.0418  7.0297\n",
      "     10        0.0366  7.0430\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2380\u001b[0m  7.0601\n",
      "      2        \u001b[36m0.0723\u001b[0m  7.0501\n",
      "      3        0.2357  7.0593\n",
      "      4        0.2043  7.0853\n",
      "      5        0.0923  7.0631\n",
      "      6        \u001b[36m0.0522\u001b[0m  7.0953\n",
      "      7        0.0672  7.0800\n",
      "      8        \u001b[36m0.0441\u001b[0m  7.0450\n",
      "      9        0.0498  7.0611\n",
      "     10        \u001b[36m0.0269\u001b[0m  7.0188\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2799\u001b[0m  5.0956\n",
      "      2        \u001b[36m0.1660\u001b[0m  5.1729\n",
      "      3        \u001b[36m0.1606\u001b[0m  5.1080\n",
      "      4        \u001b[36m0.1223\u001b[0m  5.2440\n",
      "      5        \u001b[36m0.0982\u001b[0m  5.1044\n",
      "      6        0.1131  5.1852\n",
      "      7        0.1220  5.1459\n",
      "      8        \u001b[36m0.0829\u001b[0m  5.0938\n",
      "      9        \u001b[36m0.0782\u001b[0m  5.1344\n",
      "     10        \u001b[36m0.0662\u001b[0m  5.0911\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  51.9s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3212\u001b[0m  5.0558\n",
      "      2        \u001b[36m0.1768\u001b[0m  5.1484\n",
      "      3        \u001b[36m0.1425\u001b[0m  5.0326\n",
      "      4        \u001b[36m0.0814\u001b[0m  5.0922\n",
      "      5        0.0816  5.1893\n",
      "      6        0.1050  5.1449\n",
      "      7        \u001b[36m0.0751\u001b[0m  5.2194\n",
      "      8        \u001b[36m0.0578\u001b[0m  5.1525\n",
      "      9        0.0601  5.1435\n",
      "     10        0.0715  5.0196\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  51.8s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3306\u001b[0m  5.1169\n",
      "      2        \u001b[36m0.1455\u001b[0m  5.1388\n",
      "      3        \u001b[36m0.1136\u001b[0m  5.0930\n",
      "      4        \u001b[36m0.0814\u001b[0m  5.1581\n",
      "      5        \u001b[36m0.0716\u001b[0m  5.1348\n",
      "      6        \u001b[36m0.0698\u001b[0m  5.1045\n",
      "      7        0.0779  5.0492\n",
      "      8        0.0733  5.1479\n",
      "      9        \u001b[36m0.0664\u001b[0m  5.1738\n",
      "     10        0.1846  5.0336\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  51.7s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3228\u001b[0m  5.0506\n",
      "      2        \u001b[36m0.2090\u001b[0m  5.0767\n",
      "      3        \u001b[36m0.1439\u001b[0m  5.1284\n",
      "      4        \u001b[36m0.1124\u001b[0m  5.1093\n",
      "      5        \u001b[36m0.0972\u001b[0m  5.1423\n",
      "      6        \u001b[36m0.0859\u001b[0m  5.1052\n",
      "      7        0.1130  5.0760\n",
      "      8        0.1126  5.1034\n",
      "      9        \u001b[36m0.0751\u001b[0m  5.1560\n",
      "     10        \u001b[36m0.0658\u001b[0m  5.0711\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  51.6s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2887\u001b[0m  5.1257\n",
      "      2        \u001b[36m0.1402\u001b[0m  5.0955\n",
      "      3        \u001b[36m0.0868\u001b[0m  5.0457\n",
      "      4        \u001b[36m0.0622\u001b[0m  5.0174\n",
      "      5        \u001b[36m0.0527\u001b[0m  5.0995\n",
      "      6        0.0635  5.0676\n",
      "      7        0.0609  5.0821\n",
      "      8        \u001b[36m0.0387\u001b[0m  5.0136\n",
      "      9        0.0415  5.0024\n",
      "     10        0.0409  5.1348\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  51.2s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2463\u001b[0m  5.7064\n",
      "      2        \u001b[36m0.1160\u001b[0m  5.7553\n",
      "      3        \u001b[36m0.0933\u001b[0m  5.6137\n",
      "      4        \u001b[36m0.0831\u001b[0m  5.5875\n",
      "      5        \u001b[36m0.0492\u001b[0m  5.6471\n",
      "      6        \u001b[36m0.0359\u001b[0m  5.6268\n",
      "      7        0.1616  5.6647\n",
      "      8        0.4483  5.6662\n",
      "      9        0.3268  5.6719\n",
      "     10        0.2360  5.6880\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  57.2s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2450\u001b[0m  5.6746\n",
      "      2        \u001b[36m0.0607\u001b[0m  5.7690\n",
      "      3        0.0740  5.6705\n",
      "      4        \u001b[36m0.0302\u001b[0m  5.6947\n",
      "      5        0.1204  5.6854\n",
      "      6        0.2732  5.6820\n",
      "      7        0.3649  5.6211\n",
      "      8        0.2067  5.6933\n",
      "      9        0.4636  5.6854\n",
      "     10        0.3031  5.6715\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  57.4s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2230\u001b[0m  5.7025\n",
      "      2        \u001b[36m0.0506\u001b[0m  5.6215\n",
      "      3        \u001b[36m0.0443\u001b[0m  5.6222\n",
      "      4        \u001b[36m0.0297\u001b[0m  5.6841\n",
      "      5        \u001b[36m0.0212\u001b[0m  5.6683\n",
      "      6        0.0274  5.7180\n",
      "      7        \u001b[36m0.0211\u001b[0m  5.6339\n",
      "      8        0.0270  5.7330\n",
      "      9        \u001b[36m0.0202\u001b[0m  5.6701\n",
      "     10        0.0238  5.6868\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  57.3s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2579\u001b[0m  5.6804\n",
      "      2        \u001b[36m0.1214\u001b[0m  5.7200\n",
      "      3        \u001b[36m0.0722\u001b[0m  5.6954\n",
      "      4        \u001b[36m0.0521\u001b[0m  5.6524\n",
      "      5        0.0628  5.6378\n",
      "      6        \u001b[36m0.0487\u001b[0m  5.5964\n",
      "      7        \u001b[36m0.0334\u001b[0m  5.6225\n",
      "      8        0.0498  5.6556\n",
      "      9        0.2852  5.5942\n",
      "     10        0.4640  5.5948\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  57.0s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2741\u001b[0m  5.6358\n",
      "      2        \u001b[36m0.1478\u001b[0m  5.7242\n",
      "      3        \u001b[36m0.0875\u001b[0m  5.6897\n",
      "      4        \u001b[36m0.0615\u001b[0m  5.7210\n",
      "      5        \u001b[36m0.0438\u001b[0m  5.6015\n",
      "      6        \u001b[36m0.0367\u001b[0m  5.6981\n",
      "      7        \u001b[36m0.0315\u001b[0m  5.6655\n",
      "      8        0.0375  5.7051\n",
      "      9        \u001b[36m0.0271\u001b[0m  5.6944\n",
      "     10        0.0345  5.7297\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  57.5s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2405\u001b[0m  8.7664\n",
      "      2        0.2624  8.7618\n",
      "      3        \u001b[36m0.1900\u001b[0m  8.7689\n",
      "      4        \u001b[36m0.1287\u001b[0m  8.7772\n",
      "      5        \u001b[36m0.1062\u001b[0m  8.7857\n",
      "      6        \u001b[36m0.0941\u001b[0m  8.7832\n",
      "      7        \u001b[36m0.0863\u001b[0m  8.7810\n",
      "      8        \u001b[36m0.0838\u001b[0m  8.7170\n",
      "      9        \u001b[36m0.0616\u001b[0m  8.7757\n",
      "     10        0.0664  8.7875\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2321\u001b[0m  8.7764\n",
      "      2        \u001b[36m0.1417\u001b[0m  8.7701\n",
      "      3        \u001b[36m0.0765\u001b[0m  8.7730\n",
      "      4        \u001b[36m0.0509\u001b[0m  8.7748\n",
      "      5        \u001b[36m0.0425\u001b[0m  8.7725\n",
      "      6        \u001b[36m0.0355\u001b[0m  8.7879\n",
      "      7        \u001b[36m0.0275\u001b[0m  8.8003\n",
      "      8        0.0280  8.7960\n",
      "      9        0.2022  8.7847\n",
      "     10        0.3233  8.7660\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3447\u001b[0m  8.7547\n",
      "      2        \u001b[36m0.2134\u001b[0m  8.7813\n",
      "      3        \u001b[36m0.0750\u001b[0m  8.7830\n",
      "      4        \u001b[36m0.0530\u001b[0m  8.7787\n",
      "      5        \u001b[36m0.0420\u001b[0m  8.7758\n",
      "      6        0.1414  8.7290\n",
      "      7        0.5401  8.7162\n",
      "      8        0.2822  8.7320\n",
      "      9        0.1908  8.7514\n",
      "     10        0.1396  8.7961\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2481\u001b[0m  8.7568\n",
      "      2        \u001b[36m0.0911\u001b[0m  8.7513\n",
      "      3        0.2589  8.7669\n",
      "      4        0.2226  8.7541\n",
      "      5        0.1514  8.7928\n",
      "      6        0.1670  8.7659\n",
      "      7        0.4849  8.7462\n",
      "      8        0.6091  8.7767\n",
      "      9        0.5662  8.7642\n",
      "     10        0.5176  8.7809\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2249\u001b[0m  8.7878\n",
      "      2        \u001b[36m0.0712\u001b[0m  8.7726\n",
      "      3        \u001b[36m0.0521\u001b[0m  8.7795\n",
      "      4        \u001b[36m0.0337\u001b[0m  8.7892\n",
      "      5        \u001b[36m0.0324\u001b[0m  8.7686\n",
      "      6        \u001b[36m0.0250\u001b[0m  8.7877\n",
      "      7        0.1727  8.7831\n",
      "      8        0.5027  8.7788\n",
      "      9        0.5575  8.7680\n",
      "     10        0.5020  8.7760\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3084\u001b[0m  7.0691\n",
      "      2        \u001b[36m0.0947\u001b[0m  7.0462\n",
      "      3        \u001b[36m0.0503\u001b[0m  7.0723\n",
      "      4        \u001b[36m0.0478\u001b[0m  7.0919\n",
      "      5        0.0630  7.0449\n",
      "      6        \u001b[36m0.0475\u001b[0m  7.0949\n",
      "      7        0.0802  7.0619\n",
      "      8        \u001b[36m0.0313\u001b[0m  7.0412\n",
      "      9        0.0512  7.0987\n",
      "     10        0.0392  7.0717\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2558\u001b[0m  7.0495\n",
      "      2        \u001b[36m0.0746\u001b[0m  7.0503\n",
      "      3        \u001b[36m0.0500\u001b[0m  7.0647\n",
      "      4        \u001b[36m0.0283\u001b[0m  7.0607\n",
      "      5        0.1788  7.0612\n",
      "      6        0.1807  7.0663\n",
      "      7        0.1076  7.0696\n",
      "      8        0.2272  7.0793\n",
      "      9        0.1587  7.0682\n",
      "     10        0.1773  7.0457\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2678\u001b[0m  7.0718\n",
      "      2        \u001b[36m0.2555\u001b[0m  7.0723\n",
      "      3        \u001b[36m0.2014\u001b[0m  7.0528\n",
      "      4        \u001b[36m0.0950\u001b[0m  7.0910\n",
      "      5        \u001b[36m0.0577\u001b[0m  7.0685\n",
      "      6        \u001b[36m0.0520\u001b[0m  7.0705\n",
      "      7        \u001b[36m0.0515\u001b[0m  7.0704\n",
      "      8        \u001b[36m0.0317\u001b[0m  7.0675\n",
      "      9        0.0323  7.0882\n",
      "     10        \u001b[36m0.0244\u001b[0m  7.0457\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3110\u001b[0m  7.0578\n",
      "      2        0.6756  7.0403\n",
      "      3        0.6692  7.0423\n",
      "      4        0.6189  7.0700\n",
      "      5        0.5640  7.0655\n",
      "      6        0.5485  7.0825\n",
      "      7        0.4043  7.0448\n",
      "      8        \u001b[36m0.1662\u001b[0m  7.0657\n",
      "      9        \u001b[36m0.1158\u001b[0m  7.0818\n",
      "     10        \u001b[36m0.0928\u001b[0m  7.0689\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3541\u001b[0m  7.0665\n",
      "      2        \u001b[36m0.1779\u001b[0m  7.0615\n",
      "      3        0.2282  7.0789\n",
      "      4        0.2252  7.0175\n",
      "      5        \u001b[36m0.1187\u001b[0m  7.0381\n",
      "      6        \u001b[36m0.0828\u001b[0m  7.0863\n",
      "      7        \u001b[36m0.0549\u001b[0m  7.0486\n",
      "      8        0.0559  7.0554\n",
      "      9        \u001b[36m0.0386\u001b[0m  7.0454\n",
      "     10        0.0395  7.0676\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3489\u001b[0m  5.1857\n",
      "      2        \u001b[36m0.2937\u001b[0m  5.1471\n",
      "      3        \u001b[36m0.1896\u001b[0m  5.1408\n",
      "      4        \u001b[36m0.1295\u001b[0m  5.1101\n",
      "      5        \u001b[36m0.1051\u001b[0m  5.1695\n",
      "      6        \u001b[36m0.1003\u001b[0m  5.1507\n",
      "      7        \u001b[36m0.0978\u001b[0m  5.0706\n",
      "      8        \u001b[36m0.0790\u001b[0m  5.0068\n",
      "      9        0.2021  5.1293\n",
      "     10        0.1175  5.0619\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  51.7s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3073\u001b[0m  5.0641\n",
      "      2        \u001b[36m0.1566\u001b[0m  5.1333\n",
      "      3        \u001b[36m0.1030\u001b[0m  5.1567\n",
      "      4        0.1082  5.1260\n",
      "      5        \u001b[36m0.0726\u001b[0m  5.1284\n",
      "      6        \u001b[36m0.0710\u001b[0m  5.0052\n",
      "      7        \u001b[36m0.0596\u001b[0m  5.0088\n",
      "      8        \u001b[36m0.0541\u001b[0m  5.0873\n",
      "      9        0.2460  5.1431\n",
      "     10        0.3443  5.1180\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  51.5s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3089\u001b[0m  5.0593\n",
      "      2        \u001b[36m0.2070\u001b[0m  5.1090\n",
      "      3        \u001b[36m0.1516\u001b[0m  5.1517\n",
      "      4        \u001b[36m0.1354\u001b[0m  5.0261\n",
      "      5        \u001b[36m0.1083\u001b[0m  5.1183\n",
      "      6        0.1151  5.1043\n",
      "      7        \u001b[36m0.1006\u001b[0m  5.0690\n",
      "      8        \u001b[36m0.0779\u001b[0m  5.1006\n",
      "      9        \u001b[36m0.0703\u001b[0m  5.2193\n",
      "     10        0.0850  5.1567\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  51.7s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3328\u001b[0m  5.1741\n",
      "      2        \u001b[36m0.1915\u001b[0m  5.1477\n",
      "      3        0.2024  5.0891\n",
      "      4        \u001b[36m0.1283\u001b[0m  5.0977\n",
      "      5        0.1468  5.0547\n",
      "      6        \u001b[36m0.0981\u001b[0m  5.1772\n",
      "      7        0.1044  5.0564\n",
      "      8        \u001b[36m0.0907\u001b[0m  5.0451\n",
      "      9        \u001b[36m0.0762\u001b[0m  5.1075\n",
      "     10        \u001b[36m0.0702\u001b[0m  5.0548\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  51.6s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2930\u001b[0m  5.1162\n",
      "      2        \u001b[36m0.1678\u001b[0m  5.0409\n",
      "      3        \u001b[36m0.1337\u001b[0m  5.1474\n",
      "      4        \u001b[36m0.1085\u001b[0m  5.1058\n",
      "      5        \u001b[36m0.0900\u001b[0m  5.0595\n",
      "      6        \u001b[36m0.0683\u001b[0m  5.1479\n",
      "      7        0.0840  5.1229\n",
      "      8        0.0827  5.2000\n",
      "      9        \u001b[36m0.0552\u001b[0m  5.1330\n",
      "     10        0.1168  5.1041\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  51.7s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2441\u001b[0m  5.7487\n",
      "      2        \u001b[36m0.0886\u001b[0m  5.7442\n",
      "      3        0.1446  5.6809\n",
      "      4        \u001b[36m0.0567\u001b[0m  5.8217\n",
      "      5        \u001b[36m0.0450\u001b[0m  5.7801\n",
      "      6        0.0966  5.8153\n",
      "      7        0.3487  5.6417\n",
      "      8        0.3004  5.7947\n",
      "      9        0.2293  5.6317\n",
      "     10        0.1838  5.6959\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  57.9s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2686\u001b[0m  5.7044\n",
      "      2        \u001b[36m0.0780\u001b[0m  5.7933\n",
      "      3        \u001b[36m0.0546\u001b[0m  5.8223\n",
      "      4        \u001b[36m0.0460\u001b[0m  5.7674\n",
      "      5        \u001b[36m0.0337\u001b[0m  5.8029\n",
      "      6        0.6170  5.7421\n",
      "      7        0.5607  5.7971\n",
      "      8        0.5071  5.6604\n",
      "      9        0.5019  5.8442\n",
      "     10        0.4701  5.7788\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  58.3s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3223\u001b[0m  5.8105\n",
      "      2        \u001b[36m0.1831\u001b[0m  5.7778\n",
      "      3        \u001b[36m0.1094\u001b[0m  5.5938\n",
      "      4        \u001b[36m0.0927\u001b[0m  5.7229\n",
      "      5        \u001b[36m0.0484\u001b[0m  5.8357\n",
      "      6        0.0807  5.7433\n",
      "      7        0.2899  5.7011\n",
      "      8        0.5012  5.7366\n",
      "      9        0.3608  5.7934\n",
      "     10        0.4699  5.6815\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  58.0s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2971\u001b[0m  5.7418\n",
      "      2        \u001b[36m0.1443\u001b[0m  5.7716\n",
      "      3        \u001b[36m0.1422\u001b[0m  5.6661\n",
      "      4        0.1773  5.6880\n",
      "      5        \u001b[36m0.1342\u001b[0m  5.6077\n",
      "      6        0.2154  5.7783\n",
      "      7        0.1757  5.6792\n",
      "      8        \u001b[36m0.1232\u001b[0m  5.6889\n",
      "      9        0.1835  5.6322\n",
      "     10        \u001b[36m0.1106\u001b[0m  5.6868\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  57.5s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2993\u001b[0m  5.7273\n",
      "      2        \u001b[36m0.1310\u001b[0m  5.6720\n",
      "      3        \u001b[36m0.0607\u001b[0m  5.6637\n",
      "      4        0.0607  5.6641\n",
      "      5        \u001b[36m0.0511\u001b[0m  5.7206\n",
      "      6        \u001b[36m0.0493\u001b[0m  5.7093\n",
      "      7        0.0524  5.6703\n",
      "      8        0.0731  5.7496\n",
      "      9        0.5464  5.7523\n",
      "     10        0.6773  5.6995\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  57.6s\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3493\u001b[0m  8.7891\n",
      "      2        \u001b[36m0.1720\u001b[0m  8.7574\n",
      "      3        \u001b[36m0.1426\u001b[0m  8.7863\n",
      "      4        \u001b[36m0.0514\u001b[0m  8.7376\n",
      "      5        \u001b[36m0.0437\u001b[0m  8.7671\n",
      "      6        0.0443  8.8042\n",
      "      7        0.2296  8.7664\n",
      "      8        0.2339  8.7727\n",
      "      9        0.1243  8.7694\n",
      "     10        0.1013  8.7452\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2680\u001b[0m  8.7788\n",
      "      2        \u001b[36m0.1137\u001b[0m  8.7211\n",
      "      3        \u001b[36m0.0606\u001b[0m  8.7450\n",
      "      4        0.4330  8.7775\n",
      "      5        0.3852  8.7755\n",
      "      6        0.5899  8.7818\n",
      "      7        0.3979  8.7860\n",
      "      8        0.2058  8.7798\n",
      "      9        0.1580  8.7909\n",
      "     10        0.1682  8.7905\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2616\u001b[0m  8.7479\n",
      "      2        \u001b[36m0.1550\u001b[0m  8.7458\n",
      "      3        \u001b[36m0.0897\u001b[0m  8.7731\n",
      "      4        \u001b[36m0.0482\u001b[0m  8.7359\n",
      "      5        \u001b[36m0.0421\u001b[0m  8.7499\n",
      "      6        0.0661  8.7885\n",
      "      7        0.0538  8.7956\n",
      "      8        0.0432  8.7619\n",
      "      9        0.1058  8.7758\n",
      "     10        0.3393  8.7679\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3450\u001b[0m  8.7775\n",
      "      2        0.4448  8.7657\n",
      "      3        \u001b[36m0.2633\u001b[0m  8.7692\n",
      "      4        \u001b[36m0.1616\u001b[0m  8.7748\n",
      "      5        \u001b[36m0.1535\u001b[0m  8.7811\n",
      "      6        \u001b[36m0.0909\u001b[0m  8.7621\n",
      "      7        \u001b[36m0.0623\u001b[0m  8.7844\n",
      "      8        0.0779  8.7733\n",
      "      9        \u001b[36m0.0620\u001b[0m  8.7811\n",
      "     10        \u001b[36m0.0580\u001b[0m  8.7759\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2298\u001b[0m  8.7783\n",
      "      2        \u001b[36m0.0644\u001b[0m  8.7637\n",
      "      3        0.2457  8.7799\n",
      "      4        0.0820  8.7847\n",
      "      5        \u001b[36m0.0532\u001b[0m  8.7949\n",
      "      6        \u001b[36m0.0486\u001b[0m  8.7802\n",
      "      7        \u001b[36m0.0429\u001b[0m  8.7748\n",
      "      8        \u001b[36m0.0295\u001b[0m  8.7694\n",
      "      9        0.3612  8.7757\n",
      "     10        0.6524  8.7508\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.5min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2360\u001b[0m  7.0785\n",
      "      2        \u001b[36m0.0714\u001b[0m  7.0555\n",
      "      3        \u001b[36m0.0630\u001b[0m  7.0851\n",
      "      4        \u001b[36m0.0463\u001b[0m  7.0901\n",
      "      5        0.0788  7.0906\n",
      "      6        0.2502  7.0808\n",
      "      7        0.0913  7.0301\n",
      "      8        0.2121  7.0838\n",
      "      9        0.0663  7.0510\n",
      "     10        0.0892  7.0796\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2614\u001b[0m  7.0421\n",
      "      2        \u001b[36m0.1563\u001b[0m  7.0565\n",
      "      3        \u001b[36m0.0551\u001b[0m  7.0765\n",
      "      4        0.5081  7.0187\n",
      "      5        0.6198  7.0896\n",
      "      6        0.5590  7.0673\n",
      "      7        0.5307  7.0286\n",
      "      8        0.4885  7.0636\n",
      "      9        0.4284  7.0607\n",
      "     10        0.4087  7.0770\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3583\u001b[0m  7.0752\n",
      "      2        \u001b[36m0.0856\u001b[0m  7.0861\n",
      "      3        \u001b[36m0.0522\u001b[0m  7.0813\n",
      "      4        0.0620  7.0639\n",
      "      5        0.5592  7.0705\n",
      "      6        0.6535  7.0447\n",
      "      7        0.6251  7.0421\n",
      "      8        0.5811  7.0728\n",
      "      9        0.5491  7.0784\n",
      "     10        0.4947  7.0792\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2547\u001b[0m  7.0795\n",
      "      2        \u001b[36m0.0558\u001b[0m  7.0660\n",
      "      3        0.0569  7.0480\n",
      "      4        \u001b[36m0.0282\u001b[0m  7.0576\n",
      "      5        0.0332  7.0494\n",
      "      6        0.1848  7.0186\n",
      "      7        0.4153  7.0797\n",
      "      8        0.6203  7.0513\n",
      "      9        0.5133  7.0779\n",
      "     10        0.4160  7.0475\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3603\u001b[0m  7.0740\n",
      "      2        \u001b[36m0.2107\u001b[0m  7.0381\n",
      "      3        \u001b[36m0.1305\u001b[0m  7.0592\n",
      "      4        \u001b[36m0.1024\u001b[0m  7.0802\n",
      "      5        0.1513  7.0602\n",
      "      6        0.1316  7.0900\n",
      "      7        \u001b[36m0.0985\u001b[0m  7.0490\n",
      "      8        \u001b[36m0.0838\u001b[0m  7.0702\n",
      "      9        0.1770  7.0537\n",
      "     10        0.1028  7.0487\n",
      "[CV]  net__batch_size=32, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.2min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2946\u001b[0m  5.0606\n",
      "      2        \u001b[36m0.1370\u001b[0m  5.0861\n",
      "      3        \u001b[36m0.0927\u001b[0m  5.1115\n",
      "      4        \u001b[36m0.0737\u001b[0m  5.1662\n",
      "      5        \u001b[36m0.0678\u001b[0m  5.1519\n",
      "      6        \u001b[36m0.0480\u001b[0m  5.1287\n",
      "      7        0.0853  5.1076\n",
      "      8        0.0571  5.1061\n",
      "      9        \u001b[36m0.0438\u001b[0m  5.1575\n",
      "     10        \u001b[36m0.0399\u001b[0m  5.0991\n",
      "     11        \u001b[36m0.0329\u001b[0m  5.0556\n",
      "     12        0.0332  5.1202\n",
      "     13        0.0383  5.2358\n",
      "     14        \u001b[36m0.0329\u001b[0m  5.1590\n",
      "     15        0.0333  5.2230\n",
      "     16        0.0403  5.1109\n",
      "     17        0.0381  5.0508\n",
      "     18        0.0334  5.1813\n",
      "     19        0.1838  5.1214\n",
      "     20        0.0622  5.0431\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3330\u001b[0m  5.1309\n",
      "      2        \u001b[36m0.1900\u001b[0m  5.1493\n",
      "      3        \u001b[36m0.1317\u001b[0m  5.1179\n",
      "      4        0.1491  5.0784\n",
      "      5        \u001b[36m0.0977\u001b[0m  5.0162\n",
      "      6        \u001b[36m0.0859\u001b[0m  5.0400\n",
      "      7        \u001b[36m0.0738\u001b[0m  5.1399\n",
      "      8        \u001b[36m0.0605\u001b[0m  5.0731\n",
      "      9        0.2719  5.0837\n",
      "     10        0.1204  5.1044\n",
      "     11        0.0992  5.1658\n",
      "     12        0.1135  5.1018\n",
      "     13        0.0702  5.1562\n",
      "     14        0.0636  5.1041\n",
      "     15        0.1582  5.0055\n",
      "     16        0.1923  5.1396\n",
      "     17        0.2326  5.1389\n",
      "     18        0.1586  5.1359\n",
      "     19        0.1480  5.1197\n",
      "     20        0.2899  5.1555\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2538\u001b[0m  5.2250\n",
      "      2        \u001b[36m0.1382\u001b[0m  5.2104\n",
      "      3        \u001b[36m0.0859\u001b[0m  5.1317\n",
      "      4        \u001b[36m0.0842\u001b[0m  5.1407\n",
      "      5        \u001b[36m0.0564\u001b[0m  5.1549\n",
      "      6        \u001b[36m0.0512\u001b[0m  5.0816\n",
      "      7        \u001b[36m0.0389\u001b[0m  5.0786\n",
      "      8        0.0490  5.0933\n",
      "      9        0.1048  5.1287\n",
      "     10        0.0603  5.1517\n",
      "     11        0.0425  5.1323\n",
      "     12        \u001b[36m0.0363\u001b[0m  5.1471\n",
      "     13        0.0399  5.1281\n",
      "     14        \u001b[36m0.0337\u001b[0m  5.1777\n",
      "     15        \u001b[36m0.0304\u001b[0m  5.0684\n",
      "     16        \u001b[36m0.0279\u001b[0m  5.0481\n",
      "     17        0.1358  5.1400\n",
      "     18        0.1162  5.1232\n",
      "     19        0.0553  5.0663\n",
      "     20        0.0473  5.1209\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2681\u001b[0m  5.1407\n",
      "      2        \u001b[36m0.1127\u001b[0m  5.1176\n",
      "      3        \u001b[36m0.1042\u001b[0m  5.1226\n",
      "      4        \u001b[36m0.0568\u001b[0m  5.1629\n",
      "      5        \u001b[36m0.0539\u001b[0m  5.1104\n",
      "      6        \u001b[36m0.0447\u001b[0m  5.0986\n",
      "      7        \u001b[36m0.0402\u001b[0m  5.1505\n",
      "      8        0.0407  5.0556\n",
      "      9        0.2952  5.0995\n",
      "     10        0.1140  5.1158\n",
      "     11        0.0820  5.1101\n",
      "     12        0.1940  5.0408\n",
      "     13        0.3204  5.1611\n",
      "     14        0.2991  5.0172\n",
      "     15        0.2286  5.1356\n",
      "     16        0.1812  5.1119\n",
      "     17        0.1628  5.1753\n",
      "     18        0.1709  5.0902\n",
      "     19        0.2884  5.1390\n",
      "     20        0.3059  5.1579\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2789\u001b[0m  5.1580\n",
      "      2        \u001b[36m0.1410\u001b[0m  5.0440\n",
      "      3        \u001b[36m0.0948\u001b[0m  5.0781\n",
      "      4        \u001b[36m0.0682\u001b[0m  5.0754\n",
      "      5        0.0950  5.1366\n",
      "      6        \u001b[36m0.0606\u001b[0m  5.1122\n",
      "      7        0.1172  5.1203\n",
      "      8        0.0635  5.0412\n",
      "      9        \u001b[36m0.0464\u001b[0m  5.0988\n",
      "     10        0.0468  5.1350\n",
      "     11        \u001b[36m0.0398\u001b[0m  5.0450\n",
      "     12        \u001b[36m0.0368\u001b[0m  5.1495\n",
      "     13        \u001b[36m0.0337\u001b[0m  5.1411\n",
      "     14        0.0342  5.1265\n",
      "     15        \u001b[36m0.0276\u001b[0m  5.1046\n",
      "     16        0.0283  5.1381\n",
      "     17        \u001b[36m0.0236\u001b[0m  5.1529\n",
      "     18        0.0300  5.1014\n",
      "     19        0.0592  5.1515\n",
      "     20        0.0665  5.0762\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2592\u001b[0m  5.6731\n",
      "      2        \u001b[36m0.1387\u001b[0m  5.6849\n",
      "      3        \u001b[36m0.0772\u001b[0m  5.7089\n",
      "      4        \u001b[36m0.0696\u001b[0m  5.6788\n",
      "      5        \u001b[36m0.0391\u001b[0m  5.6337\n",
      "      6        0.0488  5.6587\n",
      "      7        \u001b[36m0.0350\u001b[0m  5.7568\n",
      "      8        0.0455  5.7149\n",
      "      9        0.0904  5.6839\n",
      "     10        0.3056  5.7457\n",
      "     11        0.6512  5.7725\n",
      "     12        0.6294  5.6573\n",
      "     13        0.6254  5.7021\n",
      "     14        0.5892  5.8250\n",
      "     15        0.6006  5.7829\n",
      "     16        0.6709  5.6872\n",
      "     17        0.6589  5.5834\n",
      "     18        0.6406  5.7415\n",
      "     19        0.6010  5.7775\n",
      "     20        0.5541  5.6233\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2851\u001b[0m  5.7343\n",
      "      2        \u001b[36m0.1072\u001b[0m  5.7068\n",
      "      3        0.5799  5.7222\n",
      "      4        0.4424  5.6158\n",
      "      5        0.4414  5.6551\n",
      "      6        0.4679  5.7025\n",
      "      7        0.3482  5.6265\n",
      "      8        0.1839  5.7594\n",
      "      9        0.1292  5.6716\n",
      "     10        0.2119  5.6934\n",
      "     11        0.1670  5.7276\n",
      "     12        \u001b[36m0.1035\u001b[0m  5.5988\n",
      "     13        0.1138  5.6382\n",
      "     14        \u001b[36m0.0899\u001b[0m  5.7040\n",
      "     15        \u001b[36m0.0522\u001b[0m  5.6318\n",
      "     16        0.3440  5.7154\n",
      "     17        0.3197  5.7201\n",
      "     18        0.2549  5.6293\n",
      "     19        0.2209  5.6114\n",
      "     20        0.1803  5.7030\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2503\u001b[0m  5.6660\n",
      "      2        \u001b[36m0.1119\u001b[0m  5.7894\n",
      "      3        \u001b[36m0.0807\u001b[0m  5.7068\n",
      "      4        \u001b[36m0.0424\u001b[0m  5.6765\n",
      "      5        0.3719  5.6651\n",
      "      6        0.3971  5.6629\n",
      "      7        0.2011  5.7020\n",
      "      8        0.1443  5.6295\n",
      "      9        0.1335  5.6441\n",
      "     10        0.2639  5.7063\n",
      "     11        0.1741  5.6394\n",
      "     12        0.1039  5.7304\n",
      "     13        0.1053  5.6952\n",
      "     14        0.2031  5.6788\n",
      "     15        0.1463  5.6255\n",
      "     16        0.0656  5.6198\n",
      "     17        0.0586  5.6057\n",
      "     18        0.0533  5.6843\n",
      "     19        \u001b[36m0.0379\u001b[0m  5.6614\n",
      "     20        \u001b[36m0.0307\u001b[0m  5.6030\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2371\u001b[0m  5.6626\n",
      "      2        \u001b[36m0.0968\u001b[0m  5.6592\n",
      "      3        \u001b[36m0.0528\u001b[0m  5.6748\n",
      "      4        \u001b[36m0.0414\u001b[0m  5.6511\n",
      "      5        0.0471  5.6938\n",
      "      6        \u001b[36m0.0375\u001b[0m  5.7136\n",
      "      7        0.2490  5.6697\n",
      "      8        0.0775  5.6826\n",
      "      9        0.2082  5.6206\n",
      "     10        0.2635  5.5898\n",
      "     11        0.2803  5.7811\n",
      "     12        0.2403  5.6176\n",
      "     13        0.1318  5.7374\n",
      "     14        0.2630  5.8406\n",
      "     15        0.1210  5.8235\n",
      "     16        0.0753  5.7058\n",
      "     17        0.1001  5.7858\n",
      "     18        0.0606  5.7915\n",
      "     19        0.1150  5.7900\n",
      "     20        0.1048  5.9449\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2393\u001b[0m  6.0877\n",
      "      2        \u001b[36m0.0743\u001b[0m  5.7894\n",
      "      3        \u001b[36m0.0441\u001b[0m  5.7855\n",
      "      4        0.0604  5.5932\n",
      "      5        0.0477  5.5787\n",
      "      6        0.1317  5.6589\n",
      "      7        0.0712  5.6305\n",
      "      8        \u001b[36m0.0288\u001b[0m  5.6505\n",
      "      9        \u001b[36m0.0254\u001b[0m  5.7217\n",
      "     10        0.0338  5.7001\n",
      "     11        0.0444  5.6794\n",
      "     12        0.0499  5.6874\n",
      "     13        0.0441  5.6995\n",
      "     14        0.0542  5.7434\n",
      "     15        0.0581  5.7052\n",
      "     16        0.0505  5.7405\n",
      "     17        0.1071  5.7665\n",
      "     18        0.2134  5.7164\n",
      "     19        0.3284  5.6306\n",
      "     20        0.3196  5.7238\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2973\u001b[0m  8.7122\n",
      "      2        \u001b[36m0.2090\u001b[0m  8.7162\n",
      "      3        \u001b[36m0.1065\u001b[0m  8.7253\n",
      "      4        \u001b[36m0.0697\u001b[0m  8.7250\n",
      "      5        \u001b[36m0.0546\u001b[0m  8.7319\n",
      "      6        \u001b[36m0.0534\u001b[0m  8.7268\n",
      "      7        \u001b[36m0.0396\u001b[0m  8.7282\n",
      "      8        \u001b[36m0.0354\u001b[0m  8.7275\n",
      "      9        0.0420  8.7407\n",
      "     10        0.0371  8.7177\n",
      "     11        \u001b[36m0.0252\u001b[0m  8.7351\n",
      "     12        0.0383  8.7320\n",
      "     13        0.0395  8.7002\n",
      "     14        \u001b[36m0.0225\u001b[0m  8.7300\n",
      "     15        \u001b[36m0.0219\u001b[0m  8.6736\n",
      "     16        0.0248  8.7132\n",
      "     17        0.0263  8.7517\n",
      "     18        0.0222  8.6836\n",
      "     19        \u001b[36m0.0193\u001b[0m  8.6962\n",
      "     20        0.0372  8.7215\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4164\u001b[0m  8.7272\n",
      "      2        \u001b[36m0.3595\u001b[0m  8.6990\n",
      "      3        \u001b[36m0.2428\u001b[0m  8.7314\n",
      "      4        \u001b[36m0.1553\u001b[0m  8.7411\n",
      "      5        0.3506  8.7382\n",
      "      6        0.2385  8.7351\n",
      "      7        0.2546  8.6788\n",
      "      8        0.3597  8.6895\n",
      "      9        0.3264  8.7372\n",
      "     10        0.2626  8.7460\n",
      "     11        0.1773  8.7312\n",
      "     12        \u001b[36m0.1495\u001b[0m  8.6721\n",
      "     13        0.2517  8.7211\n",
      "     14        0.4710  8.7378\n",
      "     15        0.5910  8.7271\n",
      "     16        0.5631  8.7319\n",
      "     17        0.5123  8.6995\n",
      "     18        0.5361  8.6955\n",
      "     19        0.4789  8.7269\n",
      "     20        0.4285  8.7289\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2646\u001b[0m  8.7379\n",
      "      2        \u001b[36m0.0653\u001b[0m  8.7261\n",
      "      3        \u001b[36m0.0447\u001b[0m  8.7351\n",
      "      4        0.3717  8.7134\n",
      "      5        0.1219  8.7086\n",
      "      6        0.0786  8.6691\n",
      "      7        0.0569  8.6856\n",
      "      8        0.0466  8.7203\n",
      "      9        \u001b[36m0.0424\u001b[0m  8.7333\n",
      "     10        0.0677  8.7313\n",
      "     11        0.0433  8.7100\n",
      "     12        \u001b[36m0.0392\u001b[0m  8.7199\n",
      "     13        \u001b[36m0.0315\u001b[0m  8.7234\n",
      "     14        \u001b[36m0.0210\u001b[0m  8.7209\n",
      "     15        0.0267  8.7160\n",
      "     16        \u001b[36m0.0180\u001b[0m  8.7060\n",
      "     17        0.0206  8.7380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        \u001b[36m0.0178\u001b[0m  8.7398\n",
      "     19        0.0667  8.7357\n",
      "     20        0.0275  8.7268\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2523\u001b[0m  8.7177\n",
      "      2        0.5999  8.7380\n",
      "      3        0.3453  8.7150\n",
      "      4        \u001b[36m0.1849\u001b[0m  8.7220\n",
      "      5        \u001b[36m0.1353\u001b[0m  8.7327\n",
      "      6        \u001b[36m0.1035\u001b[0m  8.7371\n",
      "      7        0.1245  8.7220\n",
      "      8        0.2443  8.7350\n",
      "      9        0.1438  8.7377\n",
      "     10        \u001b[36m0.0633\u001b[0m  8.7381\n",
      "     11        \u001b[36m0.0502\u001b[0m  8.7490\n",
      "     12        0.0661  8.7340\n",
      "     13        0.0626  8.6860\n",
      "     14        \u001b[36m0.0423\u001b[0m  8.7235\n",
      "     15        \u001b[36m0.0415\u001b[0m  8.7277\n",
      "     16        \u001b[36m0.0329\u001b[0m  8.7081\n",
      "     17        0.1229  8.7222\n",
      "     18        0.1702  8.7252\n",
      "     19        0.0752  8.7174\n",
      "     20        0.2279  8.7270\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4960\u001b[0m  8.6850\n",
      "      2        \u001b[36m0.4820\u001b[0m  8.7359\n",
      "      3        \u001b[36m0.3980\u001b[0m  8.7257\n",
      "      4        \u001b[36m0.2204\u001b[0m  8.7318\n",
      "      5        0.5037  8.7254\n",
      "      6        0.3327  8.7267\n",
      "      7        \u001b[36m0.1954\u001b[0m  8.7323\n",
      "      8        \u001b[36m0.1307\u001b[0m  8.7234\n",
      "      9        \u001b[36m0.0889\u001b[0m  8.7138\n",
      "     10        \u001b[36m0.0741\u001b[0m  8.7255\n",
      "     11        \u001b[36m0.0698\u001b[0m  8.7309\n",
      "     12        \u001b[36m0.0511\u001b[0m  8.7400\n",
      "     13        \u001b[36m0.0424\u001b[0m  8.7271\n",
      "     14        \u001b[36m0.0409\u001b[0m  8.7326\n",
      "     15        0.0562  8.7230\n",
      "     16        0.0470  8.7288\n",
      "     17        0.0493  8.7259\n",
      "     18        \u001b[36m0.0282\u001b[0m  8.7303\n",
      "     19        0.0327  8.7381\n",
      "     20        0.0451  8.7259\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2433\u001b[0m  7.0339\n",
      "      2        \u001b[36m0.0722\u001b[0m  7.0086\n",
      "      3        \u001b[36m0.0422\u001b[0m  7.0849\n",
      "      4        0.0429  7.0113\n",
      "      5        0.1989  6.9954\n",
      "      6        0.2280  7.0084\n",
      "      7        0.1262  7.0365\n",
      "      8        0.1025  6.9986\n",
      "      9        0.1443  7.0326\n",
      "     10        0.0520  7.0540\n",
      "     11        0.0549  7.0559\n",
      "     12        0.2302  7.0939\n",
      "     13        0.5325  7.0572\n",
      "     14        0.3594  7.0708\n",
      "     15        0.2299  7.0752\n",
      "     16        0.3175  7.0821\n",
      "     17        0.1390  7.0812\n",
      "     18        0.1759  7.0435\n",
      "     19        0.1010  7.0172\n",
      "     20        0.0865  7.0874\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2352\u001b[0m  7.0869\n",
      "      2        \u001b[36m0.0495\u001b[0m  7.0657\n",
      "      3        \u001b[36m0.0303\u001b[0m  7.0713\n",
      "      4        \u001b[36m0.0286\u001b[0m  7.0681\n",
      "      5        0.0484  7.0353\n",
      "      6        0.2927  7.0874\n",
      "      7        0.2917  7.0421\n",
      "      8        0.2259  7.0826\n",
      "      9        0.1023  7.0383\n",
      "     10        0.0970  7.0664\n",
      "     11        0.0903  7.0722\n",
      "     12        0.0554  7.0921\n",
      "     13        0.0750  7.0075\n",
      "     14        0.0465  7.0784\n",
      "     15        0.0504  7.0518\n",
      "     16        0.0456  7.0523\n",
      "     17        0.0678  7.0445\n",
      "     18        0.0493  7.0446\n",
      "     19        0.0464  7.0759\n",
      "     20        0.0318  7.0735\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2200\u001b[0m  7.0823\n",
      "      2        0.3229  7.1180\n",
      "      3        0.5677  7.0888\n",
      "      4        0.4513  7.0198\n",
      "      5        0.5109  7.0508\n",
      "      6        0.3421  7.0929\n",
      "      7        0.3088  7.0405\n",
      "      8        \u001b[36m0.1670\u001b[0m  7.0416\n",
      "      9        \u001b[36m0.1633\u001b[0m  7.0874\n",
      "     10        \u001b[36m0.0903\u001b[0m  7.0760\n",
      "     11        \u001b[36m0.0631\u001b[0m  7.0612\n",
      "     12        0.0771  7.0829\n",
      "     13        \u001b[36m0.0549\u001b[0m  7.0861\n",
      "     14        \u001b[36m0.0444\u001b[0m  7.0741\n",
      "     15        0.1025  7.0426\n",
      "     16        0.2687  7.0913\n",
      "     17        0.0737  7.0930\n",
      "     18        0.0539  7.0673\n",
      "     19        \u001b[36m0.0365\u001b[0m  7.0920\n",
      "     20        0.0419  7.0611\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2597\u001b[0m  7.0726\n",
      "      2        0.5830  7.0501\n",
      "      3        0.4954  7.0550\n",
      "      4        0.3073  7.0632\n",
      "      5        0.2955  7.0678\n",
      "      6        \u001b[36m0.2582\u001b[0m  7.0828\n",
      "      7        \u001b[36m0.1570\u001b[0m  7.0677\n",
      "      8        \u001b[36m0.1049\u001b[0m  7.0889\n",
      "      9        0.2363  7.0680\n",
      "     10        \u001b[36m0.1018\u001b[0m  7.0654\n",
      "     11        \u001b[36m0.0633\u001b[0m  7.0505\n",
      "     12        \u001b[36m0.0420\u001b[0m  7.0509\n",
      "     13        \u001b[36m0.0402\u001b[0m  7.0702\n",
      "     14        0.0684  7.0587\n",
      "     15        0.0486  7.0616\n",
      "     16        0.0456  7.0619\n",
      "     17        \u001b[36m0.0255\u001b[0m  7.0708\n",
      "     18        \u001b[36m0.0255\u001b[0m  7.0638\n",
      "     19        0.0455  7.0725\n",
      "     20        \u001b[36m0.0208\u001b[0m  7.0484\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2233\u001b[0m  7.0870\n",
      "      2        \u001b[36m0.0549\u001b[0m  7.0969\n",
      "      3        \u001b[36m0.0317\u001b[0m  7.0564\n",
      "      4        0.0397  7.0895\n",
      "      5        0.0592  7.0737\n",
      "      6        0.2210  7.0748\n",
      "      7        0.2046  7.0838\n",
      "      8        0.2413  7.0605\n",
      "      9        0.1999  7.0756\n",
      "     10        0.1462  7.0358\n",
      "     11        0.1687  7.0671\n",
      "     12        0.1703  7.0509\n",
      "     13        0.4289  7.0547\n",
      "     14        0.2869  7.0688\n",
      "     15        0.1271  7.0619\n",
      "     16        0.0738  7.0865\n",
      "     17        0.0603  7.0830\n",
      "     18        0.0662  7.0801\n",
      "     19        0.1879  7.0763\n",
      "     20        0.1271  7.0619\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3252\u001b[0m  5.0590\n",
      "      2        \u001b[36m0.2191\u001b[0m  5.0308\n",
      "      3        0.3429  5.0369\n",
      "      4        0.2526  5.1119\n",
      "      5        \u001b[36m0.2101\u001b[0m  5.0573\n",
      "      6        \u001b[36m0.1815\u001b[0m  5.0336\n",
      "      7        \u001b[36m0.1549\u001b[0m  5.0085\n",
      "      8        0.1598  5.1791\n",
      "      9        \u001b[36m0.1223\u001b[0m  5.1589\n",
      "     10        \u001b[36m0.1124\u001b[0m  5.1496\n",
      "     11        0.1183  5.0886\n",
      "     12        0.1623  5.1525\n",
      "     13        0.1301  5.0628\n",
      "     14        0.1805  5.0898\n",
      "     15        0.1127  5.1174\n",
      "     16        \u001b[36m0.0952\u001b[0m  5.1146\n",
      "     17        0.1122  5.1501\n",
      "     18        0.1547  5.1104\n",
      "     19        0.1370  5.1454\n",
      "     20        0.1861  5.2574\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3466\u001b[0m  5.1256\n",
      "      2        \u001b[36m0.2066\u001b[0m  5.1216\n",
      "      3        \u001b[36m0.1388\u001b[0m  5.1257\n",
      "      4        0.1896  5.1039\n",
      "      5        0.1424  5.1442\n",
      "      6        \u001b[36m0.1155\u001b[0m  5.0448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        \u001b[36m0.0890\u001b[0m  5.0145\n",
      "      8        0.1051  5.0294\n",
      "      9        0.1219  5.0992\n",
      "     10        \u001b[36m0.0887\u001b[0m  5.1287\n",
      "     11        \u001b[36m0.0832\u001b[0m  5.1142\n",
      "     12        \u001b[36m0.0692\u001b[0m  5.1677\n",
      "     13        0.0711  5.0707\n",
      "     14        0.0870  5.0533\n",
      "     15        0.1041  5.1655\n",
      "     16        \u001b[36m0.0665\u001b[0m  5.0444\n",
      "     17        \u001b[36m0.0512\u001b[0m  5.2106\n",
      "     18        0.0635  5.0423\n",
      "     19        0.0673  5.1646\n",
      "     20        0.0558  5.2167\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3559\u001b[0m  5.0968\n",
      "      2        \u001b[36m0.1776\u001b[0m  5.2160\n",
      "      3        0.1869  5.1090\n",
      "      4        0.2370  5.1721\n",
      "      5        \u001b[36m0.1244\u001b[0m  5.1675\n",
      "      6        \u001b[36m0.1052\u001b[0m  5.2146\n",
      "      7        \u001b[36m0.0755\u001b[0m  5.0393\n",
      "      8        0.0797  5.0520\n",
      "      9        \u001b[36m0.0644\u001b[0m  5.0250\n",
      "     10        0.0698  5.1162\n",
      "     11        \u001b[36m0.0524\u001b[0m  5.1980\n",
      "     12        \u001b[36m0.0432\u001b[0m  5.0220\n",
      "     13        0.0495  5.2212\n",
      "     14        0.1583  5.1839\n",
      "     15        0.1131  5.1090\n",
      "     16        0.0938  5.1662\n",
      "     17        0.0565  5.2208\n",
      "     18        0.0463  5.0946\n",
      "     19        0.0645  5.1131\n",
      "     20        0.0579  5.0377\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3157\u001b[0m  5.1322\n",
      "      2        \u001b[36m0.1813\u001b[0m  5.1332\n",
      "      3        \u001b[36m0.1302\u001b[0m  5.1516\n",
      "      4        \u001b[36m0.1014\u001b[0m  5.1123\n",
      "      5        \u001b[36m0.0687\u001b[0m  5.1631\n",
      "      6        \u001b[36m0.0548\u001b[0m  5.1444\n",
      "      7        \u001b[36m0.0526\u001b[0m  5.1677\n",
      "      8        \u001b[36m0.0517\u001b[0m  5.1836\n",
      "      9        0.0613  5.1169\n",
      "     10        \u001b[36m0.0427\u001b[0m  5.1443\n",
      "     11        \u001b[36m0.0394\u001b[0m  5.1625\n",
      "     12        0.0618  5.1224\n",
      "     13        0.0569  5.0872\n",
      "     14        0.0517  5.1644\n",
      "     15        0.0480  5.1659\n",
      "     16        0.0577  5.0932\n",
      "     17        0.0553  5.0449\n",
      "     18        0.0400  5.0525\n",
      "     19        0.0602  5.1295\n",
      "     20        0.2505  5.0716\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3178\u001b[0m  5.0899\n",
      "      2        \u001b[36m0.1634\u001b[0m  5.0383\n",
      "      3        \u001b[36m0.1187\u001b[0m  5.1099\n",
      "      4        \u001b[36m0.1119\u001b[0m  5.0835\n",
      "      5        \u001b[36m0.0976\u001b[0m  5.0595\n",
      "      6        \u001b[36m0.0800\u001b[0m  5.1372\n",
      "      7        \u001b[36m0.0629\u001b[0m  5.1169\n",
      "      8        \u001b[36m0.0568\u001b[0m  5.1114\n",
      "      9        0.0760  5.1517\n",
      "     10        0.0722  5.1210\n",
      "     11        \u001b[36m0.0517\u001b[0m  5.1651\n",
      "     12        0.0528  5.0389\n",
      "     13        \u001b[36m0.0437\u001b[0m  5.1037\n",
      "     14        0.0526  5.1200\n",
      "     15        0.0587  5.2210\n",
      "     16        0.0910  5.1449\n",
      "     17        0.0598  5.0956\n",
      "     18        0.0591  5.1242\n",
      "     19        0.0485  5.1646\n",
      "     20        \u001b[36m0.0427\u001b[0m  5.1549\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2369\u001b[0m  5.8334\n",
      "      2        \u001b[36m0.1215\u001b[0m  5.6905\n",
      "      3        \u001b[36m0.0727\u001b[0m  5.6724\n",
      "      4        \u001b[36m0.0669\u001b[0m  5.6546\n",
      "      5        \u001b[36m0.0492\u001b[0m  5.6693\n",
      "      6        0.0614  5.6960\n",
      "      7        0.2107  5.6575\n",
      "      8        0.6577  5.6749\n",
      "      9        0.6375  5.6258\n",
      "     10        0.5716  5.6292\n",
      "     11        0.5163  5.6341\n",
      "     12        0.4169  5.6710\n",
      "     13        0.7831  5.7167\n",
      "     14        0.5865  5.7288\n",
      "     15        0.5450  5.6676\n",
      "     16        0.5775  5.7215\n",
      "     17        0.5896  5.7204\n",
      "     18        0.5698  5.6227\n",
      "     19        0.6605  5.7212\n",
      "     20        0.5938  5.6998\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3090\u001b[0m  5.6469\n",
      "      2        \u001b[36m0.1621\u001b[0m  5.6864\n",
      "      3        \u001b[36m0.1227\u001b[0m  5.6349\n",
      "      4        0.2177  5.5990\n",
      "      5        0.2708  5.6579\n",
      "      6        \u001b[36m0.1106\u001b[0m  5.6543\n",
      "      7        \u001b[36m0.0765\u001b[0m  5.6601\n",
      "      8        0.0834  5.6981\n",
      "      9        \u001b[36m0.0602\u001b[0m  5.6614\n",
      "     10        \u001b[36m0.0556\u001b[0m  5.6826\n",
      "     11        0.1244  5.6693\n",
      "     12        0.0703  5.6398\n",
      "     13        0.3066  5.6570\n",
      "     14        0.1258  5.8015\n",
      "     15        0.0727  5.6795\n",
      "     16        0.3609  5.7389\n",
      "     17        0.1886  5.6250\n",
      "     18        0.1071  5.6326\n",
      "     19        0.0924  5.6273\n",
      "     20        0.0716  5.6185\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2520\u001b[0m  5.6198\n",
      "      2        \u001b[36m0.0919\u001b[0m  5.6601\n",
      "      3        0.1295  5.8416\n",
      "      4        0.4517  5.6422\n",
      "      5        0.5054  5.6841\n",
      "      6        0.3852  5.6563\n",
      "      7        0.2520  5.6859\n",
      "      8        0.1744  5.6394\n",
      "      9        0.1422  5.6772\n",
      "     10        0.1157  5.6496\n",
      "     11        0.1073  5.7268\n",
      "     12        0.1426  5.7513\n",
      "     13        0.1133  5.6460\n",
      "     14        \u001b[36m0.0620\u001b[0m  5.6475\n",
      "     15        \u001b[36m0.0620\u001b[0m  5.7746\n",
      "     16        \u001b[36m0.0540\u001b[0m  5.5996\n",
      "     17        \u001b[36m0.0473\u001b[0m  5.5996\n",
      "     18        0.0564  5.6713\n",
      "     19        0.0631  5.6734\n",
      "     20        0.0480  5.7408\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2746\u001b[0m  5.6830\n",
      "      2        \u001b[36m0.1125\u001b[0m  5.6995\n",
      "      3        \u001b[36m0.0566\u001b[0m  5.6790\n",
      "      4        \u001b[36m0.0459\u001b[0m  5.6325\n",
      "      5        \u001b[36m0.0395\u001b[0m  5.6863\n",
      "      6        0.0717  5.6759\n",
      "      7        0.1512  5.6671\n",
      "      8        0.4136  5.6099\n",
      "      9        0.4516  5.6858\n",
      "     10        0.5664  5.5766\n",
      "     11        0.4991  5.6564\n",
      "     12        0.4588  5.7572\n",
      "     13        0.4250  5.6180\n",
      "     14        1.0707  5.7374\n",
      "     15        1.0163  5.6011\n",
      "     16        0.6367  5.8081\n",
      "     17        0.6040  5.6292\n",
      "     18        0.5873  5.6322\n",
      "     19        0.5696  5.6159\n",
      "     20        0.5323  5.6749\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2685\u001b[0m  5.7253\n",
      "      2        \u001b[36m0.0648\u001b[0m  5.6662\n",
      "      3        \u001b[36m0.0351\u001b[0m  5.7092\n",
      "      4        0.0436  5.7074\n",
      "      5        \u001b[36m0.0274\u001b[0m  5.7338\n",
      "      6        \u001b[36m0.0246\u001b[0m  5.6724\n",
      "      7        \u001b[36m0.0218\u001b[0m  5.6748\n",
      "      8        0.0254  5.5903\n",
      "      9        0.0242  5.6870\n",
      "     10        0.0433  5.6615\n",
      "     11        0.0467  5.6158\n",
      "     12        0.0866  5.7284\n",
      "     13        0.1556  5.6432\n",
      "     14        0.5022  5.6831\n",
      "     15        0.4355  5.6908\n",
      "     16        0.3682  5.6418\n",
      "     17        0.3271  5.7813\n",
      "     18        0.6199  5.7130\n",
      "     19        0.5380  5.7135\n",
      "     20        0.4234  5.7000\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2553\u001b[0m  8.7174\n",
      "      2        \u001b[36m0.1047\u001b[0m  8.7332\n",
      "      3        \u001b[36m0.0709\u001b[0m  8.7452\n",
      "      4        0.1828  8.7055\n",
      "      5        0.3871  8.7378\n",
      "      6        0.2891  8.6979\n",
      "      7        0.1925  8.7289\n",
      "      8        0.1638  8.7226\n",
      "      9        0.1015  8.7098\n",
      "     10        0.0843  8.7186\n",
      "     11        0.4161  8.7179\n",
      "     12        0.5901  8.7609\n",
      "     13        0.5461  8.7036\n",
      "     14        0.5786  8.7405\n",
      "     15        0.4872  8.7179\n",
      "     16        0.5015  8.7184\n",
      "     17        0.4478  8.7323\n",
      "     18        0.3101  8.7362\n",
      "     19        0.2303  8.7364\n",
      "     20        0.2257  8.7109\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2761\u001b[0m  8.7304\n",
      "      2        \u001b[36m0.1796\u001b[0m  8.7319\n",
      "      3        \u001b[36m0.0520\u001b[0m  8.6960\n",
      "      4        \u001b[36m0.0410\u001b[0m  8.7342\n",
      "      5        \u001b[36m0.0339\u001b[0m  8.7439\n",
      "      6        0.0391  8.7145\n",
      "      7        \u001b[36m0.0320\u001b[0m  8.7211\n",
      "      8        0.1062  8.7028\n",
      "      9        0.2233  8.7312\n",
      "     10        0.2973  8.7300\n",
      "     11        0.4015  8.7201\n",
      "     12        0.4908  8.7314\n",
      "     13        0.4333  8.7290\n",
      "     14        0.4501  8.7054\n",
      "     15        0.3394  8.7247\n",
      "     16        0.4489  8.7339\n",
      "     17        0.4010  8.6914\n",
      "     18        0.3272  8.7176\n",
      "     19        0.3301  8.7350\n",
      "     20        0.3812  8.7202\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3130\u001b[0m  8.7395\n",
      "      2        \u001b[36m0.1296\u001b[0m  8.7124\n",
      "      3        \u001b[36m0.0796\u001b[0m  8.6878\n",
      "      4        \u001b[36m0.0528\u001b[0m  8.7180\n",
      "      5        \u001b[36m0.0407\u001b[0m  8.7485\n",
      "      6        0.1192  8.7248\n",
      "      7        0.0674  8.7142\n",
      "      8        0.0548  8.7394\n",
      "      9        \u001b[36m0.0404\u001b[0m  8.7241\n",
      "     10        0.2263  8.7352\n",
      "     11        0.2778  8.7304\n",
      "     12        0.1164  8.7295\n",
      "     13        0.0666  8.7443\n",
      "     14        0.0589  8.7324\n",
      "     15        0.0622  8.7236\n",
      "     16        0.1727  8.7221\n",
      "     17        0.2808  8.7298\n",
      "     18        0.0912  8.7377\n",
      "     19        0.0704  8.6915\n",
      "     20        0.0744  8.7431\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2600\u001b[0m  8.7298\n",
      "      2        0.2677  8.7279\n",
      "      3        0.3161  8.7277\n",
      "      4        0.3650  8.7241\n",
      "      5        \u001b[36m0.2210\u001b[0m  8.7381\n",
      "      6        \u001b[36m0.1249\u001b[0m  8.7418\n",
      "      7        \u001b[36m0.0897\u001b[0m  8.7346\n",
      "      8        \u001b[36m0.0874\u001b[0m  8.7192\n",
      "      9        \u001b[36m0.0802\u001b[0m  8.7160\n",
      "     10        \u001b[36m0.0757\u001b[0m  8.7198\n",
      "     11        0.0938  8.6738\n",
      "     12        0.1322  8.7172\n",
      "     13        \u001b[36m0.0608\u001b[0m  8.7362\n",
      "     14        \u001b[36m0.0571\u001b[0m  8.7313\n",
      "     15        \u001b[36m0.0447\u001b[0m  8.7297\n",
      "     16        0.0481  8.7172\n",
      "     17        \u001b[36m0.0435\u001b[0m  8.7050\n",
      "     18        \u001b[36m0.0342\u001b[0m  8.7177\n",
      "     19        \u001b[36m0.0303\u001b[0m  8.7182\n",
      "     20        0.0447  8.7309\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3585\u001b[0m  8.7415\n",
      "      2        \u001b[36m0.1284\u001b[0m  8.7349\n",
      "      3        \u001b[36m0.0855\u001b[0m  8.7249\n",
      "      4        \u001b[36m0.0613\u001b[0m  8.6764\n",
      "      5        0.0642  8.6761\n",
      "      6        0.0902  8.7243\n",
      "      7        \u001b[36m0.0506\u001b[0m  8.6731\n",
      "      8        \u001b[36m0.0354\u001b[0m  8.7194\n",
      "      9        0.0408  8.6906\n",
      "     10        0.0513  8.7284\n",
      "     11        0.0470  8.7308\n",
      "     12        0.0842  8.7237\n",
      "     13        0.0425  8.7073\n",
      "     14        \u001b[36m0.0328\u001b[0m  8.7310\n",
      "     15        \u001b[36m0.0322\u001b[0m  8.6906\n",
      "     16        0.0692  8.7083\n",
      "     17        0.4030  8.7207\n",
      "     18        0.3583  8.7282\n",
      "     19        0.3488  8.7373\n",
      "     20        0.3286  8.7198\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4422\u001b[0m  6.9842\n",
      "      2        \u001b[36m0.1684\u001b[0m  7.0213\n",
      "      3        \u001b[36m0.0709\u001b[0m  7.0363\n",
      "      4        \u001b[36m0.0587\u001b[0m  7.0125\n",
      "      5        \u001b[36m0.0443\u001b[0m  6.9849\n",
      "      6        \u001b[36m0.0351\u001b[0m  7.0049\n",
      "      7        0.0430  7.0208\n",
      "      8        \u001b[36m0.0330\u001b[0m  7.0207\n",
      "      9        0.0385  7.0092\n",
      "     10        0.4925  7.0186\n",
      "     11        0.3608  7.0519\n",
      "     12        0.4554  7.0406\n",
      "     13        0.3846  7.0323\n",
      "     14        0.3253  7.0838\n",
      "     15        0.2885  7.0618\n",
      "     16        0.2576  7.0609\n",
      "     17        0.2381  7.0724\n",
      "     18        0.2141  7.0466\n",
      "     19        0.2594  7.0465\n",
      "     20        0.2789  7.0767\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2550\u001b[0m  7.0000\n",
      "      2        \u001b[36m0.2340\u001b[0m  7.0560\n",
      "      3        \u001b[36m0.1077\u001b[0m  7.0796\n",
      "      4        \u001b[36m0.0399\u001b[0m  7.0865\n",
      "      5        \u001b[36m0.0350\u001b[0m  7.0941\n",
      "      6        0.0358  7.0962\n",
      "      7        \u001b[36m0.0300\u001b[0m  7.0730\n",
      "      8        0.0308  7.0693\n",
      "      9        0.0328  7.0678\n",
      "     10        \u001b[36m0.0258\u001b[0m  7.0443\n",
      "     11        0.3115  7.0307\n",
      "     12        0.5552  7.0462\n",
      "     13        0.6060  7.0604\n",
      "     14        0.4777  7.0623\n",
      "     15        0.4859  7.0530\n",
      "     16        0.5427  7.0515\n",
      "     17        0.4794  7.0699\n",
      "     18        0.4774  7.0587\n",
      "     19        0.4035  7.0633\n",
      "     20        0.2943  7.0491\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2426\u001b[0m  7.0477\n",
      "      2        0.3522  7.0636\n",
      "      3        0.3367  7.0597\n",
      "      4        \u001b[36m0.2073\u001b[0m  7.0849\n",
      "      5        \u001b[36m0.1392\u001b[0m  7.0522\n",
      "      6        0.1465  7.0586\n",
      "      7        \u001b[36m0.0996\u001b[0m  7.0504\n",
      "      8        \u001b[36m0.0928\u001b[0m  7.0968\n",
      "      9        0.1327  7.0507\n",
      "     10        \u001b[36m0.0895\u001b[0m  7.0379\n",
      "     11        \u001b[36m0.0731\u001b[0m  7.0751\n",
      "     12        \u001b[36m0.0725\u001b[0m  7.0617\n",
      "     13        \u001b[36m0.0590\u001b[0m  7.0616\n",
      "     14        \u001b[36m0.0568\u001b[0m  7.0815\n",
      "     15        0.0674  7.0902\n",
      "     16        0.0768  7.0686\n",
      "     17        \u001b[36m0.0508\u001b[0m  7.0746\n",
      "     18        0.0621  7.0800\n",
      "     19        \u001b[36m0.0321\u001b[0m  7.0925\n",
      "     20        0.0332  7.0809\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2307\u001b[0m  7.0970\n",
      "      2        \u001b[36m0.0577\u001b[0m  7.0777\n",
      "      3        0.1560  7.0568\n",
      "      4        0.5757  7.0313\n",
      "      5        0.4360  7.0709\n",
      "      6        0.3378  7.0595\n",
      "      7        0.3198  7.0376\n",
      "      8        0.3477  7.0804\n",
      "      9        0.2614  7.0860\n",
      "     10        0.1586  7.0809\n",
      "     11        0.3557  7.0696\n",
      "     12        0.1669  7.0732\n",
      "     13        0.1022  7.0792\n",
      "     14        0.0948  7.0608\n",
      "     15        0.1277  7.0996\n",
      "     16        0.0673  7.0869\n",
      "     17        0.0770  7.0824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        0.0655  7.0899\n",
      "     19        0.0882  7.0879\n",
      "     20        0.0688  7.0292\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3258\u001b[0m  7.0809\n",
      "      2        \u001b[36m0.1157\u001b[0m  7.0680\n",
      "      3        \u001b[36m0.0647\u001b[0m  7.0763\n",
      "      4        \u001b[36m0.0403\u001b[0m  7.0643\n",
      "      5        \u001b[36m0.0394\u001b[0m  7.0424\n",
      "      6        \u001b[36m0.0319\u001b[0m  7.0364\n",
      "      7        0.4331  7.0500\n",
      "      8        0.2856  7.0882\n",
      "      9        0.1956  7.0363\n",
      "     10        0.1528  7.0675\n",
      "     11        0.1185  7.0334\n",
      "     12        0.1176  7.0700\n",
      "     13        0.0861  7.0718\n",
      "     14        0.0717  7.0704\n",
      "     15        0.0929  7.0826\n",
      "     16        0.0593  7.0890\n",
      "     17        0.0450  7.0622\n",
      "     18        0.0468  7.0734\n",
      "     19        0.0474  7.0644\n",
      "     20        0.0768  7.0663\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3446\u001b[0m  5.2267\n",
      "      2        \u001b[36m0.1981\u001b[0m  5.0071\n",
      "      3        \u001b[36m0.1797\u001b[0m  5.1253\n",
      "      4        \u001b[36m0.1225\u001b[0m  5.2083\n",
      "      5        \u001b[36m0.0952\u001b[0m  5.1842\n",
      "      6        \u001b[36m0.0788\u001b[0m  5.2010\n",
      "      7        \u001b[36m0.0667\u001b[0m  5.0950\n",
      "      8        0.0768  5.1854\n",
      "      9        0.0840  5.2148\n",
      "     10        \u001b[36m0.0656\u001b[0m  5.2530\n",
      "     11        0.1386  5.0573\n",
      "     12        0.2032  5.0422\n",
      "     13        0.1612  5.1370\n",
      "     14        0.1625  5.2123\n",
      "     15        0.1520  5.2370\n",
      "     16        0.1607  5.1862\n",
      "     17        0.3491  5.0363\n",
      "     18        0.5348  5.0502\n",
      "     19        0.4183  5.1484\n",
      "     20        0.2195  5.1810\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3391\u001b[0m  5.2150\n",
      "      2        \u001b[36m0.2986\u001b[0m  5.0343\n",
      "      3        \u001b[36m0.2365\u001b[0m  5.1340\n",
      "      4        \u001b[36m0.1930\u001b[0m  5.2032\n",
      "      5        \u001b[36m0.1734\u001b[0m  5.0906\n",
      "      6        \u001b[36m0.1504\u001b[0m  5.2081\n",
      "      7        \u001b[36m0.1259\u001b[0m  5.0342\n",
      "      8        0.1924  5.1144\n",
      "      9        0.1546  5.0912\n",
      "     10        0.1287  5.2064\n",
      "     11        \u001b[36m0.1245\u001b[0m  5.1116\n",
      "     12        0.1411  5.0391\n",
      "     13        0.1250  5.1177\n",
      "     14        0.3406  5.4246\n",
      "     15        0.3838  5.0617\n",
      "     16        0.3137  5.0941\n",
      "     17        0.2607  5.0662\n",
      "     18        0.2169  5.0654\n",
      "     19        0.1796  5.0382\n",
      "     20        0.1552  5.0525\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2983\u001b[0m  5.1091\n",
      "      2        \u001b[36m0.1860\u001b[0m  5.1145\n",
      "      3        \u001b[36m0.1156\u001b[0m  5.0440\n",
      "      4        \u001b[36m0.0710\u001b[0m  5.0554\n",
      "      5        \u001b[36m0.0666\u001b[0m  5.1456\n",
      "      6        0.0878  5.1280\n",
      "      7        0.0715  5.1555\n",
      "      8        \u001b[36m0.0558\u001b[0m  5.1426\n",
      "      9        \u001b[36m0.0432\u001b[0m  5.0954\n",
      "     10        0.3083  5.1591\n",
      "     11        0.5219  5.1562\n",
      "     12        0.5079  5.1509\n",
      "     13        0.4434  5.1012\n",
      "     14        0.3920  5.0634\n",
      "     15        0.4205  5.1170\n",
      "     16        0.3502  5.1514\n",
      "     17        0.2691  5.1300\n",
      "     18        0.2300  5.1395\n",
      "     19        0.2227  5.1570\n",
      "     20        0.1860  5.0916\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3332\u001b[0m  5.2019\n",
      "      2        \u001b[36m0.2141\u001b[0m  5.0816\n",
      "      3        \u001b[36m0.1661\u001b[0m  5.1648\n",
      "      4        \u001b[36m0.1521\u001b[0m  5.1391\n",
      "      5        \u001b[36m0.1078\u001b[0m  5.0741\n",
      "      6        \u001b[36m0.1058\u001b[0m  5.1544\n",
      "      7        \u001b[36m0.0935\u001b[0m  5.1368\n",
      "      8        \u001b[36m0.0926\u001b[0m  5.1082\n",
      "      9        0.0964  5.1750\n",
      "     10        \u001b[36m0.0853\u001b[0m  5.1058\n",
      "     11        \u001b[36m0.0837\u001b[0m  5.1887\n",
      "     12        \u001b[36m0.0759\u001b[0m  5.1587\n",
      "     13        \u001b[36m0.0646\u001b[0m  5.1060\n",
      "     14        \u001b[36m0.0559\u001b[0m  5.1280\n",
      "     15        \u001b[36m0.0503\u001b[0m  5.0566\n",
      "     16        0.0606  5.0831\n",
      "     17        0.0556  5.0545\n",
      "     18        0.0580  5.1420\n",
      "     19        0.0737  5.1242\n",
      "     20        0.0696  5.1140\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3221\u001b[0m  5.1910\n",
      "      2        \u001b[36m0.1931\u001b[0m  5.0550\n",
      "      3        0.2378  5.2349\n",
      "      4        \u001b[36m0.1563\u001b[0m  5.1249\n",
      "      5        \u001b[36m0.1331\u001b[0m  5.1542\n",
      "      6        \u001b[36m0.1264\u001b[0m  5.1378\n",
      "      7        \u001b[36m0.1229\u001b[0m  5.1394\n",
      "      8        \u001b[36m0.1049\u001b[0m  5.2257\n",
      "      9        0.1083  5.0787\n",
      "     10        0.1304  5.1260\n",
      "     11        0.1154  5.0357\n",
      "     12        \u001b[36m0.0900\u001b[0m  5.0384\n",
      "     13        0.1173  5.0205\n",
      "     14        0.1035  5.1637\n",
      "     15        \u001b[36m0.0821\u001b[0m  5.1431\n",
      "     16        \u001b[36m0.0693\u001b[0m  5.2132\n",
      "     17        0.0815  5.1273\n",
      "     18        \u001b[36m0.0673\u001b[0m  5.1620\n",
      "     19        0.0894  5.1735\n",
      "     20        0.0785  5.1406\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.7min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2517\u001b[0m  5.6952\n",
      "      2        \u001b[36m0.1055\u001b[0m  5.6777\n",
      "      3        \u001b[36m0.0897\u001b[0m  5.6397\n",
      "      4        \u001b[36m0.0511\u001b[0m  5.6526\n",
      "      5        0.0613  5.8005\n",
      "      6        0.1271  5.7352\n",
      "      7        0.4193  5.7700\n",
      "      8        0.5955  5.8731\n",
      "      9        0.6432  6.2692\n",
      "     10        0.6526  5.7661\n",
      "     11        0.6479  6.0561\n",
      "     12        0.6383  5.9591\n",
      "     13        0.6227  5.7032\n",
      "     14        0.5974  5.7889\n",
      "     15        0.5708  5.7077\n",
      "     16        0.5790  5.6534\n",
      "     17        0.6895  5.6543\n",
      "     18        0.6671  5.7610\n",
      "     19        0.6486  5.6951\n",
      "     20        0.6297  5.6554\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2566\u001b[0m  5.7233\n",
      "      2        \u001b[36m0.1683\u001b[0m  5.7003\n",
      "      3        0.1720  5.7991\n",
      "      4        \u001b[36m0.1203\u001b[0m  5.7032\n",
      "      5        \u001b[36m0.0680\u001b[0m  5.6851\n",
      "      6        0.1078  5.7997\n",
      "      7        0.0739  5.7047\n",
      "      8        \u001b[36m0.0579\u001b[0m  5.7088\n",
      "      9        \u001b[36m0.0483\u001b[0m  5.7171\n",
      "     10        0.0906  5.6428\n",
      "     11        0.0661  5.6390\n",
      "     12        \u001b[36m0.0386\u001b[0m  5.6302\n",
      "     13        0.0729  5.6318\n",
      "     14        0.0435  5.6589\n",
      "     15        \u001b[36m0.0335\u001b[0m  5.6281\n",
      "     16        0.0386  5.6292\n",
      "     17        0.0396  5.7009\n",
      "     18        0.1703  5.6989\n",
      "     19        0.2735  5.6998\n",
      "     20        0.2793  5.6762\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2507\u001b[0m  5.6611\n",
      "      2        \u001b[36m0.1364\u001b[0m  5.6471\n",
      "      3        \u001b[36m0.0647\u001b[0m  5.7020\n",
      "      4        0.2238  5.5997\n",
      "      5        0.3440  5.6929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        0.3587  5.6663\n",
      "      7        0.2656  5.7303\n",
      "      8        0.6223  5.7175\n",
      "      9        0.6210  5.6360\n",
      "     10        0.6660  5.6877\n",
      "     11        0.6486  5.7099\n",
      "     12        0.6437  5.6272\n",
      "     13        0.6195  5.5920\n",
      "     14        0.6209  5.5883\n",
      "     15        0.6239  5.7158\n",
      "     16        0.6112  5.8055\n",
      "     17        0.6164  5.8133\n",
      "     18        0.6098  5.7109\n",
      "     19        0.5779  5.8376\n",
      "     20        0.8472  5.6585\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3206\u001b[0m  5.7257\n",
      "      2        \u001b[36m0.2294\u001b[0m  5.6793\n",
      "      3        \u001b[36m0.1287\u001b[0m  5.7234\n",
      "      4        0.2247  5.7834\n",
      "      5        0.1849  5.8167\n",
      "      6        \u001b[36m0.0823\u001b[0m  5.7445\n",
      "      7        \u001b[36m0.0586\u001b[0m  5.6493\n",
      "      8        0.0836  5.7455\n",
      "      9        0.4943  5.7271\n",
      "     10        0.2541  5.7231\n",
      "     11        0.2394  5.6696\n",
      "     12        0.5918  5.6736\n",
      "     13        0.5175  5.6601\n",
      "     14        0.3924  5.6540\n",
      "     15        0.2723  5.6194\n",
      "     16        0.2257  5.7588\n",
      "     17        0.4123  5.6385\n",
      "     18        0.4961  5.7445\n",
      "     19        0.3749  5.6361\n",
      "     20        0.2218  5.6491\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2617\u001b[0m  5.6540\n",
      "      2        \u001b[36m0.1135\u001b[0m  5.6527\n",
      "      3        \u001b[36m0.0728\u001b[0m  5.6834\n",
      "      4        \u001b[36m0.0469\u001b[0m  5.6211\n",
      "      5        \u001b[36m0.0397\u001b[0m  5.5811\n",
      "      6        0.0424  5.7661\n",
      "      7        0.0500  5.6737\n",
      "      8        \u001b[36m0.0329\u001b[0m  5.8528\n",
      "      9        \u001b[36m0.0317\u001b[0m  5.6402\n",
      "     10        \u001b[36m0.0234\u001b[0m  5.7697\n",
      "     11        0.0338  5.7760\n",
      "     12        0.0352  5.6776\n",
      "     13        \u001b[36m0.0208\u001b[0m  5.5985\n",
      "     14        \u001b[36m0.0196\u001b[0m  5.6463\n",
      "     15        \u001b[36m0.0175\u001b[0m  5.7012\n",
      "     16        \u001b[36m0.0150\u001b[0m  5.6421\n",
      "     17        0.0167  5.6898\n",
      "     18        0.0224  5.7355\n",
      "     19        0.0228  5.7774\n",
      "     20        0.0206  5.6902\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2666\u001b[0m  8.7367\n",
      "      2        \u001b[36m0.1594\u001b[0m  8.7231\n",
      "      3        0.2532  8.7366\n",
      "      4        0.2269  8.7361\n",
      "      5        0.3211  8.7367\n",
      "      6        0.2866  8.7454\n",
      "      7        0.2575  8.7307\n",
      "      8        0.2729  8.7337\n",
      "      9        0.4331  8.7331\n",
      "     10        0.3035  8.7305\n",
      "     11        0.2138  8.7218\n",
      "     12        \u001b[36m0.1523\u001b[0m  8.7385\n",
      "     13        \u001b[36m0.1258\u001b[0m  8.7315\n",
      "     14        0.1341  8.7306\n",
      "     15        0.5930  8.7025\n",
      "     16        0.7138  8.7448\n",
      "     17        0.6048  8.7250\n",
      "     18        0.5917  8.7093\n",
      "     19        0.5726  8.7135\n",
      "     20        0.5536  8.7491\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2784\u001b[0m  8.7333\n",
      "      2        \u001b[36m0.0888\u001b[0m  8.7312\n",
      "      3        \u001b[36m0.0424\u001b[0m  8.7008\n",
      "      4        \u001b[36m0.0373\u001b[0m  8.7279\n",
      "      5        \u001b[36m0.0316\u001b[0m  8.7350\n",
      "      6        0.0322  8.7199\n",
      "      7        \u001b[36m0.0257\u001b[0m  8.7118\n",
      "      8        \u001b[36m0.0238\u001b[0m  8.7328\n",
      "      9        0.7430  8.7015\n",
      "     10        0.6443  8.7259\n",
      "     11        0.6310  8.7073\n",
      "     12        0.6462  8.6667\n",
      "     13        0.6542  8.7413\n",
      "     14        0.6532  8.7332\n",
      "     15        0.6456  8.7388\n",
      "     16        0.6784  8.6742\n",
      "     17        0.6637  8.7286\n",
      "     18        0.6691  8.7401\n",
      "     19        0.6670  8.7390\n",
      "     20        0.6639  8.7431\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2410\u001b[0m  8.7567\n",
      "      2        \u001b[36m0.1138\u001b[0m  8.7055\n",
      "      3        0.1426  8.7364\n",
      "      4        \u001b[36m0.0803\u001b[0m  8.7302\n",
      "      5        \u001b[36m0.0527\u001b[0m  8.6692\n",
      "      6        \u001b[36m0.0399\u001b[0m  8.7353\n",
      "      7        0.1405  8.6938\n",
      "      8        0.3815  8.7234\n",
      "      9        0.2630  8.7173\n",
      "     10        0.7858  8.7254\n",
      "     11        0.4961  8.7022\n",
      "     12        0.4212  8.7202\n",
      "     13        0.6037  8.6860\n",
      "     14        0.5737  8.7377\n",
      "     15        0.5230  8.7237\n",
      "     16        0.4976  8.6938\n",
      "     17        0.4932  8.7270\n",
      "     18        0.4488  8.7051\n",
      "     19        0.5622  8.7215\n",
      "     20        0.4499  8.7402\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3727\u001b[0m  8.7321\n",
      "      2        \u001b[36m0.1766\u001b[0m  8.7261\n",
      "      3        \u001b[36m0.1448\u001b[0m  8.7089\n",
      "      4        \u001b[36m0.1199\u001b[0m  8.7234\n",
      "      5        \u001b[36m0.0619\u001b[0m  8.7304\n",
      "      6        \u001b[36m0.0477\u001b[0m  8.7234\n",
      "      7        \u001b[36m0.0377\u001b[0m  8.6757\n",
      "      8        0.0610  8.7398\n",
      "      9        \u001b[36m0.0362\u001b[0m  8.7417\n",
      "     10        0.0382  8.7434\n",
      "     11        0.0400  8.7476\n",
      "     12        \u001b[36m0.0338\u001b[0m  8.7480\n",
      "     13        0.0347  8.7424\n",
      "     14        \u001b[36m0.0323\u001b[0m  8.7366\n",
      "     15        \u001b[36m0.0222\u001b[0m  8.6832\n",
      "     16        0.7088  8.7300\n",
      "     17        0.5798  8.7011\n",
      "     18        0.6067  8.7356\n",
      "     19        0.5503  8.7384\n",
      "     20        0.4845  8.7499\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3133\u001b[0m  8.7057\n",
      "      2        \u001b[36m0.1068\u001b[0m  8.7267\n",
      "      3        \u001b[36m0.0581\u001b[0m  8.7118\n",
      "      4        \u001b[36m0.0470\u001b[0m  8.7356\n",
      "      5        0.0653  8.7362\n",
      "      6        0.4404  8.7210\n",
      "      7        0.2310  8.7384\n",
      "      8        0.2687  8.7430\n",
      "      9        0.6245  8.7301\n",
      "     10        0.5513  8.7219\n",
      "     11        0.3383  8.7083\n",
      "     12        0.2123  8.7133\n",
      "     13        0.1586  8.7368\n",
      "     14        0.1196  8.6828\n",
      "     15        0.1024  8.6944\n",
      "     16        0.0956  8.7222\n",
      "     17        0.0782  8.7182\n",
      "     18        0.0962  8.7295\n",
      "     19        0.0652  8.7025\n",
      "     20        0.0732  8.6927\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2337\u001b[0m  7.0318\n",
      "      2        \u001b[36m0.1319\u001b[0m  7.0498\n",
      "      3        \u001b[36m0.0532\u001b[0m  7.0061\n",
      "      4        \u001b[36m0.0297\u001b[0m  7.0090\n",
      "      5        \u001b[36m0.0291\u001b[0m  7.0446\n",
      "      6        0.1480  7.0209\n",
      "      7        0.4128  7.0101\n",
      "      8        0.2432  7.0423\n",
      "      9        0.1222  7.0806\n",
      "     10        0.0987  7.0938\n",
      "     11        0.1825  7.0593\n",
      "     12        0.2148  7.0689\n",
      "     13        0.1169  7.0556\n",
      "     14        0.0811  7.0777\n",
      "     15        0.1118  7.0849\n",
      "     16        0.0838  7.0458\n",
      "     17        0.0832  7.0684\n",
      "     18        0.0750  7.0399\n",
      "     19        0.0541  7.0946\n",
      "     20        0.7427  7.0823\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2654\u001b[0m  7.0715\n",
      "      2        \u001b[36m0.0968\u001b[0m  7.0440\n",
      "      3        \u001b[36m0.0517\u001b[0m  7.0643\n",
      "      4        0.0769  7.0473\n",
      "      5        0.2968  7.0611\n",
      "      6        0.4023  7.0669\n",
      "      7        0.3543  7.0813\n",
      "      8        0.2924  7.0525\n",
      "      9        0.0910  7.0542\n",
      "     10        0.0690  7.0502\n",
      "     11        0.2574  7.0518\n",
      "     12        0.1235  7.0802\n",
      "     13        0.1077  7.0812\n",
      "     14        0.1053  7.0580\n",
      "     15        0.0831  7.0757\n",
      "     16        0.1331  7.0688\n",
      "     17        0.0778  7.0212\n",
      "     18        0.0819  7.0779\n",
      "     19        0.1285  7.0161\n",
      "     20        0.0701  7.0815\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2334\u001b[0m  7.0211\n",
      "      2        \u001b[36m0.0884\u001b[0m  7.0636\n",
      "      3        \u001b[36m0.0424\u001b[0m  7.0889\n",
      "      4        0.0511  7.0920\n",
      "      5        0.5952  7.0711\n",
      "      6        0.4846  7.0848\n",
      "      7        0.3924  7.0813\n",
      "      8        0.3422  7.0754\n",
      "      9        0.2199  7.0627\n",
      "     10        0.1254  7.0129\n",
      "     11        0.0859  7.0468\n",
      "     12        0.0737  7.0918\n",
      "     13        0.0647  7.0863\n",
      "     14        0.0675  7.0461\n",
      "     15        0.0653  7.0849\n",
      "     16        0.0557  7.0763\n",
      "     17        0.0591  7.0732\n",
      "     18        0.3112  7.0897\n",
      "     19        0.1375  7.0614\n",
      "     20        0.1171  7.0959\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2726\u001b[0m  7.0567\n",
      "      2        \u001b[36m0.1831\u001b[0m  7.0449\n",
      "      3        \u001b[36m0.0631\u001b[0m  7.0745\n",
      "      4        0.0634  7.0462\n",
      "      5        \u001b[36m0.0410\u001b[0m  7.0452\n",
      "      6        \u001b[36m0.0383\u001b[0m  7.0472\n",
      "      7        0.0481  7.0666\n",
      "      8        0.0835  7.0768\n",
      "      9        0.3681  7.0560\n",
      "     10        0.1802  7.0753\n",
      "     11        0.1326  7.0437\n",
      "     12        0.0965  7.0811\n",
      "     13        0.0889  7.0352\n",
      "     14        0.1027  7.0741\n",
      "     15        0.0647  7.0685\n",
      "     16        0.2328  7.0690\n",
      "     17        0.2255  7.0332\n",
      "     18        0.2092  7.0666\n",
      "     19        0.2108  7.0633\n",
      "     20        0.2044  7.0744\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3725\u001b[0m  7.0686\n",
      "      2        \u001b[36m0.1078\u001b[0m  7.0845\n",
      "      3        \u001b[36m0.0494\u001b[0m  7.0926\n",
      "      4        \u001b[36m0.0333\u001b[0m  7.0344\n",
      "      5        \u001b[36m0.0298\u001b[0m  7.0930\n",
      "      6        0.0379  7.0857\n",
      "      7        0.0730  7.0616\n",
      "      8        0.5303  7.0717\n",
      "      9        0.5576  7.0438\n",
      "     10        0.6005  7.0781\n",
      "     11        0.5971  7.0926\n",
      "     12        0.5077  7.0675\n",
      "     13        0.4815  7.0843\n",
      "     14        0.4390  7.1296\n",
      "     15        0.3183  7.0531\n",
      "     16        0.2723  7.0534\n",
      "     17        0.2109  7.0663\n",
      "     18        0.2513  7.0835\n",
      "     19        0.1795  7.0752\n",
      "     20        0.1013  7.0377\n",
      "[CV]  net__batch_size=32, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2929\u001b[0m  5.1006\n",
      "      2        \u001b[36m0.1876\u001b[0m  5.0733\n",
      "      3        \u001b[36m0.1383\u001b[0m  5.0905\n",
      "      4        \u001b[36m0.0977\u001b[0m  5.1123\n",
      "      5        \u001b[36m0.0727\u001b[0m  5.1098\n",
      "      6        0.1063  5.1628\n",
      "      7        0.2430  5.0842\n",
      "      8        0.1311  5.2101\n",
      "      9        0.0882  5.2079\n",
      "     10        0.0811  5.1248\n",
      "     11        0.0729  5.0751\n",
      "     12        \u001b[36m0.0509\u001b[0m  5.2102\n",
      "     13        0.0556  5.2189\n",
      "     14        0.0521  5.0571\n",
      "     15        \u001b[36m0.0486\u001b[0m  5.1586\n",
      "     16        \u001b[36m0.0400\u001b[0m  5.0593\n",
      "     17        \u001b[36m0.0390\u001b[0m  5.0710\n",
      "     18        \u001b[36m0.0315\u001b[0m  5.2298\n",
      "     19        0.0375  5.1845\n",
      "     20        0.0414  5.2193\n",
      "     21        0.0339  5.2548\n",
      "     22        \u001b[36m0.0298\u001b[0m  5.0829\n",
      "     23        \u001b[36m0.0241\u001b[0m  5.2212\n",
      "     24        0.0338  5.1058\n",
      "     25        0.0351  5.0279\n",
      "     26        0.0285  5.2314\n",
      "     27        0.0253  5.1681\n",
      "     28        0.0281  5.3188\n",
      "     29        0.0319  5.0160\n",
      "     30        0.0278  5.0107\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3199\u001b[0m  5.0079\n",
      "      2        \u001b[36m0.2086\u001b[0m  5.0878\n",
      "      3        \u001b[36m0.1012\u001b[0m  5.1725\n",
      "      4        \u001b[36m0.0628\u001b[0m  5.1774\n",
      "      5        \u001b[36m0.0519\u001b[0m  5.0572\n",
      "      6        \u001b[36m0.0430\u001b[0m  5.2387\n",
      "      7        0.0695  5.1623\n",
      "      8        0.0464  5.0481\n",
      "      9        \u001b[36m0.0318\u001b[0m  5.1918\n",
      "     10        \u001b[36m0.0290\u001b[0m  5.1368\n",
      "     11        0.0358  5.1117\n",
      "     12        0.0293  5.1919\n",
      "     13        0.0299  5.2071\n",
      "     14        0.0314  5.1509\n",
      "     15        0.0341  5.0777\n",
      "     16        0.0627  5.1183\n",
      "     17        0.0414  5.1485\n",
      "     18        0.0444  5.1363\n",
      "     19        0.0412  5.1513\n",
      "     20        0.0388  5.0649\n",
      "     21        0.0394  5.0627\n",
      "     22        0.0541  5.1240\n",
      "     23        0.0433  5.0832\n",
      "     24        0.0345  5.1501\n",
      "     25        0.0337  5.0982\n",
      "     26        0.0398  5.0891\n",
      "     27        0.0355  5.1207\n",
      "     28        \u001b[36m0.0250\u001b[0m  5.0932\n",
      "     29        0.0601  5.0482\n",
      "     30        0.0600  5.1236\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3644\u001b[0m  5.0750\n",
      "      2        \u001b[36m0.1246\u001b[0m  5.1594\n",
      "      3        \u001b[36m0.0880\u001b[0m  5.0665\n",
      "      4        \u001b[36m0.0716\u001b[0m  5.0116\n",
      "      5        \u001b[36m0.0591\u001b[0m  5.0993\n",
      "      6        0.0641  5.0305\n",
      "      7        \u001b[36m0.0511\u001b[0m  5.0687\n",
      "      8        0.0679  5.0539\n",
      "      9        0.0740  5.0189\n",
      "     10        \u001b[36m0.0451\u001b[0m  5.0711\n",
      "     11        \u001b[36m0.0370\u001b[0m  5.0756\n",
      "     12        \u001b[36m0.0367\u001b[0m  5.1359\n",
      "     13        0.0395  5.1087\n",
      "     14        0.0544  5.1321\n",
      "     15        0.0500  5.1080\n",
      "     16        0.0573  5.1194\n",
      "     17        0.0825  5.1960\n",
      "     18        0.1464  5.0630\n",
      "     19        0.0995  5.1116\n",
      "     20        0.0938  5.1025\n",
      "     21        0.1064  5.0998\n",
      "     22        0.1272  5.1448\n",
      "     23        0.1397  5.1197\n",
      "     24        0.1121  5.1364\n",
      "     25        0.1743  5.1145\n",
      "     26        0.2412  5.0296\n",
      "     27        0.1480  5.2112\n",
      "     28        0.1012  5.1219\n",
      "     29        0.1565  5.1292\n",
      "     30        0.1248  5.0279\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2920\u001b[0m  5.1570\n",
      "      2        \u001b[36m0.1466\u001b[0m  5.0843\n",
      "      3        \u001b[36m0.1251\u001b[0m  5.1530\n",
      "      4        0.1508  5.1199\n",
      "      5        \u001b[36m0.0781\u001b[0m  5.1399\n",
      "      6        0.0888  5.0812\n",
      "      7        0.1476  5.1249\n",
      "      8        0.1006  5.1277\n",
      "      9        \u001b[36m0.0656\u001b[0m  5.1221\n",
      "     10        0.1328  5.1019\n",
      "     11        0.0778  5.1478\n",
      "     12        \u001b[36m0.0588\u001b[0m  5.1311\n",
      "     13        \u001b[36m0.0498\u001b[0m  5.0138\n",
      "     14        \u001b[36m0.0431\u001b[0m  5.0515\n",
      "     15        \u001b[36m0.0353\u001b[0m  5.1655\n",
      "     16        \u001b[36m0.0339\u001b[0m  5.1954\n",
      "     17        0.0373  5.0506\n",
      "     18        \u001b[36m0.0330\u001b[0m  5.2074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19        0.0338  5.1183\n",
      "     20        \u001b[36m0.0290\u001b[0m  5.1416\n",
      "     21        0.0380  5.0922\n",
      "     22        \u001b[36m0.0288\u001b[0m  5.0101\n",
      "     23        \u001b[36m0.0255\u001b[0m  5.0378\n",
      "     24        0.0295  5.1297\n",
      "     25        \u001b[36m0.0233\u001b[0m  5.1533\n",
      "     26        0.0261  5.0766\n",
      "     27        0.0234  5.0130\n",
      "     28        0.0247  5.1331\n",
      "     29        0.0243  5.1980\n",
      "     30        0.0266  5.0901\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2777\u001b[0m  5.0262\n",
      "      2        \u001b[36m0.1377\u001b[0m  5.0457\n",
      "      3        \u001b[36m0.1006\u001b[0m  5.1409\n",
      "      4        \u001b[36m0.0860\u001b[0m  5.1381\n",
      "      5        \u001b[36m0.0701\u001b[0m  5.1332\n",
      "      6        \u001b[36m0.0479\u001b[0m  5.0475\n",
      "      7        \u001b[36m0.0397\u001b[0m  5.1391\n",
      "      8        0.0422  5.0630\n",
      "      9        0.0477  5.1227\n",
      "     10        \u001b[36m0.0379\u001b[0m  5.0653\n",
      "     11        \u001b[36m0.0362\u001b[0m  5.1401\n",
      "     12        \u001b[36m0.0269\u001b[0m  5.1456\n",
      "     13        0.0543  5.1104\n",
      "     14        0.0412  5.1209\n",
      "     15        0.0310  5.0088\n",
      "     16        0.0290  5.1376\n",
      "     17        0.0444  5.1450\n",
      "     18        0.0387  5.1484\n",
      "     19        0.1308  5.2301\n",
      "     20        0.0924  5.1526\n",
      "     21        0.0634  5.1295\n",
      "     22        0.1159  5.0563\n",
      "     23        0.1109  5.1151\n",
      "     24        0.1500  5.1002\n",
      "     25        0.0751  5.0707\n",
      "     26        0.0797  5.0724\n",
      "     27        0.0907  5.1201\n",
      "     28        0.0794  5.0417\n",
      "     29        0.0496  5.1274\n",
      "     30        0.0607  5.0870\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2790\u001b[0m  5.6807\n",
      "      2        \u001b[36m0.1297\u001b[0m  5.7700\n",
      "      3        \u001b[36m0.0624\u001b[0m  5.6566\n",
      "      4        0.0715  5.7235\n",
      "      5        0.1013  5.6702\n",
      "      6        \u001b[36m0.0484\u001b[0m  5.7009\n",
      "      7        \u001b[36m0.0355\u001b[0m  5.6768\n",
      "      8        \u001b[36m0.0300\u001b[0m  5.6492\n",
      "      9        \u001b[36m0.0275\u001b[0m  5.7442\n",
      "     10        \u001b[36m0.0227\u001b[0m  5.7606\n",
      "     11        0.0262  5.6968\n",
      "     12        0.0429  5.6760\n",
      "     13        0.0446  5.6156\n",
      "     14        0.0312  5.7430\n",
      "     15        0.0255  5.6900\n",
      "     16        0.0651  5.7078\n",
      "     17        0.0626  5.6277\n",
      "     18        0.0446  5.6705\n",
      "     19        0.0537  5.6972\n",
      "     20        0.4576  5.7084\n",
      "     21        0.4932  5.6873\n",
      "     22        0.4210  5.7221\n",
      "     23        0.3527  5.7148\n",
      "     24        0.3366  5.6262\n",
      "     25        0.7057  5.8184\n",
      "     26        0.4861  5.7521\n",
      "     27        0.4279  5.6483\n",
      "     28        0.4131  5.6615\n",
      "     29        0.5843  5.6969\n",
      "     30        0.5257  5.7188\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2778\u001b[0m  5.7260\n",
      "      2        \u001b[36m0.1026\u001b[0m  5.6653\n",
      "      3        0.2347  5.7141\n",
      "      4        0.1168  5.6839\n",
      "      5        \u001b[36m0.0537\u001b[0m  5.7942\n",
      "      6        \u001b[36m0.0368\u001b[0m  5.6390\n",
      "      7        0.0451  5.6895\n",
      "      8        0.0523  5.7439\n",
      "      9        0.0430  5.7085\n",
      "     10        \u001b[36m0.0329\u001b[0m  5.6714\n",
      "     11        \u001b[36m0.0213\u001b[0m  5.7162\n",
      "     12        0.0246  5.6749\n",
      "     13        0.0232  5.7137\n",
      "     14        0.0253  5.7072\n",
      "     15        0.0514  5.6333\n",
      "     16        0.2112  5.6803\n",
      "     17        0.4522  5.7562\n",
      "     18        0.6254  5.6731\n",
      "     19        0.5841  5.6008\n",
      "     20        0.5801  5.5968\n",
      "     21        0.5988  5.7146\n",
      "     22        0.5506  5.7014\n",
      "     23        0.5050  5.6732\n",
      "     24        0.4837  5.8042\n",
      "     25        0.4067  5.6942\n",
      "     26        0.2965  5.6924\n",
      "     27        0.2024  5.6776\n",
      "     28        0.1354  5.7306\n",
      "     29        0.1292  5.7876\n",
      "     30        0.1020  5.6846\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2719\u001b[0m  5.6396\n",
      "      2        \u001b[36m0.1254\u001b[0m  5.7704\n",
      "      3        0.4428  5.7515\n",
      "      4        0.1673  5.7348\n",
      "      5        \u001b[36m0.1088\u001b[0m  5.7857\n",
      "      6        \u001b[36m0.0659\u001b[0m  5.7849\n",
      "      7        0.2376  5.7562\n",
      "      8        \u001b[36m0.0505\u001b[0m  5.8160\n",
      "      9        \u001b[36m0.0406\u001b[0m  5.6533\n",
      "     10        0.0480  5.6826\n",
      "     11        \u001b[36m0.0404\u001b[0m  5.6830\n",
      "     12        0.0567  5.7724\n",
      "     13        0.0506  5.8024\n",
      "     14        \u001b[36m0.0400\u001b[0m  5.8373\n",
      "     15        \u001b[36m0.0264\u001b[0m  5.8215\n",
      "     16        0.0269  5.7182\n",
      "     17        \u001b[36m0.0241\u001b[0m  5.6773\n",
      "     18        \u001b[36m0.0181\u001b[0m  5.7900\n",
      "     19        0.0279  5.6245\n",
      "     20        \u001b[36m0.0168\u001b[0m  5.7884\n",
      "     21        \u001b[36m0.0145\u001b[0m  5.7314\n",
      "     22        0.0220  5.7347\n",
      "     23        \u001b[36m0.0135\u001b[0m  5.6644\n",
      "     24        0.0199  5.6072\n",
      "     25        \u001b[36m0.0130\u001b[0m  5.5970\n",
      "     26        0.0285  5.8351\n",
      "     27        0.0241  5.7530\n",
      "     28        0.0307  5.6992\n",
      "     29        0.0201  5.6822\n",
      "     30        \u001b[36m0.0126\u001b[0m  5.7990\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2976\u001b[0m  5.6657\n",
      "      2        \u001b[36m0.1254\u001b[0m  5.6056\n",
      "      3        \u001b[36m0.0467\u001b[0m  5.7880\n",
      "      4        \u001b[36m0.0325\u001b[0m  5.6734\n",
      "      5        \u001b[36m0.0279\u001b[0m  5.7447\n",
      "      6        \u001b[36m0.0273\u001b[0m  5.7527\n",
      "      7        \u001b[36m0.0217\u001b[0m  5.7595\n",
      "      8        0.0288  5.7188\n",
      "      9        \u001b[36m0.0194\u001b[0m  5.6745\n",
      "     10        0.0226  5.6840\n",
      "     11        0.0269  5.6736\n",
      "     12        0.2379  5.7821\n",
      "     13        0.1865  5.6041\n",
      "     14        0.2621  5.7330\n",
      "     15        0.2096  5.7043\n",
      "     16        0.1432  5.6918\n",
      "     17        0.0991  5.7138\n",
      "     18        0.0649  5.5954\n",
      "     19        0.0544  5.7113\n",
      "     20        0.0554  5.7376\n",
      "     21        0.1044  5.7349\n",
      "     22        0.1310  5.7092\n",
      "     23        0.1286  5.6165\n",
      "     24        0.0713  5.6173\n",
      "     25        0.1935  5.6016\n",
      "     26        0.0791  6.0697\n",
      "     27        0.0739  5.7102\n",
      "     28        0.5687  5.7922\n",
      "     29        0.4677  5.6687\n",
      "     30        0.4505  5.7358\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3069\u001b[0m  5.6419\n",
      "      2        \u001b[36m0.0615\u001b[0m  5.6289\n",
      "      3        \u001b[36m0.0406\u001b[0m  5.6846\n",
      "      4        \u001b[36m0.0361\u001b[0m  5.6930\n",
      "      5        \u001b[36m0.0222\u001b[0m  5.6657\n",
      "      6        0.0223  5.6063\n",
      "      7        \u001b[36m0.0212\u001b[0m  5.7102\n",
      "      8        0.0214  5.7010\n",
      "      9        \u001b[36m0.0175\u001b[0m  5.6716\n",
      "     10        0.0211  5.6370\n",
      "     11        0.0240  5.7057\n",
      "     12        \u001b[36m0.0145\u001b[0m  5.7362\n",
      "     13        0.0393  5.6488\n",
      "     14        0.2192  5.6981\n",
      "     15        0.1857  5.7420\n",
      "     16        0.4744  5.7320\n",
      "     17        0.3582  5.6584\n",
      "     18        0.2802  5.7000\n",
      "     19        0.2207  5.7591\n",
      "     20        0.1606  5.7097\n",
      "     21        0.0998  5.7112\n",
      "     22        0.2487  5.6899\n",
      "     23        0.3512  5.6505\n",
      "     24        0.2318  5.7548\n",
      "     25        0.1016  5.6090\n",
      "     26        0.0803  5.6733\n",
      "     27        0.0671  5.6701\n",
      "     28        0.0565  5.6757\n",
      "     29        0.0870  5.7965\n",
      "     30        0.0411  5.6986\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2259\u001b[0m  8.7120\n",
      "      2        \u001b[36m0.0832\u001b[0m  8.7160\n",
      "      3        \u001b[36m0.0545\u001b[0m  8.7097\n",
      "      4        0.4038  8.7285\n",
      "      5        0.5437  8.7385\n",
      "      6        0.4670  8.7428\n",
      "      7        0.4327  8.7175\n",
      "      8        0.3611  8.7167\n",
      "      9        0.3651  8.7094\n",
      "     10        0.3804  8.7328\n",
      "     11        0.2970  8.6740\n",
      "     12        0.2365  8.6776\n",
      "     13        0.7790  8.7145\n",
      "     14        0.6834  8.7095\n",
      "     15        0.6602  8.7296\n",
      "     16        0.6293  8.7350\n",
      "     17        0.5772  8.7299\n",
      "     18        0.5061  8.7118\n",
      "     19        0.5380  8.7255\n",
      "     20        0.2940  8.7313\n",
      "     21        0.1656  8.7160\n",
      "     22        0.4043  8.6946\n",
      "     23        0.4843  8.7188\n",
      "     24        0.3834  8.7357\n",
      "     25        0.6606  8.7275\n",
      "     26        0.6539  8.7275\n",
      "     27        0.6277  8.7263\n",
      "     28        0.6439  8.7164\n",
      "     29        0.6058  8.7331\n",
      "     30        0.5719  8.7405\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2450\u001b[0m  8.7133\n",
      "      2        \u001b[36m0.0531\u001b[0m  8.7223\n",
      "      3        0.0566  8.7441\n",
      "      4        \u001b[36m0.0354\u001b[0m  8.7478\n",
      "      5        0.0766  8.7365\n",
      "      6        \u001b[36m0.0345\u001b[0m  8.7372\n",
      "      7        \u001b[36m0.0257\u001b[0m  8.7460\n",
      "      8        0.0517  8.7361\n",
      "      9        0.0288  8.7226\n",
      "     10        0.0278  8.7050\n",
      "     11        0.0475  8.7287\n",
      "     12        0.0261  8.7183\n",
      "     13        \u001b[36m0.0218\u001b[0m  8.7360\n",
      "     14        0.0222  8.7298\n",
      "     15        \u001b[36m0.0185\u001b[0m  8.7391\n",
      "     16        0.3318  8.7286\n",
      "     17        0.4405  8.7374\n",
      "     18        0.2958  8.7250\n",
      "     19        0.4540  8.7308\n",
      "     20        0.2711  8.7355\n",
      "     21        0.2914  8.7238\n",
      "     22        0.1780  8.7321\n",
      "     23        0.1335  8.7434\n",
      "     24        0.1523  8.7333\n",
      "     25        0.2261  8.7397\n",
      "     26        0.1150  8.7283\n",
      "     27        0.0834  8.7239\n",
      "     28        0.0815  8.7457\n",
      "     29        0.1014  8.7392\n",
      "     30        0.0933  8.6854\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2246\u001b[0m  8.7363\n",
      "      2        \u001b[36m0.1853\u001b[0m  8.7188\n",
      "      3        0.2841  8.7156\n",
      "      4        0.3515  8.7290\n",
      "      5        0.2757  8.7207\n",
      "      6        \u001b[36m0.1049\u001b[0m  8.7061\n",
      "      7        \u001b[36m0.0943\u001b[0m  8.7338\n",
      "      8        \u001b[36m0.0656\u001b[0m  8.7184\n",
      "      9        \u001b[36m0.0452\u001b[0m  8.7281\n",
      "     10        \u001b[36m0.0389\u001b[0m  8.7327\n",
      "     11        \u001b[36m0.0334\u001b[0m  8.7401\n",
      "     12        \u001b[36m0.0328\u001b[0m  8.7211\n",
      "     13        0.0558  8.7309\n",
      "     14        0.1481  8.7414\n",
      "     15        0.6408  8.7478\n",
      "     16        0.5474  8.7186\n",
      "     17        0.4494  8.7352\n",
      "     18        0.3922  8.7524\n",
      "     19        0.3248  8.7407\n",
      "     20        0.2587  8.7500\n",
      "     21        0.3179  8.7319\n",
      "     22        0.2963  8.7321\n",
      "     23        0.2612  8.7280\n",
      "     24        0.2931  8.7347\n",
      "     25        0.2307  8.7355\n",
      "     26        0.2005  8.7390\n",
      "     27        0.5422  8.7329\n",
      "     28        0.6351  8.7330\n",
      "     29        0.4166  8.7280\n",
      "     30        0.3324  8.7354\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2353\u001b[0m  8.7340\n",
      "      2        \u001b[36m0.0824\u001b[0m  8.7163\n",
      "      3        \u001b[36m0.0442\u001b[0m  8.7499\n",
      "      4        0.3513  8.7001\n",
      "      5        0.2332  8.7195\n",
      "      6        0.1115  8.7192\n",
      "      7        0.1320  8.7234\n",
      "      8        0.0992  8.7427\n",
      "      9        0.0484  8.7421\n",
      "     10        \u001b[36m0.0413\u001b[0m  8.7268\n",
      "     11        0.0469  8.7331\n",
      "     12        0.0439  8.7411\n",
      "     13        0.0549  8.7213\n",
      "     14        \u001b[36m0.0292\u001b[0m  8.7315\n",
      "     15        \u001b[36m0.0237\u001b[0m  8.7117\n",
      "     16        \u001b[36m0.0229\u001b[0m  8.7196\n",
      "     17        0.0236  8.7199\n",
      "     18        0.0250  8.7190\n",
      "     19        0.0242  8.6991\n",
      "     20        0.0230  8.7319\n",
      "     21        \u001b[36m0.0216\u001b[0m  8.7413\n",
      "     22        0.4815  8.7224\n",
      "     23        0.5924  8.7204\n",
      "     24        0.5789  8.7328\n",
      "     25        0.5907  8.7410\n",
      "     26        0.5599  8.7287\n",
      "     27        0.6519  8.7422\n",
      "     28        0.5975  8.6914\n",
      "     29        0.6240  8.7209\n",
      "     30        0.5931  8.7243\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2649\u001b[0m  8.7479\n",
      "      2        \u001b[36m0.1113\u001b[0m  8.7363\n",
      "      3        0.1722  8.7323\n",
      "      4        0.2334  8.7297\n",
      "      5        0.1148  8.7290\n",
      "      6        0.1113  8.7408\n",
      "      7        \u001b[36m0.0744\u001b[0m  8.7244\n",
      "      8        0.1299  8.7429\n",
      "      9        \u001b[36m0.0482\u001b[0m  8.7146\n",
      "     10        \u001b[36m0.0354\u001b[0m  8.7390\n",
      "     11        \u001b[36m0.0312\u001b[0m  8.7304\n",
      "     12        \u001b[36m0.0259\u001b[0m  8.7235\n",
      "     13        0.0322  8.7313\n",
      "     14        0.0288  8.7374\n",
      "     15        0.1942  8.7368\n",
      "     16        0.0577  8.7383\n",
      "     17        0.0427  8.7462\n",
      "     18        0.0353  8.7475\n",
      "     19        0.0283  8.7467\n",
      "     20        0.0263  8.6786\n",
      "     21        0.0310  8.7300\n",
      "     22        0.0276  8.7131\n",
      "     23        0.0369  8.7473\n",
      "     24        0.0264  8.6869\n",
      "     25        \u001b[36m0.0221\u001b[0m  8.7388\n",
      "     26        0.1094  8.7292\n",
      "     27        0.0967  8.7338\n",
      "     28        0.0812  8.6768\n",
      "     29        0.1319  8.7297\n",
      "     30        0.2341  8.7257\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2875\u001b[0m  6.9952\n",
      "      2        \u001b[36m0.0792\u001b[0m  7.0021\n",
      "      3        \u001b[36m0.0483\u001b[0m  7.0054\n",
      "      4        \u001b[36m0.0406\u001b[0m  7.0286\n",
      "      5        \u001b[36m0.0271\u001b[0m  7.0038\n",
      "      6        0.0364  7.0304\n",
      "      7        0.0437  7.0378\n",
      "      8        \u001b[36m0.0213\u001b[0m  7.0393\n",
      "      9        0.0215  7.0110\n",
      "     10        \u001b[36m0.0202\u001b[0m  7.0462\n",
      "     11        0.1497  7.0303\n",
      "     12        0.2517  7.0504\n",
      "     13        0.1534  7.0854\n",
      "     14        0.1611  7.0704\n",
      "     15        0.1890  7.0302\n",
      "     16        0.0852  7.0779\n",
      "     17        0.0920  7.0731\n",
      "     18        0.3473  7.0327\n",
      "     19        0.2956  7.0717\n",
      "     20        0.2237  7.0745\n",
      "     21        0.5460  7.0837\n",
      "     22        0.5011  7.0797\n",
      "     23        0.4834  7.0643\n",
      "     24        0.5079  7.0543\n",
      "     25        0.5438  7.0655\n",
      "     26        0.5329  7.0438\n",
      "     27        0.5200  7.0447\n",
      "     28        0.4770  7.0389\n",
      "     29        0.3739  7.0676\n",
      "     30        0.2798  7.0919\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5231\u001b[0m  7.0492\n",
      "      2        \u001b[36m0.2061\u001b[0m  7.0797\n",
      "      3        \u001b[36m0.0647\u001b[0m  7.0763\n",
      "      4        \u001b[36m0.0461\u001b[0m  7.0347\n",
      "      5        \u001b[36m0.0350\u001b[0m  7.0712\n",
      "      6        \u001b[36m0.0342\u001b[0m  7.0838\n",
      "      7        \u001b[36m0.0294\u001b[0m  7.0594\n",
      "      8        0.0308  7.0904\n",
      "      9        0.0761  7.0681\n",
      "     10        0.1848  7.0883\n",
      "     11        0.0753  7.0826\n",
      "     12        0.2547  7.0656\n",
      "     13        0.1579  7.0516\n",
      "     14        0.0926  7.0762\n",
      "     15        0.0875  7.0455\n",
      "     16        0.0770  7.0920\n",
      "     17        0.0634  7.0733\n",
      "     18        0.0643  7.0406\n",
      "     19        0.0653  7.0434\n",
      "     20        0.0447  7.0199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     21        0.0409  7.0698\n",
      "     22        0.0463  7.0492\n",
      "     23        0.0681  7.0820\n",
      "     24        0.0840  7.0695\n",
      "     25        0.0341  7.0437\n",
      "     26        0.0430  7.0757\n",
      "     27        \u001b[36m0.0257\u001b[0m  7.0547\n",
      "     28        0.0332  7.1007\n",
      "     29        0.1158  7.0696\n",
      "     30        0.1281  7.0741\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3269\u001b[0m  7.0593\n",
      "      2        0.3524  7.0520\n",
      "      3        \u001b[36m0.1311\u001b[0m  7.0493\n",
      "      4        \u001b[36m0.1069\u001b[0m  7.0854\n",
      "      5        \u001b[36m0.0628\u001b[0m  7.0462\n",
      "      6        \u001b[36m0.0528\u001b[0m  7.0832\n",
      "      7        \u001b[36m0.0505\u001b[0m  7.0361\n",
      "      8        0.0780  7.0554\n",
      "      9        0.0695  7.0753\n",
      "     10        0.6356  7.0832\n",
      "     11        0.4021  7.0422\n",
      "     12        0.2743  7.0550\n",
      "     13        0.2013  7.0647\n",
      "     14        0.1421  7.0500\n",
      "     15        0.1578  7.0953\n",
      "     16        0.0758  7.0728\n",
      "     17        0.0565  7.0816\n",
      "     18        \u001b[36m0.0449\u001b[0m  7.0599\n",
      "     19        0.0563  7.0874\n",
      "     20        0.0917  7.0674\n",
      "     21        0.0653  7.0672\n",
      "     22        0.1004  7.0740\n",
      "     23        0.0668  7.0598\n",
      "     24        \u001b[36m0.0357\u001b[0m  7.0576\n",
      "     25        0.0387  7.0375\n",
      "     26        0.0489  7.0714\n",
      "     27        \u001b[36m0.0260\u001b[0m  7.0470\n",
      "     28        \u001b[36m0.0242\u001b[0m  7.0777\n",
      "     29        \u001b[36m0.0235\u001b[0m  7.0691\n",
      "     30        \u001b[36m0.0197\u001b[0m  7.0643\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2431\u001b[0m  7.0936\n",
      "      2        \u001b[36m0.1569\u001b[0m  7.0502\n",
      "      3        \u001b[36m0.0541\u001b[0m  7.0749\n",
      "      4        0.1102  7.0435\n",
      "      5        0.1989  7.0724\n",
      "      6        0.1261  7.0491\n",
      "      7        0.1135  7.0536\n",
      "      8        0.2064  7.0556\n",
      "      9        0.4705  7.0697\n",
      "     10        0.2542  7.0825\n",
      "     11        0.1642  7.0312\n",
      "     12        0.1083  7.0575\n",
      "     13        0.0857  7.0802\n",
      "     14        0.0860  7.0504\n",
      "     15        0.2773  7.0708\n",
      "     16        0.3750  7.0982\n",
      "     17        0.2470  7.0725\n",
      "     18        0.3042  7.0942\n",
      "     19        0.1934  7.0700\n",
      "     20        0.1435  7.0762\n",
      "     21        0.1095  7.0522\n",
      "     22        0.0972  7.0509\n",
      "     23        0.0953  7.0520\n",
      "     24        0.1314  7.0711\n",
      "     25        0.2558  7.0338\n",
      "     26        0.1482  7.0887\n",
      "     27        0.6958  7.0481\n",
      "     28        0.5000  7.0761\n",
      "     29        0.4831  7.0204\n",
      "     30        0.5528  7.0496\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4283\u001b[0m  7.0920\n",
      "      2        \u001b[36m0.2532\u001b[0m  7.0644\n",
      "      3        \u001b[36m0.1582\u001b[0m  7.0218\n",
      "      4        \u001b[36m0.0868\u001b[0m  7.0415\n",
      "      5        \u001b[36m0.0579\u001b[0m  7.0852\n",
      "      6        \u001b[36m0.0452\u001b[0m  7.0575\n",
      "      7        \u001b[36m0.0401\u001b[0m  7.0800\n",
      "      8        \u001b[36m0.0334\u001b[0m  7.0734\n",
      "      9        0.0945  7.0527\n",
      "     10        0.0373  7.0690\n",
      "     11        \u001b[36m0.0299\u001b[0m  7.0538\n",
      "     12        \u001b[36m0.0257\u001b[0m  7.0405\n",
      "     13        0.0268  7.0473\n",
      "     14        0.0300  7.0779\n",
      "     15        0.0270  7.0841\n",
      "     16        0.0268  7.0804\n",
      "     17        0.0261  7.0560\n",
      "     18        \u001b[36m0.0193\u001b[0m  7.0683\n",
      "     19        0.0253  7.0628\n",
      "     20        0.1354  7.0511\n",
      "     21        0.0959  7.0606\n",
      "     22        0.2618  7.0655\n",
      "     23        0.3591  7.0369\n",
      "     24        0.2208  7.0719\n",
      "     25        0.1026  7.0765\n",
      "     26        0.0622  7.0836\n",
      "     27        0.0594  7.0560\n",
      "     28        0.0453  7.0902\n",
      "     29        0.0398  7.0756\n",
      "     30        0.0318  7.0462\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2983\u001b[0m  5.1654\n",
      "      2        \u001b[36m0.1132\u001b[0m  5.1349\n",
      "      3        \u001b[36m0.0831\u001b[0m  5.0900\n",
      "      4        \u001b[36m0.0566\u001b[0m  5.1241\n",
      "      5        \u001b[36m0.0470\u001b[0m  5.0537\n",
      "      6        0.0471  5.0911\n",
      "      7        0.0483  5.1374\n",
      "      8        \u001b[36m0.0341\u001b[0m  5.1699\n",
      "      9        \u001b[36m0.0314\u001b[0m  5.0555\n",
      "     10        0.0363  5.1498\n",
      "     11        \u001b[36m0.0303\u001b[0m  5.1602\n",
      "     12        0.0322  5.1031\n",
      "     13        0.0312  5.1432\n",
      "     14        \u001b[36m0.0213\u001b[0m  5.0367\n",
      "     15        0.0290  5.1597\n",
      "     16        \u001b[36m0.0204\u001b[0m  5.1464\n",
      "     17        0.0251  5.1153\n",
      "     18        0.0229  5.1046\n",
      "     19        0.0235  5.1532\n",
      "     20        0.0245  5.0953\n",
      "     21        0.0234  5.0479\n",
      "     22        0.0581  5.2304\n",
      "     23        0.0548  5.1154\n",
      "     24        0.0543  5.1374\n",
      "     25        0.0409  5.0935\n",
      "     26        0.0318  5.1443\n",
      "     27        0.0271  5.1537\n",
      "     28        0.0394  5.1063\n",
      "     29        0.0304  5.1693\n",
      "     30        0.0282  5.0495\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3003\u001b[0m  5.1113\n",
      "      2        \u001b[36m0.2853\u001b[0m  5.1261\n",
      "      3        \u001b[36m0.1425\u001b[0m  5.0884\n",
      "      4        0.1860  5.0541\n",
      "      5        \u001b[36m0.1079\u001b[0m  5.1718\n",
      "      6        \u001b[36m0.0935\u001b[0m  5.1152\n",
      "      7        \u001b[36m0.0784\u001b[0m  5.1419\n",
      "      8        0.1735  5.1552\n",
      "      9        0.0996  5.1229\n",
      "     10        \u001b[36m0.0777\u001b[0m  5.1200\n",
      "     11        \u001b[36m0.0710\u001b[0m  5.0667\n",
      "     12        \u001b[36m0.0647\u001b[0m  5.1252\n",
      "     13        \u001b[36m0.0555\u001b[0m  5.0769\n",
      "     14        0.0617  5.1147\n",
      "     15        \u001b[36m0.0525\u001b[0m  5.1129\n",
      "     16        \u001b[36m0.0497\u001b[0m  5.1527\n",
      "     17        \u001b[36m0.0482\u001b[0m  5.0633\n",
      "     18        0.1411  5.0965\n",
      "     19        0.0714  5.1557\n",
      "     20        0.0517  5.1265\n",
      "     21        0.0504  5.0836\n",
      "     22        0.1387  5.0235\n",
      "     23        0.4197  5.0164\n",
      "     24        0.3787  5.1126\n",
      "     25        0.4124  5.2383\n",
      "     26        0.3827  5.1087\n",
      "     27        0.3497  5.1562\n",
      "     28        0.3605  5.1239\n",
      "     29        0.3412  5.0657\n",
      "     30        0.3326  5.1541\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3260\u001b[0m  5.0689\n",
      "      2        \u001b[36m0.2010\u001b[0m  5.1356\n",
      "      3        \u001b[36m0.1347\u001b[0m  5.1632\n",
      "      4        \u001b[36m0.1230\u001b[0m  5.1123\n",
      "      5        \u001b[36m0.1110\u001b[0m  5.1416\n",
      "      6        \u001b[36m0.0916\u001b[0m  5.1476\n",
      "      7        \u001b[36m0.0819\u001b[0m  5.1157\n",
      "      8        \u001b[36m0.0609\u001b[0m  5.1264\n",
      "      9        \u001b[36m0.0496\u001b[0m  5.0690\n",
      "     10        0.0614  5.1048\n",
      "     11        \u001b[36m0.0433\u001b[0m  5.1572\n",
      "     12        0.0442  5.1374\n",
      "     13        \u001b[36m0.0423\u001b[0m  5.1553\n",
      "     14        0.0474  5.2399\n",
      "     15        0.0485  5.0698\n",
      "     16        0.0486  5.1154\n",
      "     17        0.2861  5.0909\n",
      "     18        0.2696  5.0826\n",
      "     19        0.2185  5.1370\n",
      "     20        0.1679  5.1334\n",
      "     21        0.1491  5.1047\n",
      "     22        0.1970  5.0628\n",
      "     23        0.2026  5.1561\n",
      "     24        0.1604  5.0425\n",
      "     25        0.2241  5.0821\n",
      "     26        0.1971  5.0196\n",
      "     27        0.2121  5.1813\n",
      "     28        0.4171  5.1202\n",
      "     29        0.4379  5.1154\n",
      "     30        0.3631  5.0847\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3101\u001b[0m  5.0893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.1654\u001b[0m  5.0996\n",
      "      3        0.3577  5.1389\n",
      "      4        0.1925  5.2046\n",
      "      5        \u001b[36m0.1247\u001b[0m  5.0472\n",
      "      6        0.2149  5.1345\n",
      "      7        \u001b[36m0.0986\u001b[0m  5.1361\n",
      "      8        \u001b[36m0.0830\u001b[0m  5.2448\n",
      "      9        \u001b[36m0.0748\u001b[0m  5.2030\n",
      "     10        \u001b[36m0.0634\u001b[0m  5.2001\n",
      "     11        0.0917  5.1630\n",
      "     12        0.0653  5.0931\n",
      "     13        \u001b[36m0.0550\u001b[0m  5.2084\n",
      "     14        0.0552  5.1831\n",
      "     15        \u001b[36m0.0414\u001b[0m  5.0640\n",
      "     16        0.1640  5.0385\n",
      "     17        0.1622  5.1230\n",
      "     18        0.3331  5.1641\n",
      "     19        0.5343  5.1558\n",
      "     20        0.4352  5.0734\n",
      "     21        0.3740  5.1301\n",
      "     22        0.3236  5.0461\n",
      "     23        0.2747  5.0875\n",
      "     24        0.2360  5.1473\n",
      "     25        0.2032  5.1132\n",
      "     26        0.1707  5.0788\n",
      "     27        0.1611  5.0920\n",
      "     28        0.1399  5.0742\n",
      "     29        0.1278  5.0829\n",
      "     30        0.1283  5.1216\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2886\u001b[0m  5.0418\n",
      "      2        \u001b[36m0.1520\u001b[0m  5.1071\n",
      "      3        \u001b[36m0.1041\u001b[0m  5.0900\n",
      "      4        \u001b[36m0.0774\u001b[0m  5.1080\n",
      "      5        \u001b[36m0.0705\u001b[0m  5.0563\n",
      "      6        \u001b[36m0.0613\u001b[0m  5.0913\n",
      "      7        \u001b[36m0.0519\u001b[0m  5.1776\n",
      "      8        \u001b[36m0.0504\u001b[0m  5.1148\n",
      "      9        \u001b[36m0.0476\u001b[0m  5.0817\n",
      "     10        0.0476  5.1423\n",
      "     11        \u001b[36m0.0368\u001b[0m  5.1789\n",
      "     12        0.0438  5.2369\n",
      "     13        0.0590  5.0256\n",
      "     14        0.0525  5.1400\n",
      "     15        0.1402  5.1224\n",
      "     16        0.2299  5.0326\n",
      "     17        0.1301  5.0976\n",
      "     18        0.3178  5.1272\n",
      "     19        0.1745  5.0184\n",
      "     20        0.2982  5.1007\n",
      "     21        0.4427  5.0155\n",
      "     22        0.4756  5.1244\n",
      "     23        0.4704  5.1240\n",
      "     24        0.4927  5.0572\n",
      "     25        0.4895  5.1411\n",
      "     26        0.4872  5.1478\n",
      "     27        0.4966  5.0258\n",
      "     28        0.4919  5.1019\n",
      "     29        0.5214  5.0864\n",
      "     30        0.5240  5.1628\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2619\u001b[0m  5.6913\n",
      "      2        \u001b[36m0.1277\u001b[0m  5.8291\n",
      "      3        \u001b[36m0.0515\u001b[0m  5.6730\n",
      "      4        \u001b[36m0.0450\u001b[0m  5.7174\n",
      "      5        0.1018  5.6393\n",
      "      6        0.0815  5.6658\n",
      "      7        0.1031  5.7257\n",
      "      8        0.1169  5.7512\n",
      "      9        0.0947  5.6332\n",
      "     10        0.1009  5.7274\n",
      "     11        0.0601  5.8435\n",
      "     12        0.5192  5.6078\n",
      "     13        0.4929  5.5929\n",
      "     14        0.4232  5.7243\n",
      "     15        0.2709  5.7136\n",
      "     16        0.2473  5.7229\n",
      "     17        0.2128  5.7080\n",
      "     18        0.1558  5.6784\n",
      "     19        0.2444  5.6980\n",
      "     20        0.1487  5.6536\n",
      "     21        0.0962  5.6562\n",
      "     22        0.0953  5.6311\n",
      "     23        0.0985  5.6702\n",
      "     24        0.3323  5.7111\n",
      "     25        0.2076  5.6514\n",
      "     26        0.1461  5.6102\n",
      "     27        0.1176  5.6244\n",
      "     28        0.1364  5.6221\n",
      "     29        0.0976  5.7381\n",
      "     30        0.2830  5.8519\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2261\u001b[0m  5.8264\n",
      "      2        \u001b[36m0.0849\u001b[0m  5.7677\n",
      "      3        \u001b[36m0.0450\u001b[0m  5.7587\n",
      "      4        \u001b[36m0.0341\u001b[0m  5.6876\n",
      "      5        0.0365  5.7796\n",
      "      6        \u001b[36m0.0272\u001b[0m  5.7601\n",
      "      7        0.0282  5.5954\n",
      "      8        0.3535  5.7077\n",
      "      9        0.6380  5.6948\n",
      "     10        0.6622  5.6478\n",
      "     11        0.6365  5.6858\n",
      "     12        0.6193  5.7568\n",
      "     13        0.6541  5.6619\n",
      "     14        0.6005  5.7117\n",
      "     15        0.7564  5.6455\n",
      "     16        0.5782  5.5954\n",
      "     17        0.6135  5.6144\n",
      "     18        0.5780  5.6782\n",
      "     19        0.4960  5.6871\n",
      "     20        0.3836  5.6278\n",
      "     21        0.3251  5.8114\n",
      "     22        0.2775  5.7626\n",
      "     23        0.2457  5.7267\n",
      "     24        0.2764  5.6763\n",
      "     25        0.3753  5.7025\n",
      "     26        0.5970  5.7190\n",
      "     27        0.5974  5.6339\n",
      "     28        0.6492  5.6443\n",
      "     29        0.6162  5.6333\n",
      "     30        0.5448  5.6379\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2514\u001b[0m  5.6865\n",
      "      2        \u001b[36m0.1493\u001b[0m  5.7445\n",
      "      3        \u001b[36m0.0637\u001b[0m  5.7834\n",
      "      4        \u001b[36m0.0375\u001b[0m  5.6439\n",
      "      5        \u001b[36m0.0318\u001b[0m  5.6368\n",
      "      6        0.0325  5.6224\n",
      "      7        \u001b[36m0.0294\u001b[0m  5.7708\n",
      "      8        \u001b[36m0.0211\u001b[0m  5.6436\n",
      "      9        0.0266  5.6359\n",
      "     10        \u001b[36m0.0178\u001b[0m  5.6416\n",
      "     11        0.0195  5.6911\n",
      "     12        \u001b[36m0.0149\u001b[0m  5.7036\n",
      "     13        0.0289  5.7172\n",
      "     14        0.4136  5.7004\n",
      "     15        0.5973  5.6979\n",
      "     16        0.5998  5.5957\n",
      "     17        0.6033  5.6703\n",
      "     18        0.6096  5.6534\n",
      "     19        0.5997  5.7281\n",
      "     20        0.6016  5.6956\n",
      "     21        0.6375  5.6376\n",
      "     22        0.6312  5.8294\n",
      "     23        0.6164  5.7040\n",
      "     24        0.6389  5.6909\n",
      "     25        0.6183  5.7267\n",
      "     26        0.6092  5.7040\n",
      "     27        0.5632  5.6617\n",
      "     28        0.4970  5.6141\n",
      "     29        0.4160  5.6616\n",
      "     30        0.3909  5.7390\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2992\u001b[0m  5.6715\n",
      "      2        \u001b[36m0.0819\u001b[0m  5.7608\n",
      "      3        \u001b[36m0.0439\u001b[0m  5.7089\n",
      "      4        \u001b[36m0.0411\u001b[0m  5.6816\n",
      "      5        \u001b[36m0.0263\u001b[0m  5.6557\n",
      "      6        0.0297  5.6833\n",
      "      7        \u001b[36m0.0221\u001b[0m  5.6331\n",
      "      8        0.5872  5.6534\n",
      "      9        0.6429  5.6827\n",
      "     10        0.5335  5.6905\n",
      "     11        0.4079  5.7095\n",
      "     12        0.3048  5.7157\n",
      "     13        0.2834  5.7028\n",
      "     14        0.2217  5.7620\n",
      "     15        0.1592  5.6728\n",
      "     16        0.1154  5.8306\n",
      "     17        0.2553  5.6854\n",
      "     18        0.4815  5.6329\n",
      "     19        0.3481  5.6851\n",
      "     20        0.2395  5.6228\n",
      "     21        0.2312  5.6198\n",
      "     22        0.1734  5.7016\n",
      "     23        0.1370  5.6424\n",
      "     24        0.1293  5.6596\n",
      "     25        0.0933  5.7371\n",
      "     26        0.0792  5.6086\n",
      "     27        0.1444  5.6729\n",
      "     28        0.1121  5.6468\n",
      "     29        0.0641  5.6053\n",
      "     30        0.0663  5.7449\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2672\u001b[0m  5.6389\n",
      "      2        \u001b[36m0.1437\u001b[0m  5.6767\n",
      "      3        \u001b[36m0.0653\u001b[0m  5.6702\n",
      "      4        0.0788  5.8111\n",
      "      5        \u001b[36m0.0388\u001b[0m  5.7180\n",
      "      6        \u001b[36m0.0309\u001b[0m  5.6443\n",
      "      7        \u001b[36m0.0298\u001b[0m  5.6377\n",
      "      8        0.1048  5.6114\n",
      "      9        0.0590  5.8158\n",
      "     10        0.6024  5.7462\n",
      "     11        0.5250  5.7782\n",
      "     12        0.3945  5.7566\n",
      "     13        0.2562  5.7697\n",
      "     14        0.2879  5.7941\n",
      "     15        0.1847  5.6301\n",
      "     16        0.2138  5.7508\n",
      "     17        0.2383  5.8321\n",
      "     18        0.0989  5.7349\n",
      "     19        0.2037  5.6041\n",
      "     20        0.4720  5.5919\n",
      "     21        0.6288  5.7961\n",
      "     22        0.5856  5.7465\n",
      "     23        0.5601  5.8464\n",
      "     24        0.6112  5.7640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25        0.5249  5.7271\n",
      "     26        0.4763  5.8885\n",
      "     27        0.6459  5.8130\n",
      "     28        0.5944  5.8117\n",
      "     29        0.5561  5.8115\n",
      "     30        0.5187  5.5988\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2984\u001b[0m  8.7326\n",
      "      2        \u001b[36m0.1063\u001b[0m  8.7460\n",
      "      3        \u001b[36m0.0455\u001b[0m  8.7431\n",
      "      4        0.0572  8.7198\n",
      "      5        \u001b[36m0.0429\u001b[0m  8.6738\n",
      "      6        \u001b[36m0.0323\u001b[0m  8.7275\n",
      "      7        0.0498  8.7326\n",
      "      8        0.0374  8.7089\n",
      "      9        0.1711  8.7388\n",
      "     10        0.5415  8.7474\n",
      "     11        0.5221  8.7437\n",
      "     12        0.5695  8.7403\n",
      "     13        0.5070  8.7381\n",
      "     14        0.6176  8.7064\n",
      "     15        0.4245  8.6817\n",
      "     16        0.3053  8.7675\n",
      "     17        0.2233  8.7363\n",
      "     18        0.1585  8.7383\n",
      "     19        0.1259  8.7298\n",
      "     20        0.1148  8.7047\n",
      "     21        0.1008  8.7244\n",
      "     22        0.2578  8.7417\n",
      "     23        0.2283  8.7362\n",
      "     24        0.1670  8.7454\n",
      "     25        0.2267  8.6926\n",
      "     26        0.3749  8.7106\n",
      "     27        0.2572  8.7345\n",
      "     28        0.1495  8.7471\n",
      "     29        0.1141  8.7333\n",
      "     30        0.1133  8.7363\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2358\u001b[0m  8.6746\n",
      "      2        0.2924  8.7358\n",
      "      3        0.3297  8.7299\n",
      "      4        0.2864  8.6906\n",
      "      5        \u001b[36m0.1061\u001b[0m  8.7237\n",
      "      6        \u001b[36m0.0892\u001b[0m  8.6809\n",
      "      7        \u001b[36m0.0766\u001b[0m  8.7359\n",
      "      8        0.0768  8.7338\n",
      "      9        0.1259  8.7179\n",
      "     10        \u001b[36m0.0607\u001b[0m  8.7094\n",
      "     11        \u001b[36m0.0433\u001b[0m  8.7300\n",
      "     12        \u001b[36m0.0375\u001b[0m  8.6822\n",
      "     13        \u001b[36m0.0318\u001b[0m  8.7367\n",
      "     14        0.0430  8.7193\n",
      "     15        0.0744  8.7244\n",
      "     16        0.1912  8.7311\n",
      "     17        0.1209  8.7249\n",
      "     18        0.0495  8.7328\n",
      "     19        0.0371  8.7281\n",
      "     20        0.0676  8.7078\n",
      "     21        0.0407  8.7332\n",
      "     22        0.2415  8.7439\n",
      "     23        0.1357  8.7141\n",
      "     24        0.4675  8.7292\n",
      "     25        0.5892  8.6724\n",
      "     26        0.5420  8.7158\n",
      "     27        0.5358  8.7289\n",
      "     28        0.4560  8.7146\n",
      "     29        0.3683  8.7189\n",
      "     30        0.3002  8.7249\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2591\u001b[0m  8.7251\n",
      "      2        \u001b[36m0.1046\u001b[0m  8.7332\n",
      "      3        \u001b[36m0.0571\u001b[0m  8.7352\n",
      "      4        0.1693  8.7221\n",
      "      5        0.1069  8.7264\n",
      "      6        0.0736  8.7434\n",
      "      7        \u001b[36m0.0441\u001b[0m  8.7330\n",
      "      8        \u001b[36m0.0374\u001b[0m  8.7378\n",
      "      9        \u001b[36m0.0282\u001b[0m  8.7424\n",
      "     10        0.0401  8.7331\n",
      "     11        0.4399  8.7347\n",
      "     12        0.6257  8.7416\n",
      "     13        0.5972  8.7302\n",
      "     14        0.5790  8.6851\n",
      "     15        0.5638  8.7372\n",
      "     16        0.5463  8.7471\n",
      "     17        0.5229  8.7163\n",
      "     18        0.4934  8.7462\n",
      "     19        0.4514  8.7411\n",
      "     20        0.4118  8.7317\n",
      "     21        0.3598  8.7098\n",
      "     22        0.2920  8.7157\n",
      "     23        0.2835  8.6797\n",
      "     24        0.3234  8.6798\n",
      "     25        0.3418  8.7378\n",
      "     26        0.1643  8.7351\n",
      "     27        0.1167  8.7433\n",
      "     28        0.0908  8.7436\n",
      "     29        0.2806  8.6715\n",
      "     30        0.1955  8.7266\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3009\u001b[0m  8.7335\n",
      "      2        0.3195  8.7409\n",
      "      3        \u001b[36m0.2683\u001b[0m  8.7392\n",
      "      4        \u001b[36m0.1264\u001b[0m  8.7328\n",
      "      5        \u001b[36m0.1141\u001b[0m  8.7116\n",
      "      6        \u001b[36m0.0753\u001b[0m  8.7234\n",
      "      7        \u001b[36m0.0506\u001b[0m  8.7330\n",
      "      8        \u001b[36m0.0424\u001b[0m  8.7344\n",
      "      9        \u001b[36m0.0420\u001b[0m  8.7406\n",
      "     10        \u001b[36m0.0359\u001b[0m  8.7285\n",
      "     11        \u001b[36m0.0331\u001b[0m  8.7314\n",
      "     12        \u001b[36m0.0321\u001b[0m  8.7270\n",
      "     13        0.0346  8.7347\n",
      "     14        \u001b[36m0.0312\u001b[0m  8.7182\n",
      "     15        0.0388  8.7411\n",
      "     16        \u001b[36m0.0260\u001b[0m  8.7387\n",
      "     17        \u001b[36m0.0245\u001b[0m  8.7177\n",
      "     18        0.0349  8.7110\n",
      "     19        0.0711  8.7077\n",
      "     20        0.0534  8.7247\n",
      "     21        0.0324  8.7247\n",
      "     22        0.0252  8.7261\n",
      "     23        0.0292  8.7460\n",
      "     24        \u001b[36m0.0231\u001b[0m  8.7200\n",
      "     25        \u001b[36m0.0177\u001b[0m  8.7347\n",
      "     26        0.0284  8.7429\n",
      "     27        0.0285  8.7254\n",
      "     28        \u001b[36m0.0172\u001b[0m  8.7063\n",
      "     29        0.0243  8.7228\n",
      "     30        0.0763  8.7435\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2808\u001b[0m  8.7140\n",
      "      2        \u001b[36m0.1487\u001b[0m  8.7382\n",
      "      3        0.2083  8.7164\n",
      "      4        0.1817  8.7140\n",
      "      5        \u001b[36m0.0786\u001b[0m  8.7289\n",
      "      6        \u001b[36m0.0541\u001b[0m  8.7348\n",
      "      7        \u001b[36m0.0415\u001b[0m  8.7298\n",
      "      8        0.0511  8.7244\n",
      "      9        0.3540  8.7344\n",
      "     10        0.3729  8.7374\n",
      "     11        0.1376  8.7031\n",
      "     12        0.0863  8.7202\n",
      "     13        0.0710  8.7108\n",
      "     14        0.0679  8.7329\n",
      "     15        0.3992  8.7304\n",
      "     16        0.1975  8.7366\n",
      "     17        0.3022  8.7135\n",
      "     18        0.1872  8.7111\n",
      "     19        0.2364  8.7514\n",
      "     20        0.2049  8.7132\n",
      "     21        0.1414  8.7286\n",
      "     22        0.3469  8.7106\n",
      "     23        0.4970  8.7335\n",
      "     24        0.3712  8.7453\n",
      "     25        0.5595  8.7295\n",
      "     26        0.5315  8.7383\n",
      "     27        0.5370  8.7131\n",
      "     28        0.4582  8.7016\n",
      "     29        0.3889  8.7293\n",
      "     30        0.4091  8.7332\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4938\u001b[0m  6.9844\n",
      "      2        \u001b[36m0.4794\u001b[0m  7.0263\n",
      "      3        0.5906  7.0069\n",
      "      4        \u001b[36m0.4261\u001b[0m  7.0553\n",
      "      5        \u001b[36m0.2575\u001b[0m  7.0321\n",
      "      6        \u001b[36m0.1727\u001b[0m  7.0273\n",
      "      7        \u001b[36m0.1636\u001b[0m  7.0113\n",
      "      8        \u001b[36m0.1131\u001b[0m  7.0316\n",
      "      9        \u001b[36m0.0777\u001b[0m  7.0543\n",
      "     10        0.0838  7.0289\n",
      "     11        0.0839  7.0502\n",
      "     12        \u001b[36m0.0632\u001b[0m  7.0689\n",
      "     13        0.1090  7.0876\n",
      "     14        \u001b[36m0.0591\u001b[0m  7.0992\n",
      "     15        \u001b[36m0.0489\u001b[0m  7.0636\n",
      "     16        0.0535  7.0753\n",
      "     17        \u001b[36m0.0299\u001b[0m  7.0575\n",
      "     18        0.0441  7.0632\n",
      "     19        0.2057  7.0684\n",
      "     20        0.2067  7.0572\n",
      "     21        0.0926  7.0643\n",
      "     22        0.0549  7.0484\n",
      "     23        0.1254  7.0862\n",
      "     24        0.0581  7.0854\n",
      "     25        0.0651  7.0554\n",
      "     26        0.0618  7.0422\n",
      "     27        0.0744  7.0551\n",
      "     28        0.0363  7.0420\n",
      "     29        0.1746  7.0916\n",
      "     30        0.1790  7.0916\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2645\u001b[0m  7.0932\n",
      "      2        \u001b[36m0.0494\u001b[0m  7.0512\n",
      "      3        \u001b[36m0.0320\u001b[0m  7.0756\n",
      "      4        0.0412  7.0886\n",
      "      5        \u001b[36m0.0306\u001b[0m  7.0999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        \u001b[36m0.0252\u001b[0m  7.0842\n",
      "      7        \u001b[36m0.0235\u001b[0m  7.0475\n",
      "      8        0.0311  7.0783\n",
      "      9        0.0280  7.0430\n",
      "     10        \u001b[36m0.0219\u001b[0m  7.0550\n",
      "     11        0.0313  7.0580\n",
      "     12        0.0245  7.0798\n",
      "     13        0.4174  7.0757\n",
      "     14        0.4888  7.0207\n",
      "     15        0.4150  7.0752\n",
      "     16        0.3904  7.0609\n",
      "     17        0.3393  7.0754\n",
      "     18        0.4498  7.0595\n",
      "     19        0.2598  7.0882\n",
      "     20        0.2411  7.0637\n",
      "     21        0.3072  7.0624\n",
      "     22        0.4946  7.0940\n",
      "     23        0.4951  7.0332\n",
      "     24        0.3446  7.0811\n",
      "     25        0.2634  7.0961\n",
      "     26        0.2194  7.0700\n",
      "     27        0.2658  7.0728\n",
      "     28        0.1495  7.0302\n",
      "     29        0.1011  7.0352\n",
      "     30        0.1669  7.0385\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2566\u001b[0m  7.0492\n",
      "      2        \u001b[36m0.0568\u001b[0m  7.0494\n",
      "      3        \u001b[36m0.0441\u001b[0m  7.0296\n",
      "      4        \u001b[36m0.0359\u001b[0m  7.0649\n",
      "      5        \u001b[36m0.0230\u001b[0m  7.0167\n",
      "      6        0.5070  7.0254\n",
      "      7        0.6523  7.0646\n",
      "      8        0.6157  7.0648\n",
      "      9        0.6163  7.0786\n",
      "     10        0.6385  7.0704\n",
      "     11        0.5975  7.0607\n",
      "     12        0.4984  7.0594\n",
      "     13        0.3267  7.0484\n",
      "     14        0.1969  7.0863\n",
      "     15        0.1525  7.0733\n",
      "     16        0.1075  7.0709\n",
      "     17        0.0936  7.0543\n",
      "     18        0.1213  7.0458\n",
      "     19        0.0978  7.0775\n",
      "     20        0.4636  7.0657\n",
      "     21        0.1519  7.0976\n",
      "     22        0.2827  7.0565\n",
      "     23        0.1656  7.0638\n",
      "     24        0.4578  7.0716\n",
      "     25        0.4176  7.0298\n",
      "     26        0.2853  7.0524\n",
      "     27        0.2002  7.0774\n",
      "     28        1.5484  7.0695\n",
      "     29        0.3733  7.0684\n",
      "     30        0.2644  7.0921\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2508\u001b[0m  7.0545\n",
      "      2        \u001b[36m0.0976\u001b[0m  7.0961\n",
      "      3        0.5869  7.0583\n",
      "      4        0.5458  7.0442\n",
      "      5        0.4409  7.0374\n",
      "      6        0.3839  7.0865\n",
      "      7        0.2859  7.0598\n",
      "      8        0.1799  7.0450\n",
      "      9        0.1297  7.0301\n",
      "     10        \u001b[36m0.0954\u001b[0m  7.0363\n",
      "     11        \u001b[36m0.0904\u001b[0m  7.0787\n",
      "     12        \u001b[36m0.0670\u001b[0m  7.0875\n",
      "     13        \u001b[36m0.0586\u001b[0m  7.0569\n",
      "     14        0.0612  7.0691\n",
      "     15        0.0858  7.0471\n",
      "     16        \u001b[36m0.0512\u001b[0m  7.0761\n",
      "     17        \u001b[36m0.0389\u001b[0m  7.0643\n",
      "     18        0.0430  7.0685\n",
      "     19        0.0458  7.0752\n",
      "     20        \u001b[36m0.0336\u001b[0m  7.0531\n",
      "     21        0.0669  7.0587\n",
      "     22        0.0418  7.0618\n",
      "     23        \u001b[36m0.0319\u001b[0m  7.0877\n",
      "     24        \u001b[36m0.0282\u001b[0m  7.0876\n",
      "     25        0.0627  7.0637\n",
      "     26        0.1099  7.0860\n",
      "     27        0.0366  7.0668\n",
      "     28        \u001b[36m0.0239\u001b[0m  7.0863\n",
      "     29        0.0419  7.0640\n",
      "     30        0.0714  7.0667\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2444\u001b[0m  7.0688\n",
      "      2        \u001b[36m0.0515\u001b[0m  7.0608\n",
      "      3        0.0657  7.0764\n",
      "      4        \u001b[36m0.0330\u001b[0m  7.0655\n",
      "      5        \u001b[36m0.0298\u001b[0m  7.0569\n",
      "      6        \u001b[36m0.0214\u001b[0m  7.0654\n",
      "      7        0.0251  7.0667\n",
      "      8        0.0251  7.0798\n",
      "      9        \u001b[36m0.0165\u001b[0m  7.0484\n",
      "     10        0.0275  7.0823\n",
      "     11        0.0196  7.0898\n",
      "     12        0.0186  7.0636\n",
      "     13        0.0271  7.0485\n",
      "     14        0.1691  7.0387\n",
      "     15        0.1339  7.0593\n",
      "     16        0.0468  7.0902\n",
      "     17        0.0461  7.0559\n",
      "     18        0.0507  7.0551\n",
      "     19        0.2620  7.1042\n",
      "     20        0.3535  7.0644\n",
      "     21        0.2348  7.0798\n",
      "     22        0.3729  7.0486\n",
      "     23        0.3032  7.0884\n",
      "     24        0.3728  7.0870\n",
      "     25        0.2741  7.0898\n",
      "     26        0.3005  7.0964\n",
      "     27        0.2956  7.0567\n",
      "     28        0.1593  7.0909\n",
      "     29        0.1228  7.0747\n",
      "     30        0.6936  7.0608\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4017\u001b[0m  5.1075\n",
      "      2        \u001b[36m0.2740\u001b[0m  5.2194\n",
      "      3        \u001b[36m0.2242\u001b[0m  5.0204\n",
      "      4        \u001b[36m0.2200\u001b[0m  5.0308\n",
      "      5        0.2822  5.0750\n",
      "      6        0.2333  5.2125\n",
      "      7        \u001b[36m0.2154\u001b[0m  5.1201\n",
      "      8        \u001b[36m0.1573\u001b[0m  5.1872\n",
      "      9        \u001b[36m0.1412\u001b[0m  5.1814\n",
      "     10        0.2052  5.0491\n",
      "     11        \u001b[36m0.1276\u001b[0m  5.0240\n",
      "     12        0.1648  5.1461\n",
      "     13        \u001b[36m0.1260\u001b[0m  5.0948\n",
      "     14        \u001b[36m0.1035\u001b[0m  5.0237\n",
      "     15        0.1077  5.1452\n",
      "     16        \u001b[36m0.0925\u001b[0m  5.0281\n",
      "     17        0.1254  5.0187\n",
      "     18        \u001b[36m0.0900\u001b[0m  5.0377\n",
      "     19        \u001b[36m0.0888\u001b[0m  5.1071\n",
      "     20        \u001b[36m0.0814\u001b[0m  5.1132\n",
      "     21        0.0916  5.1112\n",
      "     22        \u001b[36m0.0787\u001b[0m  5.1303\n",
      "     23        0.0888  5.0573\n",
      "     24        0.0924  5.1589\n",
      "     25        0.0944  5.1748\n",
      "     26        0.1338  5.0470\n",
      "     27        0.1114  5.1362\n",
      "     28        0.0890  5.2205\n",
      "     29        0.1334  5.0905\n",
      "     30        0.1694  5.1565\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3086\u001b[0m  5.1541\n",
      "      2        \u001b[36m0.1625\u001b[0m  5.1251\n",
      "      3        \u001b[36m0.1212\u001b[0m  5.1130\n",
      "      4        \u001b[36m0.0911\u001b[0m  5.0389\n",
      "      5        \u001b[36m0.0720\u001b[0m  5.1063\n",
      "      6        0.5674  5.1091\n",
      "      7        0.4300  5.1300\n",
      "      8        0.3230  5.0918\n",
      "      9        0.3128  5.0439\n",
      "     10        0.1936  5.0874\n",
      "     11        0.1351  5.1569\n",
      "     12        0.4161  5.1157\n",
      "     13        0.4261  5.1325\n",
      "     14        0.3036  5.1325\n",
      "     15        0.2795  5.0672\n",
      "     16        0.2405  5.1625\n",
      "     17        0.1741  5.0936\n",
      "     18        0.1795  5.1638\n",
      "     19        0.2219  5.1427\n",
      "     20        0.1778  5.0482\n",
      "     21        0.1495  5.1384\n",
      "     22        0.1171  5.0804\n",
      "     23        0.0921  5.1847\n",
      "     24        0.1153  5.1650\n",
      "     25        0.1118  5.0557\n",
      "     26        0.2274  5.1511\n",
      "     27        0.1713  5.1197\n",
      "     28        0.2702  5.1501\n",
      "     29        0.2483  5.1414\n",
      "     30        0.2922  5.0466\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3273\u001b[0m  5.1023\n",
      "      2        \u001b[36m0.2387\u001b[0m  5.0379\n",
      "      3        \u001b[36m0.1641\u001b[0m  5.1262\n",
      "      4        \u001b[36m0.1440\u001b[0m  5.1133\n",
      "      5        \u001b[36m0.1094\u001b[0m  5.1428\n",
      "      6        0.1788  5.1794\n",
      "      7        0.1471  5.1131\n",
      "      8        \u001b[36m0.1009\u001b[0m  5.0858\n",
      "      9        0.2067  5.0374\n",
      "     10        0.3947  5.0672\n",
      "     11        0.2159  5.1635\n",
      "     12        0.1852  5.1936\n",
      "     13        0.2022  5.0601\n",
      "     14        0.1275  5.0417\n",
      "     15        0.2371  5.1398\n",
      "     16        0.2574  5.1442\n",
      "     17        0.3284  5.1330\n",
      "     18        0.2826  5.0658\n",
      "     19        0.2124  5.1564\n",
      "     20        0.1748  5.1134\n",
      "     21        0.1456  5.3190\n",
      "     22        0.1376  5.1796\n",
      "     23        0.1269  5.1348\n",
      "     24        0.1242  5.1273\n",
      "     25        0.1125  5.0854\n",
      "     26        0.1200  5.1193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27        \u001b[36m0.1008\u001b[0m  5.1048\n",
      "     28        0.1060  5.1200\n",
      "     29        0.1053  5.0905\n",
      "     30        0.1107  5.1271\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3826\u001b[0m  5.0759\n",
      "      2        \u001b[36m0.2333\u001b[0m  5.0728\n",
      "      3        \u001b[36m0.1722\u001b[0m  5.1070\n",
      "      4        \u001b[36m0.1492\u001b[0m  5.1147\n",
      "      5        0.1679  5.1487\n",
      "      6        0.2065  5.0931\n",
      "      7        \u001b[36m0.1382\u001b[0m  5.1354\n",
      "      8        0.1576  5.0821\n",
      "      9        \u001b[36m0.1122\u001b[0m  5.0994\n",
      "     10        \u001b[36m0.1031\u001b[0m  5.1219\n",
      "     11        0.1115  5.1065\n",
      "     12        0.1072  5.1674\n",
      "     13        \u001b[36m0.0856\u001b[0m  5.1256\n",
      "     14        0.1480  5.1077\n",
      "     15        0.2198  5.1434\n",
      "     16        0.1749  5.1470\n",
      "     17        0.1408  5.1550\n",
      "     18        0.1293  5.0680\n",
      "     19        0.0932  5.0846\n",
      "     20        \u001b[36m0.0779\u001b[0m  5.1219\n",
      "     21        \u001b[36m0.0728\u001b[0m  5.1320\n",
      "     22        0.0851  5.1731\n",
      "     23        0.1292  5.1521\n",
      "     24        0.1038  5.1199\n",
      "     25        0.1284  5.0436\n",
      "     26        0.1439  5.0220\n",
      "     27        0.1194  5.1609\n",
      "     28        0.1298  5.1093\n",
      "     29        0.3395  5.1382\n",
      "     30        0.2120  5.0362\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3614\u001b[0m  5.1121\n",
      "      2        \u001b[36m0.1909\u001b[0m  5.0982\n",
      "      3        \u001b[36m0.1348\u001b[0m  5.1219\n",
      "      4        0.1375  5.1136\n",
      "      5        \u001b[36m0.0860\u001b[0m  5.1268\n",
      "      6        0.1272  5.1188\n",
      "      7        0.1232  5.0530\n",
      "      8        \u001b[36m0.0817\u001b[0m  5.1003\n",
      "      9        0.0833  5.0312\n",
      "     10        0.0820  5.0817\n",
      "     11        0.1184  5.0471\n",
      "     12        0.1110  5.1030\n",
      "     13        \u001b[36m0.0816\u001b[0m  5.1624\n",
      "     14        0.1477  5.1182\n",
      "     15        0.1009  5.1444\n",
      "     16        0.1011  5.1832\n",
      "     17        0.0899  5.0841\n",
      "     18        0.1278  5.1387\n",
      "     19        0.0848  5.1192\n",
      "     20        0.1407  5.1497\n",
      "     21        0.1148  5.0405\n",
      "     22        0.1206  5.1117\n",
      "     23        0.1430  5.1604\n",
      "     24        0.1041  5.1301\n",
      "     25        0.1156  5.1652\n",
      "     26        0.2275  5.0636\n",
      "     27        0.1718  5.0986\n",
      "     28        0.1299  5.0228\n",
      "     29        0.1179  5.0592\n",
      "     30        0.1099  5.1602\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 2.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2506\u001b[0m  5.6444\n",
      "      2        \u001b[36m0.1035\u001b[0m  5.7028\n",
      "      3        \u001b[36m0.0551\u001b[0m  5.6457\n",
      "      4        \u001b[36m0.0399\u001b[0m  5.6964\n",
      "      5        \u001b[36m0.0359\u001b[0m  5.6936\n",
      "      6        \u001b[36m0.0333\u001b[0m  5.7366\n",
      "      7        0.4054  5.7461\n",
      "      8        0.4291  5.6533\n",
      "      9        0.2055  5.7142\n",
      "     10        0.1233  5.6536\n",
      "     11        0.3353  5.6466\n",
      "     12        0.3742  5.7129\n",
      "     13        0.3682  5.6021\n",
      "     14        0.2889  5.6772\n",
      "     15        0.3456  6.0639\n",
      "     16        0.1628  5.6737\n",
      "     17        0.1091  5.7286\n",
      "     18        0.2021  5.7274\n",
      "     19        0.1570  5.6844\n",
      "     20        0.2609  5.5988\n",
      "     21        0.2933  5.6504\n",
      "     22        0.1943  5.6410\n",
      "     23        0.2490  5.6971\n",
      "     24        0.4273  5.6667\n",
      "     25        0.5768  5.6569\n",
      "     26        0.5666  5.6928\n",
      "     27        0.6075  5.7021\n",
      "     28        0.6291  5.7835\n",
      "     29        0.5989  5.8021\n",
      "     30        0.5791  5.6362\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3026\u001b[0m  5.6166\n",
      "      2        \u001b[36m0.1781\u001b[0m  5.6415\n",
      "      3        \u001b[36m0.1229\u001b[0m  5.7280\n",
      "      4        \u001b[36m0.0575\u001b[0m  5.7112\n",
      "      5        \u001b[36m0.0424\u001b[0m  5.6220\n",
      "      6        0.4273  5.7065\n",
      "      7        0.5800  5.7187\n",
      "      8        0.5581  5.6259\n",
      "      9        0.4982  5.7967\n",
      "     10        0.3257  5.6625\n",
      "     11        0.2380  5.6268\n",
      "     12        0.1763  5.6223\n",
      "     13        0.2053  5.6234\n",
      "     14        0.4638  5.6200\n",
      "     15        0.4474  5.6265\n",
      "     16        0.6284  5.6091\n",
      "     17        0.5807  5.6578\n",
      "     18        0.5452  5.7448\n",
      "     19        0.5074  5.7468\n",
      "     20        0.4647  5.7043\n",
      "     21        0.4456  5.6340\n",
      "     22        0.4155  5.7380\n",
      "     23        0.6100  5.6875\n",
      "     24        0.4910  5.6639\n",
      "     25        0.4244  5.6798\n",
      "     26        0.3940  5.6882\n",
      "     27        0.3548  5.7367\n",
      "     28        0.3184  5.6896\n",
      "     29        0.2736  5.6487\n",
      "     30        0.3582  5.7274\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2472\u001b[0m  5.6471\n",
      "      2        \u001b[36m0.2114\u001b[0m  5.7113\n",
      "      3        \u001b[36m0.1790\u001b[0m  5.6559\n",
      "      4        0.5006  5.6175\n",
      "      5        0.3437  5.6930\n",
      "      6        0.2439  5.7424\n",
      "      7        \u001b[36m0.1538\u001b[0m  5.7348\n",
      "      8        \u001b[36m0.1404\u001b[0m  5.7434\n",
      "      9        \u001b[36m0.0971\u001b[0m  5.6599\n",
      "     10        \u001b[36m0.0753\u001b[0m  5.7979\n",
      "     11        0.4180  5.7428\n",
      "     12        0.4375  5.6272\n",
      "     13        0.4112  5.7083\n",
      "     14        0.4593  5.5990\n",
      "     15        0.4463  5.6908\n",
      "     16        0.3356  5.6595\n",
      "     17        0.5337  5.6210\n",
      "     18        0.3667  5.6065\n",
      "     19        0.3183  5.7455\n",
      "     20        0.4260  5.7017\n",
      "     21        0.3989  5.6050\n",
      "     22        0.2446  5.5943\n",
      "     23        0.1693  5.7184\n",
      "     24        0.1435  5.6814\n",
      "     25        0.2358  5.6675\n",
      "     26        0.3550  5.7119\n",
      "     27        0.5073  5.6431\n",
      "     28        0.4439  5.7031\n",
      "     29        0.3343  5.7431\n",
      "     30        0.2943  5.7203\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2794\u001b[0m  5.8308\n",
      "      2        \u001b[36m0.1759\u001b[0m  5.7117\n",
      "      3        \u001b[36m0.0921\u001b[0m  5.7823\n",
      "      4        \u001b[36m0.0729\u001b[0m  5.6630\n",
      "      5        \u001b[36m0.0683\u001b[0m  5.7308\n",
      "      6        0.1191  5.6642\n",
      "      7        0.0976  5.6905\n",
      "      8        0.0860  5.7075\n",
      "      9        0.0709  5.7115\n",
      "     10        \u001b[36m0.0564\u001b[0m  5.7445\n",
      "     11        \u001b[36m0.0501\u001b[0m  5.6427\n",
      "     12        0.5423  5.7055\n",
      "     13        0.4355  5.6566\n",
      "     14        0.3490  5.6310\n",
      "     15        0.3566  5.6278\n",
      "     16        0.2618  5.7124\n",
      "     17        0.2067  5.6157\n",
      "     18        0.2302  5.6990\n",
      "     19        0.2200  5.7041\n",
      "     20        0.1662  5.6945\n",
      "     21        0.1521  5.7233\n",
      "     22        0.1652  5.7230\n",
      "     23        0.1026  5.7018\n",
      "     24        0.0836  5.7334\n",
      "     25        0.4227  5.6806\n",
      "     26        0.5713  5.7273\n",
      "     27        0.5432  5.7122\n",
      "     28        0.4295  5.7265\n",
      "     29        0.3110  5.6989\n",
      "     30        0.2424  5.7003\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2444\u001b[0m  5.7198\n",
      "      2        \u001b[36m0.1401\u001b[0m  5.7185\n",
      "      3        \u001b[36m0.0889\u001b[0m  5.6243\n",
      "      4        \u001b[36m0.0414\u001b[0m  5.7150\n",
      "      5        0.0432  5.7474\n",
      "      6        \u001b[36m0.0346\u001b[0m  5.6372\n",
      "      7        \u001b[36m0.0333\u001b[0m  5.7241\n",
      "      8        \u001b[36m0.0274\u001b[0m  5.6684\n",
      "      9        0.0316  5.6979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        \u001b[36m0.0258\u001b[0m  5.6048\n",
      "     11        0.0512  5.6071\n",
      "     12        0.0415  5.7161\n",
      "     13        \u001b[36m0.0223\u001b[0m  5.7056\n",
      "     14        \u001b[36m0.0178\u001b[0m  5.7030\n",
      "     15        0.0188  5.6125\n",
      "     16        0.0209  5.7155\n",
      "     17        0.0472  5.6884\n",
      "     18        0.2979  5.6899\n",
      "     19        0.6279  5.6773\n",
      "     20        0.6215  5.6632\n",
      "     21        0.6115  5.7094\n",
      "     22        0.5985  5.6085\n",
      "     23        0.5814  5.7669\n",
      "     24        0.5695  5.7087\n",
      "     25        0.5636  5.7213\n",
      "     26        0.5621  5.6832\n",
      "     27        0.5433  5.7839\n",
      "     28        0.5080  5.6198\n",
      "     29        0.5073  5.7302\n",
      "     30        0.4746  5.6714\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 2.9min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2851\u001b[0m  8.7340\n",
      "      2        0.3109  8.7385\n",
      "      3        0.4130  8.7336\n",
      "      4        \u001b[36m0.2364\u001b[0m  8.7287\n",
      "      5        \u001b[36m0.1798\u001b[0m  8.7322\n",
      "      6        \u001b[36m0.1026\u001b[0m  8.7219\n",
      "      7        \u001b[36m0.0738\u001b[0m  8.6871\n",
      "      8        0.1388  8.6945\n",
      "      9        0.2563  8.7125\n",
      "     10        0.1138  8.7273\n",
      "     11        0.2317  8.7276\n",
      "     12        0.1803  8.7331\n",
      "     13        0.1048  8.7318\n",
      "     14        0.1670  8.7329\n",
      "     15        0.1881  8.7474\n",
      "     16        0.5195  8.7268\n",
      "     17        0.3841  8.7313\n",
      "     18        0.4335  8.7234\n",
      "     19        0.2675  8.7438\n",
      "     20        0.2630  8.7428\n",
      "     21        0.4227  8.7256\n",
      "     22        0.2245  8.6820\n",
      "     23        0.1976  8.7055\n",
      "     24        0.3783  8.7240\n",
      "     25        0.2444  8.7306\n",
      "     26        0.2695  8.7344\n",
      "     27        0.4088  8.7221\n",
      "     28        0.4990  8.7328\n",
      "     29        0.5154  8.7518\n",
      "     30        0.3558  8.7352\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2764\u001b[0m  8.7349\n",
      "      2        0.4093  8.7414\n",
      "      3        0.6345  8.7358\n",
      "      4        0.6252  8.7416\n",
      "      5        0.5872  8.7372\n",
      "      6        0.5498  8.7292\n",
      "      7        0.5235  8.7394\n",
      "      8        0.5038  8.7068\n",
      "      9        0.4648  8.7415\n",
      "     10        0.4104  8.7343\n",
      "     11        0.6501  8.7355\n",
      "     12        0.6400  8.7400\n",
      "     13        0.5663  8.7438\n",
      "     14        0.5226  8.7392\n",
      "     15        0.5267  8.7240\n",
      "     16        0.5384  8.7243\n",
      "     17        0.3323  8.6730\n",
      "     18        \u001b[36m0.2196\u001b[0m  8.7068\n",
      "     19        \u001b[36m0.1618\u001b[0m  8.7364\n",
      "     20        \u001b[36m0.1359\u001b[0m  8.7411\n",
      "     21        \u001b[36m0.1039\u001b[0m  8.7461\n",
      "     22        0.4916  8.7248\n",
      "     23        0.3928  8.7301\n",
      "     24        0.2887  8.6994\n",
      "     25        0.3470  8.7178\n",
      "     26        0.2292  8.6921\n",
      "     27        0.7739  8.7525\n",
      "     28        0.6747  8.7242\n",
      "     29        0.7313  8.6988\n",
      "     30        0.7191  8.7389\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3274\u001b[0m  8.7056\n",
      "      2        0.3890  8.6919\n",
      "      3        \u001b[36m0.1519\u001b[0m  8.7106\n",
      "      4        \u001b[36m0.0904\u001b[0m  8.7404\n",
      "      5        \u001b[36m0.0704\u001b[0m  8.6709\n",
      "      6        \u001b[36m0.0644\u001b[0m  8.7400\n",
      "      7        \u001b[36m0.0409\u001b[0m  8.7284\n",
      "      8        \u001b[36m0.0356\u001b[0m  8.6936\n",
      "      9        0.0366  8.7146\n",
      "     10        0.0850  8.7430\n",
      "     11        0.4906  8.7309\n",
      "     12        0.4003  8.6921\n",
      "     13        0.2469  8.7256\n",
      "     14        0.4035  8.7119\n",
      "     15        0.2706  8.7260\n",
      "     16        0.2131  8.7078\n",
      "     17        0.1274  8.7349\n",
      "     18        0.7080  8.7331\n",
      "     19        0.4515  8.7197\n",
      "     20        0.3221  8.7136\n",
      "     21        0.2131  8.7183\n",
      "     22        0.2568  8.7179\n",
      "     23        0.2052  8.7296\n",
      "     24        0.1670  8.7102\n",
      "     25        0.1325  8.7365\n",
      "     26        0.0991  8.6685\n",
      "     27        0.3452  8.6940\n",
      "     28        0.3100  8.7038\n",
      "     29        0.1619  8.7228\n",
      "     30        0.1985  8.7152\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3209\u001b[0m  8.7326\n",
      "      2        0.3319  8.7446\n",
      "      3        \u001b[36m0.2624\u001b[0m  8.6817\n",
      "      4        \u001b[36m0.1932\u001b[0m  8.7281\n",
      "      5        \u001b[36m0.1255\u001b[0m  8.7192\n",
      "      6        0.2604  8.7461\n",
      "      7        0.2589  8.7406\n",
      "      8        0.1432  8.7195\n",
      "      9        \u001b[36m0.0733\u001b[0m  8.7367\n",
      "     10        \u001b[36m0.0675\u001b[0m  8.7407\n",
      "     11        0.0729  8.7295\n",
      "     12        \u001b[36m0.0584\u001b[0m  8.7144\n",
      "     13        \u001b[36m0.0428\u001b[0m  8.7250\n",
      "     14        0.0483  8.7368\n",
      "     15        0.0619  8.7326\n",
      "     16        0.0462  8.6965\n",
      "     17        0.0467  8.6942\n",
      "     18        \u001b[36m0.0370\u001b[0m  8.7333\n",
      "     19        0.0975  8.7259\n",
      "     20        0.0812  8.7135\n",
      "     21        0.0619  8.7335\n",
      "     22        0.0424  8.7096\n",
      "     23        0.2191  8.7335\n",
      "     24        0.0982  8.7236\n",
      "     25        0.0790  8.6866\n",
      "     26        0.3563  8.6726\n",
      "     27        0.2018  8.7548\n",
      "     28        0.1595  8.6953\n",
      "     29        0.1565  8.7340\n",
      "     30        0.1209  8.7319\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4392\u001b[0m  8.7288\n",
      "      2        0.6234  8.7385\n",
      "      3        0.4430  8.7322\n",
      "      4        \u001b[36m0.2300\u001b[0m  8.7254\n",
      "      5        \u001b[36m0.1889\u001b[0m  8.7358\n",
      "      6        \u001b[36m0.1451\u001b[0m  8.6834\n",
      "      7        \u001b[36m0.1178\u001b[0m  8.6891\n",
      "      8        \u001b[36m0.0974\u001b[0m  8.7178\n",
      "      9        \u001b[36m0.0704\u001b[0m  8.7266\n",
      "     10        \u001b[36m0.0622\u001b[0m  8.7342\n",
      "     11        \u001b[36m0.0535\u001b[0m  8.7335\n",
      "     12        0.1903  8.7306\n",
      "     13        0.0865  8.7334\n",
      "     14        0.0762  8.7505\n",
      "     15        0.0550  8.7063\n",
      "     16        \u001b[36m0.0372\u001b[0m  8.7414\n",
      "     17        0.1277  8.7292\n",
      "     18        0.2709  8.7413\n",
      "     19        0.3951  8.7300\n",
      "     20        0.6041  8.7335\n",
      "     21        0.4796  8.7021\n",
      "     22        0.4520  8.7401\n",
      "     23        0.5211  8.7451\n",
      "     24        0.4235  8.7320\n",
      "     25        0.3813  8.7258\n",
      "     26        0.6742  8.7199\n",
      "     27        0.6473  8.7349\n",
      "     28        0.5967  8.7266\n",
      "     29        0.5827  8.6971\n",
      "     30        0.5755  8.7423\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 4.4min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2897\u001b[0m  7.0207\n",
      "      2        \u001b[36m0.1945\u001b[0m  7.0474\n",
      "      3        \u001b[36m0.1825\u001b[0m  7.0433\n",
      "      4        \u001b[36m0.1341\u001b[0m  7.0069\n",
      "      5        \u001b[36m0.0779\u001b[0m  7.0521\n",
      "      6        \u001b[36m0.0579\u001b[0m  7.0441\n",
      "      7        0.4109  7.0306\n",
      "      8        0.6089  7.0105\n",
      "      9        0.5616  7.0735\n",
      "     10        0.4293  7.0936\n",
      "     11        0.4213  7.0637\n",
      "     12        0.2328  7.0520\n",
      "     13        0.1823  7.0629\n",
      "     14        0.1815  7.0505\n",
      "     15        0.1568  7.0628\n",
      "     16        0.2300  7.0517\n",
      "     17        0.2970  7.0595\n",
      "     18        0.1760  7.0656\n",
      "     19        0.1323  7.0978\n",
      "     20        0.1265  7.0752\n",
      "     21        0.1192  7.0439\n",
      "     22        0.1245  7.0133\n",
      "     23        0.1013  7.0646\n",
      "     24        0.1205  7.0741\n",
      "     25        0.1585  7.0341\n",
      "     26        0.1473  7.0494\n",
      "     27        0.3361  7.0709\n",
      "     28        0.1760  7.0812\n",
      "     29        0.1416  7.0572\n",
      "     30        0.1439  7.0508\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2677\u001b[0m  7.0412\n",
      "      2        \u001b[36m0.1586\u001b[0m  7.0905\n",
      "      3        0.3858  7.0158\n",
      "      4        0.2936  7.0565\n",
      "      5        0.2325  7.0862\n",
      "      6        \u001b[36m0.1065\u001b[0m  7.1036\n",
      "      7        \u001b[36m0.0878\u001b[0m  7.0912\n",
      "      8        \u001b[36m0.0627\u001b[0m  7.0683\n",
      "      9        \u001b[36m0.0586\u001b[0m  7.0724\n",
      "     10        \u001b[36m0.0481\u001b[0m  7.0220\n",
      "     11        0.0489  7.0303\n",
      "     12        0.0537  7.0656\n",
      "     13        0.0992  7.0659\n",
      "     14        0.1878  7.0746\n",
      "     15        0.0733  7.0721\n",
      "     16        0.0756  7.0556\n",
      "     17        0.0619  7.0759\n",
      "     18        0.1560  7.0445\n",
      "     19        0.1133  7.0698\n",
      "     20        0.2728  7.0757\n",
      "     21        0.2015  7.0398\n",
      "     22        0.1652  7.0566\n",
      "     23        0.1071  7.0697\n",
      "     24        0.0761  7.0748\n",
      "     25        0.0988  7.0692\n",
      "     26        0.0617  7.0418\n",
      "     27        0.0879  7.0564\n",
      "     28        0.0837  7.0458\n",
      "     29        0.1259  7.0870\n",
      "     30        0.2062  7.0584\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2532\u001b[0m  7.0358\n",
      "      2        \u001b[36m0.1019\u001b[0m  7.0505\n",
      "      3        0.2805  7.0808\n",
      "      4        0.3218  7.0553\n",
      "      5        0.1678  7.0763\n",
      "      6        \u001b[36m0.0774\u001b[0m  7.0843\n",
      "      7        0.1059  7.0598\n",
      "      8        0.2574  7.0628\n",
      "      9        0.1920  7.0882\n",
      "     10        0.1231  7.0705\n",
      "     11        \u001b[36m0.0744\u001b[0m  7.0724\n",
      "     12        0.1290  7.0703\n",
      "     13        0.1211  7.0399\n",
      "     14        0.0937  7.0509\n",
      "     15        0.0900  7.0483\n",
      "     16        0.3044  7.0412\n",
      "     17        0.2770  7.0702\n",
      "     18        0.1765  7.0578\n",
      "     19        0.1330  7.0500\n",
      "     20        0.1219  7.0596\n",
      "     21        0.2489  7.0523\n",
      "     22        0.2667  7.0493\n",
      "     23        0.1694  7.0491\n",
      "     24        0.1365  7.0685\n",
      "     25        0.2316  7.0561\n",
      "     26        0.2486  7.0670\n",
      "     27        0.1464  7.0760\n",
      "     28        0.1312  7.0480\n",
      "     29        0.2127  7.0597\n",
      "     30        0.2016  7.0565\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3173\u001b[0m  7.0419\n",
      "      2        \u001b[36m0.1624\u001b[0m  7.0697\n",
      "      3        \u001b[36m0.0741\u001b[0m  7.0344\n",
      "      4        \u001b[36m0.0512\u001b[0m  7.0598\n",
      "      5        0.0988  7.0858\n",
      "      6        \u001b[36m0.0473\u001b[0m  7.0675\n",
      "      7        \u001b[36m0.0436\u001b[0m  7.0756\n",
      "      8        \u001b[36m0.0283\u001b[0m  7.0733\n",
      "      9        0.0320  7.0808\n",
      "     10        \u001b[36m0.0260\u001b[0m  7.0595\n",
      "     11        0.3084  7.0401\n",
      "     12        0.6249  7.0743\n",
      "     13        0.6143  7.0857\n",
      "     14        0.6091  7.0581\n",
      "     15        0.6026  7.0111\n",
      "     16        0.6312  7.0449\n",
      "     17        0.6171  7.0510\n",
      "     18        0.5767  7.0427\n",
      "     19        0.5839  7.0438\n",
      "     20        0.5566  7.0539\n",
      "     21        0.6080  7.0686\n",
      "     22        0.5339  7.0631\n",
      "     23        0.5797  7.0785\n",
      "     24        1.0239  7.0858\n",
      "     25        0.7296  7.0730\n",
      "     26        0.5984  7.0826\n",
      "     27        0.5805  7.0786\n",
      "     28        0.5979  7.0567\n",
      "     29        0.5725  7.0753\n",
      "     30        0.8911  7.0653\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3465\u001b[0m  7.0833\n",
      "      2        \u001b[36m0.0888\u001b[0m  7.0174\n",
      "      3        \u001b[36m0.0442\u001b[0m  7.0120\n",
      "      4        \u001b[36m0.0313\u001b[0m  7.0674\n",
      "      5        \u001b[36m0.0303\u001b[0m  7.0680\n",
      "      6        \u001b[36m0.0254\u001b[0m  7.0050\n",
      "      7        0.0311  7.0468\n",
      "      8        \u001b[36m0.0211\u001b[0m  7.0759\n",
      "      9        \u001b[36m0.0205\u001b[0m  7.0312\n",
      "     10        0.2011  7.0656\n",
      "     11        0.4447  7.0491\n",
      "     12        0.4132  7.0427\n",
      "     13        0.2236  7.0738\n",
      "     14        0.1858  7.0745\n",
      "     15        0.1589  7.0760\n",
      "     16        0.1089  7.0667\n",
      "     17        0.1190  7.0759\n",
      "     18        0.1162  7.0421\n",
      "     19        0.0664  7.0577\n",
      "     20        0.1309  7.0756\n",
      "     21        0.0750  7.0768\n",
      "     22        0.1273  7.0339\n",
      "     23        0.0725  7.0318\n",
      "     24        0.2616  7.0645\n",
      "     25        0.3842  7.0832\n",
      "     26        0.2430  7.0813\n",
      "     27        0.1648  7.0652\n",
      "     28        0.1558  7.0539\n",
      "     29        0.1307  7.0558\n",
      "     30        0.1362  7.0370\n",
      "[CV]  net__batch_size=32, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 3.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3072\u001b[0m  2.8255\n",
      "      2        \u001b[36m0.1670\u001b[0m  2.7925\n",
      "      3        \u001b[36m0.1253\u001b[0m  2.8153\n",
      "      4        \u001b[36m0.0892\u001b[0m  2.7793\n",
      "      5        \u001b[36m0.0786\u001b[0m  2.7947\n",
      "      6        \u001b[36m0.0683\u001b[0m  2.7999\n",
      "      7        \u001b[36m0.0505\u001b[0m  2.7994\n",
      "      8        0.0826  2.8113\n",
      "      9        0.0724  2.7991\n",
      "     10        0.0740  2.7997\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  28.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3186\u001b[0m  2.8267\n",
      "      2        \u001b[36m0.1985\u001b[0m  2.7841\n",
      "      3        \u001b[36m0.1434\u001b[0m  2.8315\n",
      "      4        \u001b[36m0.0914\u001b[0m  2.7832\n",
      "      5        \u001b[36m0.0605\u001b[0m  2.7910\n",
      "      6        \u001b[36m0.0574\u001b[0m  2.7769\n",
      "      7        \u001b[36m0.0406\u001b[0m  2.8125\n",
      "      8        0.0628  2.8030\n",
      "      9        0.0409  2.7870\n",
      "     10        \u001b[36m0.0312\u001b[0m  2.8088\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  28.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3392\u001b[0m  2.8259\n",
      "      2        \u001b[36m0.1596\u001b[0m  2.8173\n",
      "      3        \u001b[36m0.1082\u001b[0m  2.8027\n",
      "      4        \u001b[36m0.0964\u001b[0m  2.7904\n",
      "      5        0.1033  2.8222\n",
      "      6        \u001b[36m0.0699\u001b[0m  2.7918\n",
      "      7        0.0744  2.7971\n",
      "      8        0.0992  2.8260\n",
      "      9        \u001b[36m0.0604\u001b[0m  2.7912\n",
      "     10        \u001b[36m0.0455\u001b[0m  2.7991\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  28.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3148\u001b[0m  2.7982\n",
      "      2        \u001b[36m0.1951\u001b[0m  2.8218\n",
      "      3        \u001b[36m0.1187\u001b[0m  2.7852\n",
      "      4        0.1261  2.7876\n",
      "      5        0.2209  2.8241\n",
      "      6        \u001b[36m0.0942\u001b[0m  2.7981\n",
      "      7        \u001b[36m0.0717\u001b[0m  2.8157\n",
      "      8        0.0739  2.7970\n",
      "      9        \u001b[36m0.0502\u001b[0m  2.7863\n",
      "     10        0.0515  2.7917\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  28.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3644\u001b[0m  2.8079\n",
      "      2        \u001b[36m0.1869\u001b[0m  2.8035\n",
      "      3        \u001b[36m0.1421\u001b[0m  2.8074\n",
      "      4        \u001b[36m0.1194\u001b[0m  2.8131\n",
      "      5        0.1460  2.7813\n",
      "      6        \u001b[36m0.0871\u001b[0m  2.8319\n",
      "      7        0.0996  2.7921\n",
      "      8        \u001b[36m0.0722\u001b[0m  2.7906\n",
      "      9        \u001b[36m0.0516\u001b[0m  2.8301\n",
      "     10        \u001b[36m0.0384\u001b[0m  2.8345\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  28.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2639\u001b[0m  3.0997\n",
      "      2        \u001b[36m0.1377\u001b[0m  3.0635\n",
      "      3        \u001b[36m0.0849\u001b[0m  3.0918\n",
      "      4        \u001b[36m0.0476\u001b[0m  3.0729\n",
      "      5        \u001b[36m0.0375\u001b[0m  3.0781\n",
      "      6        0.1958  3.1090\n",
      "      7        0.2979  3.1010\n",
      "      8        0.1205  3.1248\n",
      "      9        0.0919  3.1325\n",
      "     10        0.0604  3.0810\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  31.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3109\u001b[0m  3.0927\n",
      "      2        \u001b[36m0.1764\u001b[0m  3.1119\n",
      "      3        \u001b[36m0.1053\u001b[0m  3.0900\n",
      "      4        \u001b[36m0.0609\u001b[0m  3.0910\n",
      "      5        0.0624  3.0784\n",
      "      6        \u001b[36m0.0491\u001b[0m  3.1087\n",
      "      7        0.0647  3.1003\n",
      "      8        0.5933  3.1040\n",
      "      9        0.5721  3.0833\n",
      "     10        0.4407  3.1108\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  31.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2658\u001b[0m  3.1281\n",
      "      2        \u001b[36m0.1168\u001b[0m  3.1188\n",
      "      3        \u001b[36m0.0887\u001b[0m  3.1201\n",
      "      4        \u001b[36m0.0626\u001b[0m  3.0813\n",
      "      5        0.0762  3.0941\n",
      "      6        \u001b[36m0.0492\u001b[0m  3.1222\n",
      "      7        \u001b[36m0.0412\u001b[0m  3.1010\n",
      "      8        \u001b[36m0.0240\u001b[0m  3.1061\n",
      "      9        0.0566  3.1164\n",
      "     10        0.0293  3.0935\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  31.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2986\u001b[0m  3.0921\n",
      "      2        \u001b[36m0.1902\u001b[0m  3.1010\n",
      "      3        \u001b[36m0.1793\u001b[0m  3.1188\n",
      "      4        0.2611  3.0768\n",
      "      5        0.2238  3.1005\n",
      "      6        \u001b[36m0.1626\u001b[0m  3.0899\n",
      "      7        \u001b[36m0.1310\u001b[0m  3.1226\n",
      "      8        0.2348  3.1363\n",
      "      9        0.4035  3.1263\n",
      "     10        0.3711  3.1134\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  31.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3300\u001b[0m  3.0658\n",
      "      2        \u001b[36m0.0990\u001b[0m  3.0803\n",
      "      3        \u001b[36m0.0638\u001b[0m  3.1007\n",
      "      4        \u001b[36m0.0410\u001b[0m  3.1121\n",
      "      5        \u001b[36m0.0399\u001b[0m  3.0842\n",
      "      6        0.0437  3.1107\n",
      "      7        \u001b[36m0.0377\u001b[0m  3.0957\n",
      "      8        \u001b[36m0.0238\u001b[0m  3.0983\n",
      "      9        0.0246  3.0982\n",
      "     10        \u001b[36m0.0183\u001b[0m  3.1262\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  31.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2951\u001b[0m  4.7675\n",
      "      2        \u001b[36m0.1283\u001b[0m  4.7744\n",
      "      3        \u001b[36m0.0696\u001b[0m  4.7711\n",
      "      4        \u001b[36m0.0531\u001b[0m  4.7703\n",
      "      5        0.0584  4.7453\n",
      "      6        0.0650  4.7768\n",
      "      7        0.5534  4.7715\n",
      "      8        0.3345  4.7576\n",
      "      9        0.3524  4.7800\n",
      "     10        0.1744  4.7746\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  48.1s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2919\u001b[0m  4.7613\n",
      "      2        \u001b[36m0.0856\u001b[0m  4.7714\n",
      "      3        \u001b[36m0.0502\u001b[0m  4.7764\n",
      "      4        \u001b[36m0.0379\u001b[0m  4.7825\n",
      "      5        \u001b[36m0.0306\u001b[0m  4.7742\n",
      "      6        0.0310  4.7865\n",
      "      7        \u001b[36m0.0181\u001b[0m  4.7687\n",
      "      8        0.0217  4.7822\n",
      "      9        0.0403  4.7720\n",
      "     10        0.0291  4.7695\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  48.1s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2652\u001b[0m  4.7635\n",
      "      2        0.3226  4.7695\n",
      "      3        0.3062  4.7673\n",
      "      4        \u001b[36m0.2414\u001b[0m  4.7584\n",
      "      5        \u001b[36m0.0929\u001b[0m  4.7686\n",
      "      6        0.3782  4.7630\n",
      "      7        0.1153  4.7641\n",
      "      8        \u001b[36m0.0716\u001b[0m  4.7719\n",
      "      9        0.3478  4.7636\n",
      "     10        0.1619  4.7598\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  48.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2709\u001b[0m  4.7432\n",
      "      2        \u001b[36m0.1025\u001b[0m  4.7798\n",
      "      3        \u001b[36m0.0507\u001b[0m  4.7721\n",
      "      4        \u001b[36m0.0429\u001b[0m  4.7579\n",
      "      5        0.0436  4.7785\n",
      "      6        \u001b[36m0.0352\u001b[0m  4.7489\n",
      "      7        \u001b[36m0.0322\u001b[0m  4.7653\n",
      "      8        \u001b[36m0.0195\u001b[0m  4.7766\n",
      "      9        0.0224  4.7714\n",
      "     10        0.0251  4.7667\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  48.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2927\u001b[0m  4.7708\n",
      "      2        \u001b[36m0.1133\u001b[0m  4.7760\n",
      "      3        \u001b[36m0.0616\u001b[0m  4.7871\n",
      "      4        \u001b[36m0.0404\u001b[0m  4.7376\n",
      "      5        0.2049  4.7579\n",
      "      6        0.1622  4.7633\n",
      "      7        0.2741  4.7622\n",
      "      8        0.2092  4.7522\n",
      "      9        0.1299  4.7713\n",
      "     10        0.0706  4.7726\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  48.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2765\u001b[0m  4.0411\n",
      "      2        \u001b[36m0.1130\u001b[0m  4.0206\n",
      "      3        \u001b[36m0.0624\u001b[0m  4.0432\n",
      "      4        \u001b[36m0.0474\u001b[0m  4.0321\n",
      "      5        \u001b[36m0.0319\u001b[0m  4.0367\n",
      "      6        0.3058  4.0362\n",
      "      7        0.1068  4.0350\n",
      "      8        0.0713  4.0404\n",
      "      9        0.0559  4.0383\n",
      "     10        0.0413  4.0480\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  40.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2486\u001b[0m  4.0404\n",
      "      2        \u001b[36m0.2033\u001b[0m  4.0483\n",
      "      3        0.3052  4.0291\n",
      "      4        \u001b[36m0.0976\u001b[0m  4.0477\n",
      "      5        \u001b[36m0.0484\u001b[0m  4.0491\n",
      "      6        \u001b[36m0.0350\u001b[0m  4.0504\n",
      "      7        \u001b[36m0.0337\u001b[0m  4.0558\n",
      "      8        \u001b[36m0.0244\u001b[0m  4.0434\n",
      "      9        0.0315  4.0564\n",
      "     10        \u001b[36m0.0228\u001b[0m  4.0517\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  40.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2908\u001b[0m  4.0460\n",
      "      2        \u001b[36m0.2231\u001b[0m  4.0374\n",
      "      3        \u001b[36m0.1999\u001b[0m  4.0448\n",
      "      4        \u001b[36m0.1316\u001b[0m  4.0395\n",
      "      5        \u001b[36m0.0858\u001b[0m  4.0225\n",
      "      6        \u001b[36m0.0634\u001b[0m  4.0492\n",
      "      7        \u001b[36m0.0464\u001b[0m  4.0411\n",
      "      8        \u001b[36m0.0383\u001b[0m  4.0417\n",
      "      9        \u001b[36m0.0373\u001b[0m  4.0613\n",
      "     10        \u001b[36m0.0366\u001b[0m  4.0525\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  40.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2736\u001b[0m  4.0659\n",
      "      2        \u001b[36m0.0603\u001b[0m  4.0533\n",
      "      3        \u001b[36m0.0299\u001b[0m  4.0567\n",
      "      4        \u001b[36m0.0247\u001b[0m  4.0445\n",
      "      5        0.0305  4.0535\n",
      "      6        \u001b[36m0.0202\u001b[0m  4.0673\n",
      "      7        \u001b[36m0.0174\u001b[0m  4.0452\n",
      "      8        \u001b[36m0.0171\u001b[0m  4.0465\n",
      "      9        0.0231  4.0522\n",
      "     10        0.0197  4.0426\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  40.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2738\u001b[0m  4.0259\n",
      "      2        \u001b[36m0.1081\u001b[0m  4.0401\n",
      "      3        \u001b[36m0.0429\u001b[0m  4.0433\n",
      "      4        0.0911  4.0367\n",
      "      5        0.3009  4.0475\n",
      "      6        0.0981  4.0520\n",
      "      7        0.1251  4.0553\n",
      "      8        0.0531  4.0415\n",
      "      9        0.0492  4.0492\n",
      "     10        \u001b[36m0.0293\u001b[0m  4.0684\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  40.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3154\u001b[0m  2.7885\n",
      "      2        \u001b[36m0.2362\u001b[0m  2.8008\n",
      "      3        \u001b[36m0.2227\u001b[0m  2.8199\n",
      "      4        0.2971  2.8072\n",
      "      5        0.2247  2.7891\n",
      "      6        \u001b[36m0.1785\u001b[0m  2.7898\n",
      "      7        \u001b[36m0.1576\u001b[0m  2.7996\n",
      "      8        \u001b[36m0.1377\u001b[0m  2.8244\n",
      "      9        \u001b[36m0.1298\u001b[0m  2.8051\n",
      "     10        \u001b[36m0.1246\u001b[0m  2.8147\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  28.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3360\u001b[0m  2.8169\n",
      "      2        \u001b[36m0.2116\u001b[0m  2.8060\n",
      "      3        \u001b[36m0.1702\u001b[0m  2.8143\n",
      "      4        \u001b[36m0.1486\u001b[0m  2.8268\n",
      "      5        0.1851  2.8148\n",
      "      6        0.3631  2.8082\n",
      "      7        0.3293  2.8265\n",
      "      8        0.2609  2.8284\n",
      "      9        0.1709  2.8148\n",
      "     10        \u001b[36m0.1411\u001b[0m  2.8301\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  28.5s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3030\u001b[0m  2.8032\n",
      "      2        \u001b[36m0.2748\u001b[0m  2.7888\n",
      "      3        \u001b[36m0.1682\u001b[0m  2.8204\n",
      "      4        0.1815  2.7972\n",
      "      5        \u001b[36m0.1361\u001b[0m  2.8211\n",
      "      6        \u001b[36m0.1276\u001b[0m  2.7693\n",
      "      7        \u001b[36m0.1258\u001b[0m  2.7925\n",
      "      8        0.1692  2.7796\n",
      "      9        0.1805  2.8078\n",
      "     10        \u001b[36m0.0981\u001b[0m  2.8038\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  28.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3164\u001b[0m  2.7816\n",
      "      2        \u001b[36m0.1960\u001b[0m  2.7898\n",
      "      3        \u001b[36m0.1643\u001b[0m  2.7849\n",
      "      4        \u001b[36m0.1316\u001b[0m  2.8052\n",
      "      5        \u001b[36m0.0956\u001b[0m  2.7796\n",
      "      6        \u001b[36m0.0719\u001b[0m  2.8154\n",
      "      7        \u001b[36m0.0621\u001b[0m  2.8099\n",
      "      8        0.0638  2.7922\n",
      "      9        \u001b[36m0.0556\u001b[0m  2.7997\n",
      "     10        0.0807  2.8214\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  28.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3129\u001b[0m  2.8012\n",
      "      2        \u001b[36m0.2333\u001b[0m  2.8388\n",
      "      3        \u001b[36m0.1979\u001b[0m  2.8138\n",
      "      4        \u001b[36m0.0966\u001b[0m  2.7806\n",
      "      5        0.0979  2.7855\n",
      "      6        \u001b[36m0.0631\u001b[0m  2.7947\n",
      "      7        \u001b[36m0.0503\u001b[0m  2.8107\n",
      "      8        \u001b[36m0.0437\u001b[0m  2.8009\n",
      "      9        \u001b[36m0.0345\u001b[0m  2.8201\n",
      "     10        0.0376  2.7870\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  28.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3184\u001b[0m  3.0997\n",
      "      2        \u001b[36m0.1842\u001b[0m  3.0837\n",
      "      3        \u001b[36m0.1052\u001b[0m  3.0873\n",
      "      4        \u001b[36m0.0784\u001b[0m  3.0783\n",
      "      5        \u001b[36m0.0569\u001b[0m  3.1299\n",
      "      6        \u001b[36m0.0452\u001b[0m  3.0728\n",
      "      7        0.0464  3.0670\n",
      "      8        \u001b[36m0.0352\u001b[0m  3.1083\n",
      "      9        \u001b[36m0.0352\u001b[0m  3.1134\n",
      "     10        \u001b[36m0.0248\u001b[0m  3.1317\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  31.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2833\u001b[0m  3.0568\n",
      "      2        \u001b[36m0.1408\u001b[0m  3.0715\n",
      "      3        \u001b[36m0.0762\u001b[0m  3.0879\n",
      "      4        \u001b[36m0.0618\u001b[0m  3.0635\n",
      "      5        \u001b[36m0.0498\u001b[0m  3.0414\n",
      "      6        0.0512  3.0518\n",
      "      7        \u001b[36m0.0338\u001b[0m  3.1315\n",
      "      8        0.0388  3.0965\n",
      "      9        0.0350  3.1422\n",
      "     10        \u001b[36m0.0213\u001b[0m  3.1277\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  31.2s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2640\u001b[0m  3.1140\n",
      "      2        \u001b[36m0.1337\u001b[0m  3.1088\n",
      "      3        \u001b[36m0.0825\u001b[0m  3.1224\n",
      "      4        \u001b[36m0.0647\u001b[0m  3.1132\n",
      "      5        \u001b[36m0.0410\u001b[0m  3.1110\n",
      "      6        \u001b[36m0.0276\u001b[0m  3.1007\n",
      "      7        0.2365  3.1083\n",
      "      8        0.3733  3.1016\n",
      "      9        0.1849  3.1009\n",
      "     10        0.1082  3.1008\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  31.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3103\u001b[0m  3.1410\n",
      "      2        \u001b[36m0.1412\u001b[0m  3.0880\n",
      "      3        \u001b[36m0.0771\u001b[0m  3.1398\n",
      "      4        \u001b[36m0.0444\u001b[0m  3.1185\n",
      "      5        0.0520  3.0924\n",
      "      6        \u001b[36m0.0433\u001b[0m  3.1017\n",
      "      7        \u001b[36m0.0318\u001b[0m  3.1228\n",
      "      8        \u001b[36m0.0244\u001b[0m  3.0845\n",
      "      9        \u001b[36m0.0221\u001b[0m  3.1137\n",
      "     10        \u001b[36m0.0209\u001b[0m  3.1265\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  31.5s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3182\u001b[0m  3.0901\n",
      "      2        \u001b[36m0.1580\u001b[0m  3.1006\n",
      "      3        0.1640  3.1186\n",
      "      4        0.2322  3.1317\n",
      "      5        \u001b[36m0.1498\u001b[0m  3.1292\n",
      "      6        \u001b[36m0.1153\u001b[0m  3.1259\n",
      "      7        \u001b[36m0.0657\u001b[0m  3.1323\n",
      "      8        \u001b[36m0.0583\u001b[0m  3.1105\n",
      "      9        \u001b[36m0.0456\u001b[0m  3.1346\n",
      "     10        0.0670  3.1195\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  31.5s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3034\u001b[0m  4.7711\n",
      "      2        \u001b[36m0.1480\u001b[0m  4.7665\n",
      "      3        \u001b[36m0.1057\u001b[0m  4.7741\n",
      "      4        0.3004  4.7688\n",
      "      5        0.4873  4.7625\n",
      "      6        0.2115  4.7549\n",
      "      7        0.1133  4.7690\n",
      "      8        \u001b[36m0.0802\u001b[0m  4.7796\n",
      "      9        \u001b[36m0.0528\u001b[0m  4.7733\n",
      "     10        \u001b[36m0.0477\u001b[0m  4.7417\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  48.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2642\u001b[0m  4.7545\n",
      "      2        \u001b[36m0.1360\u001b[0m  4.7710\n",
      "      3        \u001b[36m0.0976\u001b[0m  4.7593\n",
      "      4        \u001b[36m0.0553\u001b[0m  4.7660\n",
      "      5        \u001b[36m0.0359\u001b[0m  4.7393\n",
      "      6        0.0545  4.7391\n",
      "      7        \u001b[36m0.0327\u001b[0m  4.7666\n",
      "      8        \u001b[36m0.0271\u001b[0m  4.7645\n",
      "      9        \u001b[36m0.0199\u001b[0m  4.7657\n",
      "     10        0.1376  4.7606\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  48.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2646\u001b[0m  4.7575\n",
      "      2        \u001b[36m0.1327\u001b[0m  4.7374\n",
      "      3        \u001b[36m0.0888\u001b[0m  4.7615\n",
      "      4        0.1177  4.7698\n",
      "      5        0.5666  4.7618\n",
      "      6        0.6452  4.7714\n",
      "      7        0.6249  4.7702\n",
      "      8        0.6123  4.7652\n",
      "      9        0.5229  4.7552\n",
      "     10        0.4590  4.7693\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  48.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2649\u001b[0m  4.7551\n",
      "      2        \u001b[36m0.1303\u001b[0m  4.7436\n",
      "      3        0.1488  4.7505\n",
      "      4        \u001b[36m0.0494\u001b[0m  4.7532\n",
      "      5        0.0887  4.7503\n",
      "      6        \u001b[36m0.0477\u001b[0m  4.7605\n",
      "      7        \u001b[36m0.0283\u001b[0m  4.7577\n",
      "      8        \u001b[36m0.0199\u001b[0m  4.7700\n",
      "      9        \u001b[36m0.0164\u001b[0m  4.7598\n",
      "     10        0.0358  4.7558\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  47.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3242\u001b[0m  4.7609\n",
      "      2        \u001b[36m0.1347\u001b[0m  4.7370\n",
      "      3        \u001b[36m0.0890\u001b[0m  4.7633\n",
      "      4        \u001b[36m0.0359\u001b[0m  4.7623\n",
      "      5        \u001b[36m0.0300\u001b[0m  4.7687\n",
      "      6        \u001b[36m0.0246\u001b[0m  4.7620\n",
      "      7        \u001b[36m0.0209\u001b[0m  4.7627\n",
      "      8        0.0745  4.7642\n",
      "      9        0.4298  4.7487\n",
      "     10        0.5177  4.7520\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  48.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3604\u001b[0m  4.0358\n",
      "      2        \u001b[36m0.1285\u001b[0m  4.0352\n",
      "      3        0.1356  4.0380\n",
      "      4        0.3024  4.0371\n",
      "      5        0.5209  4.0522\n",
      "      6        0.5669  4.0453\n",
      "      7        0.5006  4.0181\n",
      "      8        0.4823  4.0288\n",
      "      9        0.3271  4.0395\n",
      "     10        0.2401  4.0439\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  40.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4019\u001b[0m  4.0361\n",
      "      2        \u001b[36m0.0944\u001b[0m  4.0240\n",
      "      3        \u001b[36m0.0422\u001b[0m  4.0215\n",
      "      4        0.0777  4.0457\n",
      "      5        \u001b[36m0.0337\u001b[0m  4.0601\n",
      "      6        \u001b[36m0.0268\u001b[0m  4.0286\n",
      "      7        \u001b[36m0.0247\u001b[0m  4.0430\n",
      "      8        \u001b[36m0.0207\u001b[0m  4.0438\n",
      "      9        0.0327  4.0212\n",
      "     10        0.0461  4.0417\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  40.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2756\u001b[0m  4.0648\n",
      "      2        \u001b[36m0.1129\u001b[0m  4.0607\n",
      "      3        \u001b[36m0.0757\u001b[0m  4.0518\n",
      "      4        0.2708  4.0490\n",
      "      5        0.1728  4.0440\n",
      "      6        0.1983  4.0290\n",
      "      7        0.0780  4.0387\n",
      "      8        \u001b[36m0.0556\u001b[0m  4.0676\n",
      "      9        \u001b[36m0.0399\u001b[0m  4.0612\n",
      "     10        \u001b[36m0.0371\u001b[0m  4.0512\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  40.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2917\u001b[0m  4.0396\n",
      "      2        \u001b[36m0.1173\u001b[0m  4.0552\n",
      "      3        \u001b[36m0.0543\u001b[0m  4.0484\n",
      "      4        \u001b[36m0.0326\u001b[0m  4.0324\n",
      "      5        0.0396  4.0523\n",
      "      6        0.0728  4.0530\n",
      "      7        \u001b[36m0.0322\u001b[0m  4.0600\n",
      "      8        0.2742  4.0642\n",
      "      9        0.1254  4.0380\n",
      "     10        0.0640  4.0435\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  40.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2577\u001b[0m  4.0450\n",
      "      2        \u001b[36m0.1026\u001b[0m  4.0674\n",
      "      3        \u001b[36m0.0497\u001b[0m  4.0457\n",
      "      4        \u001b[36m0.0435\u001b[0m  4.0583\n",
      "      5        0.0450  4.0613\n",
      "      6        0.1561  4.0477\n",
      "      7        0.0713  4.0313\n",
      "      8        \u001b[36m0.0337\u001b[0m  4.0597\n",
      "      9        \u001b[36m0.0284\u001b[0m  4.0684\n",
      "     10        \u001b[36m0.0255\u001b[0m  4.0516\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  41.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3867\u001b[0m  2.7856\n",
      "      2        \u001b[36m0.2143\u001b[0m  2.8061\n",
      "      3        \u001b[36m0.1611\u001b[0m  2.8092\n",
      "      4        \u001b[36m0.1392\u001b[0m  2.7858\n",
      "      5        \u001b[36m0.1159\u001b[0m  2.7965\n",
      "      6        0.2765  2.7853\n",
      "      7        0.1644  2.7879\n",
      "      8        0.1225  2.7822\n",
      "      9        \u001b[36m0.1042\u001b[0m  2.8000\n",
      "     10        \u001b[36m0.0892\u001b[0m  2.7854\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  28.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3312\u001b[0m  2.8020\n",
      "      2        \u001b[36m0.2142\u001b[0m  2.8349\n",
      "      3        \u001b[36m0.1816\u001b[0m  2.7887\n",
      "      4        0.2110  2.8126\n",
      "      5        \u001b[36m0.1366\u001b[0m  2.8268\n",
      "      6        0.1380  2.8176\n",
      "      7        \u001b[36m0.1143\u001b[0m  2.7838\n",
      "      8        \u001b[36m0.0923\u001b[0m  2.8072\n",
      "      9        \u001b[36m0.0850\u001b[0m  2.8026\n",
      "     10        0.0855  2.8056\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  28.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3507\u001b[0m  2.7955\n",
      "      2        \u001b[36m0.2366\u001b[0m  2.8201\n",
      "      3        \u001b[36m0.1789\u001b[0m  2.7870\n",
      "      4        \u001b[36m0.1242\u001b[0m  2.7850\n",
      "      5        0.1265  2.8074\n",
      "      6        \u001b[36m0.0957\u001b[0m  2.8051\n",
      "      7        0.1602  2.7915\n",
      "      8        0.2172  2.8008\n",
      "      9        0.1109  2.8231\n",
      "     10        \u001b[36m0.0939\u001b[0m  2.7857\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  28.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3575\u001b[0m  2.7954\n",
      "      2        \u001b[36m0.2224\u001b[0m  2.8274\n",
      "      3        \u001b[36m0.1639\u001b[0m  2.8072\n",
      "      4        \u001b[36m0.1272\u001b[0m  2.8251\n",
      "      5        \u001b[36m0.1053\u001b[0m  2.8265\n",
      "      6        \u001b[36m0.0960\u001b[0m  2.8145\n",
      "      7        \u001b[36m0.0777\u001b[0m  2.8291\n",
      "      8        0.0898  2.8225\n",
      "      9        \u001b[36m0.0773\u001b[0m  2.8125\n",
      "     10        0.1025  2.8529\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  28.5s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3801\u001b[0m  2.8204\n",
      "      2        \u001b[36m0.2806\u001b[0m  2.7912\n",
      "      3        \u001b[36m0.2323\u001b[0m  2.8057\n",
      "      4        \u001b[36m0.1927\u001b[0m  2.8284\n",
      "      5        \u001b[36m0.1313\u001b[0m  2.8158\n",
      "      6        \u001b[36m0.1075\u001b[0m  2.7956\n",
      "      7        0.1127  2.7848\n",
      "      8        \u001b[36m0.0788\u001b[0m  2.8076\n",
      "      9        \u001b[36m0.0739\u001b[0m  2.8283\n",
      "     10        \u001b[36m0.0594\u001b[0m  2.7997\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  28.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2894\u001b[0m  3.1000\n",
      "      2        \u001b[36m0.1861\u001b[0m  3.1175\n",
      "      3        \u001b[36m0.1153\u001b[0m  3.0706\n",
      "      4        \u001b[36m0.0828\u001b[0m  3.0584\n",
      "      5        \u001b[36m0.0620\u001b[0m  3.0863\n",
      "      6        \u001b[36m0.0415\u001b[0m  3.0755\n",
      "      7        0.0421  3.1155\n",
      "      8        \u001b[36m0.0351\u001b[0m  3.0838\n",
      "      9        0.0378  3.0762\n",
      "     10        0.0368  3.0922\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  31.2s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2955\u001b[0m  3.0852\n",
      "      2        \u001b[36m0.1505\u001b[0m  3.0942\n",
      "      3        \u001b[36m0.0893\u001b[0m  3.1194\n",
      "      4        \u001b[36m0.0427\u001b[0m  3.0866\n",
      "      5        \u001b[36m0.0322\u001b[0m  3.1272\n",
      "      6        \u001b[36m0.0308\u001b[0m  3.0715\n",
      "      7        \u001b[36m0.0234\u001b[0m  3.0670\n",
      "      8        0.0286  3.0754\n",
      "      9        \u001b[36m0.0195\u001b[0m  3.1292\n",
      "     10        0.0227  3.1105\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  31.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3290\u001b[0m  3.0558\n",
      "      2        0.4929  3.0501\n",
      "      3        0.4327  3.0418\n",
      "      4        \u001b[36m0.3034\u001b[0m  3.1526\n",
      "      5        \u001b[36m0.2353\u001b[0m  3.0929\n",
      "      6        \u001b[36m0.1276\u001b[0m  3.1191\n",
      "      7        0.1636  3.1085\n",
      "      8        0.5321  3.1154\n",
      "      9        0.2409  3.0842\n",
      "     10        0.1565  3.0889\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  31.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3093\u001b[0m  3.1038\n",
      "      2        \u001b[36m0.1654\u001b[0m  3.1184\n",
      "      3        \u001b[36m0.1064\u001b[0m  3.0967\n",
      "      4        \u001b[36m0.0775\u001b[0m  3.0846\n",
      "      5        0.1253  3.1100\n",
      "      6        0.3936  3.1150\n",
      "      7        0.3099  3.0839\n",
      "      8        0.2425  3.1303\n",
      "      9        0.1559  3.0822\n",
      "     10        0.1114  3.1026\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  31.4s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3362\u001b[0m  3.1188\n",
      "      2        \u001b[36m0.1163\u001b[0m  3.0836\n",
      "      3        \u001b[36m0.0751\u001b[0m  3.1257\n",
      "      4        \u001b[36m0.0538\u001b[0m  3.0739\n",
      "      5        \u001b[36m0.0401\u001b[0m  3.1069\n",
      "      6        \u001b[36m0.0375\u001b[0m  3.1123\n",
      "      7        \u001b[36m0.0293\u001b[0m  3.1004\n",
      "      8        0.0310  3.0780\n",
      "      9        \u001b[36m0.0279\u001b[0m  3.0766\n",
      "     10        \u001b[36m0.0264\u001b[0m  3.0881\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  31.3s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3083\u001b[0m  4.7549\n",
      "      2        \u001b[36m0.1261\u001b[0m  4.7556\n",
      "      3        \u001b[36m0.0958\u001b[0m  4.7530\n",
      "      4        0.1123  4.7543\n",
      "      5        0.3946  4.7536\n",
      "      6        0.3064  4.7555\n",
      "      7        0.1513  4.7328\n",
      "      8        \u001b[36m0.0797\u001b[0m  4.7711\n",
      "      9        \u001b[36m0.0731\u001b[0m  4.7540\n",
      "     10        \u001b[36m0.0496\u001b[0m  4.7590\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  47.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3177\u001b[0m  4.7694\n",
      "      2        \u001b[36m0.1500\u001b[0m  4.7717\n",
      "      3        \u001b[36m0.0955\u001b[0m  4.7695\n",
      "      4        \u001b[36m0.0648\u001b[0m  4.7640\n",
      "      5        \u001b[36m0.0381\u001b[0m  4.7757\n",
      "      6        \u001b[36m0.0365\u001b[0m  4.7480\n",
      "      7        \u001b[36m0.0296\u001b[0m  4.7526\n",
      "      8        0.0417  4.7835\n",
      "      9        0.0312  4.7753\n",
      "     10        0.0326  4.7681\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  48.1s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2999\u001b[0m  4.7641\n",
      "      2        \u001b[36m0.1293\u001b[0m  4.7432\n",
      "      3        0.2233  4.7582\n",
      "      4        0.1318  4.7539\n",
      "      5        \u001b[36m0.0824\u001b[0m  4.7397\n",
      "      6        \u001b[36m0.0550\u001b[0m  4.7697\n",
      "      7        0.0588  4.7726\n",
      "      8        \u001b[36m0.0534\u001b[0m  4.7582\n",
      "      9        \u001b[36m0.0405\u001b[0m  4.7577\n",
      "     10        0.1208  4.7585\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  48.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2914\u001b[0m  4.7590\n",
      "      2        \u001b[36m0.2298\u001b[0m  4.7641\n",
      "      3        0.5704  4.7841\n",
      "      4        0.3379  4.7696\n",
      "      5        \u001b[36m0.1383\u001b[0m  4.7662\n",
      "      6        \u001b[36m0.1328\u001b[0m  4.7636\n",
      "      7        \u001b[36m0.1197\u001b[0m  4.7678\n",
      "      8        \u001b[36m0.0600\u001b[0m  4.7400\n",
      "      9        0.0785  4.7648\n",
      "     10        0.0740  4.7639\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  48.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2761\u001b[0m  4.7621\n",
      "      2        \u001b[36m0.0910\u001b[0m  4.7512\n",
      "      3        \u001b[36m0.0518\u001b[0m  4.7529\n",
      "      4        \u001b[36m0.0304\u001b[0m  4.7490\n",
      "      5        0.0361  4.7558\n",
      "      6        \u001b[36m0.0233\u001b[0m  4.7571\n",
      "      7        \u001b[36m0.0204\u001b[0m  4.7492\n",
      "      8        \u001b[36m0.0186\u001b[0m  4.7594\n",
      "      9        0.0225  4.7593\n",
      "     10        0.0198  4.7595\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  47.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3595\u001b[0m  4.0475\n",
      "      2        \u001b[36m0.0699\u001b[0m  4.0223\n",
      "      3        \u001b[36m0.0472\u001b[0m  4.0538\n",
      "      4        \u001b[36m0.0389\u001b[0m  4.0510\n",
      "      5        0.0472  4.0518\n",
      "      6        \u001b[36m0.0325\u001b[0m  4.0590\n",
      "      7        \u001b[36m0.0311\u001b[0m  4.0394\n",
      "      8        \u001b[36m0.0238\u001b[0m  4.0390\n",
      "      9        0.0563  4.0645\n",
      "     10        0.0289  4.0611\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  40.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3121\u001b[0m  4.0379\n",
      "      2        \u001b[36m0.1499\u001b[0m  4.0511\n",
      "      3        \u001b[36m0.0685\u001b[0m  4.0251\n",
      "      4        0.2616  4.0227\n",
      "      5        0.1584  4.0313\n",
      "      6        0.0877  4.0436\n",
      "      7        0.0787  4.0456\n",
      "      8        0.2848  4.0395\n",
      "      9        0.1872  4.0561\n",
      "     10        0.1725  4.0485\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  40.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5236\u001b[0m  4.0370\n",
      "      2        \u001b[36m0.1375\u001b[0m  4.0398\n",
      "      3        0.1894  4.0263\n",
      "      4        \u001b[36m0.1116\u001b[0m  4.0393\n",
      "      5        \u001b[36m0.0595\u001b[0m  4.0225\n",
      "      6        \u001b[36m0.0541\u001b[0m  4.0557\n",
      "      7        \u001b[36m0.0342\u001b[0m  4.0428\n",
      "      8        0.0363  4.0519\n",
      "      9        \u001b[36m0.0298\u001b[0m  4.0348\n",
      "     10        0.0360  4.0487\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  40.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5008\u001b[0m  4.0636\n",
      "      2        \u001b[36m0.1716\u001b[0m  4.0552\n",
      "      3        \u001b[36m0.1176\u001b[0m  4.0670\n",
      "      4        \u001b[36m0.0656\u001b[0m  4.0517\n",
      "      5        \u001b[36m0.0434\u001b[0m  4.0427\n",
      "      6        \u001b[36m0.0428\u001b[0m  4.0711\n",
      "      7        \u001b[36m0.0354\u001b[0m  4.0514\n",
      "      8        0.0375  4.0555\n",
      "      9        0.0491  4.0686\n",
      "     10        \u001b[36m0.0338\u001b[0m  4.0593\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  41.0s\n",
      "[CV] net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5125\u001b[0m  4.0447\n",
      "      2        \u001b[36m0.2233\u001b[0m  4.0509\n",
      "      3        \u001b[36m0.1428\u001b[0m  4.0396\n",
      "      4        \u001b[36m0.1171\u001b[0m  4.0623\n",
      "      5        \u001b[36m0.0985\u001b[0m  4.0411\n",
      "      6        \u001b[36m0.0695\u001b[0m  4.0461\n",
      "      7        \u001b[36m0.0608\u001b[0m  4.0372\n",
      "      8        0.0624  4.0402\n",
      "      9        \u001b[36m0.0443\u001b[0m  4.0209\n",
      "     10        \u001b[36m0.0379\u001b[0m  4.0361\n",
      "[CV]  net__batch_size=64, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  40.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3218\u001b[0m  2.7980\n",
      "      2        \u001b[36m0.2137\u001b[0m  2.7963\n",
      "      3        \u001b[36m0.1691\u001b[0m  2.7909\n",
      "      4        0.3141  2.8071\n",
      "      5        0.3289  2.8265\n",
      "      6        0.2676  2.8301\n",
      "      7        0.2307  2.7968\n",
      "      8        0.2129  2.8107\n",
      "      9        0.1965  2.8077\n",
      "     10        0.4558  2.8112\n",
      "     11        0.4452  2.8017\n",
      "     12        0.3752  2.8239\n",
      "     13        0.3197  2.7853\n",
      "     14        0.3005  2.7881\n",
      "     15        0.2387  2.7982\n",
      "     16        0.1983  2.8322\n",
      "     17        0.1885  2.8303\n",
      "     18        0.1841  2.7879\n",
      "     19        0.1789  2.8267\n",
      "     20        \u001b[36m0.1318\u001b[0m  2.8306\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  56.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3035\u001b[0m  2.7933\n",
      "      2        \u001b[36m0.2333\u001b[0m  2.7934\n",
      "      3        \u001b[36m0.1962\u001b[0m  2.8074\n",
      "      4        \u001b[36m0.1741\u001b[0m  2.7913\n",
      "      5        \u001b[36m0.1212\u001b[0m  2.8006\n",
      "      6        \u001b[36m0.0996\u001b[0m  2.8450\n",
      "      7        \u001b[36m0.0925\u001b[0m  2.8012\n",
      "      8        0.3839  2.8107\n",
      "      9        0.2137  2.8159\n",
      "     10        0.1340  2.7817\n",
      "     11        0.0942  2.8304\n",
      "     12        \u001b[36m0.0794\u001b[0m  2.8115\n",
      "     13        0.0830  2.8296\n",
      "     14        \u001b[36m0.0767\u001b[0m  2.7865\n",
      "     15        0.0826  2.7852\n",
      "     16        0.1440  2.8062\n",
      "     17        0.0850  2.8048\n",
      "     18        \u001b[36m0.0576\u001b[0m  2.7843\n",
      "     19        0.0587  2.7710\n",
      "     20        \u001b[36m0.0505\u001b[0m  2.7892\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  56.7s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2968\u001b[0m  2.8249\n",
      "      2        \u001b[36m0.1498\u001b[0m  2.7942\n",
      "      3        \u001b[36m0.1149\u001b[0m  2.8243\n",
      "      4        \u001b[36m0.0886\u001b[0m  2.8227\n",
      "      5        \u001b[36m0.0768\u001b[0m  2.8247\n",
      "      6        \u001b[36m0.0584\u001b[0m  2.8281\n",
      "      7        \u001b[36m0.0574\u001b[0m  2.8072\n",
      "      8        \u001b[36m0.0413\u001b[0m  2.8063\n",
      "      9        0.2900  2.7963\n",
      "     10        0.2813  2.8388\n",
      "     11        0.1909  2.8301\n",
      "     12        0.1309  2.8040\n",
      "     13        0.0824  2.8126\n",
      "     14        0.0785  2.7883\n",
      "     15        0.0617  2.7800\n",
      "     16        0.0544  2.8051\n",
      "     17        0.1083  2.8073\n",
      "     18        0.0628  2.8193\n",
      "     19        0.0616  2.8109\n",
      "     20        0.0771  2.7914\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  56.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3230\u001b[0m  2.7940\n",
      "      2        \u001b[36m0.1722\u001b[0m  2.8156\n",
      "      3        \u001b[36m0.1430\u001b[0m  2.8166\n",
      "      4        \u001b[36m0.1130\u001b[0m  2.8418\n",
      "      5        \u001b[36m0.1065\u001b[0m  2.8317\n",
      "      6        \u001b[36m0.0872\u001b[0m  2.8043\n",
      "      7        \u001b[36m0.0722\u001b[0m  2.7951\n",
      "      8        \u001b[36m0.0661\u001b[0m  2.8222\n",
      "      9        \u001b[36m0.0567\u001b[0m  2.8349\n",
      "     10        \u001b[36m0.0456\u001b[0m  2.8088\n",
      "     11        0.0480  2.8130\n",
      "     12        0.0491  2.8187\n",
      "     13        \u001b[36m0.0454\u001b[0m  2.8295\n",
      "     14        0.0458  2.8341\n",
      "     15        0.0511  2.8018\n",
      "     16        \u001b[36m0.0393\u001b[0m  2.7917\n",
      "     17        \u001b[36m0.0319\u001b[0m  2.8293\n",
      "     18        0.0357  2.8248\n",
      "     19        \u001b[36m0.0271\u001b[0m  2.8312\n",
      "     20        \u001b[36m0.0262\u001b[0m  2.8268\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  57.1s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2942\u001b[0m  2.8132\n",
      "      2        \u001b[36m0.2761\u001b[0m  2.8115\n",
      "      3        \u001b[36m0.1641\u001b[0m  2.8302\n",
      "      4        0.1676  2.7912\n",
      "      5        \u001b[36m0.1080\u001b[0m  2.8090\n",
      "      6        \u001b[36m0.0864\u001b[0m  2.8025\n",
      "      7        \u001b[36m0.0783\u001b[0m  2.8009\n",
      "      8        0.0921  2.8002\n",
      "      9        \u001b[36m0.0618\u001b[0m  2.8324\n",
      "     10        0.0966  2.7902\n",
      "     11        \u001b[36m0.0592\u001b[0m  2.7832\n",
      "     12        \u001b[36m0.0501\u001b[0m  2.7958\n",
      "     13        0.0668  2.8120\n",
      "     14        0.0537  2.8246\n",
      "     15        \u001b[36m0.0393\u001b[0m  2.7978\n",
      "     16        \u001b[36m0.0347\u001b[0m  2.8193\n",
      "     17        0.0477  2.8082\n",
      "     18        0.0391  2.7968\n",
      "     19        0.0440  2.8003\n",
      "     20        0.0463  2.8215\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  56.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3016\u001b[0m  3.1152\n",
      "      2        \u001b[36m0.1577\u001b[0m  3.1075\n",
      "      3        \u001b[36m0.1492\u001b[0m  3.0980\n",
      "      4        \u001b[36m0.1479\u001b[0m  3.0663\n",
      "      5        \u001b[36m0.0715\u001b[0m  3.0614\n",
      "      6        \u001b[36m0.0531\u001b[0m  3.0961\n",
      "      7        0.2529  3.0919\n",
      "      8        0.1659  3.0897\n",
      "      9        0.0824  3.1187\n",
      "     10        0.0633  3.1131\n",
      "     11        0.0635  3.1088\n",
      "     12        0.0653  3.1078\n",
      "     13        \u001b[36m0.0527\u001b[0m  3.0609\n",
      "     14        \u001b[36m0.0442\u001b[0m  3.0893\n",
      "     15        \u001b[36m0.0347\u001b[0m  3.0794\n",
      "     16        \u001b[36m0.0307\u001b[0m  3.0820\n",
      "     17        0.0314  3.1243\n",
      "     18        0.0352  3.0938\n",
      "     19        0.0317  3.0901\n",
      "     20        \u001b[36m0.0228\u001b[0m  3.1285\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2635\u001b[0m  3.1174\n",
      "      2        \u001b[36m0.1356\u001b[0m  3.1017\n",
      "      3        \u001b[36m0.0996\u001b[0m  3.1243\n",
      "      4        \u001b[36m0.0542\u001b[0m  3.1138\n",
      "      5        \u001b[36m0.0492\u001b[0m  3.1108\n",
      "      6        \u001b[36m0.0372\u001b[0m  3.1195\n",
      "      7        \u001b[36m0.0259\u001b[0m  3.1283\n",
      "      8        0.1237  3.0897\n",
      "      9        0.3981  3.1365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        0.3203  3.1424\n",
      "     11        0.2032  3.1215\n",
      "     12        0.3100  3.1122\n",
      "     13        0.2792  3.1085\n",
      "     14        0.1637  3.1389\n",
      "     15        0.1236  3.0895\n",
      "     16        0.1137  3.1440\n",
      "     17        0.0784  3.1116\n",
      "     18        0.0700  3.1045\n",
      "     19        0.0695  3.1227\n",
      "     20        0.0712  3.1262\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.1min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2655\u001b[0m  3.1242\n",
      "      2        \u001b[36m0.1457\u001b[0m  3.0948\n",
      "      3        \u001b[36m0.0896\u001b[0m  3.0894\n",
      "      4        \u001b[36m0.0721\u001b[0m  3.0940\n",
      "      5        0.0741  3.1191\n",
      "      6        \u001b[36m0.0463\u001b[0m  3.0930\n",
      "      7        \u001b[36m0.0304\u001b[0m  3.0880\n",
      "      8        0.0320  3.1095\n",
      "      9        0.0427  3.1092\n",
      "     10        \u001b[36m0.0258\u001b[0m  3.0988\n",
      "     11        0.0389  3.1163\n",
      "     12        0.0393  3.0892\n",
      "     13        0.0276  3.0891\n",
      "     14        \u001b[36m0.0166\u001b[0m  3.0896\n",
      "     15        \u001b[36m0.0165\u001b[0m  3.1047\n",
      "     16        0.0253  3.1006\n",
      "     17        0.0216  3.1113\n",
      "     18        \u001b[36m0.0114\u001b[0m  3.1087\n",
      "     19        0.0275  3.0796\n",
      "     20        0.0343  3.1265\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2614\u001b[0m  3.1256\n",
      "      2        \u001b[36m0.0498\u001b[0m  3.0896\n",
      "      3        \u001b[36m0.0454\u001b[0m  3.1182\n",
      "      4        \u001b[36m0.0246\u001b[0m  3.0700\n",
      "      5        \u001b[36m0.0221\u001b[0m  3.1242\n",
      "      6        0.0356  3.1299\n",
      "      7        \u001b[36m0.0201\u001b[0m  3.1394\n",
      "      8        0.0204  3.1127\n",
      "      9        \u001b[36m0.0166\u001b[0m  3.0686\n",
      "     10        \u001b[36m0.0159\u001b[0m  3.1060\n",
      "     11        0.0219  3.1171\n",
      "     12        0.0188  3.0941\n",
      "     13        0.0183  3.0804\n",
      "     14        0.0296  3.0625\n",
      "     15        0.0209  3.1041\n",
      "     16        \u001b[36m0.0159\u001b[0m  3.1301\n",
      "     17        0.0173  3.1259\n",
      "     18        \u001b[36m0.0146\u001b[0m  3.1136\n",
      "     19        \u001b[36m0.0125\u001b[0m  3.1242\n",
      "     20        0.0127  3.1149\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2688\u001b[0m  3.0932\n",
      "      2        \u001b[36m0.1447\u001b[0m  3.1098\n",
      "      3        \u001b[36m0.1345\u001b[0m  3.1308\n",
      "      4        \u001b[36m0.1145\u001b[0m  3.0830\n",
      "      5        \u001b[36m0.0776\u001b[0m  3.1087\n",
      "      6        0.0868  3.1209\n",
      "      7        \u001b[36m0.0464\u001b[0m  3.0867\n",
      "      8        \u001b[36m0.0349\u001b[0m  3.1056\n",
      "      9        \u001b[36m0.0280\u001b[0m  3.1190\n",
      "     10        0.1873  3.1283\n",
      "     11        0.5498  3.1294\n",
      "     12        0.4881  3.0620\n",
      "     13        0.4725  3.0823\n",
      "     14        0.4401  3.1363\n",
      "     15        0.4749  3.1141\n",
      "     16        0.3897  3.1042\n",
      "     17        0.2857  3.1152\n",
      "     18        0.2146  3.0993\n",
      "     19        0.1956  3.0897\n",
      "     20        0.3566  3.1076\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2596\u001b[0m  4.7650\n",
      "      2        0.3966  4.7741\n",
      "      3        \u001b[36m0.1242\u001b[0m  4.7618\n",
      "      4        \u001b[36m0.1106\u001b[0m  4.7718\n",
      "      5        \u001b[36m0.0843\u001b[0m  4.7564\n",
      "      6        \u001b[36m0.0756\u001b[0m  4.7596\n",
      "      7        0.0823  4.7667\n",
      "      8        \u001b[36m0.0725\u001b[0m  4.7719\n",
      "      9        \u001b[36m0.0603\u001b[0m  4.7736\n",
      "     10        \u001b[36m0.0530\u001b[0m  4.7697\n",
      "     11        0.0666  4.7597\n",
      "     12        0.0602  4.7652\n",
      "     13        0.0682  4.7619\n",
      "     14        \u001b[36m0.0407\u001b[0m  4.7629\n",
      "     15        \u001b[36m0.0355\u001b[0m  4.7804\n",
      "     16        0.0429  4.7793\n",
      "     17        0.0358  4.7691\n",
      "     18        0.0383  4.7700\n",
      "     19        0.0382  4.7687\n",
      "     20        0.0487  4.7681\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2650\u001b[0m  4.7561\n",
      "      2        \u001b[36m0.1355\u001b[0m  4.7529\n",
      "      3        \u001b[36m0.0736\u001b[0m  4.7547\n",
      "      4        \u001b[36m0.0386\u001b[0m  4.7610\n",
      "      5        \u001b[36m0.0347\u001b[0m  4.7621\n",
      "      6        0.0354  4.7567\n",
      "      7        0.0504  4.7730\n",
      "      8        \u001b[36m0.0286\u001b[0m  4.7547\n",
      "      9        \u001b[36m0.0222\u001b[0m  4.7534\n",
      "     10        0.0293  4.7538\n",
      "     11        0.0808  4.7538\n",
      "     12        0.3551  4.7620\n",
      "     13        0.6194  4.7409\n",
      "     14        0.5519  4.7551\n",
      "     15        0.5063  4.7501\n",
      "     16        0.4894  4.7636\n",
      "     17        0.4449  4.7648\n",
      "     18        0.4434  4.7713\n",
      "     19        0.3646  4.7665\n",
      "     20        0.2823  4.7688\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3204\u001b[0m  4.7789\n",
      "      2        \u001b[36m0.2714\u001b[0m  4.7742\n",
      "      3        \u001b[36m0.1087\u001b[0m  4.7804\n",
      "      4        \u001b[36m0.0726\u001b[0m  4.7789\n",
      "      5        \u001b[36m0.0469\u001b[0m  4.7537\n",
      "      6        \u001b[36m0.0371\u001b[0m  4.7768\n",
      "      7        0.0414  4.7725\n",
      "      8        \u001b[36m0.0246\u001b[0m  4.7689\n",
      "      9        \u001b[36m0.0229\u001b[0m  4.7540\n",
      "     10        \u001b[36m0.0210\u001b[0m  4.7737\n",
      "     11        \u001b[36m0.0159\u001b[0m  4.7805\n",
      "     12        0.0270  4.7852\n",
      "     13        0.0214  4.7644\n",
      "     14        \u001b[36m0.0131\u001b[0m  4.7849\n",
      "     15        0.0464  4.7734\n",
      "     16        0.0546  4.7812\n",
      "     17        0.0374  4.7773\n",
      "     18        0.0368  4.7690\n",
      "     19        0.0498  4.7692\n",
      "     20        0.0720  4.7823\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2802\u001b[0m  4.7664\n",
      "      2        \u001b[36m0.1265\u001b[0m  4.7473\n",
      "      3        \u001b[36m0.0789\u001b[0m  4.7416\n",
      "      4        \u001b[36m0.0414\u001b[0m  4.7715\n",
      "      5        0.1479  4.7383\n",
      "      6        0.3891  4.7680\n",
      "      7        0.2493  4.7693\n",
      "      8        0.2463  4.7555\n",
      "      9        0.2502  4.7394\n",
      "     10        0.3008  4.7367\n",
      "     11        0.4103  4.7749\n",
      "     12        0.2831  4.7471\n",
      "     13        0.1577  4.7710\n",
      "     14        0.0967  4.7608\n",
      "     15        0.0930  4.7588\n",
      "     16        0.0737  4.7660\n",
      "     17        0.0499  4.7817\n",
      "     18        0.0543  4.7656\n",
      "     19        0.0451  4.7581\n",
      "     20        \u001b[36m0.0362\u001b[0m  4.7762\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2587\u001b[0m  4.7730\n",
      "      2        \u001b[36m0.1035\u001b[0m  4.7687\n",
      "      3        \u001b[36m0.0629\u001b[0m  4.7746\n",
      "      4        0.2519  4.7586\n",
      "      5        0.1758  4.7671\n",
      "      6        0.0953  4.7690\n",
      "      7        0.0873  4.7437\n",
      "      8        \u001b[36m0.0468\u001b[0m  4.7770\n",
      "      9        0.0474  4.7551\n",
      "     10        \u001b[36m0.0342\u001b[0m  4.7523\n",
      "     11        \u001b[36m0.0300\u001b[0m  4.7852\n",
      "     12        \u001b[36m0.0232\u001b[0m  4.7453\n",
      "     13        0.0251  4.7680\n",
      "     14        0.0532  4.7655\n",
      "     15        0.1233  4.7805\n",
      "     16        0.0516  4.7723\n",
      "     17        0.0325  4.7475\n",
      "     18        0.0256  4.7443\n",
      "     19        0.0437  4.7786\n",
      "     20        0.0409  4.7681\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3013\u001b[0m  4.0466\n",
      "      2        \u001b[36m0.0814\u001b[0m  4.0519\n",
      "      3        \u001b[36m0.0538\u001b[0m  4.0350\n",
      "      4        \u001b[36m0.0395\u001b[0m  4.0508\n",
      "      5        \u001b[36m0.0391\u001b[0m  4.0383\n",
      "      6        \u001b[36m0.0339\u001b[0m  4.0506\n",
      "      7        0.1578  4.0477\n",
      "      8        0.0701  4.0436\n",
      "      9        0.0369  4.0426\n",
      "     10        0.0452  4.0505\n",
      "     11        0.0462  4.0528\n",
      "     12        \u001b[36m0.0280\u001b[0m  4.0589\n",
      "     13        \u001b[36m0.0251\u001b[0m  4.0511\n",
      "     14        \u001b[36m0.0234\u001b[0m  4.0556\n",
      "     15        0.2266  4.0445\n",
      "     16        0.5348  4.0523\n",
      "     17        0.3445  4.0429\n",
      "     18        0.2303  4.0504\n",
      "     19        0.3338  4.0385\n",
      "     20        0.2213  4.0491\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2977\u001b[0m  4.0570\n",
      "      2        \u001b[36m0.1401\u001b[0m  4.0415\n",
      "      3        \u001b[36m0.0783\u001b[0m  4.0404\n",
      "      4        \u001b[36m0.0527\u001b[0m  4.0551\n",
      "      5        \u001b[36m0.0330\u001b[0m  4.0607\n",
      "      6        \u001b[36m0.0321\u001b[0m  4.0383\n",
      "      7        0.0808  4.0632\n",
      "      8        0.0626  4.0401\n",
      "      9        \u001b[36m0.0305\u001b[0m  4.0570\n",
      "     10        0.3396  4.0442\n",
      "     11        0.5076  4.0595\n",
      "     12        0.2376  4.0532\n",
      "     13        0.1352  4.0453\n",
      "     14        0.3284  4.0575\n",
      "     15        0.1710  4.0439\n",
      "     16        0.1328  4.0521\n",
      "     17        0.1109  4.0456\n",
      "     18        0.0888  4.0400\n",
      "     19        0.0561  4.0389\n",
      "     20        0.0415  4.0352\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2998\u001b[0m  4.0413\n",
      "      2        \u001b[36m0.0982\u001b[0m  4.0392\n",
      "      3        0.2617  4.0531\n",
      "      4        0.3432  4.0419\n",
      "      5        0.3789  4.0500\n",
      "      6        0.3254  4.0627\n",
      "      7        0.1155  4.0579\n",
      "      8        \u001b[36m0.0765\u001b[0m  4.0721\n",
      "      9        \u001b[36m0.0649\u001b[0m  4.0238\n",
      "     10        \u001b[36m0.0405\u001b[0m  4.0465\n",
      "     11        \u001b[36m0.0349\u001b[0m  4.0433\n",
      "     12        0.0401  4.0411\n",
      "     13        0.0407  4.0430\n",
      "     14        0.2015  4.0561\n",
      "     15        0.3940  4.0416\n",
      "     16        0.2317  4.0355\n",
      "     17        0.1295  4.0571\n",
      "     18        0.0819  4.0421\n",
      "     19        0.0761  4.0527\n",
      "     20        0.0544  4.0433\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2876\u001b[0m  4.0557\n",
      "      2        0.3076  4.0480\n",
      "      3        0.4350  4.0454\n",
      "      4        0.5150  4.0372\n",
      "      5        0.3624  4.0179\n",
      "      6        \u001b[36m0.2377\u001b[0m  4.0177\n",
      "      7        0.2508  4.0114\n",
      "      8        0.2598  4.0538\n",
      "      9        \u001b[36m0.1808\u001b[0m  4.0388\n",
      "     10        0.2178  4.0421\n",
      "     11        \u001b[36m0.1308\u001b[0m  4.0448\n",
      "     12        \u001b[36m0.0959\u001b[0m  4.0463\n",
      "     13        \u001b[36m0.0917\u001b[0m  4.0487\n",
      "     14        0.2783  4.0331\n",
      "     15        0.2114  4.0563\n",
      "     16        \u001b[36m0.0876\u001b[0m  4.0372\n",
      "     17        \u001b[36m0.0619\u001b[0m  4.0551\n",
      "     18        \u001b[36m0.0495\u001b[0m  4.0434\n",
      "     19        \u001b[36m0.0373\u001b[0m  4.0511\n",
      "     20        0.0406  4.0472\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2727\u001b[0m  4.0443\n",
      "      2        \u001b[36m0.1090\u001b[0m  4.0486\n",
      "      3        0.3308  4.0213\n",
      "      4        0.1155  4.0408\n",
      "      5        \u001b[36m0.0687\u001b[0m  4.0406\n",
      "      6        0.1185  4.0518\n",
      "      7        \u001b[36m0.0394\u001b[0m  4.0498\n",
      "      8        \u001b[36m0.0293\u001b[0m  4.0479\n",
      "      9        \u001b[36m0.0241\u001b[0m  4.0641\n",
      "     10        0.0266  4.0551\n",
      "     11        0.0318  4.0554\n",
      "     12        0.0327  4.0535\n",
      "     13        0.0248  4.0483\n",
      "     14        \u001b[36m0.0195\u001b[0m  4.0489\n",
      "     15        \u001b[36m0.0170\u001b[0m  4.0404\n",
      "     16        0.0181  4.0675\n",
      "     17        \u001b[36m0.0170\u001b[0m  4.0625\n",
      "     18        0.0372  4.0569\n",
      "     19        \u001b[36m0.0153\u001b[0m  4.0627\n",
      "     20        0.0197  4.0666\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3416\u001b[0m  2.7946\n",
      "      2        \u001b[36m0.2381\u001b[0m  2.7860\n",
      "      3        0.2768  2.7863\n",
      "      4        \u001b[36m0.1758\u001b[0m  2.7862\n",
      "      5        \u001b[36m0.1339\u001b[0m  2.8281\n",
      "      6        \u001b[36m0.1169\u001b[0m  2.7975\n",
      "      7        \u001b[36m0.1161\u001b[0m  2.8112\n",
      "      8        \u001b[36m0.1152\u001b[0m  2.7888\n",
      "      9        0.1460  2.8134\n",
      "     10        \u001b[36m0.0887\u001b[0m  2.8086\n",
      "     11        \u001b[36m0.0847\u001b[0m  2.7874\n",
      "     12        0.0914  2.7942\n",
      "     13        \u001b[36m0.0828\u001b[0m  2.7876\n",
      "     14        \u001b[36m0.0563\u001b[0m  2.7913\n",
      "     15        0.0581  2.7940\n",
      "     16        0.0657  2.7919\n",
      "     17        \u001b[36m0.0556\u001b[0m  2.7962\n",
      "     18        \u001b[36m0.0500\u001b[0m  2.8034\n",
      "     19        \u001b[36m0.0400\u001b[0m  2.8284\n",
      "     20        0.0451  2.8239\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  56.7s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3738\u001b[0m  2.8318\n",
      "      2        \u001b[36m0.2155\u001b[0m  2.8352\n",
      "      3        \u001b[36m0.1290\u001b[0m  2.8095\n",
      "      4        \u001b[36m0.1106\u001b[0m  2.8170\n",
      "      5        \u001b[36m0.0837\u001b[0m  2.8027\n",
      "      6        \u001b[36m0.0687\u001b[0m  2.7965\n",
      "      7        0.0710  2.7948\n",
      "      8        \u001b[36m0.0680\u001b[0m  2.8056\n",
      "      9        \u001b[36m0.0545\u001b[0m  2.7822\n",
      "     10        \u001b[36m0.0532\u001b[0m  2.8252\n",
      "     11        \u001b[36m0.0530\u001b[0m  2.7937\n",
      "     12        \u001b[36m0.0510\u001b[0m  2.8115\n",
      "     13        \u001b[36m0.0470\u001b[0m  2.8262\n",
      "     14        \u001b[36m0.0416\u001b[0m  2.8404\n",
      "     15        0.0488  2.8311\n",
      "     16        0.0504  2.7943\n",
      "     17        0.0458  2.8201\n",
      "     18        0.0616  2.7817\n",
      "     19        0.0487  2.7836\n",
      "     20        \u001b[36m0.0373\u001b[0m  2.7810\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  56.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3245\u001b[0m  2.7871\n",
      "      2        \u001b[36m0.2234\u001b[0m  2.7901\n",
      "      3        \u001b[36m0.2145\u001b[0m  2.7979\n",
      "      4        \u001b[36m0.1388\u001b[0m  2.8140\n",
      "      5        \u001b[36m0.1385\u001b[0m  2.8035\n",
      "      6        \u001b[36m0.1272\u001b[0m  2.7997\n",
      "      7        \u001b[36m0.1114\u001b[0m  2.8078\n",
      "      8        \u001b[36m0.0825\u001b[0m  2.8189\n",
      "      9        \u001b[36m0.0740\u001b[0m  2.8368\n",
      "     10        \u001b[36m0.0687\u001b[0m  2.8123\n",
      "     11        \u001b[36m0.0580\u001b[0m  2.8028\n",
      "     12        \u001b[36m0.0565\u001b[0m  2.8204\n",
      "     13        \u001b[36m0.0448\u001b[0m  2.7988\n",
      "     14        \u001b[36m0.0398\u001b[0m  2.8308\n",
      "     15        \u001b[36m0.0386\u001b[0m  2.8153\n",
      "     16        \u001b[36m0.0358\u001b[0m  2.8101\n",
      "     17        0.0442  2.7987\n",
      "     18        \u001b[36m0.0345\u001b[0m  2.7900\n",
      "     19        0.1290  2.7924\n",
      "     20        0.0600  2.7985\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  56.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3179\u001b[0m  2.7847\n",
      "      2        \u001b[36m0.1698\u001b[0m  2.7918\n",
      "      3        \u001b[36m0.1365\u001b[0m  2.8086\n",
      "      4        \u001b[36m0.1049\u001b[0m  2.8290\n",
      "      5        \u001b[36m0.0779\u001b[0m  2.8105\n",
      "      6        0.0910  2.7905\n",
      "      7        \u001b[36m0.0551\u001b[0m  2.7987\n",
      "      8        0.0895  2.8038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        0.1284  2.7983\n",
      "     10        0.1003  2.8202\n",
      "     11        0.0670  2.8339\n",
      "     12        0.0661  2.8142\n",
      "     13        0.0729  2.8129\n",
      "     14        \u001b[36m0.0448\u001b[0m  2.8077\n",
      "     15        \u001b[36m0.0441\u001b[0m  2.8000\n",
      "     16        0.0498  2.8050\n",
      "     17        \u001b[36m0.0426\u001b[0m  2.8185\n",
      "     18        \u001b[36m0.0396\u001b[0m  2.8104\n",
      "     19        \u001b[36m0.0385\u001b[0m  2.7764\n",
      "     20        \u001b[36m0.0344\u001b[0m  2.8353\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  56.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3556\u001b[0m  2.8108\n",
      "      2        \u001b[36m0.2484\u001b[0m  2.7895\n",
      "      3        \u001b[36m0.2069\u001b[0m  2.8188\n",
      "      4        \u001b[36m0.1573\u001b[0m  2.7878\n",
      "      5        \u001b[36m0.1341\u001b[0m  2.8139\n",
      "      6        \u001b[36m0.1088\u001b[0m  2.7831\n",
      "      7        \u001b[36m0.0938\u001b[0m  2.8340\n",
      "      8        \u001b[36m0.0764\u001b[0m  2.8158\n",
      "      9        \u001b[36m0.0721\u001b[0m  2.7800\n",
      "     10        0.1504  2.8334\n",
      "     11        \u001b[36m0.0687\u001b[0m  2.8191\n",
      "     12        0.1090  2.8286\n",
      "     13        0.0740  2.8175\n",
      "     14        \u001b[36m0.0585\u001b[0m  2.8268\n",
      "     15        \u001b[36m0.0555\u001b[0m  2.8060\n",
      "     16        \u001b[36m0.0460\u001b[0m  2.8216\n",
      "     17        \u001b[36m0.0436\u001b[0m  2.8153\n",
      "     18        0.0449  2.7975\n",
      "     19        \u001b[36m0.0400\u001b[0m  2.7937\n",
      "     20        0.0580  2.7939\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  56.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2577\u001b[0m  3.0824\n",
      "      2        \u001b[36m0.1463\u001b[0m  3.1033\n",
      "      3        \u001b[36m0.0971\u001b[0m  3.1210\n",
      "      4        \u001b[36m0.0714\u001b[0m  3.0772\n",
      "      5        \u001b[36m0.0585\u001b[0m  3.0748\n",
      "      6        \u001b[36m0.0333\u001b[0m  3.0999\n",
      "      7        0.0416  3.1281\n",
      "      8        0.0398  3.0955\n",
      "      9        0.0429  3.0890\n",
      "     10        0.0795  3.0875\n",
      "     11        0.0499  3.1043\n",
      "     12        0.0810  3.0889\n",
      "     13        0.0482  3.1264\n",
      "     14        0.1668  3.1279\n",
      "     15        0.4912  3.1107\n",
      "     16        0.3705  3.1034\n",
      "     17        0.2477  3.1133\n",
      "     18        0.2233  3.0745\n",
      "     19        0.1147  3.0820\n",
      "     20        0.0985  3.0768\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3435\u001b[0m  3.1314\n",
      "      2        \u001b[36m0.1701\u001b[0m  3.0918\n",
      "      3        \u001b[36m0.0766\u001b[0m  3.1029\n",
      "      4        \u001b[36m0.0451\u001b[0m  3.1115\n",
      "      5        \u001b[36m0.0319\u001b[0m  3.1281\n",
      "      6        0.0388  3.0649\n",
      "      7        0.0414  3.1277\n",
      "      8        0.0350  3.1084\n",
      "      9        \u001b[36m0.0253\u001b[0m  3.0592\n",
      "     10        \u001b[36m0.0234\u001b[0m  3.1058\n",
      "     11        0.0252  3.1265\n",
      "     12        0.3427  3.0760\n",
      "     13        0.6323  3.0846\n",
      "     14        0.6317  3.1169\n",
      "     15        0.6133  3.0700\n",
      "     16        0.5671  3.1358\n",
      "     17        0.6321  3.0684\n",
      "     18        0.5819  3.1178\n",
      "     19        0.5505  3.0830\n",
      "     20        0.5105  3.0955\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2875\u001b[0m  3.0663\n",
      "      2        \u001b[36m0.1515\u001b[0m  3.0969\n",
      "      3        \u001b[36m0.1042\u001b[0m  3.0997\n",
      "      4        \u001b[36m0.0556\u001b[0m  3.1208\n",
      "      5        0.1535  3.1038\n",
      "      6        0.0758  3.1171\n",
      "      7        0.1461  3.0950\n",
      "      8        0.0959  3.1112\n",
      "      9        0.0608  3.1281\n",
      "     10        \u001b[36m0.0535\u001b[0m  3.0905\n",
      "     11        0.0681  3.1226\n",
      "     12        \u001b[36m0.0426\u001b[0m  3.1206\n",
      "     13        \u001b[36m0.0375\u001b[0m  3.0849\n",
      "     14        \u001b[36m0.0321\u001b[0m  3.0962\n",
      "     15        0.0577  3.0917\n",
      "     16        0.0396  3.1237\n",
      "     17        \u001b[36m0.0317\u001b[0m  3.1169\n",
      "     18        0.0432  3.1207\n",
      "     19        0.0354  3.1074\n",
      "     20        \u001b[36m0.0267\u001b[0m  3.0849\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2831\u001b[0m  3.1156\n",
      "      2        \u001b[36m0.1748\u001b[0m  3.0838\n",
      "      3        \u001b[36m0.1432\u001b[0m  3.0915\n",
      "      4        \u001b[36m0.1081\u001b[0m  3.0934\n",
      "      5        \u001b[36m0.0590\u001b[0m  3.1107\n",
      "      6        \u001b[36m0.0478\u001b[0m  3.1093\n",
      "      7        0.0589  3.1127\n",
      "      8        0.0550  3.0874\n",
      "      9        \u001b[36m0.0455\u001b[0m  3.1222\n",
      "     10        \u001b[36m0.0307\u001b[0m  3.0651\n",
      "     11        0.0563  3.1259\n",
      "     12        0.0308  3.1013\n",
      "     13        \u001b[36m0.0280\u001b[0m  3.0927\n",
      "     14        \u001b[36m0.0251\u001b[0m  3.0880\n",
      "     15        0.0324  3.1331\n",
      "     16        \u001b[36m0.0223\u001b[0m  3.1198\n",
      "     17        0.0620  3.0661\n",
      "     18        0.0517  3.1297\n",
      "     19        0.0281  3.1098\n",
      "     20        \u001b[36m0.0203\u001b[0m  3.1201\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2821\u001b[0m  3.1003\n",
      "      2        \u001b[36m0.1381\u001b[0m  3.1211\n",
      "      3        \u001b[36m0.0857\u001b[0m  3.0826\n",
      "      4        \u001b[36m0.0572\u001b[0m  3.0681\n",
      "      5        \u001b[36m0.0343\u001b[0m  3.0555\n",
      "      6        0.0470  3.0549\n",
      "      7        0.0634  3.0888\n",
      "      8        0.0459  3.1246\n",
      "      9        \u001b[36m0.0305\u001b[0m  3.0827\n",
      "     10        \u001b[36m0.0231\u001b[0m  3.0853\n",
      "     11        0.1115  3.0642\n",
      "     12        0.3093  3.0617\n",
      "     13        0.1434  3.0733\n",
      "     14        0.3638  3.1214\n",
      "     15        0.5637  3.1265\n",
      "     16        0.3630  3.1255\n",
      "     17        0.2812  3.1136\n",
      "     18        0.1798  3.0920\n",
      "     19        0.1334  3.1218\n",
      "     20        0.1264  3.0957\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2783\u001b[0m  4.7709\n",
      "      2        \u001b[36m0.1308\u001b[0m  4.7404\n",
      "      3        \u001b[36m0.0586\u001b[0m  4.7711\n",
      "      4        0.0586  4.7802\n",
      "      5        \u001b[36m0.0394\u001b[0m  4.7588\n",
      "      6        \u001b[36m0.0247\u001b[0m  4.7773\n",
      "      7        0.0366  4.7714\n",
      "      8        0.0279  4.7731\n",
      "      9        0.0253  4.7683\n",
      "     10        \u001b[36m0.0176\u001b[0m  4.7712\n",
      "     11        0.0191  4.7746\n",
      "     12        0.2212  4.7523\n",
      "     13        0.1732  4.7804\n",
      "     14        0.1150  4.7755\n",
      "     15        0.0927  4.7718\n",
      "     16        0.1484  4.7417\n",
      "     17        0.2365  4.7663\n",
      "     18        0.1376  4.7758\n",
      "     19        0.2224  4.7802\n",
      "     20        0.1077  4.7559\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3265\u001b[0m  4.7516\n",
      "      2        \u001b[36m0.1416\u001b[0m  4.7577\n",
      "      3        \u001b[36m0.0580\u001b[0m  4.7722\n",
      "      4        \u001b[36m0.0427\u001b[0m  4.7741\n",
      "      5        0.0577  4.7659\n",
      "      6        \u001b[36m0.0352\u001b[0m  4.7731\n",
      "      7        \u001b[36m0.0284\u001b[0m  4.7628\n",
      "      8        0.0410  4.7636\n",
      "      9        \u001b[36m0.0245\u001b[0m  4.7664\n",
      "     10        0.0271  4.7683\n",
      "     11        0.2154  4.7869\n",
      "     12        0.2505  4.7572\n",
      "     13        0.1554  4.7640\n",
      "     14        0.1022  4.7613\n",
      "     15        0.0704  4.7714\n",
      "     16        0.0712  4.7649\n",
      "     17        0.0784  4.7645\n",
      "     18        0.0621  4.7701\n",
      "     19        0.1470  4.7563\n",
      "     20        0.0777  4.7670\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2625\u001b[0m  4.7571\n",
      "      2        \u001b[36m0.1034\u001b[0m  4.7609\n",
      "      3        \u001b[36m0.0730\u001b[0m  4.7651\n",
      "      4        0.3375  4.7673\n",
      "      5        0.1191  4.7670\n",
      "      6        0.0732  4.7542\n",
      "      7        0.1053  4.7454\n",
      "      8        \u001b[36m0.0504\u001b[0m  4.7648\n",
      "      9        \u001b[36m0.0377\u001b[0m  4.7711\n",
      "     10        0.0399  4.7612\n",
      "     11        \u001b[36m0.0273\u001b[0m  4.7537\n",
      "     12        0.0275  4.7563\n",
      "     13        0.0341  4.7367\n",
      "     14        0.0379  4.7452\n",
      "     15        \u001b[36m0.0248\u001b[0m  4.7549\n",
      "     16        0.0361  4.7740\n",
      "     17        \u001b[36m0.0220\u001b[0m  4.7637\n",
      "     18        0.0284  4.7645\n",
      "     19        0.0363  4.7640\n",
      "     20        \u001b[36m0.0204\u001b[0m  4.7683\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2965\u001b[0m  4.7451\n",
      "      2        \u001b[36m0.1216\u001b[0m  4.7750\n",
      "      3        \u001b[36m0.0609\u001b[0m  4.7669\n",
      "      4        \u001b[36m0.0425\u001b[0m  4.7698\n",
      "      5        \u001b[36m0.0355\u001b[0m  4.7717\n",
      "      6        0.0364  4.7470\n",
      "      7        0.0372  4.7780\n",
      "      8        0.0563  4.7858\n",
      "      9        \u001b[36m0.0283\u001b[0m  4.7683\n",
      "     10        \u001b[36m0.0247\u001b[0m  4.7752\n",
      "     11        0.0263  4.7482\n",
      "     12        \u001b[36m0.0177\u001b[0m  4.7787\n",
      "     13        0.4876  4.7747\n",
      "     14        0.3372  4.7723\n",
      "     15        0.1852  4.7842\n",
      "     16        0.1261  4.7715\n",
      "     17        0.0924  4.7711\n",
      "     18        0.0714  4.7769\n",
      "     19        0.0727  4.7505\n",
      "     20        0.0621  4.7623\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4086\u001b[0m  4.7686\n",
      "      2        \u001b[36m0.2555\u001b[0m  4.7677\n",
      "      3        \u001b[36m0.1089\u001b[0m  4.7693\n",
      "      4        \u001b[36m0.0733\u001b[0m  4.7593\n",
      "      5        \u001b[36m0.0540\u001b[0m  4.7715\n",
      "      6        \u001b[36m0.0485\u001b[0m  4.7768\n",
      "      7        \u001b[36m0.0303\u001b[0m  4.7505\n",
      "      8        0.0306  4.7637\n",
      "      9        0.0408  4.7731\n",
      "     10        0.1713  4.7743\n",
      "     11        0.0551  4.7642\n",
      "     12        0.0769  4.7716\n",
      "     13        0.0353  4.7740\n",
      "     14        0.0335  4.7567\n",
      "     15        \u001b[36m0.0296\u001b[0m  4.7579\n",
      "     16        \u001b[36m0.0230\u001b[0m  4.7741\n",
      "     17        0.0245  4.7696\n",
      "     18        0.0285  4.7654\n",
      "     19        0.0240  4.7733\n",
      "     20        \u001b[36m0.0207\u001b[0m  4.7563\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2613\u001b[0m  4.0489\n",
      "      2        \u001b[36m0.1706\u001b[0m  4.0607\n",
      "      3        0.4038  4.0489\n",
      "      4        0.3106  4.0579\n",
      "      5        0.2373  4.0383\n",
      "      6        \u001b[36m0.1323\u001b[0m  4.0558\n",
      "      7        \u001b[36m0.0937\u001b[0m  4.0592\n",
      "      8        0.2515  4.0593\n",
      "      9        0.1225  4.0491\n",
      "     10        \u001b[36m0.0660\u001b[0m  4.0542\n",
      "     11        \u001b[36m0.0592\u001b[0m  4.0400\n",
      "     12        \u001b[36m0.0508\u001b[0m  4.0560\n",
      "     13        0.0654  4.0453\n",
      "     14        0.0567  4.0502\n",
      "     15        \u001b[36m0.0401\u001b[0m  4.0448\n",
      "     16        \u001b[36m0.0395\u001b[0m  4.0323\n",
      "     17        0.1038  4.0430\n",
      "     18        0.0591  4.0534\n",
      "     19        0.0505  4.0384\n",
      "     20        0.0529  4.0472\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2908\u001b[0m  4.0438\n",
      "      2        \u001b[36m0.1228\u001b[0m  4.0636\n",
      "      3        \u001b[36m0.0613\u001b[0m  4.0344\n",
      "      4        \u001b[36m0.0372\u001b[0m  4.0526\n",
      "      5        0.3419  4.0522\n",
      "      6        0.2204  4.0279\n",
      "      7        0.0778  4.0364\n",
      "      8        0.2217  4.0365\n",
      "      9        0.3153  4.0555\n",
      "     10        0.1282  4.0370\n",
      "     11        0.0625  4.0377\n",
      "     12        0.0708  4.0492\n",
      "     13        0.0500  4.0472\n",
      "     14        0.0406  4.0451\n",
      "     15        \u001b[36m0.0310\u001b[0m  4.0528\n",
      "     16        0.0421  4.0601\n",
      "     17        0.0349  4.0619\n",
      "     18        0.5176  4.0392\n",
      "     19        0.4381  4.0420\n",
      "     20        0.3824  4.0390\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2639\u001b[0m  4.0342\n",
      "      2        \u001b[36m0.1253\u001b[0m  4.0425\n",
      "      3        \u001b[36m0.0733\u001b[0m  4.0630\n",
      "      4        \u001b[36m0.0585\u001b[0m  4.0454\n",
      "      5        0.2425  4.0246\n",
      "      6        0.3732  4.0462\n",
      "      7        0.4305  4.0585\n",
      "      8        0.4838  4.0567\n",
      "      9        0.3082  4.0590\n",
      "     10        0.2599  4.0528\n",
      "     11        0.1346  4.0575\n",
      "     12        0.0930  4.0636\n",
      "     13        0.0808  4.0599\n",
      "     14        0.0619  4.0485\n",
      "     15        0.4728  4.0500\n",
      "     16        0.1881  4.0462\n",
      "     17        0.1097  4.0555\n",
      "     18        0.0810  4.0472\n",
      "     19        0.0722  4.0471\n",
      "     20        0.0746  4.0513\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2785\u001b[0m  4.0517\n",
      "      2        \u001b[36m0.2514\u001b[0m  4.0251\n",
      "      3        \u001b[36m0.0901\u001b[0m  4.0480\n",
      "      4        \u001b[36m0.0599\u001b[0m  4.0445\n",
      "      5        \u001b[36m0.0313\u001b[0m  4.0428\n",
      "      6        \u001b[36m0.0312\u001b[0m  4.0610\n",
      "      7        0.0403  4.0293\n",
      "      8        0.3971  4.0495\n",
      "      9        0.4249  4.0376\n",
      "     10        0.2648  4.0294\n",
      "     11        0.1746  4.0443\n",
      "     12        0.1628  4.0486\n",
      "     13        0.0885  4.0407\n",
      "     14        0.0582  4.0371\n",
      "     15        0.0407  4.0511\n",
      "     16        0.0461  4.0275\n",
      "     17        0.1746  4.0466\n",
      "     18        0.1498  4.0448\n",
      "     19        0.0557  4.0521\n",
      "     20        0.0389  4.0542\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2700\u001b[0m  4.0272\n",
      "      2        \u001b[36m0.0868\u001b[0m  4.0387\n",
      "      3        0.4110  4.0532\n",
      "      4        0.1890  4.0211\n",
      "      5        0.5461  4.0371\n",
      "      6        0.4152  4.0403\n",
      "      7        0.3590  4.0477\n",
      "      8        0.3153  4.0510\n",
      "      9        0.3557  4.0503\n",
      "     10        0.1924  4.0518\n",
      "     11        0.2272  4.0375\n",
      "     12        0.1462  4.0377\n",
      "     13        \u001b[36m0.0849\u001b[0m  4.0476\n",
      "     14        \u001b[36m0.0767\u001b[0m  4.0495\n",
      "     15        \u001b[36m0.0666\u001b[0m  4.0436\n",
      "     16        0.1263  4.0477\n",
      "     17        0.0672  4.0374\n",
      "     18        0.3356  4.0459\n",
      "     19        0.1505  4.0447\n",
      "     20        0.0970  4.0312\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3532\u001b[0m  2.8094\n",
      "      2        \u001b[36m0.2043\u001b[0m  2.8239\n",
      "      3        \u001b[36m0.1506\u001b[0m  2.8129\n",
      "      4        0.2028  2.8185\n",
      "      5        0.1703  2.7909\n",
      "      6        0.1580  2.7988\n",
      "      7        0.1572  2.8166\n",
      "      8        \u001b[36m0.1135\u001b[0m  2.7884\n",
      "      9        0.2065  2.8233\n",
      "     10        0.1504  2.8058\n",
      "     11        0.1179  2.7909\n",
      "     12        0.1171  2.7908\n",
      "     13        0.1385  2.7840\n",
      "     14        \u001b[36m0.1010\u001b[0m  2.8168\n",
      "     15        \u001b[36m0.0829\u001b[0m  2.8127\n",
      "     16        \u001b[36m0.0736\u001b[0m  2.8285\n",
      "     17        0.0812  2.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        0.4095  2.8331\n",
      "     19        0.5731  2.8131\n",
      "     20        0.5104  2.8160\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  56.9s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3913\u001b[0m  2.8270\n",
      "      2        \u001b[36m0.2529\u001b[0m  2.8025\n",
      "      3        \u001b[36m0.1922\u001b[0m  2.8000\n",
      "      4        0.2000  2.7967\n",
      "      5        0.1928  2.8052\n",
      "      6        \u001b[36m0.1485\u001b[0m  2.8069\n",
      "      7        \u001b[36m0.1226\u001b[0m  2.8065\n",
      "      8        \u001b[36m0.1030\u001b[0m  2.7813\n",
      "      9        0.2020  2.7900\n",
      "     10        0.1145  2.7997\n",
      "     11        \u001b[36m0.0928\u001b[0m  2.7817\n",
      "     12        \u001b[36m0.0852\u001b[0m  2.8177\n",
      "     13        \u001b[36m0.0794\u001b[0m  2.7823\n",
      "     14        \u001b[36m0.0783\u001b[0m  2.8019\n",
      "     15        \u001b[36m0.0646\u001b[0m  2.8038\n",
      "     16        0.0716  2.8164\n",
      "     17        \u001b[36m0.0619\u001b[0m  2.8134\n",
      "     18        \u001b[36m0.0583\u001b[0m  2.7976\n",
      "     19        0.0705  2.8120\n",
      "     20        0.0741  2.7920\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  56.7s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3555\u001b[0m  2.7884\n",
      "      2        \u001b[36m0.2206\u001b[0m  2.7911\n",
      "      3        \u001b[36m0.1534\u001b[0m  2.8034\n",
      "      4        0.2713  2.8156\n",
      "      5        0.1860  2.7854\n",
      "      6        \u001b[36m0.1076\u001b[0m  2.8409\n",
      "      7        \u001b[36m0.0972\u001b[0m  2.8315\n",
      "      8        \u001b[36m0.0845\u001b[0m  2.8339\n",
      "      9        \u001b[36m0.0816\u001b[0m  2.8313\n",
      "     10        \u001b[36m0.0778\u001b[0m  2.7922\n",
      "     11        0.4530  2.7968\n",
      "     12        0.4465  2.7846\n",
      "     13        0.3562  2.7936\n",
      "     14        0.2805  2.8011\n",
      "     15        0.4264  2.7917\n",
      "     16        0.6278  2.7908\n",
      "     17        0.5892  2.7916\n",
      "     18        0.5606  2.8264\n",
      "     19        0.5404  2.8085\n",
      "     20        0.5182  2.8084\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  56.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3505\u001b[0m  2.7800\n",
      "      2        \u001b[36m0.2066\u001b[0m  2.8200\n",
      "      3        \u001b[36m0.2041\u001b[0m  2.8032\n",
      "      4        0.2677  2.7975\n",
      "      5        \u001b[36m0.1602\u001b[0m  2.8185\n",
      "      6        0.2181  2.7985\n",
      "      7        \u001b[36m0.1588\u001b[0m  2.7958\n",
      "      8        \u001b[36m0.1566\u001b[0m  2.8209\n",
      "      9        \u001b[36m0.0953\u001b[0m  2.8047\n",
      "     10        \u001b[36m0.0776\u001b[0m  2.7784\n",
      "     11        0.0812  2.7997\n",
      "     12        \u001b[36m0.0630\u001b[0m  2.8295\n",
      "     13        0.0910  2.7966\n",
      "     14        0.0791  2.8048\n",
      "     15        0.0631  2.8206\n",
      "     16        0.0773  2.7989\n",
      "     17        0.0630  2.8214\n",
      "     18        \u001b[36m0.0571\u001b[0m  2.8190\n",
      "     19        0.0576  2.7869\n",
      "     20        \u001b[36m0.0512\u001b[0m  2.8064\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  56.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3203\u001b[0m  2.7891\n",
      "      2        \u001b[36m0.2542\u001b[0m  2.7914\n",
      "      3        \u001b[36m0.1545\u001b[0m  2.8221\n",
      "      4        \u001b[36m0.0987\u001b[0m  2.8161\n",
      "      5        0.1102  2.8379\n",
      "      6        0.1472  2.8056\n",
      "      7        0.2611  2.8335\n",
      "      8        0.1461  2.8130\n",
      "      9        \u001b[36m0.0809\u001b[0m  2.8129\n",
      "     10        0.2625  2.7883\n",
      "     11        0.3203  2.8242\n",
      "     12        0.2793  2.7962\n",
      "     13        0.2029  2.8014\n",
      "     14        0.1527  2.7941\n",
      "     15        0.1597  2.8081\n",
      "     16        0.1335  2.7842\n",
      "     17        0.1142  2.8054\n",
      "     18        0.1052  2.8080\n",
      "     19        0.1056  2.8018\n",
      "     20        0.1155  2.8053\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  56.8s\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2834\u001b[0m  3.0600\n",
      "      2        \u001b[36m0.1525\u001b[0m  3.1082\n",
      "      3        \u001b[36m0.1498\u001b[0m  3.0907\n",
      "      4        \u001b[36m0.1080\u001b[0m  3.1320\n",
      "      5        \u001b[36m0.0752\u001b[0m  3.1074\n",
      "      6        \u001b[36m0.0492\u001b[0m  3.0801\n",
      "      7        0.0647  3.1197\n",
      "      8        0.0536  3.0677\n",
      "      9        \u001b[36m0.0478\u001b[0m  3.1277\n",
      "     10        \u001b[36m0.0301\u001b[0m  3.0758\n",
      "     11        \u001b[36m0.0269\u001b[0m  3.0928\n",
      "     12        0.0294  3.0872\n",
      "     13        0.0370  3.1097\n",
      "     14        0.0274  3.0824\n",
      "     15        0.0294  3.1244\n",
      "     16        0.0478  3.0877\n",
      "     17        0.0343  3.0719\n",
      "     18        0.0370  3.1344\n",
      "     19        0.0298  3.1101\n",
      "     20        0.0286  3.0857\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3142\u001b[0m  3.0825\n",
      "      2        \u001b[36m0.1545\u001b[0m  3.0934\n",
      "      3        \u001b[36m0.0859\u001b[0m  3.1225\n",
      "      4        \u001b[36m0.0522\u001b[0m  3.1265\n",
      "      5        \u001b[36m0.0406\u001b[0m  3.1142\n",
      "      6        0.0555  3.0960\n",
      "      7        \u001b[36m0.0373\u001b[0m  3.1047\n",
      "      8        0.0399  3.0692\n",
      "      9        \u001b[36m0.0308\u001b[0m  3.0940\n",
      "     10        \u001b[36m0.0284\u001b[0m  3.0700\n",
      "     11        0.0793  3.0656\n",
      "     12        0.0384  3.0939\n",
      "     13        \u001b[36m0.0251\u001b[0m  3.0962\n",
      "     14        0.0374  3.1031\n",
      "     15        0.0571  3.1072\n",
      "     16        0.0404  3.1199\n",
      "     17        0.0291  3.1030\n",
      "     18        0.0264  3.0806\n",
      "     19        0.0315  3.0872\n",
      "     20        0.0422  3.1358\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3175\u001b[0m  3.0988\n",
      "      2        \u001b[36m0.1160\u001b[0m  3.1152\n",
      "      3        \u001b[36m0.0725\u001b[0m  3.1115\n",
      "      4        0.1640  3.1277\n",
      "      5        0.0811  3.1080\n",
      "      6        \u001b[36m0.0517\u001b[0m  3.1012\n",
      "      7        \u001b[36m0.0395\u001b[0m  3.1252\n",
      "      8        0.4356  3.1192\n",
      "      9        0.6280  3.0980\n",
      "     10        0.6078  3.1048\n",
      "     11        0.5879  3.1292\n",
      "     12        0.5563  3.0812\n",
      "     13        0.5198  3.1180\n",
      "     14        0.4745  3.0940\n",
      "     15        0.4415  3.1227\n",
      "     16        0.4113  3.1321\n",
      "     17        0.5278  3.1236\n",
      "     18        0.6510  3.0783\n",
      "     19        0.5977  3.0615\n",
      "     20        0.6089  3.1195\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3170\u001b[0m  3.0930\n",
      "      2        \u001b[36m0.1742\u001b[0m  3.1243\n",
      "      3        \u001b[36m0.0975\u001b[0m  3.0688\n",
      "      4        \u001b[36m0.0788\u001b[0m  3.1145\n",
      "      5        \u001b[36m0.0466\u001b[0m  3.0958\n",
      "      6        \u001b[36m0.0372\u001b[0m  3.1000\n",
      "      7        0.1108  3.1096\n",
      "      8        \u001b[36m0.0364\u001b[0m  3.0966\n",
      "      9        \u001b[36m0.0312\u001b[0m  3.1157\n",
      "     10        \u001b[36m0.0272\u001b[0m  3.0899\n",
      "     11        0.0320  3.1233\n",
      "     12        \u001b[36m0.0241\u001b[0m  3.1007\n",
      "     13        0.0396  3.1233\n",
      "     14        \u001b[36m0.0232\u001b[0m  3.1263\n",
      "     15        0.0358  3.0925\n",
      "     16        0.0337  3.0936\n",
      "     17        \u001b[36m0.0213\u001b[0m  3.1329\n",
      "     18        0.0404  3.1172\n",
      "     19        0.0225  3.1046\n",
      "     20        \u001b[36m0.0192\u001b[0m  3.1141\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2732\u001b[0m  3.1094\n",
      "      2        \u001b[36m0.1213\u001b[0m  3.0660\n",
      "      3        0.2100  3.0826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        0.4979  3.1151\n",
      "      5        0.1834  3.1082\n",
      "      6        \u001b[36m0.1166\u001b[0m  3.1146\n",
      "      7        \u001b[36m0.1040\u001b[0m  3.1015\n",
      "      8        0.1192  3.1000\n",
      "      9        0.1123  3.0781\n",
      "     10        \u001b[36m0.0878\u001b[0m  3.0841\n",
      "     11        \u001b[36m0.0649\u001b[0m  3.0859\n",
      "     12        0.0893  3.1127\n",
      "     13        0.0807  3.1158\n",
      "     14        \u001b[36m0.0556\u001b[0m  3.1210\n",
      "     15        \u001b[36m0.0418\u001b[0m  3.1211\n",
      "     16        \u001b[36m0.0365\u001b[0m  3.1326\n",
      "     17        \u001b[36m0.0309\u001b[0m  3.1121\n",
      "     18        0.0691  3.0781\n",
      "     19        0.2379  3.0712\n",
      "     20        0.1060  3.1235\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2832\u001b[0m  4.7595\n",
      "      2        \u001b[36m0.2070\u001b[0m  4.7392\n",
      "      3        0.2361  4.7643\n",
      "      4        0.2371  4.7556\n",
      "      5        0.2172  4.7538\n",
      "      6        \u001b[36m0.1170\u001b[0m  4.7510\n",
      "      7        \u001b[36m0.1013\u001b[0m  4.7541\n",
      "      8        \u001b[36m0.0771\u001b[0m  4.7704\n",
      "      9        \u001b[36m0.0618\u001b[0m  4.7558\n",
      "     10        \u001b[36m0.0559\u001b[0m  4.7646\n",
      "     11        0.1620  4.7622\n",
      "     12        0.1871  4.7618\n",
      "     13        0.1305  4.7625\n",
      "     14        0.0683  4.7514\n",
      "     15        \u001b[36m0.0415\u001b[0m  4.7516\n",
      "     16        \u001b[36m0.0359\u001b[0m  4.7534\n",
      "     17        0.0408  4.7379\n",
      "     18        \u001b[36m0.0318\u001b[0m  4.7566\n",
      "     19        0.0371  4.7527\n",
      "     20        0.0632  4.7551\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2982\u001b[0m  4.7555\n",
      "      2        \u001b[36m0.1521\u001b[0m  4.7761\n",
      "      3        0.4229  4.7733\n",
      "      4        0.1830  4.7435\n",
      "      5        \u001b[36m0.1095\u001b[0m  4.7764\n",
      "      6        \u001b[36m0.0715\u001b[0m  4.7677\n",
      "      7        \u001b[36m0.0572\u001b[0m  4.7741\n",
      "      8        0.0818  4.7713\n",
      "      9        \u001b[36m0.0461\u001b[0m  4.7651\n",
      "     10        \u001b[36m0.0328\u001b[0m  4.7690\n",
      "     11        0.0404  4.7709\n",
      "     12        \u001b[36m0.0300\u001b[0m  4.7441\n",
      "     13        0.0401  4.7629\n",
      "     14        \u001b[36m0.0243\u001b[0m  4.7694\n",
      "     15        0.0437  4.7428\n",
      "     16        \u001b[36m0.0214\u001b[0m  4.7706\n",
      "     17        0.0230  4.7775\n",
      "     18        0.0244  4.7701\n",
      "     19        \u001b[36m0.0173\u001b[0m  4.7664\n",
      "     20        0.0218  4.7684\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2696\u001b[0m  4.7651\n",
      "      2        0.4114  4.7604\n",
      "      3        \u001b[36m0.1222\u001b[0m  4.7553\n",
      "      4        0.2578  4.7569\n",
      "      5        \u001b[36m0.0808\u001b[0m  4.7660\n",
      "      6        \u001b[36m0.0570\u001b[0m  4.7510\n",
      "      7        \u001b[36m0.0382\u001b[0m  4.7725\n",
      "      8        0.0517  4.7733\n",
      "      9        0.0462  4.7749\n",
      "     10        \u001b[36m0.0309\u001b[0m  4.7364\n",
      "     11        0.0550  4.7737\n",
      "     12        0.0619  4.7612\n",
      "     13        0.0317  4.7730\n",
      "     14        \u001b[36m0.0270\u001b[0m  4.7723\n",
      "     15        \u001b[36m0.0199\u001b[0m  4.7692\n",
      "     16        0.0251  4.7694\n",
      "     17        0.0257  4.7758\n",
      "     18        0.0257  4.7686\n",
      "     19        0.0278  4.7403\n",
      "     20        0.0318  4.7600\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3275\u001b[0m  4.7607\n",
      "      2        \u001b[36m0.1484\u001b[0m  4.7435\n",
      "      3        \u001b[36m0.0956\u001b[0m  4.7682\n",
      "      4        \u001b[36m0.0806\u001b[0m  4.7516\n",
      "      5        \u001b[36m0.0496\u001b[0m  4.7703\n",
      "      6        \u001b[36m0.0365\u001b[0m  4.7569\n",
      "      7        \u001b[36m0.0332\u001b[0m  4.7600\n",
      "      8        0.0416  4.7707\n",
      "      9        0.0489  4.7630\n",
      "     10        \u001b[36m0.0285\u001b[0m  4.7553\n",
      "     11        0.0363  4.7707\n",
      "     12        \u001b[36m0.0283\u001b[0m  4.7736\n",
      "     13        0.6493  4.7436\n",
      "     14        0.6169  4.7679\n",
      "     15        0.5980  4.7646\n",
      "     16        0.5765  4.7605\n",
      "     17        0.5583  4.7642\n",
      "     18        0.5418  4.7630\n",
      "     19        0.5276  4.7603\n",
      "     20        0.5149  4.7635\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2763\u001b[0m  4.7763\n",
      "      2        \u001b[36m0.1111\u001b[0m  4.7797\n",
      "      3        \u001b[36m0.0707\u001b[0m  4.7841\n",
      "      4        \u001b[36m0.0479\u001b[0m  4.7811\n",
      "      5        \u001b[36m0.0465\u001b[0m  4.7512\n",
      "      6        0.0763  4.7752\n",
      "      7        0.1318  4.7808\n",
      "      8        0.0966  4.7815\n",
      "      9        0.1156  4.7817\n",
      "     10        0.1544  4.7788\n",
      "     11        0.5318  4.7826\n",
      "     12        0.3232  4.7501\n",
      "     13        0.5246  4.7584\n",
      "     14        0.4946  4.7812\n",
      "     15        0.3171  4.7681\n",
      "     16        0.3022  4.7902\n",
      "     17        0.2085  4.7830\n",
      "     18        0.2417  4.7640\n",
      "     19        0.3464  4.7703\n",
      "     20        0.2024  4.7698\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2672\u001b[0m  4.0312\n",
      "      2        \u001b[36m0.1684\u001b[0m  4.0375\n",
      "      3        \u001b[36m0.1018\u001b[0m  4.0458\n",
      "      4        \u001b[36m0.0566\u001b[0m  4.0529\n",
      "      5        0.4789  4.0447\n",
      "      6        0.4478  4.0392\n",
      "      7        0.3166  4.0432\n",
      "      8        0.2110  4.0490\n",
      "      9        0.3274  4.0319\n",
      "     10        0.5143  4.0508\n",
      "     11        0.3440  4.0491\n",
      "     12        0.2616  4.0359\n",
      "     13        0.2186  4.0435\n",
      "     14        0.1885  4.0422\n",
      "     15        0.1508  4.0557\n",
      "     16        0.1408  4.0189\n",
      "     17        0.1018  4.0500\n",
      "     18        0.0840  4.0565\n",
      "     19        0.0721  4.0424\n",
      "     20        0.0591  4.0470\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2950\u001b[0m  4.0584\n",
      "      2        \u001b[36m0.0871\u001b[0m  4.0513\n",
      "      3        \u001b[36m0.0489\u001b[0m  4.0607\n",
      "      4        \u001b[36m0.0296\u001b[0m  4.0472\n",
      "      5        0.0371  4.0540\n",
      "      6        0.2194  4.0435\n",
      "      7        0.5509  4.0508\n",
      "      8        0.4392  4.0477\n",
      "      9        0.3700  4.0497\n",
      "     10        0.3812  4.0518\n",
      "     11        0.4288  4.0569\n",
      "     12        0.3761  4.0559\n",
      "     13        0.4207  4.0678\n",
      "     14        0.1891  4.0534\n",
      "     15        0.3530  4.0450\n",
      "     16        0.6937  4.0399\n",
      "     17        0.5787  4.0448\n",
      "     18        0.5585  4.0524\n",
      "     19        0.5420  4.0323\n",
      "     20        0.5604  4.0514\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3527\u001b[0m  4.0519\n",
      "      2        \u001b[36m0.1280\u001b[0m  4.0433\n",
      "      3        \u001b[36m0.0649\u001b[0m  4.0469\n",
      "      4        \u001b[36m0.0353\u001b[0m  4.0502\n",
      "      5        \u001b[36m0.0268\u001b[0m  4.0559\n",
      "      6        0.0415  4.0488\n",
      "      7        \u001b[36m0.0209\u001b[0m  4.0514\n",
      "      8        0.0252  4.0210\n",
      "      9        0.1022  4.0594\n",
      "     10        0.1188  4.0538\n",
      "     11        0.3799  4.0354\n",
      "     12        0.1593  4.0394\n",
      "     13        0.1747  4.0408\n",
      "     14        0.1247  4.0557\n",
      "     15        0.1272  4.0611\n",
      "     16        0.1256  4.0377\n",
      "     17        0.0951  4.0404\n",
      "     18        0.0827  4.0487\n",
      "     19        0.0589  4.0582\n",
      "     20        0.3452  4.0550\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3248\u001b[0m  4.0373\n",
      "      2        \u001b[36m0.1762\u001b[0m  4.0574\n",
      "      3        \u001b[36m0.1165\u001b[0m  4.0463\n",
      "      4        0.3553  4.0450\n",
      "      5        0.2675  4.0437\n",
      "      6        0.1744  4.0437\n",
      "      7        0.1316  4.0471\n",
      "      8        0.3510  4.0569\n",
      "      9        \u001b[36m0.1016\u001b[0m  4.0298\n",
      "     10        \u001b[36m0.0537\u001b[0m  4.0248\n",
      "     11        \u001b[36m0.0406\u001b[0m  4.0479\n",
      "     12        \u001b[36m0.0370\u001b[0m  4.0529\n",
      "     13        0.0663  4.0328\n",
      "     14        \u001b[36m0.0347\u001b[0m  4.0450\n",
      "     15        0.1281  4.0468\n",
      "     16        0.0854  4.0431\n",
      "     17        0.0441  4.0500\n",
      "     18        0.0434  4.0451\n",
      "     19        0.0373  4.0579\n",
      "     20        \u001b[36m0.0328\u001b[0m  4.0479\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2962\u001b[0m  4.0275\n",
      "      2        \u001b[36m0.1273\u001b[0m  4.0293\n",
      "      3        \u001b[36m0.0767\u001b[0m  4.0499\n",
      "      4        0.1160  4.0701\n",
      "      5        0.4447  4.0514\n",
      "      6        0.2701  4.0395\n",
      "      7        0.1665  4.0461\n",
      "      8        0.1436  4.0453\n",
      "      9        0.1039  4.0452\n",
      "     10        0.2000  4.0554\n",
      "     11        0.4690  4.0332\n",
      "     12        0.2479  4.0520\n",
      "     13        0.1496  4.0404\n",
      "     14        0.2879  4.0646\n",
      "     15        0.1805  4.0598\n",
      "     16        0.0978  4.0568\n",
      "     17        \u001b[36m0.0654\u001b[0m  4.0563\n",
      "     18        \u001b[36m0.0464\u001b[0m  4.0505\n",
      "     19        \u001b[36m0.0427\u001b[0m  4.0452\n",
      "     20        0.0669  4.0515\n",
      "[CV]  net__batch_size=64, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3461\u001b[0m  2.8234\n",
      "      2        \u001b[36m0.1713\u001b[0m  2.7985\n",
      "      3        0.1724  2.7927\n",
      "      4        \u001b[36m0.1165\u001b[0m  2.7918\n",
      "      5        0.1330  2.8111\n",
      "      6        0.1457  2.8114\n",
      "      7        0.1865  2.7876\n",
      "      8        0.2090  2.8028\n",
      "      9        0.1930  2.7947\n",
      "     10        0.1264  2.8223\n",
      "     11        \u001b[36m0.1076\u001b[0m  2.8290\n",
      "     12        \u001b[36m0.0926\u001b[0m  2.7975\n",
      "     13        \u001b[36m0.0806\u001b[0m  2.8114\n",
      "     14        0.1007  2.8199\n",
      "     15        \u001b[36m0.0735\u001b[0m  2.8199\n",
      "     16        \u001b[36m0.0671\u001b[0m  2.8158\n",
      "     17        0.0808  2.8114\n",
      "     18        \u001b[36m0.0613\u001b[0m  2.7833\n",
      "     19        0.0662  2.8299\n",
      "     20        0.0629  2.8127\n",
      "     21        \u001b[36m0.0435\u001b[0m  2.7926\n",
      "     22        0.0620  2.7911\n",
      "     23        \u001b[36m0.0420\u001b[0m  2.7885\n",
      "     24        \u001b[36m0.0411\u001b[0m  2.8061\n",
      "     25        \u001b[36m0.0317\u001b[0m  2.8299\n",
      "     26        0.0558  2.8256\n",
      "     27        0.0326  2.8116\n",
      "     28        0.0513  2.7951\n",
      "     29        0.0972  2.7880\n",
      "     30        0.0506  2.8241\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4041\u001b[0m  2.8099\n",
      "      2        \u001b[36m0.2475\u001b[0m  2.8083\n",
      "      3        0.4893  2.8049\n",
      "      4        \u001b[36m0.2285\u001b[0m  2.7849\n",
      "      5        \u001b[36m0.1459\u001b[0m  2.8105\n",
      "      6        \u001b[36m0.1026\u001b[0m  2.8183\n",
      "      7        \u001b[36m0.0992\u001b[0m  2.7908\n",
      "      8        0.1065  2.8142\n",
      "      9        \u001b[36m0.0737\u001b[0m  2.7903\n",
      "     10        \u001b[36m0.0574\u001b[0m  2.8010\n",
      "     11        \u001b[36m0.0557\u001b[0m  2.7997\n",
      "     12        0.0604  2.8060\n",
      "     13        0.0579  2.7923\n",
      "     14        \u001b[36m0.0493\u001b[0m  2.7905\n",
      "     15        0.0547  2.8202\n",
      "     16        \u001b[36m0.0421\u001b[0m  2.8270\n",
      "     17        0.0472  2.8039\n",
      "     18        0.0566  2.7928\n",
      "     19        \u001b[36m0.0357\u001b[0m  2.7913\n",
      "     20        0.0411  2.8163\n",
      "     21        0.0734  2.8115\n",
      "     22        0.0386  2.8108\n",
      "     23        0.0385  2.7977\n",
      "     24        0.0611  2.7891\n",
      "     25        0.0389  2.7923\n",
      "     26        \u001b[36m0.0333\u001b[0m  2.8245\n",
      "     27        0.0531  2.7995\n",
      "     28        0.0492  2.7939\n",
      "     29        0.0385  2.8083\n",
      "     30        \u001b[36m0.0320\u001b[0m  2.8055\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3275\u001b[0m  2.8332\n",
      "      2        \u001b[36m0.1992\u001b[0m  2.8304\n",
      "      3        0.2051  2.8063\n",
      "      4        \u001b[36m0.1264\u001b[0m  2.7966\n",
      "      5        \u001b[36m0.1038\u001b[0m  2.8268\n",
      "      6        \u001b[36m0.0882\u001b[0m  2.8266\n",
      "      7        \u001b[36m0.0803\u001b[0m  2.8116\n",
      "      8        \u001b[36m0.0673\u001b[0m  2.7785\n",
      "      9        \u001b[36m0.0568\u001b[0m  2.8067\n",
      "     10        \u001b[36m0.0511\u001b[0m  2.8295\n",
      "     11        0.0833  2.8067\n",
      "     12        0.0808  2.8066\n",
      "     13        0.0625  2.8162\n",
      "     14        0.0526  2.7925\n",
      "     15        0.0512  2.8156\n",
      "     16        \u001b[36m0.0389\u001b[0m  2.8128\n",
      "     17        0.0430  2.8318\n",
      "     18        0.0463  2.8205\n",
      "     19        \u001b[36m0.0373\u001b[0m  2.8105\n",
      "     20        \u001b[36m0.0314\u001b[0m  2.8257\n",
      "     21        0.0327  2.8224\n",
      "     22        0.0372  2.8137\n",
      "     23        0.0459  2.8013\n",
      "     24        0.0332  2.7912\n",
      "     25        0.0499  2.7930\n",
      "     26        0.0417  2.7958\n",
      "     27        0.0365  2.8152\n",
      "     28        0.0548  2.7901\n",
      "     29        0.0571  2.8002\n",
      "     30        0.0325  2.7809\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3732\u001b[0m  2.8130\n",
      "      2        \u001b[36m0.2664\u001b[0m  2.8033\n",
      "      3        \u001b[36m0.1618\u001b[0m  2.7982\n",
      "      4        \u001b[36m0.1425\u001b[0m  2.7829\n",
      "      5        \u001b[36m0.1052\u001b[0m  2.8024\n",
      "      6        \u001b[36m0.0878\u001b[0m  2.8127\n",
      "      7        0.0890  2.8291\n",
      "      8        0.0888  2.8214\n",
      "      9        \u001b[36m0.0675\u001b[0m  2.8077\n",
      "     10        \u001b[36m0.0581\u001b[0m  2.8200\n",
      "     11        0.0623  2.8258\n",
      "     12        0.1015  2.7819\n",
      "     13        \u001b[36m0.0563\u001b[0m  2.8503\n",
      "     14        \u001b[36m0.0470\u001b[0m  2.8092\n",
      "     15        0.0519  2.7954\n",
      "     16        \u001b[36m0.0401\u001b[0m  2.7983\n",
      "     17        0.0504  2.7978\n",
      "     18        \u001b[36m0.0383\u001b[0m  2.8128\n",
      "     19        0.0465  2.8220\n",
      "     20        0.0424  2.8018\n",
      "     21        0.1081  2.8093\n",
      "     22        0.0812  2.8312\n",
      "     23        0.0560  2.8288\n",
      "     24        0.0395  2.8156\n",
      "     25        0.0412  2.8270\n",
      "     26        0.0593  2.8350\n",
      "     27        0.0426  2.7903\n",
      "     28        0.0465  2.8050\n",
      "     29        \u001b[36m0.0383\u001b[0m  2.8019\n",
      "     30        0.0584  2.8209\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2969\u001b[0m  2.8057\n",
      "      2        \u001b[36m0.1483\u001b[0m  2.7901\n",
      "      3        \u001b[36m0.1109\u001b[0m  2.7861\n",
      "      4        0.1320  2.7899\n",
      "      5        \u001b[36m0.0856\u001b[0m  2.7878\n",
      "      6        \u001b[36m0.0680\u001b[0m  2.8041\n",
      "      7        \u001b[36m0.0616\u001b[0m  2.7832\n",
      "      8        0.0703  2.7949\n",
      "      9        0.0797  2.7822\n",
      "     10        \u001b[36m0.0499\u001b[0m  2.8285\n",
      "     11        0.0533  2.8137\n",
      "     12        \u001b[36m0.0477\u001b[0m  2.8217\n",
      "     13        \u001b[36m0.0331\u001b[0m  2.8146\n",
      "     14        \u001b[36m0.0327\u001b[0m  2.8258\n",
      "     15        0.0415  2.8300\n",
      "     16        0.0331  2.7962\n",
      "     17        0.0362  2.8094\n",
      "     18        \u001b[36m0.0300\u001b[0m  2.8204\n",
      "     19        0.0371  2.7982\n",
      "     20        0.0383  2.7833\n",
      "     21        0.0332  2.7948\n",
      "     22        0.0360  2.7983\n",
      "     23        \u001b[36m0.0269\u001b[0m  2.7996\n",
      "     24        0.0272  2.8129\n",
      "     25        \u001b[36m0.0222\u001b[0m  2.8276\n",
      "     26        0.0250  2.8370\n",
      "     27        \u001b[36m0.0208\u001b[0m  2.7895\n",
      "     28        \u001b[36m0.0184\u001b[0m  2.7920\n",
      "     29        \u001b[36m0.0160\u001b[0m  2.8295\n",
      "     30        0.0262  2.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2972\u001b[0m  3.1050\n",
      "      2        \u001b[36m0.1588\u001b[0m  3.0770\n",
      "      3        \u001b[36m0.0822\u001b[0m  3.1002\n",
      "      4        0.0963  3.1071\n",
      "      5        \u001b[36m0.0561\u001b[0m  3.0720\n",
      "      6        \u001b[36m0.0341\u001b[0m  3.0879\n",
      "      7        \u001b[36m0.0220\u001b[0m  3.1075\n",
      "      8        0.0270  3.0963\n",
      "      9        0.0223  3.1144\n",
      "     10        \u001b[36m0.0175\u001b[0m  3.0856\n",
      "     11        0.0206  3.1029\n",
      "     12        0.0177  3.0982\n",
      "     13        0.0222  3.1020\n",
      "     14        0.0256  3.1027\n",
      "     15        0.0247  3.1045\n",
      "     16        0.0250  3.0933\n",
      "     17        0.0218  3.0916\n",
      "     18        0.0216  3.1112\n",
      "     19        0.0186  3.1156\n",
      "     20        \u001b[36m0.0148\u001b[0m  3.1295\n",
      "     21        0.0168  3.0923\n",
      "     22        0.0190  3.1033\n",
      "     23        0.0230  3.1244\n",
      "     24        0.0166  3.1044\n",
      "     25        \u001b[36m0.0135\u001b[0m  3.0689\n",
      "     26        \u001b[36m0.0126\u001b[0m  3.0768\n",
      "     27        0.0184  3.1221\n",
      "     28        0.0194  3.1279\n",
      "     29        0.0271  3.1060\n",
      "     30        0.0137  3.0948\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2882\u001b[0m  3.1305\n",
      "      2        \u001b[36m0.0890\u001b[0m  3.1275\n",
      "      3        \u001b[36m0.0573\u001b[0m  3.1273\n",
      "      4        \u001b[36m0.0354\u001b[0m  3.1278\n",
      "      5        0.0626  3.0745\n",
      "      6        \u001b[36m0.0302\u001b[0m  3.0685\n",
      "      7        \u001b[36m0.0280\u001b[0m  3.1244\n",
      "      8        \u001b[36m0.0263\u001b[0m  3.1044\n",
      "      9        \u001b[36m0.0243\u001b[0m  3.0837\n",
      "     10        0.0266  3.0722\n",
      "     11        0.4445  3.0710\n",
      "     12        0.3600  3.0953\n",
      "     13        0.2390  3.0797\n",
      "     14        0.1827  3.1197\n",
      "     15        0.1355  3.0986\n",
      "     16        0.0819  3.1216\n",
      "     17        0.0618  3.0761\n",
      "     18        0.0496  3.0981\n",
      "     19        0.0448  3.1581\n",
      "     20        0.0392  3.1215\n",
      "     21        0.0311  3.0935\n",
      "     22        0.0716  3.0740\n",
      "     23        0.0415  3.1252\n",
      "     24        0.0349  3.1332\n",
      "     25        0.0465  3.1130\n",
      "     26        0.0368  3.0948\n",
      "     27        0.0288  3.1112\n",
      "     28        \u001b[36m0.0223\u001b[0m  3.0742\n",
      "     29        \u001b[36m0.0190\u001b[0m  3.0775\n",
      "     30        0.0222  3.1054\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2522\u001b[0m  3.1151\n",
      "      2        \u001b[36m0.1455\u001b[0m  3.1195\n",
      "      3        \u001b[36m0.0875\u001b[0m  3.0647\n",
      "      4        \u001b[36m0.0449\u001b[0m  3.0639\n",
      "      5        0.0708  3.1076\n",
      "      6        \u001b[36m0.0417\u001b[0m  3.1243\n",
      "      7        \u001b[36m0.0282\u001b[0m  3.1090\n",
      "      8        \u001b[36m0.0276\u001b[0m  3.1248\n",
      "      9        0.0355  3.1207\n",
      "     10        0.0280  3.1154\n",
      "     11        \u001b[36m0.0192\u001b[0m  3.0823\n",
      "     12        0.0229  3.1170\n",
      "     13        \u001b[36m0.0181\u001b[0m  3.0839\n",
      "     14        0.0192  3.0961\n",
      "     15        0.0256  3.1084\n",
      "     16        0.0189  3.1179\n",
      "     17        \u001b[36m0.0153\u001b[0m  3.1199\n",
      "     18        \u001b[36m0.0118\u001b[0m  3.1141\n",
      "     19        \u001b[36m0.0108\u001b[0m  3.1151\n",
      "     20        0.0241  3.0959\n",
      "     21        0.0421  3.1168\n",
      "     22        0.5222  3.1227\n",
      "     23        0.4609  3.0749\n",
      "     24        0.4384  3.1221\n",
      "     25        0.3658  3.1157\n",
      "     26        0.2978  3.1081\n",
      "     27        0.2549  3.1316\n",
      "     28        0.3146  3.1245\n",
      "     29        0.3684  3.1151\n",
      "     30        0.3251  3.0908\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2973\u001b[0m  3.0934\n",
      "      2        \u001b[36m0.1361\u001b[0m  3.0899\n",
      "      3        \u001b[36m0.0872\u001b[0m  3.1056\n",
      "      4        \u001b[36m0.0590\u001b[0m  3.0992\n",
      "      5        0.0836  3.1069\n",
      "      6        \u001b[36m0.0557\u001b[0m  3.0901\n",
      "      7        \u001b[36m0.0339\u001b[0m  3.0995\n",
      "      8        \u001b[36m0.0325\u001b[0m  3.0951\n",
      "      9        0.0333  3.1290\n",
      "     10        \u001b[36m0.0252\u001b[0m  3.1001\n",
      "     11        \u001b[36m0.0221\u001b[0m  3.0927\n",
      "     12        \u001b[36m0.0198\u001b[0m  3.0847\n",
      "     13        0.0217  3.1277\n",
      "     14        0.0504  3.1267\n",
      "     15        0.0292  3.1072\n",
      "     16        0.0300  3.0876\n",
      "     17        0.0248  3.1261\n",
      "     18        0.0247  3.1174\n",
      "     19        \u001b[36m0.0188\u001b[0m  3.0729\n",
      "     20        \u001b[36m0.0175\u001b[0m  3.1020\n",
      "     21        0.0378  3.1206\n",
      "     22        0.0258  3.0682\n",
      "     23        \u001b[36m0.0151\u001b[0m  3.1323\n",
      "     24        0.0286  3.1118\n",
      "     25        0.0754  3.1151\n",
      "     26        0.0710  3.1012\n",
      "     27        0.5893  3.1329\n",
      "     28        0.4992  3.1147\n",
      "     29        0.4055  3.1212\n",
      "     30        0.3892  3.1156\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3169\u001b[0m  3.0810\n",
      "      2        \u001b[36m0.1696\u001b[0m  3.1303\n",
      "      3        \u001b[36m0.0895\u001b[0m  3.1007\n",
      "      4        \u001b[36m0.0587\u001b[0m  3.0979\n",
      "      5        \u001b[36m0.0362\u001b[0m  3.0704\n",
      "      6        0.1125  3.1223\n",
      "      7        0.0511  3.1300\n",
      "      8        \u001b[36m0.0298\u001b[0m  3.1059\n",
      "      9        0.0311  3.1031\n",
      "     10        0.0400  3.1187\n",
      "     11        0.0308  3.0812\n",
      "     12        0.0566  3.0865\n",
      "     13        \u001b[36m0.0267\u001b[0m  3.1168\n",
      "     14        \u001b[36m0.0205\u001b[0m  3.1042\n",
      "     15        0.0207  3.0766\n",
      "     16        \u001b[36m0.0166\u001b[0m  3.1139\n",
      "     17        0.0494  3.1009\n",
      "     18        0.0238  3.1179\n",
      "     19        0.0177  3.1138\n",
      "     20        \u001b[36m0.0135\u001b[0m  3.1284\n",
      "     21        0.1176  3.1093\n",
      "     22        0.0426  3.1359\n",
      "     23        0.0297  3.1087\n",
      "     24        0.0267  3.0965\n",
      "     25        0.0216  3.1172\n",
      "     26        0.0216  3.1176\n",
      "     27        0.1147  3.1148\n",
      "     28        0.2146  3.1210\n",
      "     29        0.1329  3.1246\n",
      "     30        0.0662  3.1140\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2925\u001b[0m  4.7694\n",
      "      2        \u001b[36m0.1454\u001b[0m  4.7677\n",
      "      3        \u001b[36m0.0851\u001b[0m  4.7744\n",
      "      4        \u001b[36m0.0498\u001b[0m  4.7762\n",
      "      5        \u001b[36m0.0374\u001b[0m  4.7705\n",
      "      6        0.0391  4.7648\n",
      "      7        \u001b[36m0.0297\u001b[0m  4.7774\n",
      "      8        \u001b[36m0.0233\u001b[0m  4.7731\n",
      "      9        \u001b[36m0.0225\u001b[0m  4.7648\n",
      "     10        0.0543  4.7735\n",
      "     11        0.0268  4.7811\n",
      "     12        0.2325  4.7699\n",
      "     13        0.0774  4.7799\n",
      "     14        0.0544  4.7798\n",
      "     15        0.0413  4.7534\n",
      "     16        0.0364  4.7686\n",
      "     17        0.0346  4.7690\n",
      "     18        0.0343  4.7468\n",
      "     19        0.0325  4.7692\n",
      "     20        0.0235  4.7637\n",
      "     21        0.0264  4.7787\n",
      "     22        \u001b[36m0.0218\u001b[0m  4.7800\n",
      "     23        0.0269  4.7715\n",
      "     24        0.0547  4.7893\n",
      "     25        0.0272  4.7670\n",
      "     26        \u001b[36m0.0181\u001b[0m  4.7520\n",
      "     27        \u001b[36m0.0151\u001b[0m  4.7727\n",
      "     28        0.0262  4.7755\n",
      "     29        \u001b[36m0.0141\u001b[0m  4.7807\n",
      "     30        0.0217  4.7696\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2972\u001b[0m  4.7344\n",
      "      2        \u001b[36m0.1229\u001b[0m  4.7515\n",
      "      3        \u001b[36m0.0501\u001b[0m  4.7306\n",
      "      4        \u001b[36m0.0305\u001b[0m  4.7562\n",
      "      5        \u001b[36m0.0250\u001b[0m  4.7556\n",
      "      6        0.0257  4.7642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        \u001b[36m0.0204\u001b[0m  4.7608\n",
      "      8        \u001b[36m0.0173\u001b[0m  4.7622\n",
      "      9        0.0213  4.7305\n",
      "     10        0.3425  4.7491\n",
      "     11        0.2927  4.7632\n",
      "     12        0.2497  4.7616\n",
      "     13        0.2828  4.7294\n",
      "     14        0.3269  4.7590\n",
      "     15        0.3723  4.7580\n",
      "     16        0.4172  4.7585\n",
      "     17        0.3194  4.7564\n",
      "     18        0.3121  4.7558\n",
      "     19        0.3680  4.7761\n",
      "     20        0.3266  4.7421\n",
      "     21        0.2600  4.7554\n",
      "     22        0.2093  4.7628\n",
      "     23        0.1625  4.7649\n",
      "     24        0.1241  4.7655\n",
      "     25        0.0960  4.7488\n",
      "     26        0.1292  4.7515\n",
      "     27        0.0826  4.7576\n",
      "     28        0.0766  4.7537\n",
      "     29        0.2578  4.7576\n",
      "     30        0.2379  4.7574\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2544\u001b[0m  4.7683\n",
      "      2        \u001b[36m0.1757\u001b[0m  4.7746\n",
      "      3        0.2159  4.7616\n",
      "      4        \u001b[36m0.0796\u001b[0m  4.7627\n",
      "      5        \u001b[36m0.0554\u001b[0m  4.7552\n",
      "      6        \u001b[36m0.0433\u001b[0m  4.7786\n",
      "      7        \u001b[36m0.0344\u001b[0m  4.7692\n",
      "      8        0.0530  4.7656\n",
      "      9        \u001b[36m0.0321\u001b[0m  4.7689\n",
      "     10        0.0335  4.7716\n",
      "     11        0.0349  4.7739\n",
      "     12        \u001b[36m0.0256\u001b[0m  4.7776\n",
      "     13        \u001b[36m0.0211\u001b[0m  4.7760\n",
      "     14        0.0290  4.7698\n",
      "     15        0.0576  4.7784\n",
      "     16        0.0440  4.7744\n",
      "     17        0.0273  4.7757\n",
      "     18        0.0372  4.7753\n",
      "     19        0.0369  4.7775\n",
      "     20        0.0223  4.7771\n",
      "     21        0.0330  4.7801\n",
      "     22        \u001b[36m0.0182\u001b[0m  4.7715\n",
      "     23        0.0293  4.7681\n",
      "     24        0.0243  4.7718\n",
      "     25        \u001b[36m0.0132\u001b[0m  4.7559\n",
      "     26        0.0209  4.7688\n",
      "     27        0.0178  4.7672\n",
      "     28        0.0182  4.7640\n",
      "     29        0.0165  4.7659\n",
      "     30        0.0133  4.7804\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2745\u001b[0m  4.7593\n",
      "      2        \u001b[36m0.1700\u001b[0m  4.7575\n",
      "      3        \u001b[36m0.0708\u001b[0m  4.7570\n",
      "      4        \u001b[36m0.0422\u001b[0m  4.7637\n",
      "      5        \u001b[36m0.0292\u001b[0m  4.7640\n",
      "      6        \u001b[36m0.0243\u001b[0m  4.7678\n",
      "      7        0.0422  4.7656\n",
      "      8        0.0295  4.7669\n",
      "      9        0.0324  4.7853\n",
      "     10        \u001b[36m0.0243\u001b[0m  4.7479\n",
      "     11        \u001b[36m0.0179\u001b[0m  4.7639\n",
      "     12        0.0214  4.7645\n",
      "     13        0.0188  4.7632\n",
      "     14        0.0238  4.7638\n",
      "     15        0.0214  4.7601\n",
      "     16        \u001b[36m0.0124\u001b[0m  4.7740\n",
      "     17        0.4667  4.7716\n",
      "     18        0.6210  4.7756\n",
      "     19        0.5599  4.7706\n",
      "     20        0.5159  4.7611\n",
      "     21        0.5735  4.7516\n",
      "     22        0.5804  4.7689\n",
      "     23        0.5826  4.7698\n",
      "     24        0.5355  4.7533\n",
      "     25        0.5268  4.7551\n",
      "     26        0.4632  4.7526\n",
      "     27        0.3552  4.7709\n",
      "     28        0.2939  4.7766\n",
      "     29        0.2695  4.7646\n",
      "     30        0.1711  4.7648\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2729\u001b[0m  4.7602\n",
      "      2        \u001b[36m0.0967\u001b[0m  4.7662\n",
      "      3        \u001b[36m0.0452\u001b[0m  4.7702\n",
      "      4        \u001b[36m0.0329\u001b[0m  4.7630\n",
      "      5        \u001b[36m0.0221\u001b[0m  4.7575\n",
      "      6        0.0267  4.7562\n",
      "      7        0.0336  4.7396\n",
      "      8        0.0270  4.7573\n",
      "      9        0.0234  4.7475\n",
      "     10        0.0227  4.7513\n",
      "     11        \u001b[36m0.0133\u001b[0m  4.7632\n",
      "     12        0.0176  4.7672\n",
      "     13        0.0933  4.7522\n",
      "     14        0.0511  4.7602\n",
      "     15        0.0410  4.7680\n",
      "     16        0.1703  4.7593\n",
      "     17        0.2256  4.7606\n",
      "     18        0.7413  4.7694\n",
      "     19        0.6279  4.7601\n",
      "     20        0.6251  4.7660\n",
      "     21        0.6076  4.7634\n",
      "     22        0.6329  4.7673\n",
      "     23        0.6283  4.7574\n",
      "     24        0.6330  4.7704\n",
      "     25        0.6192  4.7561\n",
      "     26        0.6084  4.7578\n",
      "     27        0.5971  4.7717\n",
      "     28        0.6295  4.7731\n",
      "     29        0.6138  4.7875\n",
      "     30        0.5732  4.7599\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3282\u001b[0m  4.0474\n",
      "      2        \u001b[36m0.0674\u001b[0m  4.0276\n",
      "      3        \u001b[36m0.0361\u001b[0m  4.0813\n",
      "      4        \u001b[36m0.0310\u001b[0m  4.0548\n",
      "      5        \u001b[36m0.0232\u001b[0m  4.0465\n",
      "      6        0.0296  4.0462\n",
      "      7        0.0233  4.0482\n",
      "      8        0.0293  4.0267\n",
      "      9        \u001b[36m0.0224\u001b[0m  4.0565\n",
      "     10        \u001b[36m0.0198\u001b[0m  4.0524\n",
      "     11        \u001b[36m0.0166\u001b[0m  4.0407\n",
      "     12        0.0186  4.0543\n",
      "     13        \u001b[36m0.0164\u001b[0m  4.0559\n",
      "     14        0.0198  4.0462\n",
      "     15        \u001b[36m0.0164\u001b[0m  4.0528\n",
      "     16        0.0333  4.0614\n",
      "     17        0.0235  4.0650\n",
      "     18        0.0170  4.0645\n",
      "     19        0.0168  4.0577\n",
      "     20        0.0173  4.0588\n",
      "     21        \u001b[36m0.0161\u001b[0m  4.0525\n",
      "     22        0.0690  4.0450\n",
      "     23        0.0303  4.0514\n",
      "     24        0.0198  4.0516\n",
      "     25        0.0167  4.0538\n",
      "     26        \u001b[36m0.0140\u001b[0m  4.0518\n",
      "     27        \u001b[36m0.0135\u001b[0m  4.0363\n",
      "     28        \u001b[36m0.0133\u001b[0m  4.0549\n",
      "     29        0.0147  4.0265\n",
      "     30        0.0142  4.0501\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3141\u001b[0m  4.0359\n",
      "      2        \u001b[36m0.1792\u001b[0m  4.0513\n",
      "      3        0.2157  4.0531\n",
      "      4        \u001b[36m0.1120\u001b[0m  4.0507\n",
      "      5        \u001b[36m0.0742\u001b[0m  4.0394\n",
      "      6        0.1172  4.0450\n",
      "      7        0.0786  4.0653\n",
      "      8        \u001b[36m0.0524\u001b[0m  4.0623\n",
      "      9        \u001b[36m0.0403\u001b[0m  4.0498\n",
      "     10        \u001b[36m0.0320\u001b[0m  4.0498\n",
      "     11        \u001b[36m0.0312\u001b[0m  4.0493\n",
      "     12        \u001b[36m0.0265\u001b[0m  4.0599\n",
      "     13        0.0304  4.0393\n",
      "     14        0.0313  4.0497\n",
      "     15        \u001b[36m0.0235\u001b[0m  4.0638\n",
      "     16        \u001b[36m0.0228\u001b[0m  4.0359\n",
      "     17        0.0264  4.0534\n",
      "     18        \u001b[36m0.0203\u001b[0m  4.0266\n",
      "     19        0.0205  4.0586\n",
      "     20        \u001b[36m0.0171\u001b[0m  4.0579\n",
      "     21        0.0243  4.0386\n",
      "     22        \u001b[36m0.0170\u001b[0m  4.0585\n",
      "     23        \u001b[36m0.0167\u001b[0m  4.0338\n",
      "     24        0.0266  4.0315\n",
      "     25        0.0281  4.0651\n",
      "     26        0.0181  4.0579\n",
      "     27        0.0176  4.0580\n",
      "     28        \u001b[36m0.0148\u001b[0m  4.0577\n",
      "     29        \u001b[36m0.0120\u001b[0m  4.0534\n",
      "     30        0.0320  4.0535\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3926\u001b[0m  4.0565\n",
      "      2        \u001b[36m0.2655\u001b[0m  4.0674\n",
      "      3        \u001b[36m0.1804\u001b[0m  4.0550\n",
      "      4        \u001b[36m0.1187\u001b[0m  4.0592\n",
      "      5        \u001b[36m0.0708\u001b[0m  4.0560\n",
      "      6        \u001b[36m0.0590\u001b[0m  4.0601\n",
      "      7        \u001b[36m0.0438\u001b[0m  4.0558\n",
      "      8        0.0731  4.0467\n",
      "      9        0.0452  4.0533\n",
      "     10        \u001b[36m0.0327\u001b[0m  4.0557\n",
      "     11        0.0752  4.0553\n",
      "     12        0.0501  4.0631\n",
      "     13        0.3456  4.0567\n",
      "     14        0.3597  4.0450\n",
      "     15        0.2742  4.0395\n",
      "     16        0.2047  4.0459\n",
      "     17        0.1448  4.0554\n",
      "     18        0.1162  4.0531\n",
      "     19        0.0937  4.0670\n",
      "     20        0.0718  4.0590\n",
      "     21        0.0654  4.0344\n",
      "     22        0.0651  4.0721\n",
      "     23        0.0663  4.0532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24        0.1275  4.0596\n",
      "     25        0.0839  4.0604\n",
      "     26        0.0514  4.0690\n",
      "     27        0.1004  4.0616\n",
      "     28        0.0655  4.0527\n",
      "     29        0.0476  4.0601\n",
      "     30        0.0466  4.0431\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3364\u001b[0m  4.0314\n",
      "      2        \u001b[36m0.1156\u001b[0m  4.0439\n",
      "      3        \u001b[36m0.0479\u001b[0m  4.0525\n",
      "      4        \u001b[36m0.0412\u001b[0m  4.0166\n",
      "      5        0.0718  4.0446\n",
      "      6        \u001b[36m0.0340\u001b[0m  4.0410\n",
      "      7        0.0542  4.0373\n",
      "      8        \u001b[36m0.0311\u001b[0m  4.0517\n",
      "      9        \u001b[36m0.0209\u001b[0m  4.0476\n",
      "     10        0.6228  4.0341\n",
      "     11        0.3447  4.0420\n",
      "     12        0.2252  4.0374\n",
      "     13        0.1754  4.0576\n",
      "     14        0.1341  4.0355\n",
      "     15        0.1071  4.0480\n",
      "     16        0.1213  4.0371\n",
      "     17        0.0789  4.0325\n",
      "     18        0.0709  4.0369\n",
      "     19        0.0702  4.0328\n",
      "     20        0.0567  4.0272\n",
      "     21        0.1094  4.0393\n",
      "     22        0.0843  4.0363\n",
      "     23        0.0676  4.0541\n",
      "     24        0.0604  4.0547\n",
      "     25        0.0492  4.0430\n",
      "     26        0.0309  4.0514\n",
      "     27        0.0311  4.0438\n",
      "     28        0.0364  4.0521\n",
      "     29        0.0352  4.0500\n",
      "     30        0.0438  4.0578\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2517\u001b[0m  4.0426\n",
      "      2        \u001b[36m0.0904\u001b[0m  4.0283\n",
      "      3        \u001b[36m0.0457\u001b[0m  4.0518\n",
      "      4        0.2453  4.0597\n",
      "      5        0.1366  4.0648\n",
      "      6        0.0834  4.0394\n",
      "      7        0.0605  4.0595\n",
      "      8        0.0509  4.0350\n",
      "      9        \u001b[36m0.0317\u001b[0m  4.0504\n",
      "     10        \u001b[36m0.0251\u001b[0m  4.0282\n",
      "     11        \u001b[36m0.0241\u001b[0m  4.0538\n",
      "     12        \u001b[36m0.0211\u001b[0m  4.0453\n",
      "     13        0.0252  4.0475\n",
      "     14        0.0432  4.0487\n",
      "     15        \u001b[36m0.0202\u001b[0m  4.0556\n",
      "     16        \u001b[36m0.0166\u001b[0m  4.0400\n",
      "     17        \u001b[36m0.0128\u001b[0m  4.0406\n",
      "     18        0.0140  4.0438\n",
      "     19        0.0220  4.0315\n",
      "     20        0.0175  4.0513\n",
      "     21        \u001b[36m0.0127\u001b[0m  4.0291\n",
      "     22        0.0237  4.0408\n",
      "     23        0.0209  4.0520\n",
      "     24        0.0176  4.0625\n",
      "     25        0.0191  4.0549\n",
      "     26        \u001b[36m0.0117\u001b[0m  4.0573\n",
      "     27        0.0134  4.0368\n",
      "     28        \u001b[36m0.0113\u001b[0m  4.0551\n",
      "     29        0.0122  4.0496\n",
      "     30        0.0169  4.0451\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3561\u001b[0m  2.7883\n",
      "      2        \u001b[36m0.2400\u001b[0m  2.7874\n",
      "      3        \u001b[36m0.2172\u001b[0m  2.7878\n",
      "      4        \u001b[36m0.1505\u001b[0m  2.7910\n",
      "      5        \u001b[36m0.1251\u001b[0m  2.7901\n",
      "      6        \u001b[36m0.0968\u001b[0m  2.7929\n",
      "      7        \u001b[36m0.0919\u001b[0m  2.8136\n",
      "      8        \u001b[36m0.0777\u001b[0m  2.8220\n",
      "      9        0.0905  2.8095\n",
      "     10        \u001b[36m0.0584\u001b[0m  2.8357\n",
      "     11        0.0680  2.7930\n",
      "     12        0.0644  2.7829\n",
      "     13        \u001b[36m0.0470\u001b[0m  2.7827\n",
      "     14        \u001b[36m0.0424\u001b[0m  2.8118\n",
      "     15        0.0673  2.7980\n",
      "     16        0.0636  2.7886\n",
      "     17        0.0432  2.7927\n",
      "     18        \u001b[36m0.0401\u001b[0m  2.8170\n",
      "     19        0.0439  2.7970\n",
      "     20        0.0445  2.8133\n",
      "     21        0.0442  2.8270\n",
      "     22        0.0435  2.8094\n",
      "     23        \u001b[36m0.0387\u001b[0m  2.8353\n",
      "     24        \u001b[36m0.0347\u001b[0m  2.8085\n",
      "     25        \u001b[36m0.0280\u001b[0m  2.8063\n",
      "     26        \u001b[36m0.0269\u001b[0m  2.7826\n",
      "     27        0.0437  2.7960\n",
      "     28        0.0301  2.8089\n",
      "     29        0.0282  2.7919\n",
      "     30        0.0551  2.7932\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3488\u001b[0m  2.8394\n",
      "      2        \u001b[36m0.2968\u001b[0m  2.7938\n",
      "      3        \u001b[36m0.2197\u001b[0m  2.8147\n",
      "      4        \u001b[36m0.1484\u001b[0m  2.8183\n",
      "      5        0.1621  2.8367\n",
      "      6        \u001b[36m0.1305\u001b[0m  2.8169\n",
      "      7        0.1895  2.8042\n",
      "      8        \u001b[36m0.0891\u001b[0m  2.7833\n",
      "      9        \u001b[36m0.0729\u001b[0m  2.7869\n",
      "     10        0.0749  2.8229\n",
      "     11        0.0825  2.7914\n",
      "     12        \u001b[36m0.0600\u001b[0m  2.8259\n",
      "     13        \u001b[36m0.0543\u001b[0m  2.8214\n",
      "     14        0.0597  2.8335\n",
      "     15        0.0847  2.8250\n",
      "     16        0.0681  2.8238\n",
      "     17        0.0631  2.8168\n",
      "     18        0.0860  2.8248\n",
      "     19        0.0692  2.8276\n",
      "     20        \u001b[36m0.0517\u001b[0m  2.8320\n",
      "     21        0.0541  2.8151\n",
      "     22        \u001b[36m0.0444\u001b[0m  2.8116\n",
      "     23        \u001b[36m0.0414\u001b[0m  2.7976\n",
      "     24        0.0534  2.8017\n",
      "     25        0.0454  2.7920\n",
      "     26        0.0689  2.8304\n",
      "     27        \u001b[36m0.0370\u001b[0m  2.7837\n",
      "     28        0.0476  2.7809\n",
      "     29        0.0393  2.8004\n",
      "     30        0.0390  2.7852\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3490\u001b[0m  2.7807\n",
      "      2        \u001b[36m0.2314\u001b[0m  2.7934\n",
      "      3        \u001b[36m0.2062\u001b[0m  2.8078\n",
      "      4        \u001b[36m0.1642\u001b[0m  2.7826\n",
      "      5        0.3304  2.7984\n",
      "      6        0.3173  2.8237\n",
      "      7        0.2212  2.7975\n",
      "      8        0.2580  2.8287\n",
      "      9        \u001b[36m0.1589\u001b[0m  2.8209\n",
      "     10        \u001b[36m0.1422\u001b[0m  2.8012\n",
      "     11        \u001b[36m0.1303\u001b[0m  2.8121\n",
      "     12        \u001b[36m0.0768\u001b[0m  2.7969\n",
      "     13        0.0779  2.8015\n",
      "     14        \u001b[36m0.0684\u001b[0m  2.8101\n",
      "     15        \u001b[36m0.0653\u001b[0m  2.8309\n",
      "     16        \u001b[36m0.0600\u001b[0m  2.8049\n",
      "     17        \u001b[36m0.0577\u001b[0m  2.8239\n",
      "     18        \u001b[36m0.0478\u001b[0m  2.8128\n",
      "     19        0.0592  2.8294\n",
      "     20        \u001b[36m0.0467\u001b[0m  2.8152\n",
      "     21        0.0898  2.7970\n",
      "     22        0.0661  2.7999\n",
      "     23        0.0608  2.7907\n",
      "     24        0.0628  2.8149\n",
      "     25        0.0536  2.8175\n",
      "     26        0.0553  2.7950\n",
      "     27        0.0684  2.8246\n",
      "     28        0.0555  2.8212\n",
      "     29        0.0551  2.8086\n",
      "     30        0.0733  2.8155\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3460\u001b[0m  2.7746\n",
      "      2        \u001b[36m0.2904\u001b[0m  2.8002\n",
      "      3        \u001b[36m0.2003\u001b[0m  2.7999\n",
      "      4        \u001b[36m0.1646\u001b[0m  2.8016\n",
      "      5        \u001b[36m0.1466\u001b[0m  2.7912\n",
      "      6        \u001b[36m0.1218\u001b[0m  2.8271\n",
      "      7        \u001b[36m0.0992\u001b[0m  2.8274\n",
      "      8        \u001b[36m0.0897\u001b[0m  2.7972\n",
      "      9        0.1026  2.7944\n",
      "     10        0.1166  2.8135\n",
      "     11        0.1658  2.8020\n",
      "     12        \u001b[36m0.0894\u001b[0m  2.8050\n",
      "     13        \u001b[36m0.0708\u001b[0m  2.8138\n",
      "     14        \u001b[36m0.0573\u001b[0m  2.8317\n",
      "     15        0.0708  2.8056\n",
      "     16        0.0689  2.8286\n",
      "     17        \u001b[36m0.0508\u001b[0m  2.8307\n",
      "     18        \u001b[36m0.0451\u001b[0m  2.7991\n",
      "     19        \u001b[36m0.0408\u001b[0m  2.8289\n",
      "     20        0.0952  2.8193\n",
      "     21        0.0872  2.7839\n",
      "     22        0.0678  2.8047\n",
      "     23        0.0796  2.8173\n",
      "     24        0.0548  2.7953\n",
      "     25        0.0462  2.8017\n",
      "     26        0.0751  2.7940\n",
      "     27        0.1103  2.7965\n",
      "     28        0.1199  2.8307\n",
      "     29        0.0816  2.8364\n",
      "     30        0.0676  2.8365\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3327\u001b[0m  2.8049\n",
      "      2        \u001b[36m0.2977\u001b[0m  2.7867\n",
      "      3        \u001b[36m0.1959\u001b[0m  2.8174\n",
      "      4        \u001b[36m0.1427\u001b[0m  2.8388\n",
      "      5        \u001b[36m0.1293\u001b[0m  2.8240\n",
      "      6        \u001b[36m0.1027\u001b[0m  2.8038\n",
      "      7        0.1034  2.8296\n",
      "      8        0.1165  2.8388\n",
      "      9        0.1138  2.8009\n",
      "     10        \u001b[36m0.0660\u001b[0m  2.8144\n",
      "     11        0.0697  2.7920\n",
      "     12        \u001b[36m0.0599\u001b[0m  2.8219\n",
      "     13        \u001b[36m0.0447\u001b[0m  2.8069\n",
      "     14        \u001b[36m0.0400\u001b[0m  2.7972\n",
      "     15        0.0617  2.8058\n",
      "     16        0.0475  2.8176\n",
      "     17        0.0431  2.7882\n",
      "     18        0.2284  2.8412\n",
      "     19        0.1107  2.8313\n",
      "     20        0.0745  2.8100\n",
      "     21        0.0617  2.7919\n",
      "     22        0.0572  2.7841\n",
      "     23        0.0605  2.7854\n",
      "     24        0.0517  2.7878\n",
      "     25        \u001b[36m0.0374\u001b[0m  2.7932\n",
      "     26        \u001b[36m0.0369\u001b[0m  2.8079\n",
      "     27        0.5595  2.8253\n",
      "     28        0.5148  2.7959\n",
      "     29        0.4840  2.8286\n",
      "     30        0.4823  2.7834\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2822\u001b[0m  3.0701\n",
      "      2        \u001b[36m0.2395\u001b[0m  3.1249\n",
      "      3        0.2944  3.1070\n",
      "      4        0.5027  3.0712\n",
      "      5        0.4291  3.0591\n",
      "      6        0.2625  3.0818\n",
      "      7        \u001b[36m0.1919\u001b[0m  3.0991\n",
      "      8        0.2147  3.1443\n",
      "      9        0.2793  3.0868\n",
      "     10        0.3147  3.1417\n",
      "     11        0.2363  3.1175\n",
      "     12        \u001b[36m0.1904\u001b[0m  3.1145\n",
      "     13        0.1919  3.1035\n",
      "     14        \u001b[36m0.1252\u001b[0m  3.0918\n",
      "     15        \u001b[36m0.0884\u001b[0m  3.0831\n",
      "     16        \u001b[36m0.0668\u001b[0m  3.0827\n",
      "     17        \u001b[36m0.0625\u001b[0m  3.0887\n",
      "     18        \u001b[36m0.0514\u001b[0m  3.1097\n",
      "     19        0.0600  3.0977\n",
      "     20        \u001b[36m0.0456\u001b[0m  3.1245\n",
      "     21        0.0483  3.0690\n",
      "     22        \u001b[36m0.0298\u001b[0m  3.1010\n",
      "     23        0.0561  3.0676\n",
      "     24        0.0364  3.0892\n",
      "     25        0.0428  3.1186\n",
      "     26        0.0309  3.1057\n",
      "     27        0.0338  3.1078\n",
      "     28        0.0331  3.1318\n",
      "     29        0.0523  3.0679\n",
      "     30        0.0412  3.0795\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3001\u001b[0m  3.1145\n",
      "      2        \u001b[36m0.1301\u001b[0m  3.0966\n",
      "      3        \u001b[36m0.0785\u001b[0m  3.0707\n",
      "      4        \u001b[36m0.0556\u001b[0m  3.0744\n",
      "      5        0.0768  3.0674\n",
      "      6        0.0803  3.1094\n",
      "      7        0.4998  3.1099\n",
      "      8        0.4817  3.0668\n",
      "      9        0.3683  3.0772\n",
      "     10        0.2466  3.0936\n",
      "     11        0.1919  3.0970\n",
      "     12        0.1855  3.0897\n",
      "     13        0.1432  3.1163\n",
      "     14        0.1520  3.1333\n",
      "     15        0.1515  3.1394\n",
      "     16        0.4135  3.0899\n",
      "     17        0.2257  3.0942\n",
      "     18        0.1655  3.1351\n",
      "     19        0.1344  3.1196\n",
      "     20        0.1262  3.1359\n",
      "     21        0.1126  3.1350\n",
      "     22        0.1045  3.0896\n",
      "     23        0.1022  3.1075\n",
      "     24        0.0972  3.0921\n",
      "     25        0.0779  3.0960\n",
      "     26        0.0574  3.1341\n",
      "     27        0.1059  3.1254\n",
      "     28        0.4594  3.1412\n",
      "     29        0.3116  3.0929\n",
      "     30        0.5931  3.0921\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3673\u001b[0m  3.1019\n",
      "      2        \u001b[36m0.3041\u001b[0m  3.0896\n",
      "      3        \u001b[36m0.1878\u001b[0m  3.0953\n",
      "      4        \u001b[36m0.0875\u001b[0m  3.0906\n",
      "      5        \u001b[36m0.0751\u001b[0m  3.1056\n",
      "      6        \u001b[36m0.0609\u001b[0m  3.1152\n",
      "      7        \u001b[36m0.0571\u001b[0m  3.1251\n",
      "      8        \u001b[36m0.0455\u001b[0m  3.0870\n",
      "      9        0.0709  3.1104\n",
      "     10        0.0459  3.1282\n",
      "     11        0.0835  3.0966\n",
      "     12        \u001b[36m0.0385\u001b[0m  3.1111\n",
      "     13        \u001b[36m0.0297\u001b[0m  3.1175\n",
      "     14        \u001b[36m0.0255\u001b[0m  3.0954\n",
      "     15        0.0259  3.0874\n",
      "     16        \u001b[36m0.0216\u001b[0m  3.1292\n",
      "     17        0.0232  3.0715\n",
      "     18        0.0279  3.0721\n",
      "     19        \u001b[36m0.0146\u001b[0m  3.1298\n",
      "     20        0.0196  3.1298\n",
      "     21        0.0177  3.0993\n",
      "     22        0.0266  3.0852\n",
      "     23        0.0228  3.1169\n",
      "     24        \u001b[36m0.0133\u001b[0m  3.1393\n",
      "     25        0.0273  3.1412\n",
      "     26        0.0161  3.1569\n",
      "     27        0.0195  3.0918\n",
      "     28        \u001b[36m0.0115\u001b[0m  3.1110\n",
      "     29        0.0333  3.0655\n",
      "     30        0.0255  3.1348\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2925\u001b[0m  3.1077\n",
      "      2        \u001b[36m0.1432\u001b[0m  3.0703\n",
      "      3        \u001b[36m0.0992\u001b[0m  3.0584\n",
      "      4        \u001b[36m0.0721\u001b[0m  3.0682\n",
      "      5        0.0771  3.1267\n",
      "      6        0.1085  3.0559\n",
      "      7        0.1809  3.1231\n",
      "      8        0.4035  3.0884\n",
      "      9        0.1926  3.0627\n",
      "     10        0.1386  3.0636\n",
      "     11        0.1097  3.1117\n",
      "     12        0.0925  3.1337\n",
      "     13        0.0834  3.1341\n",
      "     14        0.0743  3.1314\n",
      "     15        \u001b[36m0.0607\u001b[0m  3.1329\n",
      "     16        0.0818  3.1282\n",
      "     17        \u001b[36m0.0562\u001b[0m  3.1169\n",
      "     18        \u001b[36m0.0509\u001b[0m  3.1046\n",
      "     19        0.0619  3.1126\n",
      "     20        0.0700  3.0790\n",
      "     21        0.0827  3.0969\n",
      "     22        0.0697  3.1193\n",
      "     23        0.0662  3.0904\n",
      "     24        \u001b[36m0.0470\u001b[0m  3.1016\n",
      "     25        \u001b[36m0.0375\u001b[0m  3.0804\n",
      "     26        \u001b[36m0.0367\u001b[0m  3.0943\n",
      "     27        0.0370  3.1311\n",
      "     28        0.0371  3.1251\n",
      "     29        0.0641  3.1256\n",
      "     30        0.0627  3.1239\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2750\u001b[0m  3.1352\n",
      "      2        \u001b[36m0.1802\u001b[0m  3.0815\n",
      "      3        \u001b[36m0.0965\u001b[0m  3.1018\n",
      "      4        \u001b[36m0.0694\u001b[0m  3.1099\n",
      "      5        \u001b[36m0.0540\u001b[0m  3.1344\n",
      "      6        \u001b[36m0.0485\u001b[0m  3.1252\n",
      "      7        \u001b[36m0.0342\u001b[0m  3.1154\n",
      "      8        0.0960  3.1030\n",
      "      9        0.3966  3.0585\n",
      "     10        0.1114  3.0637\n",
      "     11        0.0706  3.0843\n",
      "     12        0.1344  3.0787\n",
      "     13        0.0538  3.0878\n",
      "     14        0.0559  3.1297\n",
      "     15        0.0603  3.1032\n",
      "     16        0.0359  3.0946\n",
      "     17        0.0634  3.0944\n",
      "     18        0.0382  3.1334\n",
      "     19        \u001b[36m0.0331\u001b[0m  3.0854\n",
      "     20        0.0758  3.1191\n",
      "     21        0.0396  3.1147\n",
      "     22        0.0405  3.1112\n",
      "     23        0.0610  3.1096\n",
      "     24        0.0868  3.1061\n",
      "     25        0.0362  3.1058\n",
      "     26        0.0340  3.1012\n",
      "     27        \u001b[36m0.0236\u001b[0m  3.1185\n",
      "     28        \u001b[36m0.0226\u001b[0m  3.1020\n",
      "     29        \u001b[36m0.0222\u001b[0m  3.1115\n",
      "     30        0.1828  3.1308\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2827\u001b[0m  4.7741\n",
      "      2        \u001b[36m0.1396\u001b[0m  4.7716\n",
      "      3        \u001b[36m0.1070\u001b[0m  4.7685\n",
      "      4        \u001b[36m0.0901\u001b[0m  4.7666\n",
      "      5        \u001b[36m0.0828\u001b[0m  4.7658\n",
      "      6        0.1423  4.7719\n",
      "      7        0.5699  4.7561\n",
      "      8        0.5896  4.7570\n",
      "      9        0.5042  4.7720\n",
      "     10        0.3740  4.7663\n",
      "     11        0.3016  4.7657\n",
      "     12        0.3872  4.7707\n",
      "     13        0.2758  4.7738\n",
      "     14        0.3469  4.7656\n",
      "     15        0.1627  4.7689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16        0.1529  4.7697\n",
      "     17        0.7774  4.7647\n",
      "     18        0.5729  4.7703\n",
      "     19        0.4986  4.7787\n",
      "     20        0.4413  4.7475\n",
      "     21        0.3676  4.7608\n",
      "     22        0.6850  4.7760\n",
      "     23        0.3896  4.7712\n",
      "     24        0.2078  4.7667\n",
      "     25        0.1911  4.7685\n",
      "     26        0.1203  4.7720\n",
      "     27        0.1304  4.7687\n",
      "     28        \u001b[36m0.0753\u001b[0m  4.7709\n",
      "     29        0.1137  4.7589\n",
      "     30        0.3781  4.7600\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2904\u001b[0m  4.7721\n",
      "      2        \u001b[36m0.1634\u001b[0m  4.7774\n",
      "      3        \u001b[36m0.0687\u001b[0m  4.7788\n",
      "      4        \u001b[36m0.0379\u001b[0m  4.7641\n",
      "      5        \u001b[36m0.0340\u001b[0m  4.7794\n",
      "      6        \u001b[36m0.0264\u001b[0m  4.7782\n",
      "      7        0.2306  4.7639\n",
      "      8        0.4706  4.7736\n",
      "      9        0.2528  4.7790\n",
      "     10        0.1536  4.7765\n",
      "     11        0.2054  4.7750\n",
      "     12        0.1053  4.7688\n",
      "     13        0.1894  4.7654\n",
      "     14        0.1784  4.7690\n",
      "     15        0.1228  4.7750\n",
      "     16        0.1098  4.7861\n",
      "     17        0.0628  4.7791\n",
      "     18        0.0489  4.7814\n",
      "     19        0.0525  4.7771\n",
      "     20        0.0474  4.7853\n",
      "     21        0.0408  4.7619\n",
      "     22        0.0677  4.7698\n",
      "     23        0.0453  4.7734\n",
      "     24        0.0560  4.7484\n",
      "     25        0.0564  4.7733\n",
      "     26        0.0682  4.7713\n",
      "     27        0.0463  4.7547\n",
      "     28        0.0379  4.7907\n",
      "     29        0.0382  4.7764\n",
      "     30        0.0463  4.7826\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2931\u001b[0m  4.7600\n",
      "      2        \u001b[36m0.1903\u001b[0m  4.7582\n",
      "      3        \u001b[36m0.0999\u001b[0m  4.7528\n",
      "      4        \u001b[36m0.0420\u001b[0m  4.7628\n",
      "      5        0.0946  4.7413\n",
      "      6        0.3937  4.7533\n",
      "      7        0.1976  4.7407\n",
      "      8        0.1601  4.7505\n",
      "      9        0.1148  4.7688\n",
      "     10        0.1140  4.7511\n",
      "     11        0.0783  4.7488\n",
      "     12        0.0495  4.7351\n",
      "     13        0.0607  4.7546\n",
      "     14        0.0465  4.7340\n",
      "     15        0.3137  4.7381\n",
      "     16        0.3332  4.7526\n",
      "     17        0.1835  4.7586\n",
      "     18        0.1512  4.7616\n",
      "     19        0.1485  4.7640\n",
      "     20        0.1079  4.7507\n",
      "     21        0.3727  4.7652\n",
      "     22        0.3293  4.7596\n",
      "     23        0.1545  4.7756\n",
      "     24        0.1292  4.7664\n",
      "     25        0.0989  4.7705\n",
      "     26        0.3772  4.7502\n",
      "     27        0.2274  4.7600\n",
      "     28        0.2636  4.7346\n",
      "     29        0.2142  4.7612\n",
      "     30        0.1220  4.7564\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3163\u001b[0m  4.7608\n",
      "      2        \u001b[36m0.1508\u001b[0m  4.7464\n",
      "      3        \u001b[36m0.1037\u001b[0m  4.7644\n",
      "      4        \u001b[36m0.0562\u001b[0m  4.7751\n",
      "      5        \u001b[36m0.0359\u001b[0m  4.7671\n",
      "      6        0.0454  4.7736\n",
      "      7        \u001b[36m0.0349\u001b[0m  4.7602\n",
      "      8        \u001b[36m0.0278\u001b[0m  4.7745\n",
      "      9        0.4563  4.7710\n",
      "     10        0.3197  4.7708\n",
      "     11        0.4492  4.7521\n",
      "     12        0.3021  4.7542\n",
      "     13        0.3160  4.7743\n",
      "     14        0.2298  4.7695\n",
      "     15        0.1625  4.7410\n",
      "     16        0.1602  4.7679\n",
      "     17        0.1150  4.7700\n",
      "     18        0.1003  4.7858\n",
      "     19        0.0823  4.7715\n",
      "     20        0.3024  4.7539\n",
      "     21        0.1643  4.7643\n",
      "     22        0.0917  4.7764\n",
      "     23        0.0662  4.7765\n",
      "     24        0.0718  4.7518\n",
      "     25        0.0474  4.7739\n",
      "     26        0.0515  4.7764\n",
      "     27        0.0440  4.7797\n",
      "     28        0.1069  4.7744\n",
      "     29        0.0826  4.8224\n",
      "     30        0.0548  4.8995\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3345\u001b[0m  4.8621\n",
      "      2        \u001b[36m0.1412\u001b[0m  4.7697\n",
      "      3        \u001b[36m0.0649\u001b[0m  4.7604\n",
      "      4        \u001b[36m0.0506\u001b[0m  4.7691\n",
      "      5        0.0609  4.7718\n",
      "      6        \u001b[36m0.0476\u001b[0m  4.7702\n",
      "      7        \u001b[36m0.0362\u001b[0m  4.7599\n",
      "      8        \u001b[36m0.0359\u001b[0m  4.7447\n",
      "      9        \u001b[36m0.0335\u001b[0m  4.7706\n",
      "     10        0.0394  4.7588\n",
      "     11        0.0390  4.7649\n",
      "     12        0.0633  4.8338\n",
      "     13        \u001b[36m0.0274\u001b[0m  4.7833\n",
      "     14        0.0430  4.7625\n",
      "     15        0.2120  4.7590\n",
      "     16        0.1170  4.7659\n",
      "     17        0.0600  4.7531\n",
      "     18        0.0447  4.7688\n",
      "     19        0.0348  4.7465\n",
      "     20        0.0299  4.7680\n",
      "     21        0.0420  4.7679\n",
      "     22        0.0912  4.7581\n",
      "     23        0.0585  4.7790\n",
      "     24        0.0417  4.7412\n",
      "     25        0.0337  4.7580\n",
      "     26        0.0293  4.7657\n",
      "     27        0.3363  4.7518\n",
      "     28        0.1418  4.7614\n",
      "     29        0.0886  4.7726\n",
      "     30        0.4057  4.7723\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2657\u001b[0m  4.0298\n",
      "      2        \u001b[36m0.1297\u001b[0m  4.0533\n",
      "      3        \u001b[36m0.0771\u001b[0m  4.0209\n",
      "      4        0.1573  4.0204\n",
      "      5        0.2797  4.0187\n",
      "      6        0.1405  4.0249\n",
      "      7        0.0869  4.0543\n",
      "      8        \u001b[36m0.0701\u001b[0m  4.0500\n",
      "      9        0.0729  4.0622\n",
      "     10        \u001b[36m0.0653\u001b[0m  4.0331\n",
      "     11        \u001b[36m0.0511\u001b[0m  4.0312\n",
      "     12        \u001b[36m0.0446\u001b[0m  4.0500\n",
      "     13        \u001b[36m0.0381\u001b[0m  4.0503\n",
      "     14        \u001b[36m0.0375\u001b[0m  4.0154\n",
      "     15        0.0541  4.0568\n",
      "     16        \u001b[36m0.0340\u001b[0m  4.0231\n",
      "     17        0.0381  4.0529\n",
      "     18        0.2086  4.0378\n",
      "     19        0.0868  4.0183\n",
      "     20        0.0562  4.0410\n",
      "     21        0.0480  4.0436\n",
      "     22        0.0469  4.0445\n",
      "     23        0.0627  4.0506\n",
      "     24        0.0420  4.0387\n",
      "     25        0.0380  4.0504\n",
      "     26        \u001b[36m0.0308\u001b[0m  4.0435\n",
      "     27        \u001b[36m0.0252\u001b[0m  4.0332\n",
      "     28        \u001b[36m0.0228\u001b[0m  4.0311\n",
      "     29        0.0275  4.0292\n",
      "     30        0.3556  4.0385\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3317\u001b[0m  4.0573\n",
      "      2        \u001b[36m0.0801\u001b[0m  4.0481\n",
      "      3        \u001b[36m0.0472\u001b[0m  4.0473\n",
      "      4        0.0599  4.0615\n",
      "      5        \u001b[36m0.0359\u001b[0m  4.0535\n",
      "      6        \u001b[36m0.0251\u001b[0m  4.0479\n",
      "      7        0.0257  4.0472\n",
      "      8        0.0478  4.0626\n",
      "      9        0.4576  4.0617\n",
      "     10        0.5535  4.0451\n",
      "     11        0.5048  4.0457\n",
      "     12        0.4655  4.0449\n",
      "     13        0.4270  4.0482\n",
      "     14        0.4607  4.0655\n",
      "     15        0.5520  4.0538\n",
      "     16        0.4198  4.0480\n",
      "     17        0.3515  4.0476\n",
      "     18        0.3040  4.0313\n",
      "     19        0.2475  4.0482\n",
      "     20        0.3303  4.0640\n",
      "     21        0.3710  4.0526\n",
      "     22        0.2128  4.0490\n",
      "     23        0.1396  4.0517\n",
      "     24        0.0911  4.0534\n",
      "     25        0.0658  4.0452\n",
      "     26        0.0529  4.0659\n",
      "     27        0.0391  4.0475\n",
      "     28        0.0424  4.0492\n",
      "     29        0.3614  4.0482\n",
      "     30        0.6668  4.0544\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3071\u001b[0m  4.0549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.1390\u001b[0m  4.0586\n",
      "      3        \u001b[36m0.0961\u001b[0m  4.0586\n",
      "      4        \u001b[36m0.0557\u001b[0m  4.0517\n",
      "      5        \u001b[36m0.0388\u001b[0m  4.0381\n",
      "      6        \u001b[36m0.0310\u001b[0m  4.0548\n",
      "      7        \u001b[36m0.0233\u001b[0m  4.0450\n",
      "      8        \u001b[36m0.0185\u001b[0m  4.0485\n",
      "      9        0.0711  4.0596\n",
      "     10        0.0554  4.0226\n",
      "     11        0.5827  4.0474\n",
      "     12        0.5065  4.0467\n",
      "     13        0.4585  4.0604\n",
      "     14        0.4183  4.0457\n",
      "     15        0.3743  4.0218\n",
      "     16        0.3340  4.0494\n",
      "     17        0.2847  4.0563\n",
      "     18        0.2261  4.0455\n",
      "     19        0.1821  4.0498\n",
      "     20        0.1328  4.0449\n",
      "     21        0.1361  4.0458\n",
      "     22        0.1132  4.0388\n",
      "     23        0.0883  4.0439\n",
      "     24        0.1142  4.0428\n",
      "     25        0.0841  4.0339\n",
      "     26        0.0576  4.0591\n",
      "     27        0.0439  4.0360\n",
      "     28        0.0839  4.0153\n",
      "     29        0.0747  4.0507\n",
      "     30        0.0788  4.0425\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2739\u001b[0m  4.0434\n",
      "      2        \u001b[36m0.1075\u001b[0m  4.0555\n",
      "      3        0.2540  4.0351\n",
      "      4        0.1807  4.0480\n",
      "      5        \u001b[36m0.0809\u001b[0m  4.0484\n",
      "      6        0.2241  4.0300\n",
      "      7        0.1574  4.0569\n",
      "      8        \u001b[36m0.0592\u001b[0m  4.0555\n",
      "      9        \u001b[36m0.0501\u001b[0m  4.0426\n",
      "     10        \u001b[36m0.0337\u001b[0m  4.0499\n",
      "     11        0.0419  4.0499\n",
      "     12        0.0434  4.0629\n",
      "     13        0.0373  4.0648\n",
      "     14        0.0391  4.0629\n",
      "     15        \u001b[36m0.0294\u001b[0m  4.0597\n",
      "     16        0.0353  4.0579\n",
      "     17        \u001b[36m0.0290\u001b[0m  4.0459\n",
      "     18        0.0393  4.0545\n",
      "     19        0.0337  4.0498\n",
      "     20        \u001b[36m0.0281\u001b[0m  4.0316\n",
      "     21        \u001b[36m0.0255\u001b[0m  4.0638\n",
      "     22        \u001b[36m0.0207\u001b[0m  4.0547\n",
      "     23        0.0285  4.0534\n",
      "     24        0.0252  4.0558\n",
      "     25        0.0262  4.0464\n",
      "     26        \u001b[36m0.0164\u001b[0m  4.0665\n",
      "     27        0.0183  4.0449\n",
      "     28        0.0170  4.0506\n",
      "     29        0.0216  4.0599\n",
      "     30        0.0205  4.0449\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2644\u001b[0m  4.0399\n",
      "      2        \u001b[36m0.0928\u001b[0m  4.0369\n",
      "      3        \u001b[36m0.0506\u001b[0m  4.0497\n",
      "      4        0.0746  4.0534\n",
      "      5        \u001b[36m0.0385\u001b[0m  4.0584\n",
      "      6        \u001b[36m0.0296\u001b[0m  4.0358\n",
      "      7        0.0515  4.0474\n",
      "      8        0.2555  4.0418\n",
      "      9        0.4888  4.0472\n",
      "     10        0.3606  4.0575\n",
      "     11        0.2561  4.0376\n",
      "     12        0.1845  4.0516\n",
      "     13        0.3133  4.0453\n",
      "     14        0.1158  4.0415\n",
      "     15        0.1107  4.0498\n",
      "     16        0.0933  4.0321\n",
      "     17        0.0652  4.0555\n",
      "     18        0.3747  4.0257\n",
      "     19        0.1720  4.0402\n",
      "     20        0.1402  4.0507\n",
      "     21        0.0605  4.0456\n",
      "     22        0.0571  4.0239\n",
      "     23        0.0365  4.0243\n",
      "     24        0.0542  4.0500\n",
      "     25        0.0433  4.0206\n",
      "     26        \u001b[36m0.0289\u001b[0m  4.0877\n",
      "     27        0.0992  4.0384\n",
      "     28        0.2885  4.0268\n",
      "     29        0.3716  4.0507\n",
      "     30        0.3273  4.0269\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3217\u001b[0m  2.8137\n",
      "      2        \u001b[36m0.2087\u001b[0m  2.8190\n",
      "      3        \u001b[36m0.1718\u001b[0m  2.8162\n",
      "      4        0.3940  2.8061\n",
      "      5        0.2140  2.7972\n",
      "      6        0.1798  2.7922\n",
      "      7        \u001b[36m0.1381\u001b[0m  2.8092\n",
      "      8        \u001b[36m0.1197\u001b[0m  2.8110\n",
      "      9        \u001b[36m0.1061\u001b[0m  2.8377\n",
      "     10        0.1194  2.8112\n",
      "     11        \u001b[36m0.0967\u001b[0m  2.7784\n",
      "     12        \u001b[36m0.0811\u001b[0m  2.7904\n",
      "     13        \u001b[36m0.0747\u001b[0m  2.8202\n",
      "     14        0.0795  2.7886\n",
      "     15        0.0796  2.7945\n",
      "     16        0.0839  2.8123\n",
      "     17        \u001b[36m0.0712\u001b[0m  2.8055\n",
      "     18        \u001b[36m0.0646\u001b[0m  2.7908\n",
      "     19        0.0953  2.8232\n",
      "     20        \u001b[36m0.0529\u001b[0m  2.8147\n",
      "     21        0.2440  2.8025\n",
      "     22        0.5085  2.8238\n",
      "     23        0.4111  2.8395\n",
      "     24        0.3858  2.7962\n",
      "     25        0.3015  2.7932\n",
      "     26        0.2611  2.8139\n",
      "     27        0.2333  2.8104\n",
      "     28        0.2380  2.8171\n",
      "     29        0.1731  2.7988\n",
      "     30        0.1544  2.8151\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3656\u001b[0m  2.7916\n",
      "      2        \u001b[36m0.2706\u001b[0m  2.8075\n",
      "      3        \u001b[36m0.2431\u001b[0m  2.8328\n",
      "      4        0.2648  2.7911\n",
      "      5        \u001b[36m0.1791\u001b[0m  2.8303\n",
      "      6        \u001b[36m0.1702\u001b[0m  2.8030\n",
      "      7        \u001b[36m0.1244\u001b[0m  2.7942\n",
      "      8        \u001b[36m0.1076\u001b[0m  2.7929\n",
      "      9        0.1189  2.7904\n",
      "     10        0.1106  2.8026\n",
      "     11        0.1573  2.8191\n",
      "     12        0.1168  2.7910\n",
      "     13        \u001b[36m0.0894\u001b[0m  2.8290\n",
      "     14        \u001b[36m0.0779\u001b[0m  2.7937\n",
      "     15        \u001b[36m0.0658\u001b[0m  2.8227\n",
      "     16        0.0973  2.8289\n",
      "     17        0.0980  2.8095\n",
      "     18        0.0692  2.8094\n",
      "     19        0.0766  2.7915\n",
      "     20        \u001b[36m0.0655\u001b[0m  2.8089\n",
      "     21        \u001b[36m0.0577\u001b[0m  2.8412\n",
      "     22        \u001b[36m0.0503\u001b[0m  2.7992\n",
      "     23        0.0588  2.8096\n",
      "     24        0.0843  2.8048\n",
      "     25        0.0686  2.8133\n",
      "     26        0.0676  2.8044\n",
      "     27        0.0925  2.8124\n",
      "     28        0.0600  2.8317\n",
      "     29        0.0613  2.7993\n",
      "     30        0.0544  2.7913\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3291\u001b[0m  2.7765\n",
      "      2        \u001b[36m0.1644\u001b[0m  2.7881\n",
      "      3        \u001b[36m0.1221\u001b[0m  2.8031\n",
      "      4        \u001b[36m0.1128\u001b[0m  2.8022\n",
      "      5        \u001b[36m0.0871\u001b[0m  2.7984\n",
      "      6        0.0906  2.8056\n",
      "      7        \u001b[36m0.0684\u001b[0m  2.7988\n",
      "      8        \u001b[36m0.0681\u001b[0m  2.8254\n",
      "      9        \u001b[36m0.0640\u001b[0m  2.8018\n",
      "     10        \u001b[36m0.0549\u001b[0m  2.8237\n",
      "     11        0.0628  2.8140\n",
      "     12        0.0900  2.8027\n",
      "     13        0.0635  2.8011\n",
      "     14        0.0837  2.7885\n",
      "     15        0.4829  2.8073\n",
      "     16        0.4740  2.8048\n",
      "     17        0.4272  2.8335\n",
      "     18        0.4294  2.8245\n",
      "     19        0.4305  2.7984\n",
      "     20        0.4483  2.8139\n",
      "     21        0.4247  2.7970\n",
      "     22        0.4048  2.7828\n",
      "     23        0.4113  2.7814\n",
      "     24        0.4116  2.8264\n",
      "     25        0.3891  2.8164\n",
      "     26        0.4150  2.7858\n",
      "     27        0.4233  2.7984\n",
      "     28        0.4242  2.7946\n",
      "     29        0.5100  2.8079\n",
      "     30        0.5188  2.8013\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3660\u001b[0m  2.7885\n",
      "      2        \u001b[36m0.3566\u001b[0m  2.8261\n",
      "      3        \u001b[36m0.3391\u001b[0m  2.8102\n",
      "      4        \u001b[36m0.2247\u001b[0m  2.7883\n",
      "      5        \u001b[36m0.1648\u001b[0m  2.7917\n",
      "      6        \u001b[36m0.1591\u001b[0m  2.7921\n",
      "      7        \u001b[36m0.1329\u001b[0m  2.7834\n",
      "      8        \u001b[36m0.1317\u001b[0m  2.7836\n",
      "      9        0.1411  2.8077\n",
      "     10        \u001b[36m0.0979\u001b[0m  2.7814\n",
      "     11        \u001b[36m0.0978\u001b[0m  2.7831\n",
      "     12        \u001b[36m0.0971\u001b[0m  2.7822\n",
      "     13        \u001b[36m0.0961\u001b[0m  2.7974\n",
      "     14        \u001b[36m0.0891\u001b[0m  2.8012\n",
      "     15        0.0948  2.7971\n",
      "     16        \u001b[36m0.0821\u001b[0m  2.7903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17        \u001b[36m0.0728\u001b[0m  2.8148\n",
      "     18        \u001b[36m0.0626\u001b[0m  2.7935\n",
      "     19        0.1334  2.7845\n",
      "     20        0.0721  2.7885\n",
      "     21        0.0834  2.8073\n",
      "     22        \u001b[36m0.0611\u001b[0m  2.7990\n",
      "     23        \u001b[36m0.0568\u001b[0m  2.7985\n",
      "     24        0.0684  2.8229\n",
      "     25        0.0573  2.8104\n",
      "     26        \u001b[36m0.0466\u001b[0m  2.8272\n",
      "     27        0.0551  2.8060\n",
      "     28        0.0631  2.7791\n",
      "     29        0.0718  2.8149\n",
      "     30        0.0642  2.8216\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3418\u001b[0m  2.8208\n",
      "      2        \u001b[36m0.1818\u001b[0m  2.8317\n",
      "      3        \u001b[36m0.1674\u001b[0m  2.8088\n",
      "      4        \u001b[36m0.1317\u001b[0m  2.8028\n",
      "      5        \u001b[36m0.1172\u001b[0m  2.8067\n",
      "      6        \u001b[36m0.1150\u001b[0m  2.8049\n",
      "      7        \u001b[36m0.0847\u001b[0m  2.7921\n",
      "      8        \u001b[36m0.0655\u001b[0m  2.8194\n",
      "      9        0.4344  2.8281\n",
      "     10        0.2387  2.8164\n",
      "     11        0.1607  2.7953\n",
      "     12        0.1310  2.8013\n",
      "     13        0.1104  2.8118\n",
      "     14        0.0928  2.8247\n",
      "     15        0.1524  2.8462\n",
      "     16        0.0922  2.8146\n",
      "     17        0.1050  2.8026\n",
      "     18        0.1034  2.7910\n",
      "     19        0.0790  2.8312\n",
      "     20        0.0670  2.8247\n",
      "     21        \u001b[36m0.0579\u001b[0m  2.7954\n",
      "     22        \u001b[36m0.0561\u001b[0m  2.8215\n",
      "     23        \u001b[36m0.0507\u001b[0m  2.7881\n",
      "     24        0.0575  2.8020\n",
      "     25        \u001b[36m0.0483\u001b[0m  2.7916\n",
      "     26        0.0701  2.8257\n",
      "     27        0.0489  2.8078\n",
      "     28        0.0538  2.7883\n",
      "     29        0.0640  2.8186\n",
      "     30        0.0513  2.8025\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total= 1.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2991\u001b[0m  3.1065\n",
      "      2        \u001b[36m0.1781\u001b[0m  3.1142\n",
      "      3        \u001b[36m0.1096\u001b[0m  3.1013\n",
      "      4        \u001b[36m0.0997\u001b[0m  3.1410\n",
      "      5        \u001b[36m0.0695\u001b[0m  3.1195\n",
      "      6        \u001b[36m0.0466\u001b[0m  3.0880\n",
      "      7        \u001b[36m0.0366\u001b[0m  3.0990\n",
      "      8        0.0419  3.0924\n",
      "      9        \u001b[36m0.0320\u001b[0m  3.0713\n",
      "     10        \u001b[36m0.0287\u001b[0m  3.0918\n",
      "     11        \u001b[36m0.0287\u001b[0m  3.1241\n",
      "     12        0.0295  3.1209\n",
      "     13        0.0329  3.1315\n",
      "     14        \u001b[36m0.0204\u001b[0m  3.1276\n",
      "     15        0.0343  3.1244\n",
      "     16        0.0299  3.0963\n",
      "     17        0.0308  3.1151\n",
      "     18        \u001b[36m0.0199\u001b[0m  3.1317\n",
      "     19        0.0243  3.0705\n",
      "     20        0.0521  3.0997\n",
      "     21        0.0330  3.0828\n",
      "     22        0.0312  3.0973\n",
      "     23        0.0585  3.1124\n",
      "     24        0.4168  3.1093\n",
      "     25        0.4099  3.1065\n",
      "     26        0.4074  3.0966\n",
      "     27        0.3872  3.0938\n",
      "     28        0.4001  3.1259\n",
      "     29        0.3905  3.1164\n",
      "     30        0.3765  3.1287\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3020\u001b[0m  3.1277\n",
      "      2        \u001b[36m0.1683\u001b[0m  3.0898\n",
      "      3        \u001b[36m0.1283\u001b[0m  3.0802\n",
      "      4        \u001b[36m0.0763\u001b[0m  3.0957\n",
      "      5        \u001b[36m0.0647\u001b[0m  3.0774\n",
      "      6        \u001b[36m0.0385\u001b[0m  3.0800\n",
      "      7        \u001b[36m0.0290\u001b[0m  3.1302\n",
      "      8        0.0415  3.0671\n",
      "      9        \u001b[36m0.0264\u001b[0m  3.1247\n",
      "     10        \u001b[36m0.0200\u001b[0m  3.1168\n",
      "     11        0.1062  3.0800\n",
      "     12        0.4000  3.0834\n",
      "     13        0.6544  3.1070\n",
      "     14        0.6284  3.1272\n",
      "     15        0.5778  3.1312\n",
      "     16        0.5261  3.0586\n",
      "     17        0.4860  3.0921\n",
      "     18        0.4390  3.1045\n",
      "     19        0.3603  3.0880\n",
      "     20        0.3060  3.0780\n",
      "     21        0.2729  3.0637\n",
      "     22        0.2406  3.1122\n",
      "     23        0.4995  3.1087\n",
      "     24        0.5319  3.1182\n",
      "     25        0.4356  3.0915\n",
      "     26        0.3652  3.0807\n",
      "     27        0.2845  3.1071\n",
      "     28        0.3232  3.1277\n",
      "     29        0.2502  3.0763\n",
      "     30        0.2405  3.1372\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2858\u001b[0m  3.0820\n",
      "      2        \u001b[36m0.1963\u001b[0m  3.1139\n",
      "      3        \u001b[36m0.0957\u001b[0m  3.1055\n",
      "      4        \u001b[36m0.0629\u001b[0m  3.0724\n",
      "      5        \u001b[36m0.0559\u001b[0m  3.0705\n",
      "      6        \u001b[36m0.0389\u001b[0m  3.0976\n",
      "      7        0.1076  3.1172\n",
      "      8        0.2767  3.1072\n",
      "      9        0.4439  3.1043\n",
      "     10        0.2778  3.0907\n",
      "     11        0.1611  3.0838\n",
      "     12        0.1022  3.1137\n",
      "     13        0.4446  3.1150\n",
      "     14        0.4784  3.1288\n",
      "     15        0.3376  3.0934\n",
      "     16        0.2231  3.1320\n",
      "     17        0.2050  3.1209\n",
      "     18        0.1777  3.0715\n",
      "     19        0.1302  3.1338\n",
      "     20        0.1164  3.1203\n",
      "     21        0.1440  3.1381\n",
      "     22        0.1048  3.1135\n",
      "     23        0.0809  3.1194\n",
      "     24        0.1151  3.1259\n",
      "     25        0.1064  3.1290\n",
      "     26        0.1102  3.0941\n",
      "     27        0.1024  3.1050\n",
      "     28        0.0659  3.0796\n",
      "     29        0.2372  3.1526\n",
      "     30        0.1487  3.1387\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3126\u001b[0m  3.0778\n",
      "      2        \u001b[36m0.1781\u001b[0m  3.1262\n",
      "      3        \u001b[36m0.1494\u001b[0m  3.0923\n",
      "      4        \u001b[36m0.0844\u001b[0m  3.1295\n",
      "      5        \u001b[36m0.0463\u001b[0m  3.0799\n",
      "      6        0.0588  3.0990\n",
      "      7        \u001b[36m0.0349\u001b[0m  3.0843\n",
      "      8        \u001b[36m0.0346\u001b[0m  3.1277\n",
      "      9        0.0475  3.1259\n",
      "     10        0.4990  3.1009\n",
      "     11        0.5837  3.0900\n",
      "     12        0.5756  3.1048\n",
      "     13        0.3153  3.0922\n",
      "     14        0.2274  3.1180\n",
      "     15        0.1668  3.0996\n",
      "     16        0.5489  3.0828\n",
      "     17        0.3146  3.1101\n",
      "     18        0.1994  3.0973\n",
      "     19        0.3966  3.1216\n",
      "     20        0.2861  3.1125\n",
      "     21        0.2660  3.1052\n",
      "     22        0.2307  3.1156\n",
      "     23        0.1958  3.1087\n",
      "     24        0.1828  3.1215\n",
      "     25        0.3122  3.1027\n",
      "     26        0.1797  3.1230\n",
      "     27        0.1474  3.1441\n",
      "     28        0.1314  3.1262\n",
      "     29        0.1468  3.0892\n",
      "     30        0.2117  3.1363\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3200\u001b[0m  3.1211\n",
      "      2        \u001b[36m0.1292\u001b[0m  3.0795\n",
      "      3        \u001b[36m0.0864\u001b[0m  3.0643\n",
      "      4        \u001b[36m0.0818\u001b[0m  3.0880\n",
      "      5        \u001b[36m0.0606\u001b[0m  3.1044\n",
      "      6        0.1402  3.1237\n",
      "      7        0.1042  3.0868\n",
      "      8        0.0672  3.1093\n",
      "      9        0.0701  3.0910\n",
      "     10        0.0625  3.0997\n",
      "     11        \u001b[36m0.0485\u001b[0m  3.0938\n",
      "     12        \u001b[36m0.0439\u001b[0m  3.0916\n",
      "     13        \u001b[36m0.0353\u001b[0m  3.1256\n",
      "     14        0.1170  3.0939\n",
      "     15        0.5097  3.0995\n",
      "     16        0.5710  3.0866\n",
      "     17        0.5543  3.1136\n",
      "     18        0.5434  3.1076\n",
      "     19        0.5294  3.1616\n",
      "     20        0.5190  3.0650\n",
      "     21        0.5094  3.0654\n",
      "     22        0.5040  3.0659\n",
      "     23        0.5190  3.1135\n",
      "     24        0.7555  3.1245\n",
      "     25        0.6532  3.0799\n",
      "     26        0.6510  3.1061\n",
      "     27        0.6535  3.1322\n",
      "     28        0.6501  3.1364\n",
      "     29        0.6329  3.1222\n",
      "     30        0.6471  3.1054\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total= 1.6min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2769\u001b[0m  4.7799\n",
      "      2        \u001b[36m0.1417\u001b[0m  4.7748\n",
      "      3        \u001b[36m0.1036\u001b[0m  4.7670\n",
      "      4        0.2870  4.7808\n",
      "      5        0.5223  4.7539\n",
      "      6        0.3899  4.7807\n",
      "      7        0.2545  4.7732\n",
      "      8        0.3247  4.7728\n",
      "      9        0.1987  4.7556\n",
      "     10        0.3050  4.7757\n",
      "     11        0.1647  4.7712\n",
      "     12        0.1118  4.7690\n",
      "     13        0.1093  4.7823\n",
      "     14        \u001b[36m0.0921\u001b[0m  4.7801\n",
      "     15        0.1028  4.7831\n",
      "     16        \u001b[36m0.0666\u001b[0m  4.7508\n",
      "     17        0.0911  4.7762\n",
      "     18        0.0838  4.7879\n",
      "     19        0.0672  4.7793\n",
      "     20        \u001b[36m0.0621\u001b[0m  4.7691\n",
      "     21        \u001b[36m0.0502\u001b[0m  4.7768\n",
      "     22        \u001b[36m0.0401\u001b[0m  4.7814\n",
      "     23        0.0768  4.7694\n",
      "     24        0.1048  4.7696\n",
      "     25        0.1456  4.7694\n",
      "     26        0.2605  4.7829\n",
      "     27        0.1018  4.7706\n",
      "     28        0.0717  4.7792\n",
      "     29        0.3263  4.7782\n",
      "     30        0.4877  4.7796\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3141\u001b[0m  4.7763\n",
      "      2        \u001b[36m0.1483\u001b[0m  4.7676\n",
      "      3        \u001b[36m0.0789\u001b[0m  4.7668\n",
      "      4        0.3567  4.7675\n",
      "      5        0.1829  4.7653\n",
      "      6        0.1510  4.7686\n",
      "      7        0.3484  4.7712\n",
      "      8        0.5216  4.7727\n",
      "      9        0.4502  4.7638\n",
      "     10        0.4063  4.7609\n",
      "     11        0.3559  4.7750\n",
      "     12        0.2939  4.7728\n",
      "     13        0.2356  4.7911\n",
      "     14        0.1761  4.7662\n",
      "     15        0.1329  4.7650\n",
      "     16        0.1279  4.7745\n",
      "     17        0.0921  4.7737\n",
      "     18        0.0915  4.7721\n",
      "     19        \u001b[36m0.0745\u001b[0m  4.7681\n",
      "     20        \u001b[36m0.0727\u001b[0m  4.7549\n",
      "     21        \u001b[36m0.0650\u001b[0m  4.7711\n",
      "     22        0.1355  4.7744\n",
      "     23        0.0707  4.7459\n",
      "     24        \u001b[36m0.0424\u001b[0m  4.7750\n",
      "     25        0.0982  4.7670\n",
      "     26        0.2368  4.7502\n",
      "     27        0.4358  4.7737\n",
      "     28        0.4224  4.7627\n",
      "     29        0.9695  4.7696\n",
      "     30        0.6601  4.7739\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2955\u001b[0m  4.7610\n",
      "      2        \u001b[36m0.1525\u001b[0m  4.7559\n",
      "      3        \u001b[36m0.0794\u001b[0m  4.7745\n",
      "      4        \u001b[36m0.0559\u001b[0m  4.7450\n",
      "      5        0.0589  4.7772\n",
      "      6        \u001b[36m0.0354\u001b[0m  4.7711\n",
      "      7        0.2667  4.7853\n",
      "      8        0.2620  4.7720\n",
      "      9        0.2646  4.7715\n",
      "     10        0.2525  4.7739\n",
      "     11        0.6467  4.7592\n",
      "     12        0.5693  4.7783\n",
      "     13        0.5457  4.7786\n",
      "     14        0.4956  4.7661\n",
      "     15        0.4450  4.7718\n",
      "     16        0.3941  4.7469\n",
      "     17        0.3319  4.7640\n",
      "     18        0.3403  4.7663\n",
      "     19        0.3894  4.7688\n",
      "     20        0.2819  4.7706\n",
      "     21        0.2598  4.7467\n",
      "     22        0.3145  4.7774\n",
      "     23        0.2295  4.7635\n",
      "     24        0.2472  4.7529\n",
      "     25        0.1454  4.7577\n",
      "     26        0.0950  4.7641\n",
      "     27        0.2096  4.7703\n",
      "     28        0.6339  4.7536\n",
      "     29        0.6125  4.7742\n",
      "     30        0.5015  4.7778\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2976\u001b[0m  4.7657\n",
      "      2        \u001b[36m0.1801\u001b[0m  4.7369\n",
      "      3        \u001b[36m0.0964\u001b[0m  4.7680\n",
      "      4        \u001b[36m0.0725\u001b[0m  4.7443\n",
      "      5        \u001b[36m0.0607\u001b[0m  4.7510\n",
      "      6        \u001b[36m0.0409\u001b[0m  4.7522\n",
      "      7        0.2447  4.7569\n",
      "      8        0.5833  4.7587\n",
      "      9        0.6188  4.7561\n",
      "     10        0.6029  4.7561\n",
      "     11        0.5799  4.7550\n",
      "     12        0.5543  4.7599\n",
      "     13        0.5782  4.7547\n",
      "     14        0.5507  4.7559\n",
      "     15        0.5326  4.7656\n",
      "     16        0.5299  4.7363\n",
      "     17        0.5531  4.7592\n",
      "     18        0.5379  4.7529\n",
      "     19        0.5049  4.7511\n",
      "     20        0.4932  4.7463\n",
      "     21        0.4739  4.7583\n",
      "     22        0.4492  4.7515\n",
      "     23        0.4236  4.7608\n",
      "     24        0.3953  4.7540\n",
      "     25        0.3527  4.7650\n",
      "     26        0.3175  4.7550\n",
      "     27        0.4399  4.7702\n",
      "     28        0.3508  4.7569\n",
      "     29        0.3197  4.7618\n",
      "     30        0.3197  4.7685\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3285\u001b[0m  4.7722\n",
      "      2        \u001b[36m0.1946\u001b[0m  4.7727\n",
      "      3        \u001b[36m0.1063\u001b[0m  4.7646\n",
      "      4        \u001b[36m0.0678\u001b[0m  4.7647\n",
      "      5        \u001b[36m0.0487\u001b[0m  4.7653\n",
      "      6        \u001b[36m0.0361\u001b[0m  4.7644\n",
      "      7        0.0491  4.7730\n",
      "      8        0.1370  4.7681\n",
      "      9        0.0517  4.7641\n",
      "     10        0.0463  4.7693\n",
      "     11        0.0398  4.7625\n",
      "     12        0.0586  4.7678\n",
      "     13        \u001b[36m0.0284\u001b[0m  4.7737\n",
      "     14        \u001b[36m0.0201\u001b[0m  4.7592\n",
      "     15        0.0322  4.7686\n",
      "     16        0.0340  4.7740\n",
      "     17        0.0252  4.7512\n",
      "     18        \u001b[36m0.0182\u001b[0m  4.7728\n",
      "     19        0.0404  4.7696\n",
      "     20        0.0422  4.7660\n",
      "     21        0.0231  4.7675\n",
      "     22        \u001b[36m0.0174\u001b[0m  4.7724\n",
      "     23        0.0269  4.7614\n",
      "     24        0.0179  4.7418\n",
      "     25        \u001b[36m0.0138\u001b[0m  4.7663\n",
      "     26        0.0240  4.7660\n",
      "     27        0.0142  4.7615\n",
      "     28        0.0296  4.7630\n",
      "     29        0.0268  4.7664\n",
      "     30        0.1445  4.7409\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 2.4min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2923\u001b[0m  4.0402\n",
      "      2        \u001b[36m0.1675\u001b[0m  4.0554\n",
      "      3        \u001b[36m0.0956\u001b[0m  4.0482\n",
      "      4        \u001b[36m0.0478\u001b[0m  4.0326\n",
      "      5        \u001b[36m0.0366\u001b[0m  4.0525\n",
      "      6        0.0372  4.0248\n",
      "      7        \u001b[36m0.0305\u001b[0m  4.0391\n",
      "      8        \u001b[36m0.0276\u001b[0m  4.0478\n",
      "      9        0.0374  4.0421\n",
      "     10        0.1039  4.0644\n",
      "     11        0.7172  4.0612\n",
      "     12        0.5904  4.0544\n",
      "     13        0.5394  4.0460\n",
      "     14        0.4778  4.0624\n",
      "     15        0.4158  4.0537\n",
      "     16        0.3708  4.0506\n",
      "     17        0.3433  4.0413\n",
      "     18        0.2937  4.0406\n",
      "     19        0.4254  4.0565\n",
      "     20        0.3540  4.0550\n",
      "     21        0.3462  4.0357\n",
      "     22        0.3116  4.0455\n",
      "     23        0.2536  4.0475\n",
      "     24        0.2564  4.0234\n",
      "     25        0.1600  4.0533\n",
      "     26        0.2127  4.0662\n",
      "     27        1.0109  4.0478\n",
      "     28        0.2829  4.0584\n",
      "     29        0.2620  4.0230\n",
      "     30        0.1560  4.0570\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2627\u001b[0m  4.0412\n",
      "      2        \u001b[36m0.1430\u001b[0m  4.0496\n",
      "      3        0.2928  4.0207\n",
      "      4        0.4015  4.0457\n",
      "      5        \u001b[36m0.1283\u001b[0m  4.0481\n",
      "      6        \u001b[36m0.0634\u001b[0m  4.0315\n",
      "      7        \u001b[36m0.0552\u001b[0m  4.0228\n",
      "      8        \u001b[36m0.0413\u001b[0m  4.0219\n",
      "      9        \u001b[36m0.0374\u001b[0m  4.0520\n",
      "     10        0.0396  4.0387\n",
      "     11        \u001b[36m0.0280\u001b[0m  4.0337\n",
      "     12        0.0369  4.0182\n",
      "     13        0.0369  4.0328\n",
      "     14        \u001b[36m0.0232\u001b[0m  4.0398\n",
      "     15        0.0303  4.0520\n",
      "     16        0.0267  4.0389\n",
      "     17        0.0236  4.0256\n",
      "     18        \u001b[36m0.0206\u001b[0m  4.0368\n",
      "     19        0.0223  4.0373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20        \u001b[36m0.0163\u001b[0m  4.0529\n",
      "     21        0.0236  4.0346\n",
      "     22        0.0269  4.0457\n",
      "     23        0.0529  4.0404\n",
      "     24        0.6837  4.0378\n",
      "     25        0.6449  4.0451\n",
      "     26        0.6516  4.0372\n",
      "     27        0.6697  4.0483\n",
      "     28        0.6749  4.0338\n",
      "     29        0.6692  4.0287\n",
      "     30        0.6633  4.0484\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2622\u001b[0m  4.0604\n",
      "      2        \u001b[36m0.1037\u001b[0m  4.0632\n",
      "      3        \u001b[36m0.0925\u001b[0m  4.0685\n",
      "      4        \u001b[36m0.0758\u001b[0m  4.0337\n",
      "      5        \u001b[36m0.0751\u001b[0m  4.0614\n",
      "      6        0.5289  4.0376\n",
      "      7        0.3436  4.0650\n",
      "      8        0.2102  4.0578\n",
      "      9        0.4034  4.0622\n",
      "     10        0.3346  4.0452\n",
      "     11        0.4629  4.0503\n",
      "     12        0.3623  4.0633\n",
      "     13        0.1847  4.0296\n",
      "     14        0.1077  4.0465\n",
      "     15        0.0819  4.0507\n",
      "     16        \u001b[36m0.0583\u001b[0m  4.0445\n",
      "     17        0.1537  4.0668\n",
      "     18        0.1030  4.0685\n",
      "     19        0.0592  4.0667\n",
      "     20        0.0709  4.0694\n",
      "     21        0.4721  4.0539\n",
      "     22        0.4877  4.0510\n",
      "     23        0.4513  4.0355\n",
      "     24        0.4247  4.0472\n",
      "     25        0.2785  4.0537\n",
      "     26        0.2308  4.0496\n",
      "     27        0.2010  4.0478\n",
      "     28        0.3246  4.0363\n",
      "     29        0.5397  4.0407\n",
      "     30        0.3861  4.0526\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3395\u001b[0m  4.0515\n",
      "      2        \u001b[36m0.1115\u001b[0m  4.0498\n",
      "      3        \u001b[36m0.0520\u001b[0m  4.0231\n",
      "      4        \u001b[36m0.0338\u001b[0m  4.0400\n",
      "      5        0.0414  4.0404\n",
      "      6        0.0350  4.0521\n",
      "      7        \u001b[36m0.0252\u001b[0m  4.0337\n",
      "      8        0.0977  4.0469\n",
      "      9        0.0921  4.0449\n",
      "     10        0.0655  4.0565\n",
      "     11        0.2401  4.0487\n",
      "     12        0.4062  4.0515\n",
      "     13        0.1418  4.0231\n",
      "     14        0.0835  4.0568\n",
      "     15        0.0717  4.0521\n",
      "     16        0.0690  4.0302\n",
      "     17        0.0519  4.0509\n",
      "     18        0.0389  4.0583\n",
      "     19        0.0458  4.0413\n",
      "     20        0.0605  4.0435\n",
      "     21        0.0549  4.0225\n",
      "     22        0.0408  4.0447\n",
      "     23        0.0313  4.0443\n",
      "     24        0.0299  4.0369\n",
      "     25        0.0627  4.0556\n",
      "     26        0.0653  4.0528\n",
      "     27        0.0317  4.0440\n",
      "     28        0.0395  4.0256\n",
      "     29        0.0675  4.0239\n",
      "     30        0.0348  4.0322\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2600\u001b[0m  4.0565\n",
      "      2        \u001b[36m0.1137\u001b[0m  4.0667\n",
      "      3        0.2445  4.0517\n",
      "      4        0.3194  4.0567\n",
      "      5        0.1496  4.0435\n",
      "      6        \u001b[36m0.1030\u001b[0m  4.0431\n",
      "      7        \u001b[36m0.0873\u001b[0m  4.0583\n",
      "      8        \u001b[36m0.0681\u001b[0m  4.0590\n",
      "      9        \u001b[36m0.0563\u001b[0m  4.0473\n",
      "     10        0.0586  4.0473\n",
      "     11        0.0577  4.0349\n",
      "     12        \u001b[36m0.0426\u001b[0m  4.0507\n",
      "     13        0.0620  4.0551\n",
      "     14        \u001b[36m0.0416\u001b[0m  4.0655\n",
      "     15        \u001b[36m0.0337\u001b[0m  4.0470\n",
      "     16        0.0595  4.0361\n",
      "     17        \u001b[36m0.0288\u001b[0m  4.0479\n",
      "     18        \u001b[36m0.0252\u001b[0m  4.0490\n",
      "     19        0.0376  4.0588\n",
      "     20        0.0456  4.0574\n",
      "     21        0.0328  4.0452\n",
      "     22        0.0277  4.0470\n",
      "     23        0.0278  4.0431\n",
      "     24        0.0565  4.0363\n",
      "     25        0.0346  4.0419\n",
      "     26        0.0393  4.0596\n",
      "     27        \u001b[36m0.0188\u001b[0m  4.0466\n",
      "     28        \u001b[36m0.0174\u001b[0m  4.0563\n",
      "     29        0.0202  4.0437\n",
      "     30        0.0187  4.0555\n",
      "[CV]  net__batch_size=64, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 2.0min\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3574\u001b[0m  1.6113\n",
      "      2        \u001b[36m0.2624\u001b[0m  1.5855\n",
      "      3        \u001b[36m0.2119\u001b[0m  1.5879\n",
      "      4        0.3066  1.5848\n",
      "      5        0.3083  1.5802\n",
      "      6        0.2437  1.5864\n",
      "      7        \u001b[36m0.2106\u001b[0m  1.5684\n",
      "      8        \u001b[36m0.1824\u001b[0m  1.5780\n",
      "      9        \u001b[36m0.1789\u001b[0m  1.5849\n",
      "     10        \u001b[36m0.1674\u001b[0m  1.5967\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3373\u001b[0m  1.6008\n",
      "      2        \u001b[36m0.2249\u001b[0m  1.5949\n",
      "      3        \u001b[36m0.1561\u001b[0m  1.5994\n",
      "      4        \u001b[36m0.1407\u001b[0m  1.6017\n",
      "      5        0.1634  1.5864\n",
      "      6        0.1978  1.5933\n",
      "      7        0.1627  1.5812\n",
      "      8        0.1461  1.6102\n",
      "      9        \u001b[36m0.1158\u001b[0m  1.5977\n",
      "     10        \u001b[36m0.0968\u001b[0m  1.5952\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  16.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3607\u001b[0m  1.5870\n",
      "      2        \u001b[36m0.2498\u001b[0m  1.6047\n",
      "      3        \u001b[36m0.1940\u001b[0m  1.6019\n",
      "      4        \u001b[36m0.1581\u001b[0m  1.5995\n",
      "      5        \u001b[36m0.1357\u001b[0m  1.5774\n",
      "      6        0.1532  1.5808\n",
      "      7        \u001b[36m0.1257\u001b[0m  1.5823\n",
      "      8        \u001b[36m0.1067\u001b[0m  1.5751\n",
      "      9        0.1513  1.5754\n",
      "     10        \u001b[36m0.0976\u001b[0m  1.5975\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2940\u001b[0m  1.5752\n",
      "      2        \u001b[36m0.2058\u001b[0m  1.5821\n",
      "      3        \u001b[36m0.1358\u001b[0m  1.5917\n",
      "      4        0.1430  1.5766\n",
      "      5        \u001b[36m0.0893\u001b[0m  1.5760\n",
      "      6        0.0953  1.5966\n",
      "      7        \u001b[36m0.0636\u001b[0m  1.5924\n",
      "      8        0.0837  1.5935\n",
      "      9        \u001b[36m0.0567\u001b[0m  1.5744\n",
      "     10        \u001b[36m0.0518\u001b[0m  1.5695\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  16.0s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3397\u001b[0m  1.5982\n",
      "      2        \u001b[36m0.2725\u001b[0m  1.5957\n",
      "      3        0.2828  1.6042\n",
      "      4        \u001b[36m0.2465\u001b[0m  1.5975\n",
      "      5        \u001b[36m0.2272\u001b[0m  1.5841\n",
      "      6        \u001b[36m0.1918\u001b[0m  1.5961\n",
      "      7        \u001b[36m0.1499\u001b[0m  1.5973\n",
      "      8        \u001b[36m0.1316\u001b[0m  1.5898\n",
      "      9        \u001b[36m0.1144\u001b[0m  1.6093\n",
      "     10        0.1202  1.5767\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  16.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3178\u001b[0m  1.7382\n",
      "      2        \u001b[36m0.1669\u001b[0m  1.7363\n",
      "      3        \u001b[36m0.1216\u001b[0m  1.7180\n",
      "      4        0.1239  1.7329\n",
      "      5        \u001b[36m0.1093\u001b[0m  1.7257\n",
      "      6        \u001b[36m0.0718\u001b[0m  1.7120\n",
      "      7        \u001b[36m0.0530\u001b[0m  1.7353\n",
      "      8        0.0595  1.7180\n",
      "      9        \u001b[36m0.0390\u001b[0m  1.7291\n",
      "     10        \u001b[36m0.0294\u001b[0m  1.7153\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  17.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2999\u001b[0m  1.7077\n",
      "      2        \u001b[36m0.1735\u001b[0m  1.7358\n",
      "      3        \u001b[36m0.1322\u001b[0m  1.7344\n",
      "      4        \u001b[36m0.1169\u001b[0m  1.7041\n",
      "      5        \u001b[36m0.1078\u001b[0m  1.7146\n",
      "      6        0.1342  1.7060\n",
      "      7        0.2436  1.7072\n",
      "      8        \u001b[36m0.1030\u001b[0m  1.7230\n",
      "      9        \u001b[36m0.0633\u001b[0m  1.7212\n",
      "     10        \u001b[36m0.0486\u001b[0m  1.7199\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  17.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3074\u001b[0m  1.7103\n",
      "      2        \u001b[36m0.1608\u001b[0m  1.7075\n",
      "      3        \u001b[36m0.1211\u001b[0m  1.7061\n",
      "      4        \u001b[36m0.0900\u001b[0m  1.7114\n",
      "      5        \u001b[36m0.0659\u001b[0m  1.7068\n",
      "      6        \u001b[36m0.0601\u001b[0m  1.7254\n",
      "      7        0.0747  1.7038\n",
      "      8        0.0801  1.7058\n",
      "      9        \u001b[36m0.0389\u001b[0m  1.7187\n",
      "     10        \u001b[36m0.0283\u001b[0m  1.7096\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  17.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3523\u001b[0m  1.7227\n",
      "      2        \u001b[36m0.1979\u001b[0m  1.7185\n",
      "      3        \u001b[36m0.1198\u001b[0m  1.7236\n",
      "      4        \u001b[36m0.0782\u001b[0m  1.7329\n",
      "      5        0.0879  1.7487\n",
      "      6        \u001b[36m0.0636\u001b[0m  1.7177\n",
      "      7        \u001b[36m0.0377\u001b[0m  1.7154\n",
      "      8        0.0470  1.7162\n",
      "      9        0.0398  1.7105\n",
      "     10        \u001b[36m0.0364\u001b[0m  1.7220\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  17.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3170\u001b[0m  1.7131\n",
      "      2        \u001b[36m0.1696\u001b[0m  1.7125\n",
      "      3        \u001b[36m0.1015\u001b[0m  1.7282\n",
      "      4        0.1182  1.7065\n",
      "      5        \u001b[36m0.0728\u001b[0m  1.7205\n",
      "      6        \u001b[36m0.0511\u001b[0m  1.7236\n",
      "      7        \u001b[36m0.0348\u001b[0m  1.7432\n",
      "      8        \u001b[36m0.0331\u001b[0m  1.7411\n",
      "      9        0.0335  1.7220\n",
      "     10        \u001b[36m0.0328\u001b[0m  1.7433\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  17.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3401\u001b[0m  2.7592\n",
      "      2        \u001b[36m0.1719\u001b[0m  2.7457\n",
      "      3        \u001b[36m0.1138\u001b[0m  2.7444\n",
      "      4        \u001b[36m0.0798\u001b[0m  2.7456\n",
      "      5        \u001b[36m0.0625\u001b[0m  2.7470\n",
      "      6        \u001b[36m0.0552\u001b[0m  2.7484\n",
      "      7        \u001b[36m0.0411\u001b[0m  2.7439\n",
      "      8        0.0448  2.7705\n",
      "      9        0.0572  2.7445\n",
      "     10        0.0909  2.7359\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  27.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2885\u001b[0m  2.7501\n",
      "      2        \u001b[36m0.1590\u001b[0m  2.7353\n",
      "      3        \u001b[36m0.0782\u001b[0m  2.7295\n",
      "      4        \u001b[36m0.0446\u001b[0m  2.7353\n",
      "      5        \u001b[36m0.0345\u001b[0m  2.7495\n",
      "      6        \u001b[36m0.0310\u001b[0m  2.7440\n",
      "      7        \u001b[36m0.0280\u001b[0m  2.7401\n",
      "      8        \u001b[36m0.0246\u001b[0m  2.7518\n",
      "      9        \u001b[36m0.0240\u001b[0m  2.7478\n",
      "     10        \u001b[36m0.0186\u001b[0m  2.7403\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  27.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2896\u001b[0m  2.7600\n",
      "      2        \u001b[36m0.1370\u001b[0m  2.7551\n",
      "      3        \u001b[36m0.0981\u001b[0m  2.7555\n",
      "      4        \u001b[36m0.0576\u001b[0m  2.7537\n",
      "      5        0.1145  2.7565\n",
      "      6        0.0839  2.7576\n",
      "      7        \u001b[36m0.0535\u001b[0m  2.7516\n",
      "      8        \u001b[36m0.0355\u001b[0m  2.7532\n",
      "      9        \u001b[36m0.0239\u001b[0m  2.7582\n",
      "     10        0.0281  2.7562\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  27.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3403\u001b[0m  2.7232\n",
      "      2        \u001b[36m0.1904\u001b[0m  2.7224\n",
      "      3        \u001b[36m0.1461\u001b[0m  2.7249\n",
      "      4        \u001b[36m0.1055\u001b[0m  2.7329\n",
      "      5        0.1088  2.7285\n",
      "      6        \u001b[36m0.0588\u001b[0m  2.7355\n",
      "      7        \u001b[36m0.0431\u001b[0m  2.7426\n",
      "      8        \u001b[36m0.0363\u001b[0m  2.7310\n",
      "      9        \u001b[36m0.0242\u001b[0m  2.7314\n",
      "     10        0.0245  2.7201\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  27.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3118\u001b[0m  2.7430\n",
      "      2        \u001b[36m0.1601\u001b[0m  2.7457\n",
      "      3        \u001b[36m0.0941\u001b[0m  2.7475\n",
      "      4        \u001b[36m0.0602\u001b[0m  2.7416\n",
      "      5        \u001b[36m0.0431\u001b[0m  2.7431\n",
      "      6        0.1235  2.7458\n",
      "      7        0.0480  2.7427\n",
      "      8        0.0438  2.7413\n",
      "      9        0.0826  2.7403\n",
      "     10        \u001b[36m0.0350\u001b[0m  2.7407\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  27.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3267\u001b[0m  2.5290\n",
      "      2        \u001b[36m0.1457\u001b[0m  2.5385\n",
      "      3        0.1660  2.5338\n",
      "      4        \u001b[36m0.0841\u001b[0m  2.5319\n",
      "      5        \u001b[36m0.0407\u001b[0m  2.5363\n",
      "      6        \u001b[36m0.0287\u001b[0m  2.5297\n",
      "      7        \u001b[36m0.0255\u001b[0m  2.5262\n",
      "      8        \u001b[36m0.0232\u001b[0m  2.5299\n",
      "      9        0.0329  2.5314\n",
      "     10        \u001b[36m0.0223\u001b[0m  2.5309\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  25.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3248\u001b[0m  2.5240\n",
      "      2        \u001b[36m0.1924\u001b[0m  2.5280\n",
      "      3        \u001b[36m0.1193\u001b[0m  2.5335\n",
      "      4        \u001b[36m0.0920\u001b[0m  2.5440\n",
      "      5        \u001b[36m0.0678\u001b[0m  2.5391\n",
      "      6        0.0707  2.5255\n",
      "      7        \u001b[36m0.0591\u001b[0m  2.5273\n",
      "      8        0.0824  2.5261\n",
      "      9        0.3039  2.5395\n",
      "     10        0.1199  2.5324\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  25.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3014\u001b[0m  2.5240\n",
      "      2        \u001b[36m0.2105\u001b[0m  2.5256\n",
      "      3        0.3385  2.5699\n",
      "      4        \u001b[36m0.1496\u001b[0m  2.5179\n",
      "      5        \u001b[36m0.1043\u001b[0m  2.5258\n",
      "      6        \u001b[36m0.0598\u001b[0m  2.5314\n",
      "      7        0.0722  2.5449\n",
      "      8        \u001b[36m0.0487\u001b[0m  2.5359\n",
      "      9        \u001b[36m0.0457\u001b[0m  2.5466\n",
      "     10        \u001b[36m0.0377\u001b[0m  2.5535\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  25.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4996\u001b[0m  2.5515\n",
      "      2        \u001b[36m0.1702\u001b[0m  2.5508\n",
      "      3        \u001b[36m0.0832\u001b[0m  2.5361\n",
      "      4        \u001b[36m0.0642\u001b[0m  2.5563\n",
      "      5        \u001b[36m0.0411\u001b[0m  2.5516\n",
      "      6        \u001b[36m0.0350\u001b[0m  2.5466\n",
      "      7        \u001b[36m0.0237\u001b[0m  2.5450\n",
      "      8        \u001b[36m0.0220\u001b[0m  2.5456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9        \u001b[36m0.0191\u001b[0m  2.5465\n",
      "     10        0.1226  2.5595\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  25.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3363\u001b[0m  2.5413\n",
      "      2        \u001b[36m0.1347\u001b[0m  2.5522\n",
      "      3        \u001b[36m0.0796\u001b[0m  2.5428\n",
      "      4        \u001b[36m0.0399\u001b[0m  2.5479\n",
      "      5        \u001b[36m0.0397\u001b[0m  2.5455\n",
      "      6        \u001b[36m0.0364\u001b[0m  2.5392\n",
      "      7        0.1438  2.5528\n",
      "      8        0.0457  2.5621\n",
      "      9        \u001b[36m0.0363\u001b[0m  2.5535\n",
      "     10        \u001b[36m0.0238\u001b[0m  2.5467\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  25.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3685\u001b[0m  1.5939\n",
      "      2        \u001b[36m0.2085\u001b[0m  1.5859\n",
      "      3        \u001b[36m0.1657\u001b[0m  1.5862\n",
      "      4        \u001b[36m0.1392\u001b[0m  1.6061\n",
      "      5        \u001b[36m0.1322\u001b[0m  1.5981\n",
      "      6        0.1584  1.6072\n",
      "      7        0.1343  1.6062\n",
      "      8        \u001b[36m0.1080\u001b[0m  1.6044\n",
      "      9        \u001b[36m0.1015\u001b[0m  1.5851\n",
      "     10        0.1414  1.5743\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  16.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4056\u001b[0m  1.5733\n",
      "      2        \u001b[36m0.2634\u001b[0m  1.5756\n",
      "      3        \u001b[36m0.1719\u001b[0m  1.5785\n",
      "      4        \u001b[36m0.1426\u001b[0m  1.5996\n",
      "      5        \u001b[36m0.1422\u001b[0m  1.5861\n",
      "      6        0.1772  1.6089\n",
      "      7        \u001b[36m0.0880\u001b[0m  1.5813\n",
      "      8        \u001b[36m0.0771\u001b[0m  1.5950\n",
      "      9        0.0875  1.5835\n",
      "     10        0.0821  1.5965\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3549\u001b[0m  1.5911\n",
      "      2        \u001b[36m0.3029\u001b[0m  1.5760\n",
      "      3        \u001b[36m0.2582\u001b[0m  1.5690\n",
      "      4        \u001b[36m0.1684\u001b[0m  1.6002\n",
      "      5        0.1878  1.5976\n",
      "      6        \u001b[36m0.1582\u001b[0m  1.6037\n",
      "      7        \u001b[36m0.1046\u001b[0m  1.6008\n",
      "      8        \u001b[36m0.0879\u001b[0m  1.5904\n",
      "      9        0.0976  1.5878\n",
      "     10        \u001b[36m0.0841\u001b[0m  1.6068\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4309\u001b[0m  1.5869\n",
      "      2        \u001b[36m0.3078\u001b[0m  1.5809\n",
      "      3        \u001b[36m0.2380\u001b[0m  1.5914\n",
      "      4        \u001b[36m0.1945\u001b[0m  1.6040\n",
      "      5        \u001b[36m0.1650\u001b[0m  1.5999\n",
      "      6        \u001b[36m0.1284\u001b[0m  1.5952\n",
      "      7        \u001b[36m0.1248\u001b[0m  1.5704\n",
      "      8        0.1343  1.5906\n",
      "      9        0.1621  1.5819\n",
      "     10        0.1485  1.5900\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3821\u001b[0m  1.6067\n",
      "      2        \u001b[36m0.2573\u001b[0m  1.5778\n",
      "      3        \u001b[36m0.2007\u001b[0m  1.5806\n",
      "      4        \u001b[36m0.1574\u001b[0m  1.5942\n",
      "      5        \u001b[36m0.1319\u001b[0m  1.5998\n",
      "      6        0.1339  1.5913\n",
      "      7        \u001b[36m0.1230\u001b[0m  1.5812\n",
      "      8        \u001b[36m0.0869\u001b[0m  1.5819\n",
      "      9        0.1103  1.6043\n",
      "     10        0.0959  1.5916\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3364\u001b[0m  1.7226\n",
      "      2        \u001b[36m0.1854\u001b[0m  1.7103\n",
      "      3        \u001b[36m0.1173\u001b[0m  1.7123\n",
      "      4        \u001b[36m0.0944\u001b[0m  1.7159\n",
      "      5        \u001b[36m0.0752\u001b[0m  1.7182\n",
      "      6        \u001b[36m0.0652\u001b[0m  1.7332\n",
      "      7        \u001b[36m0.0438\u001b[0m  1.7277\n",
      "      8        \u001b[36m0.0332\u001b[0m  1.7229\n",
      "      9        0.0379  1.7122\n",
      "     10        0.5974  1.7071\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  17.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3084\u001b[0m  1.7075\n",
      "      2        \u001b[36m0.1819\u001b[0m  1.7111\n",
      "      3        \u001b[36m0.1513\u001b[0m  1.7296\n",
      "      4        \u001b[36m0.1067\u001b[0m  1.7234\n",
      "      5        \u001b[36m0.0808\u001b[0m  1.7476\n",
      "      6        \u001b[36m0.0709\u001b[0m  1.7265\n",
      "      7        \u001b[36m0.0646\u001b[0m  1.7253\n",
      "      8        \u001b[36m0.0576\u001b[0m  1.7163\n",
      "      9        \u001b[36m0.0418\u001b[0m  1.7387\n",
      "     10        \u001b[36m0.0357\u001b[0m  1.7301\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  17.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3165\u001b[0m  1.7266\n",
      "      2        \u001b[36m0.1839\u001b[0m  1.7407\n",
      "      3        \u001b[36m0.1356\u001b[0m  1.7190\n",
      "      4        \u001b[36m0.1060\u001b[0m  1.7194\n",
      "      5        \u001b[36m0.0768\u001b[0m  1.7102\n",
      "      6        0.0930  1.7120\n",
      "      7        0.0791  1.7247\n",
      "      8        \u001b[36m0.0752\u001b[0m  1.7251\n",
      "      9        \u001b[36m0.0517\u001b[0m  1.7340\n",
      "     10        \u001b[36m0.0418\u001b[0m  1.7164\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  17.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3184\u001b[0m  1.7170\n",
      "      2        \u001b[36m0.1909\u001b[0m  1.7054\n",
      "      3        \u001b[36m0.1372\u001b[0m  1.7075\n",
      "      4        \u001b[36m0.1101\u001b[0m  1.7157\n",
      "      5        \u001b[36m0.0852\u001b[0m  1.7062\n",
      "      6        \u001b[36m0.0772\u001b[0m  1.7006\n",
      "      7        \u001b[36m0.0552\u001b[0m  1.7104\n",
      "      8        \u001b[36m0.0502\u001b[0m  1.7200\n",
      "      9        0.0512  1.7183\n",
      "     10        \u001b[36m0.0384\u001b[0m  1.7084\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  17.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3332\u001b[0m  1.7227\n",
      "      2        \u001b[36m0.2036\u001b[0m  1.7445\n",
      "      3        \u001b[36m0.1762\u001b[0m  1.7113\n",
      "      4        \u001b[36m0.1080\u001b[0m  1.7272\n",
      "      5        \u001b[36m0.0714\u001b[0m  1.7354\n",
      "      6        0.0850  1.7491\n",
      "      7        \u001b[36m0.0543\u001b[0m  1.7107\n",
      "      8        0.1149  1.7095\n",
      "      9        0.0719  1.7172\n",
      "     10        \u001b[36m0.0445\u001b[0m  1.7231\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  17.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3047\u001b[0m  2.7541\n",
      "      2        \u001b[36m0.1540\u001b[0m  2.7455\n",
      "      3        0.4778  2.7418\n",
      "      4        0.5590  2.7521\n",
      "      5        0.5709  2.7511\n",
      "      6        0.6164  2.7580\n",
      "      7        0.5692  2.7563\n",
      "      8        0.5346  2.7412\n",
      "      9        0.5048  2.7394\n",
      "     10        0.5274  2.7379\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  27.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3083\u001b[0m  2.7456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.1508\u001b[0m  2.7540\n",
      "      3        0.4147  2.7570\n",
      "      4        0.3458  2.7469\n",
      "      5        0.1822  2.7500\n",
      "      6        \u001b[36m0.1411\u001b[0m  2.7563\n",
      "      7        0.1888  2.7505\n",
      "      8        \u001b[36m0.1095\u001b[0m  2.7407\n",
      "      9        \u001b[36m0.0893\u001b[0m  2.7463\n",
      "     10        \u001b[36m0.0852\u001b[0m  2.7378\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  27.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3345\u001b[0m  2.7547\n",
      "      2        \u001b[36m0.2001\u001b[0m  2.7364\n",
      "      3        \u001b[36m0.0984\u001b[0m  2.7467\n",
      "      4        \u001b[36m0.0467\u001b[0m  2.7616\n",
      "      5        0.0777  2.7586\n",
      "      6        0.0512  2.7479\n",
      "      7        \u001b[36m0.0401\u001b[0m  2.7529\n",
      "      8        \u001b[36m0.0248\u001b[0m  2.7503\n",
      "      9        \u001b[36m0.0234\u001b[0m  2.7516\n",
      "     10        \u001b[36m0.0206\u001b[0m  2.7555\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  27.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3237\u001b[0m  2.7552\n",
      "      2        \u001b[36m0.1929\u001b[0m  2.7606\n",
      "      3        \u001b[36m0.1581\u001b[0m  2.7506\n",
      "      4        \u001b[36m0.0888\u001b[0m  2.7600\n",
      "      5        \u001b[36m0.0690\u001b[0m  2.7569\n",
      "      6        \u001b[36m0.0596\u001b[0m  2.7550\n",
      "      7        \u001b[36m0.0416\u001b[0m  2.7471\n",
      "      8        \u001b[36m0.0381\u001b[0m  2.7549\n",
      "      9        0.0493  2.7661\n",
      "     10        0.0396  2.7688\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  27.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3410\u001b[0m  2.7235\n",
      "      2        \u001b[36m0.1428\u001b[0m  2.7380\n",
      "      3        \u001b[36m0.0836\u001b[0m  2.7273\n",
      "      4        \u001b[36m0.0465\u001b[0m  2.7364\n",
      "      5        \u001b[36m0.0330\u001b[0m  2.7267\n",
      "      6        \u001b[36m0.0288\u001b[0m  2.7318\n",
      "      7        \u001b[36m0.0282\u001b[0m  2.7294\n",
      "      8        \u001b[36m0.0268\u001b[0m  2.7790\n",
      "      9        \u001b[36m0.0168\u001b[0m  2.8233\n",
      "     10        \u001b[36m0.0158\u001b[0m  2.7309\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  27.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3070\u001b[0m  2.5265\n",
      "      2        \u001b[36m0.1611\u001b[0m  2.5291\n",
      "      3        \u001b[36m0.0862\u001b[0m  2.5300\n",
      "      4        \u001b[36m0.0577\u001b[0m  2.5323\n",
      "      5        0.3690  2.5405\n",
      "      6        0.1411  2.5404\n",
      "      7        0.0729  2.5235\n",
      "      8        0.0579  2.5381\n",
      "      9        \u001b[36m0.0443\u001b[0m  2.5292\n",
      "     10        \u001b[36m0.0442\u001b[0m  2.5290\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  25.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3676\u001b[0m  2.5324\n",
      "      2        \u001b[36m0.1821\u001b[0m  2.5343\n",
      "      3        \u001b[36m0.1105\u001b[0m  2.5340\n",
      "      4        0.3770  2.5304\n",
      "      5        0.1191  2.5259\n",
      "      6        \u001b[36m0.0827\u001b[0m  2.5429\n",
      "      7        \u001b[36m0.0698\u001b[0m  2.5358\n",
      "      8        \u001b[36m0.0572\u001b[0m  2.5266\n",
      "      9        0.0736  2.5491\n",
      "     10        \u001b[36m0.0460\u001b[0m  2.5354\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  25.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3447\u001b[0m  2.5328\n",
      "      2        \u001b[36m0.1722\u001b[0m  2.5290\n",
      "      3        \u001b[36m0.1575\u001b[0m  2.5285\n",
      "      4        \u001b[36m0.0955\u001b[0m  2.5290\n",
      "      5        \u001b[36m0.0649\u001b[0m  2.5285\n",
      "      6        0.0903  2.5322\n",
      "      7        \u001b[36m0.0555\u001b[0m  2.5331\n",
      "      8        \u001b[36m0.0310\u001b[0m  2.5364\n",
      "      9        \u001b[36m0.0278\u001b[0m  2.5433\n",
      "     10        0.0654  2.5500\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  25.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2954\u001b[0m  2.5487\n",
      "      2        \u001b[36m0.1579\u001b[0m  2.5592\n",
      "      3        \u001b[36m0.1421\u001b[0m  2.5503\n",
      "      4        \u001b[36m0.0924\u001b[0m  2.5398\n",
      "      5        \u001b[36m0.0619\u001b[0m  2.5503\n",
      "      6        \u001b[36m0.0378\u001b[0m  2.5364\n",
      "      7        0.0655  2.5447\n",
      "      8        0.0523  2.5370\n",
      "      9        \u001b[36m0.0366\u001b[0m  2.5389\n",
      "     10        0.0712  2.5477\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  25.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2986\u001b[0m  2.5487\n",
      "      2        \u001b[36m0.1764\u001b[0m  2.5436\n",
      "      3        \u001b[36m0.0674\u001b[0m  2.5300\n",
      "      4        \u001b[36m0.0434\u001b[0m  2.5368\n",
      "      5        \u001b[36m0.0281\u001b[0m  2.5353\n",
      "      6        \u001b[36m0.0229\u001b[0m  2.5399\n",
      "      7        0.0981  2.5420\n",
      "      8        0.0456  2.5451\n",
      "      9        0.2976  2.5451\n",
      "     10        0.4388  2.5457\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  25.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3660\u001b[0m  1.5713\n",
      "      2        \u001b[36m0.1975\u001b[0m  1.5844\n",
      "      3        \u001b[36m0.1815\u001b[0m  1.5810\n",
      "      4        \u001b[36m0.1390\u001b[0m  1.6098\n",
      "      5        \u001b[36m0.1201\u001b[0m  1.5978\n",
      "      6        \u001b[36m0.0994\u001b[0m  1.5827\n",
      "      7        \u001b[36m0.0855\u001b[0m  1.5931\n",
      "      8        \u001b[36m0.0853\u001b[0m  1.5842\n",
      "      9        \u001b[36m0.0825\u001b[0m  1.6142\n",
      "     10        \u001b[36m0.0642\u001b[0m  1.5983\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3802\u001b[0m  1.5887\n",
      "      2        \u001b[36m0.2380\u001b[0m  1.5967\n",
      "      3        \u001b[36m0.2151\u001b[0m  1.5957\n",
      "      4        \u001b[36m0.1545\u001b[0m  1.6008\n",
      "      5        0.1629  1.5845\n",
      "      6        \u001b[36m0.1140\u001b[0m  1.5861\n",
      "      7        0.1158  1.5837\n",
      "      8        0.1616  1.5943\n",
      "      9        \u001b[36m0.1089\u001b[0m  1.5773\n",
      "     10        \u001b[36m0.0807\u001b[0m  1.5759\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3891\u001b[0m  1.5810\n",
      "      2        \u001b[36m0.2126\u001b[0m  1.5774\n",
      "      3        \u001b[36m0.1841\u001b[0m  1.6059\n",
      "      4        \u001b[36m0.1635\u001b[0m  1.6225\n",
      "      5        \u001b[36m0.1292\u001b[0m  1.5964\n",
      "      6        \u001b[36m0.1076\u001b[0m  1.6152\n",
      "      7        \u001b[36m0.0981\u001b[0m  1.6064\n",
      "      8        0.1220  1.6065\n",
      "      9        \u001b[36m0.0945\u001b[0m  1.6073\n",
      "     10        \u001b[36m0.0921\u001b[0m  1.5880\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  16.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3951\u001b[0m  1.5943\n",
      "      2        \u001b[36m0.2223\u001b[0m  1.6077\n",
      "      3        \u001b[36m0.1849\u001b[0m  1.5779\n",
      "      4        \u001b[36m0.1516\u001b[0m  1.5959\n",
      "      5        0.3206  1.6087\n",
      "      6        0.2350  1.5880\n",
      "      7        0.1791  1.5977\n",
      "      8        \u001b[36m0.1454\u001b[0m  1.5814\n",
      "      9        0.1711  1.5689\n",
      "     10        \u001b[36m0.1256\u001b[0m  1.6122\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3691\u001b[0m  1.5974\n",
      "      2        \u001b[36m0.3164\u001b[0m  1.5823\n",
      "      3        \u001b[36m0.2086\u001b[0m  1.5856\n",
      "      4        \u001b[36m0.1827\u001b[0m  1.5743\n",
      "      5        \u001b[36m0.1343\u001b[0m  1.5799\n",
      "      6        0.2011  1.5874\n",
      "      7        0.1947  1.6107\n",
      "      8        \u001b[36m0.1269\u001b[0m  1.5792\n",
      "      9        0.1882  1.5735\n",
      "     10        \u001b[36m0.1148\u001b[0m  1.6133\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  16.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3345\u001b[0m  1.7144\n",
      "      2        \u001b[36m0.1925\u001b[0m  1.7126\n",
      "      3        0.1932  1.7208\n",
      "      4        \u001b[36m0.1037\u001b[0m  1.7075\n",
      "      5        \u001b[36m0.1004\u001b[0m  1.7202\n",
      "      6        0.1278  1.7216\n",
      "      7        0.1587  1.7092\n",
      "      8        \u001b[36m0.0779\u001b[0m  1.7116\n",
      "      9        \u001b[36m0.0559\u001b[0m  1.7190\n",
      "     10        \u001b[36m0.0510\u001b[0m  1.7077\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  17.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3355\u001b[0m  1.7077\n",
      "      2        \u001b[36m0.2476\u001b[0m  1.7167\n",
      "      3        \u001b[36m0.1857\u001b[0m  1.7332\n",
      "      4        \u001b[36m0.1239\u001b[0m  1.7300\n",
      "      5        \u001b[36m0.0908\u001b[0m  1.7185\n",
      "      6        \u001b[36m0.0758\u001b[0m  1.7175\n",
      "      7        \u001b[36m0.0544\u001b[0m  1.7261\n",
      "      8        \u001b[36m0.0498\u001b[0m  1.7117\n",
      "      9        \u001b[36m0.0456\u001b[0m  1.7081\n",
      "     10        \u001b[36m0.0320\u001b[0m  1.7089\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  17.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3052\u001b[0m  1.7463\n",
      "      2        \u001b[36m0.2139\u001b[0m  1.7101\n",
      "      3        \u001b[36m0.1253\u001b[0m  1.7155\n",
      "      4        \u001b[36m0.0839\u001b[0m  1.7245\n",
      "      5        \u001b[36m0.0671\u001b[0m  1.7264\n",
      "      6        \u001b[36m0.0650\u001b[0m  1.7238\n",
      "      7        \u001b[36m0.0624\u001b[0m  1.7199\n",
      "      8        0.0706  1.7126\n",
      "      9        \u001b[36m0.0443\u001b[0m  1.7493\n",
      "     10        \u001b[36m0.0419\u001b[0m  1.7411\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  17.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3874\u001b[0m  1.7084\n",
      "      2        \u001b[36m0.2284\u001b[0m  1.7190\n",
      "      3        \u001b[36m0.1316\u001b[0m  1.7146\n",
      "      4        \u001b[36m0.1153\u001b[0m  1.7251\n",
      "      5        \u001b[36m0.1060\u001b[0m  1.7299\n",
      "      6        0.2185  1.7343\n",
      "      7        0.5908  1.7262\n",
      "      8        0.3367  1.7077\n",
      "      9        0.3064  1.7149\n",
      "     10        0.2051  1.7295\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  17.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3003\u001b[0m  1.7136\n",
      "      2        \u001b[36m0.1480\u001b[0m  1.7236\n",
      "      3        \u001b[36m0.1066\u001b[0m  1.7142\n",
      "      4        \u001b[36m0.0844\u001b[0m  1.7167\n",
      "      5        \u001b[36m0.0641\u001b[0m  1.7225\n",
      "      6        \u001b[36m0.0587\u001b[0m  1.7460\n",
      "      7        \u001b[36m0.0341\u001b[0m  1.7197\n",
      "      8        \u001b[36m0.0316\u001b[0m  1.7089\n",
      "      9        0.0467  1.7076\n",
      "     10        \u001b[36m0.0292\u001b[0m  1.7171\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  17.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3073\u001b[0m  2.7531\n",
      "      2        \u001b[36m0.1691\u001b[0m  2.7571\n",
      "      3        \u001b[36m0.0873\u001b[0m  2.7487\n",
      "      4        \u001b[36m0.0666\u001b[0m  2.7576\n",
      "      5        \u001b[36m0.0406\u001b[0m  2.7482\n",
      "      6        0.0433  2.7534\n",
      "      7        0.1563  2.7651\n",
      "      8        0.0676  2.7606\n",
      "      9        0.0497  2.7523\n",
      "     10        0.0425  2.7566\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  27.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3118\u001b[0m  2.7582\n",
      "      2        \u001b[36m0.1562\u001b[0m  2.7554\n",
      "      3        \u001b[36m0.1140\u001b[0m  2.7461\n",
      "      4        \u001b[36m0.0649\u001b[0m  2.7423\n",
      "      5        \u001b[36m0.0502\u001b[0m  2.7451\n",
      "      6        \u001b[36m0.0418\u001b[0m  2.7622\n",
      "      7        \u001b[36m0.0340\u001b[0m  2.7640\n",
      "      8        0.0564  2.7514\n",
      "      9        \u001b[36m0.0308\u001b[0m  2.7516\n",
      "     10        0.5865  2.7623\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  27.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3282\u001b[0m  2.7460\n",
      "      2        \u001b[36m0.1440\u001b[0m  2.7515\n",
      "      3        \u001b[36m0.1209\u001b[0m  2.7494\n",
      "      4        0.1505  2.7447\n",
      "      5        \u001b[36m0.0901\u001b[0m  2.7460\n",
      "      6        0.3189  2.7353\n",
      "      7        0.1452  2.7360\n",
      "      8        \u001b[36m0.0613\u001b[0m  2.7408\n",
      "      9        0.0625  2.7530\n",
      "     10        \u001b[36m0.0367\u001b[0m  2.7554\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  27.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3073\u001b[0m  2.7490\n",
      "      2        \u001b[36m0.1532\u001b[0m  2.7496\n",
      "      3        \u001b[36m0.1135\u001b[0m  2.7557\n",
      "      4        \u001b[36m0.1089\u001b[0m  2.7552\n",
      "      5        \u001b[36m0.1004\u001b[0m  2.7461\n",
      "      6        \u001b[36m0.0527\u001b[0m  2.7486\n",
      "      7        \u001b[36m0.0400\u001b[0m  2.7506\n",
      "      8        0.0486  2.7474\n",
      "      9        0.0641  2.7539\n",
      "     10        0.0663  2.7527\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  27.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2933\u001b[0m  2.7619\n",
      "      2        \u001b[36m0.1580\u001b[0m  2.7577\n",
      "      3        0.1729  2.7598\n",
      "      4        0.1644  2.7565\n",
      "      5        \u001b[36m0.0646\u001b[0m  2.7538\n",
      "      6        \u001b[36m0.0642\u001b[0m  2.7539\n",
      "      7        \u001b[36m0.0422\u001b[0m  2.7582\n",
      "      8        \u001b[36m0.0275\u001b[0m  2.7418\n",
      "      9        0.5282  2.7417\n",
      "     10        0.4536  2.7497\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  27.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3438\u001b[0m  2.4877\n",
      "      2        \u001b[36m0.1669\u001b[0m  2.4830\n",
      "      3        0.1797  2.4823\n",
      "      4        \u001b[36m0.1079\u001b[0m  2.4991\n",
      "      5        \u001b[36m0.0510\u001b[0m  2.5023\n",
      "      6        0.0573  2.4854\n",
      "      7        \u001b[36m0.0466\u001b[0m  2.4995\n",
      "      8        \u001b[36m0.0365\u001b[0m  2.4974\n",
      "      9        \u001b[36m0.0351\u001b[0m  2.5076\n",
      "     10        \u001b[36m0.0290\u001b[0m  2.4962\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  25.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3332\u001b[0m  2.5276\n",
      "      2        \u001b[36m0.1804\u001b[0m  2.5381\n",
      "      3        \u001b[36m0.1078\u001b[0m  2.5282\n",
      "      4        \u001b[36m0.0585\u001b[0m  2.5304\n",
      "      5        \u001b[36m0.0424\u001b[0m  2.5346\n",
      "      6        \u001b[36m0.0335\u001b[0m  2.5259\n",
      "      7        0.0350  2.5454\n",
      "      8        \u001b[36m0.0309\u001b[0m  2.5362\n",
      "      9        \u001b[36m0.0248\u001b[0m  2.5358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10        0.0332  2.5329\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  25.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3389\u001b[0m  2.5343\n",
      "      2        \u001b[36m0.1768\u001b[0m  2.5368\n",
      "      3        0.2824  2.5303\n",
      "      4        \u001b[36m0.1533\u001b[0m  2.5351\n",
      "      5        \u001b[36m0.0771\u001b[0m  2.5301\n",
      "      6        \u001b[36m0.0514\u001b[0m  2.5373\n",
      "      7        \u001b[36m0.0362\u001b[0m  2.5481\n",
      "      8        \u001b[36m0.0255\u001b[0m  2.5428\n",
      "      9        0.0369  2.5437\n",
      "     10        \u001b[36m0.0228\u001b[0m  2.5408\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  25.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3451\u001b[0m  2.5447\n",
      "      2        \u001b[36m0.1634\u001b[0m  2.5518\n",
      "      3        \u001b[36m0.1097\u001b[0m  2.5604\n",
      "      4        \u001b[36m0.0940\u001b[0m  2.5528\n",
      "      5        \u001b[36m0.0521\u001b[0m  2.5426\n",
      "      6        \u001b[36m0.0520\u001b[0m  2.5567\n",
      "      7        \u001b[36m0.0371\u001b[0m  2.5511\n",
      "      8        0.0385  2.5448\n",
      "      9        \u001b[36m0.0363\u001b[0m  2.5441\n",
      "     10        \u001b[36m0.0273\u001b[0m  2.5457\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  25.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3360\u001b[0m  2.5457\n",
      "      2        \u001b[36m0.2257\u001b[0m  2.5504\n",
      "      3        0.3326  2.5469\n",
      "      4        \u001b[36m0.1543\u001b[0m  2.5333\n",
      "      5        \u001b[36m0.0666\u001b[0m  2.5478\n",
      "      6        \u001b[36m0.0443\u001b[0m  2.5524\n",
      "      7        \u001b[36m0.0346\u001b[0m  2.5544\n",
      "      8        \u001b[36m0.0341\u001b[0m  2.5527\n",
      "      9        \u001b[36m0.0237\u001b[0m  2.5411\n",
      "     10        0.0345  2.5489\n",
      "[CV]  net__batch_size=128, net__max_epochs=10, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  25.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3592\u001b[0m  1.5968\n",
      "      2        \u001b[36m0.2376\u001b[0m  1.5996\n",
      "      3        \u001b[36m0.1912\u001b[0m  1.5841\n",
      "      4        \u001b[36m0.1675\u001b[0m  1.5981\n",
      "      5        \u001b[36m0.1120\u001b[0m  1.5976\n",
      "      6        0.1522  1.6004\n",
      "      7        \u001b[36m0.1091\u001b[0m  1.6073\n",
      "      8        \u001b[36m0.0933\u001b[0m  1.6038\n",
      "      9        \u001b[36m0.0752\u001b[0m  1.6011\n",
      "     10        0.1473  1.5993\n",
      "     11        \u001b[36m0.0697\u001b[0m  1.5806\n",
      "     12        0.1004  1.6046\n",
      "     13        \u001b[36m0.0567\u001b[0m  1.5837\n",
      "     14        \u001b[36m0.0442\u001b[0m  1.6125\n",
      "     15        0.0921  1.5855\n",
      "     16        0.0685  1.6047\n",
      "     17        \u001b[36m0.0407\u001b[0m  1.6061\n",
      "     18        0.0513  1.5803\n",
      "     19        \u001b[36m0.0383\u001b[0m  1.5786\n",
      "     20        0.0701  1.5833\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  32.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3411\u001b[0m  1.5994\n",
      "      2        \u001b[36m0.2457\u001b[0m  1.6013\n",
      "      3        0.2545  1.6079\n",
      "      4        \u001b[36m0.1851\u001b[0m  1.6012\n",
      "      5        \u001b[36m0.1315\u001b[0m  1.5944\n",
      "      6        0.1397  1.5715\n",
      "      7        \u001b[36m0.1030\u001b[0m  1.5796\n",
      "      8        0.1246  1.5997\n",
      "      9        \u001b[36m0.0797\u001b[0m  1.6071\n",
      "     10        \u001b[36m0.0689\u001b[0m  1.6093\n",
      "     11        \u001b[36m0.0633\u001b[0m  1.6052\n",
      "     12        \u001b[36m0.0566\u001b[0m  1.5760\n",
      "     13        \u001b[36m0.0544\u001b[0m  1.5907\n",
      "     14        \u001b[36m0.0467\u001b[0m  1.6027\n",
      "     15        0.0512  1.6098\n",
      "     16        0.1126  1.6154\n",
      "     17        0.1229  1.6113\n",
      "     18        0.0786  1.6149\n",
      "     19        0.0651  1.6034\n",
      "     20        0.2233  1.6104\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  32.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4410\u001b[0m  1.5795\n",
      "      2        \u001b[36m0.3027\u001b[0m  1.6061\n",
      "      3        \u001b[36m0.2156\u001b[0m  1.6008\n",
      "      4        \u001b[36m0.2141\u001b[0m  1.5941\n",
      "      5        \u001b[36m0.1656\u001b[0m  1.6180\n",
      "      6        \u001b[36m0.1514\u001b[0m  1.6034\n",
      "      7        \u001b[36m0.1309\u001b[0m  1.5903\n",
      "      8        \u001b[36m0.0899\u001b[0m  1.6065\n",
      "      9        \u001b[36m0.0729\u001b[0m  1.5888\n",
      "     10        \u001b[36m0.0711\u001b[0m  1.6087\n",
      "     11        \u001b[36m0.0549\u001b[0m  1.5863\n",
      "     12        0.0908  1.6046\n",
      "     13        0.0616  1.6082\n",
      "     14        0.0661  1.5851\n",
      "     15        \u001b[36m0.0497\u001b[0m  1.6075\n",
      "     16        0.0627  1.5852\n",
      "     17        0.0594  1.5744\n",
      "     18        \u001b[36m0.0424\u001b[0m  1.5733\n",
      "     19        \u001b[36m0.0399\u001b[0m  1.5822\n",
      "     20        \u001b[36m0.0345\u001b[0m  1.6073\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  32.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3488\u001b[0m  1.6080\n",
      "      2        \u001b[36m0.2580\u001b[0m  1.6161\n",
      "      3        \u001b[36m0.2223\u001b[0m  1.5830\n",
      "      4        \u001b[36m0.1697\u001b[0m  1.5992\n",
      "      5        \u001b[36m0.1515\u001b[0m  1.5926\n",
      "      6        \u001b[36m0.1127\u001b[0m  1.5945\n",
      "      7        \u001b[36m0.1022\u001b[0m  1.5838\n",
      "      8        \u001b[36m0.0902\u001b[0m  1.5812\n",
      "      9        \u001b[36m0.0834\u001b[0m  1.5996\n",
      "     10        0.0862  1.6038\n",
      "     11        \u001b[36m0.0755\u001b[0m  1.5790\n",
      "     12        0.0946  1.5733\n",
      "     13        \u001b[36m0.0610\u001b[0m  1.5983\n",
      "     14        \u001b[36m0.0598\u001b[0m  1.5904\n",
      "     15        \u001b[36m0.0501\u001b[0m  1.5870\n",
      "     16        0.0984  1.6135\n",
      "     17        0.0633  1.6139\n",
      "     18        0.0864  1.5876\n",
      "     19        0.0648  1.5927\n",
      "     20        0.0517  1.5843\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  32.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3302\u001b[0m  1.6002\n",
      "      2        \u001b[36m0.2847\u001b[0m  1.5991\n",
      "      3        \u001b[36m0.2067\u001b[0m  1.6058\n",
      "      4        0.2517  1.6011\n",
      "      5        0.2164  1.5840\n",
      "      6        \u001b[36m0.1868\u001b[0m  1.5852\n",
      "      7        \u001b[36m0.1746\u001b[0m  1.5933\n",
      "      8        \u001b[36m0.1227\u001b[0m  1.6078\n",
      "      9        0.1623  1.5857\n",
      "     10        0.1310  1.5970\n",
      "     11        \u001b[36m0.1030\u001b[0m  1.6095\n",
      "     12        0.1419  1.5817\n",
      "     13        \u001b[36m0.0987\u001b[0m  1.5833\n",
      "     14        0.1018  1.5902\n",
      "     15        \u001b[36m0.0795\u001b[0m  1.6003\n",
      "     16        0.0913  1.5980\n",
      "     17        0.0855  1.6055\n",
      "     18        \u001b[36m0.0720\u001b[0m  1.5847\n",
      "     19        \u001b[36m0.0676\u001b[0m  1.5882\n",
      "     20        \u001b[36m0.0530\u001b[0m  1.5772\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  32.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2894\u001b[0m  1.7100\n",
      "      2        \u001b[36m0.2759\u001b[0m  1.7074\n",
      "      3        \u001b[36m0.1539\u001b[0m  1.7076\n",
      "      4        \u001b[36m0.1177\u001b[0m  1.7135\n",
      "      5        \u001b[36m0.0914\u001b[0m  1.7295\n",
      "      6        \u001b[36m0.0732\u001b[0m  1.7101\n",
      "      7        \u001b[36m0.0613\u001b[0m  1.7349\n",
      "      8        \u001b[36m0.0544\u001b[0m  1.7429\n",
      "      9        0.0715  1.7248\n",
      "     10        \u001b[36m0.0392\u001b[0m  1.7234\n",
      "     11        \u001b[36m0.0292\u001b[0m  1.7194\n",
      "     12        \u001b[36m0.0289\u001b[0m  1.7274\n",
      "     13        0.0595  1.7117\n",
      "     14        0.0465  1.7231\n",
      "     15        0.0346  1.7138\n",
      "     16        0.0601  1.7413\n",
      "     17        0.0418  1.7233\n",
      "     18        0.2330  1.7257\n",
      "     19        0.3065  1.7268\n",
      "     20        0.2062  1.7181\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  34.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3493\u001b[0m  1.7094\n",
      "      2        \u001b[36m0.1923\u001b[0m  1.7173\n",
      "      3        \u001b[36m0.1232\u001b[0m  1.7092\n",
      "      4        \u001b[36m0.0973\u001b[0m  1.7127\n",
      "      5        \u001b[36m0.0510\u001b[0m  1.7309\n",
      "      6        \u001b[36m0.0391\u001b[0m  1.7280\n",
      "      7        0.0832  1.7228\n",
      "      8        \u001b[36m0.0338\u001b[0m  1.7109\n",
      "      9        \u001b[36m0.0257\u001b[0m  1.7101\n",
      "     10        \u001b[36m0.0217\u001b[0m  1.7405\n",
      "     11        0.0428  1.7311\n",
      "     12        0.0313  1.7205\n",
      "     13        0.0239  1.7116\n",
      "     14        0.0242  1.7101\n",
      "     15        \u001b[36m0.0209\u001b[0m  1.7099\n",
      "     16        \u001b[36m0.0169\u001b[0m  1.7179\n",
      "     17        \u001b[36m0.0149\u001b[0m  1.7151\n",
      "     18        0.0154  1.7368\n",
      "     19        0.0301  1.7413\n",
      "     20        \u001b[36m0.0139\u001b[0m  1.7218\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  34.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3018\u001b[0m  1.7229\n",
      "      2        0.4795  1.7183\n",
      "      3        \u001b[36m0.2569\u001b[0m  1.7248\n",
      "      4        \u001b[36m0.1678\u001b[0m  1.7109\n",
      "      5        \u001b[36m0.1230\u001b[0m  1.7255\n",
      "      6        \u001b[36m0.0878\u001b[0m  1.7207\n",
      "      7        \u001b[36m0.0693\u001b[0m  1.7159\n",
      "      8        \u001b[36m0.0585\u001b[0m  1.7136\n",
      "      9        \u001b[36m0.0542\u001b[0m  1.7199\n",
      "     10        0.0545  1.7196\n",
      "     11        \u001b[36m0.0517\u001b[0m  1.7222\n",
      "     12        \u001b[36m0.0499\u001b[0m  1.7205\n",
      "     13        \u001b[36m0.0351\u001b[0m  1.7169\n",
      "     14        \u001b[36m0.0315\u001b[0m  1.7147\n",
      "     15        \u001b[36m0.0302\u001b[0m  1.7407\n",
      "     16        \u001b[36m0.0301\u001b[0m  1.7400\n",
      "     17        \u001b[36m0.0249\u001b[0m  1.7142\n",
      "     18        \u001b[36m0.0228\u001b[0m  1.7121\n",
      "     19        0.0443  1.7122\n",
      "     20        \u001b[36m0.0206\u001b[0m  1.7124\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  34.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3214\u001b[0m  1.7307\n",
      "      2        \u001b[36m0.2105\u001b[0m  1.7448\n",
      "      3        \u001b[36m0.1808\u001b[0m  1.7237\n",
      "      4        \u001b[36m0.1261\u001b[0m  1.7195\n",
      "      5        0.1267  1.7325\n",
      "      6        \u001b[36m0.1052\u001b[0m  1.7233\n",
      "      7        \u001b[36m0.1028\u001b[0m  1.7394\n",
      "      8        \u001b[36m0.0848\u001b[0m  1.7166\n",
      "      9        \u001b[36m0.0689\u001b[0m  1.7466\n",
      "     10        \u001b[36m0.0542\u001b[0m  1.7175\n",
      "     11        0.1754  1.7287\n",
      "     12        0.0863  1.7157\n",
      "     13        0.0653  1.7150\n",
      "     14        \u001b[36m0.0508\u001b[0m  1.7280\n",
      "     15        0.0882  1.7434\n",
      "     16        0.0537  1.7298\n",
      "     17        \u001b[36m0.0412\u001b[0m  1.7404\n",
      "     18        \u001b[36m0.0353\u001b[0m  1.7285\n",
      "     19        0.0559  1.7119\n",
      "     20        \u001b[36m0.0316\u001b[0m  1.7138\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  34.9s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3076\u001b[0m  1.7155\n",
      "      2        \u001b[36m0.1783\u001b[0m  1.7312\n",
      "      3        \u001b[36m0.0986\u001b[0m  1.7174\n",
      "      4        \u001b[36m0.0839\u001b[0m  1.7145\n",
      "      5        \u001b[36m0.0691\u001b[0m  1.7138\n",
      "      6        \u001b[36m0.0416\u001b[0m  1.7151\n",
      "      7        \u001b[36m0.0347\u001b[0m  1.7309\n",
      "      8        \u001b[36m0.0309\u001b[0m  1.7109\n",
      "      9        0.0333  1.7140\n",
      "     10        \u001b[36m0.0223\u001b[0m  1.7405\n",
      "     11        \u001b[36m0.0163\u001b[0m  1.7164\n",
      "     12        \u001b[36m0.0141\u001b[0m  1.7251\n",
      "     13        0.0449  1.7173\n",
      "     14        0.0177  1.7283\n",
      "     15        \u001b[36m0.0132\u001b[0m  1.7422\n",
      "     16        0.0163  1.7148\n",
      "     17        0.0160  1.7163\n",
      "     18        0.0140  1.7214\n",
      "     19        0.0134  1.7178\n",
      "     20        \u001b[36m0.0108\u001b[0m  1.7311\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  34.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2812\u001b[0m  2.7431\n",
      "      2        \u001b[36m0.1488\u001b[0m  2.7451\n",
      "      3        \u001b[36m0.0944\u001b[0m  2.7399\n",
      "      4        \u001b[36m0.0755\u001b[0m  2.7543\n",
      "      5        \u001b[36m0.0593\u001b[0m  2.7408\n",
      "      6        \u001b[36m0.0377\u001b[0m  2.7489\n",
      "      7        \u001b[36m0.0367\u001b[0m  2.7472\n",
      "      8        0.1014  2.7422\n",
      "      9        0.4758  2.7407\n",
      "     10        0.5332  2.7489\n",
      "     11        0.4519  2.7509\n",
      "     12        0.4003  2.7499\n",
      "     13        0.3790  2.7456\n",
      "     14        0.3423  2.7506\n",
      "     15        0.4008  2.7485\n",
      "     16        0.5791  2.7531\n",
      "     17        0.5069  2.7456\n",
      "     18        0.4734  2.7479\n",
      "     19        0.4457  2.7495\n",
      "     20        0.4137  2.7500\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  55.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3310\u001b[0m  2.7531\n",
      "      2        \u001b[36m0.1614\u001b[0m  2.7606\n",
      "      3        \u001b[36m0.1043\u001b[0m  2.7565\n",
      "      4        \u001b[36m0.0852\u001b[0m  2.7519\n",
      "      5        0.0989  2.7600\n",
      "      6        \u001b[36m0.0446\u001b[0m  2.7605\n",
      "      7        \u001b[36m0.0350\u001b[0m  2.7655\n",
      "      8        \u001b[36m0.0281\u001b[0m  2.7594\n",
      "      9        \u001b[36m0.0275\u001b[0m  2.7601\n",
      "     10        \u001b[36m0.0240\u001b[0m  2.7541\n",
      "     11        0.0558  2.7592\n",
      "     12        0.0446  2.7582\n",
      "     13        0.7018  2.7398\n",
      "     14        0.6326  2.7550\n",
      "     15        0.6001  2.7554\n",
      "     16        0.5607  2.7608\n",
      "     17        0.5313  2.7455\n",
      "     18        0.5140  2.7605\n",
      "     19        0.4986  2.7624\n",
      "     20        0.5295  2.7557\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  55.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3015\u001b[0m  2.7587\n",
      "      2        \u001b[36m0.1429\u001b[0m  2.7525\n",
      "      3        \u001b[36m0.0959\u001b[0m  2.7469\n",
      "      4        \u001b[36m0.0681\u001b[0m  2.7444\n",
      "      5        \u001b[36m0.0674\u001b[0m  2.7534\n",
      "      6        \u001b[36m0.0425\u001b[0m  2.7524\n",
      "      7        0.0466  2.7546\n",
      "      8        \u001b[36m0.0315\u001b[0m  2.7480\n",
      "      9        0.1051  2.7527\n",
      "     10        0.6842  2.7491\n",
      "     11        0.4838  2.7514\n",
      "     12        0.4011  2.7565\n",
      "     13        0.3296  2.7558\n",
      "     14        0.3159  2.7365\n",
      "     15        0.2626  2.7488\n",
      "     16        0.2508  2.7533\n",
      "     17        0.2030  2.7517\n",
      "     18        0.1833  2.7566\n",
      "     19        0.1807  2.7526\n",
      "     20        0.1455  2.7510\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  55.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3346\u001b[0m  2.7425\n",
      "      2        \u001b[36m0.1688\u001b[0m  2.7471\n",
      "      3        \u001b[36m0.1175\u001b[0m  2.7461\n",
      "      4        \u001b[36m0.0766\u001b[0m  2.7554\n",
      "      5        \u001b[36m0.0518\u001b[0m  2.7532\n",
      "      6        \u001b[36m0.0365\u001b[0m  2.7369\n",
      "      7        \u001b[36m0.0256\u001b[0m  2.7393\n",
      "      8        0.0307  2.7538\n",
      "      9        0.0332  2.7555\n",
      "     10        \u001b[36m0.0238\u001b[0m  2.7548\n",
      "     11        \u001b[36m0.0226\u001b[0m  2.7540\n",
      "     12        \u001b[36m0.0176\u001b[0m  2.7540\n",
      "     13        0.0214  2.7367\n",
      "     14        0.0206  2.7368\n",
      "     15        0.0179  2.7429\n",
      "     16        0.0335  2.7372\n",
      "     17        \u001b[36m0.0168\u001b[0m  2.7368\n",
      "     18        0.0598  2.7515\n",
      "     19        0.0215  2.7532\n",
      "     20        \u001b[36m0.0162\u001b[0m  2.7528\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  55.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3279\u001b[0m  2.7435\n",
      "      2        \u001b[36m0.1432\u001b[0m  2.7428\n",
      "      3        \u001b[36m0.0746\u001b[0m  2.7659\n",
      "      4        \u001b[36m0.0476\u001b[0m  2.7537\n",
      "      5        \u001b[36m0.0348\u001b[0m  2.7417\n",
      "      6        0.0412  2.7641\n",
      "      7        \u001b[36m0.0293\u001b[0m  2.7483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        \u001b[36m0.0274\u001b[0m  2.7513\n",
      "      9        \u001b[36m0.0178\u001b[0m  2.7605\n",
      "     10        0.0289  2.7520\n",
      "     11        \u001b[36m0.0138\u001b[0m  2.7461\n",
      "     12        \u001b[36m0.0130\u001b[0m  2.7501\n",
      "     13        0.0242  2.7439\n",
      "     14        0.0272  2.7501\n",
      "     15        0.0218  2.7460\n",
      "     16        0.3025  2.7510\n",
      "     17        0.6058  2.7521\n",
      "     18        0.5355  2.7545\n",
      "     19        0.5036  2.7554\n",
      "     20        0.4813  2.7536\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total=  55.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3203\u001b[0m  2.5384\n",
      "      2        \u001b[36m0.2442\u001b[0m  2.5327\n",
      "      3        \u001b[36m0.1198\u001b[0m  2.5324\n",
      "      4        \u001b[36m0.0506\u001b[0m  2.5309\n",
      "      5        \u001b[36m0.0390\u001b[0m  2.5304\n",
      "      6        \u001b[36m0.0282\u001b[0m  2.5391\n",
      "      7        0.0324  2.5429\n",
      "      8        \u001b[36m0.0235\u001b[0m  2.5415\n",
      "      9        0.0619  2.5263\n",
      "     10        0.3988  2.5392\n",
      "     11        0.2794  2.5329\n",
      "     12        0.1849  2.5346\n",
      "     13        0.1469  2.5355\n",
      "     14        0.1391  2.5258\n",
      "     15        0.1216  2.5224\n",
      "     16        0.0691  2.5202\n",
      "     17        0.0570  2.5326\n",
      "     18        0.2034  2.5309\n",
      "     19        0.3974  2.5304\n",
      "     20        0.1651  2.5253\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  51.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3890\u001b[0m  2.4847\n",
      "      2        \u001b[36m0.3198\u001b[0m  2.4865\n",
      "      3        \u001b[36m0.2669\u001b[0m  2.4873\n",
      "      4        \u001b[36m0.1149\u001b[0m  2.4902\n",
      "      5        \u001b[36m0.0568\u001b[0m  2.4935\n",
      "      6        \u001b[36m0.0394\u001b[0m  2.4969\n",
      "      7        0.0505  2.5099\n",
      "      8        \u001b[36m0.0335\u001b[0m  2.5166\n",
      "      9        \u001b[36m0.0280\u001b[0m  2.5156\n",
      "     10        \u001b[36m0.0245\u001b[0m  2.5013\n",
      "     11        0.0591  2.4941\n",
      "     12        0.0482  2.5036\n",
      "     13        0.0323  2.4996\n",
      "     14        \u001b[36m0.0232\u001b[0m  2.5004\n",
      "     15        0.0309  2.4998\n",
      "     16        0.0263  2.5018\n",
      "     17        \u001b[36m0.0212\u001b[0m  2.4944\n",
      "     18        0.0225  2.4952\n",
      "     19        \u001b[36m0.0206\u001b[0m  2.5125\n",
      "     20        0.0284  2.5045\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  50.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3254\u001b[0m  2.5443\n",
      "      2        0.4127  2.5448\n",
      "      3        \u001b[36m0.1721\u001b[0m  2.5486\n",
      "      4        \u001b[36m0.0894\u001b[0m  2.5436\n",
      "      5        \u001b[36m0.0568\u001b[0m  2.5440\n",
      "      6        \u001b[36m0.0553\u001b[0m  2.5399\n",
      "      7        \u001b[36m0.0372\u001b[0m  2.5561\n",
      "      8        0.0756  2.5426\n",
      "      9        \u001b[36m0.0304\u001b[0m  2.5513\n",
      "     10        \u001b[36m0.0279\u001b[0m  2.5437\n",
      "     11        \u001b[36m0.0198\u001b[0m  2.5538\n",
      "     12        0.0357  2.5455\n",
      "     13        0.0259  2.5524\n",
      "     14        \u001b[36m0.0160\u001b[0m  2.5484\n",
      "     15        0.0196  2.5485\n",
      "     16        \u001b[36m0.0131\u001b[0m  2.5574\n",
      "     17        0.0153  2.5539\n",
      "     18        \u001b[36m0.0130\u001b[0m  2.5436\n",
      "     19        0.0521  2.5430\n",
      "     20        0.0227  2.5538\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  51.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3159\u001b[0m  2.5402\n",
      "      2        \u001b[36m0.2390\u001b[0m  2.5435\n",
      "      3        \u001b[36m0.1432\u001b[0m  2.5347\n",
      "      4        \u001b[36m0.0966\u001b[0m  2.5435\n",
      "      5        \u001b[36m0.0585\u001b[0m  2.5462\n",
      "      6        0.2536  2.5490\n",
      "      7        0.2097  2.5451\n",
      "      8        0.0652  2.5410\n",
      "      9        0.2668  2.5390\n",
      "     10        0.1437  2.5508\n",
      "     11        \u001b[36m0.0557\u001b[0m  2.5359\n",
      "     12        \u001b[36m0.0439\u001b[0m  2.5427\n",
      "     13        0.0547  2.5388\n",
      "     14        \u001b[36m0.0350\u001b[0m  2.5544\n",
      "     15        \u001b[36m0.0298\u001b[0m  2.5593\n",
      "     16        \u001b[36m0.0280\u001b[0m  2.5556\n",
      "     17        0.0428  2.5408\n",
      "     18        \u001b[36m0.0261\u001b[0m  2.5423\n",
      "     19        0.0265  2.5371\n",
      "     20        0.0285  2.5375\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  51.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3306\u001b[0m  2.5466\n",
      "      2        \u001b[36m0.1425\u001b[0m  2.5440\n",
      "      3        \u001b[36m0.0777\u001b[0m  2.5433\n",
      "      4        \u001b[36m0.0667\u001b[0m  2.5416\n",
      "      5        \u001b[36m0.0563\u001b[0m  2.5445\n",
      "      6        0.2277  2.5454\n",
      "      7        0.0818  2.5438\n",
      "      8        \u001b[36m0.0554\u001b[0m  2.5472\n",
      "      9        \u001b[36m0.0340\u001b[0m  2.5386\n",
      "     10        0.0382  2.5438\n",
      "     11        \u001b[36m0.0306\u001b[0m  2.5412\n",
      "     12        \u001b[36m0.0233\u001b[0m  2.5431\n",
      "     13        \u001b[36m0.0198\u001b[0m  2.5471\n",
      "     14        0.0258  2.5482\n",
      "     15        0.0220  2.5533\n",
      "     16        0.0212  2.5553\n",
      "     17        0.0234  2.5413\n",
      "     18        \u001b[36m0.0143\u001b[0m  2.5448\n",
      "     19        0.0339  2.5403\n",
      "     20        0.0268  2.5453\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total=  51.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3576\u001b[0m  1.5845\n",
      "      2        \u001b[36m0.2174\u001b[0m  1.6072\n",
      "      3        \u001b[36m0.1512\u001b[0m  1.5905\n",
      "      4        \u001b[36m0.1452\u001b[0m  1.6026\n",
      "      5        \u001b[36m0.1296\u001b[0m  1.5891\n",
      "      6        \u001b[36m0.0908\u001b[0m  1.6012\n",
      "      7        \u001b[36m0.0782\u001b[0m  1.5958\n",
      "      8        0.0889  1.5939\n",
      "      9        \u001b[36m0.0610\u001b[0m  1.6138\n",
      "     10        \u001b[36m0.0541\u001b[0m  1.5740\n",
      "     11        0.0678  1.5781\n",
      "     12        \u001b[36m0.0468\u001b[0m  1.5817\n",
      "     13        \u001b[36m0.0412\u001b[0m  1.5957\n",
      "     14        0.0479  1.5909\n",
      "     15        0.0485  1.6096\n",
      "     16        0.0446  1.5977\n",
      "     17        0.0881  1.5770\n",
      "     18        0.0512  1.5763\n",
      "     19        0.0415  1.5760\n",
      "     20        0.0450  1.6005\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  32.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3548\u001b[0m  1.5930\n",
      "      2        \u001b[36m0.2386\u001b[0m  1.5935\n",
      "      3        \u001b[36m0.2262\u001b[0m  1.5962\n",
      "      4        \u001b[36m0.1509\u001b[0m  1.6006\n",
      "      5        0.1652  1.6083\n",
      "      6        0.1698  1.5828\n",
      "      7        \u001b[36m0.1371\u001b[0m  1.5888\n",
      "      8        \u001b[36m0.1107\u001b[0m  1.5818\n",
      "      9        \u001b[36m0.0897\u001b[0m  1.6028\n",
      "     10        0.1057  1.6021\n",
      "     11        0.1359  1.6003\n",
      "     12        \u001b[36m0.0880\u001b[0m  1.5947\n",
      "     13        0.1080  1.5949\n",
      "     14        \u001b[36m0.0717\u001b[0m  1.6053\n",
      "     15        0.4034  1.6094\n",
      "     16        0.4233  1.6017\n",
      "     17        0.2834  1.5793\n",
      "     18        0.1789  1.6066\n",
      "     19        0.1160  1.6112\n",
      "     20        0.0999  1.6012\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  32.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3469\u001b[0m  1.6032\n",
      "      2        \u001b[36m0.1996\u001b[0m  1.5797\n",
      "      3        \u001b[36m0.1304\u001b[0m  1.5849\n",
      "      4        \u001b[36m0.1275\u001b[0m  1.5894\n",
      "      5        \u001b[36m0.1103\u001b[0m  1.5998\n",
      "      6        \u001b[36m0.1014\u001b[0m  1.5897\n",
      "      7        0.1117  1.5795\n",
      "      8        \u001b[36m0.0933\u001b[0m  1.5695\n",
      "      9        \u001b[36m0.0799\u001b[0m  1.5733\n",
      "     10        \u001b[36m0.0635\u001b[0m  1.6075\n",
      "     11        \u001b[36m0.0601\u001b[0m  1.6047\n",
      "     12        \u001b[36m0.0553\u001b[0m  1.5987\n",
      "     13        \u001b[36m0.0435\u001b[0m  1.6096\n",
      "     14        0.0663  1.6074\n",
      "     15        \u001b[36m0.0417\u001b[0m  1.5967\n",
      "     16        0.0426  1.5927\n",
      "     17        0.0430  1.5731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        \u001b[36m0.0336\u001b[0m  1.5984\n",
      "     19        0.0638  1.5918\n",
      "     20        0.0573  1.5874\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  32.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3474\u001b[0m  1.6023\n",
      "      2        \u001b[36m0.3197\u001b[0m  1.5855\n",
      "      3        \u001b[36m0.2062\u001b[0m  1.5923\n",
      "      4        \u001b[36m0.1908\u001b[0m  1.5809\n",
      "      5        0.1978  1.5810\n",
      "      6        \u001b[36m0.1805\u001b[0m  1.5949\n",
      "      7        \u001b[36m0.1286\u001b[0m  1.6016\n",
      "      8        0.1360  1.5985\n",
      "      9        0.1313  1.5885\n",
      "     10        \u001b[36m0.0986\u001b[0m  1.5980\n",
      "     11        \u001b[36m0.0943\u001b[0m  1.5715\n",
      "     12        0.1006  1.5765\n",
      "     13        0.1080  1.5796\n",
      "     14        \u001b[36m0.0936\u001b[0m  1.5914\n",
      "     15        0.1169  1.5989\n",
      "     16        \u001b[36m0.0900\u001b[0m  1.5826\n",
      "     17        \u001b[36m0.0779\u001b[0m  1.5851\n",
      "     18        \u001b[36m0.0661\u001b[0m  1.5945\n",
      "     19        \u001b[36m0.0589\u001b[0m  1.5902\n",
      "     20        \u001b[36m0.0512\u001b[0m  1.5769\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  32.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3992\u001b[0m  1.5855\n",
      "      2        \u001b[36m0.3368\u001b[0m  1.5991\n",
      "      3        \u001b[36m0.2109\u001b[0m  1.5751\n",
      "      4        \u001b[36m0.1457\u001b[0m  1.5812\n",
      "      5        \u001b[36m0.1242\u001b[0m  1.6074\n",
      "      6        \u001b[36m0.1043\u001b[0m  1.5814\n",
      "      7        \u001b[36m0.0734\u001b[0m  1.5999\n",
      "      8        0.1108  1.6018\n",
      "      9        0.0846  1.6058\n",
      "     10        0.1250  1.5977\n",
      "     11        0.1135  1.6005\n",
      "     12        \u001b[36m0.0713\u001b[0m  1.5804\n",
      "     13        \u001b[36m0.0660\u001b[0m  1.5895\n",
      "     14        \u001b[36m0.0606\u001b[0m  1.5880\n",
      "     15        0.0660  1.6034\n",
      "     16        0.0744  1.6018\n",
      "     17        \u001b[36m0.0454\u001b[0m  1.6094\n",
      "     18        0.0463  1.6028\n",
      "     19        \u001b[36m0.0377\u001b[0m  1.6018\n",
      "     20        0.0391  1.6082\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  32.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4009\u001b[0m  1.7285\n",
      "      2        \u001b[36m0.1992\u001b[0m  1.7160\n",
      "      3        \u001b[36m0.1404\u001b[0m  1.7246\n",
      "      4        \u001b[36m0.1178\u001b[0m  1.7178\n",
      "      5        \u001b[36m0.0971\u001b[0m  1.7266\n",
      "      6        \u001b[36m0.0953\u001b[0m  1.7490\n",
      "      7        0.1207  1.7189\n",
      "      8        \u001b[36m0.0671\u001b[0m  1.7332\n",
      "      9        0.0702  1.7328\n",
      "     10        \u001b[36m0.0470\u001b[0m  1.7146\n",
      "     11        0.0909  1.7275\n",
      "     12        0.0873  1.7223\n",
      "     13        0.1553  1.7315\n",
      "     14        0.0862  1.7190\n",
      "     15        0.0819  1.7286\n",
      "     16        0.0531  1.7129\n",
      "     17        0.0473  1.7149\n",
      "     18        \u001b[36m0.0426\u001b[0m  1.7112\n",
      "     19        \u001b[36m0.0409\u001b[0m  1.7148\n",
      "     20        0.0426  1.7224\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  34.9s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3051\u001b[0m  1.7251\n",
      "      2        \u001b[36m0.2151\u001b[0m  1.7131\n",
      "      3        \u001b[36m0.1850\u001b[0m  1.7224\n",
      "      4        \u001b[36m0.1295\u001b[0m  1.7035\n",
      "      5        \u001b[36m0.1179\u001b[0m  1.7086\n",
      "      6        \u001b[36m0.0661\u001b[0m  1.7388\n",
      "      7        0.0791  1.7438\n",
      "      8        \u001b[36m0.0449\u001b[0m  1.7461\n",
      "      9        \u001b[36m0.0414\u001b[0m  1.7363\n",
      "     10        \u001b[36m0.0325\u001b[0m  1.7267\n",
      "     11        \u001b[36m0.0308\u001b[0m  1.7185\n",
      "     12        \u001b[36m0.0285\u001b[0m  1.7263\n",
      "     13        0.0333  1.7336\n",
      "     14        \u001b[36m0.0245\u001b[0m  1.7296\n",
      "     15        0.0363  1.7051\n",
      "     16        0.0289  1.7341\n",
      "     17        \u001b[36m0.0214\u001b[0m  1.7454\n",
      "     18        0.0289  1.7258\n",
      "     19        \u001b[36m0.0179\u001b[0m  1.7178\n",
      "     20        0.0181  1.7057\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  34.9s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3243\u001b[0m  1.7020\n",
      "      2        \u001b[36m0.2473\u001b[0m  1.7231\n",
      "      3        \u001b[36m0.1424\u001b[0m  1.7254\n",
      "      4        \u001b[36m0.0821\u001b[0m  1.7290\n",
      "      5        \u001b[36m0.0728\u001b[0m  1.7407\n",
      "      6        \u001b[36m0.0535\u001b[0m  1.7108\n",
      "      7        0.0884  1.7273\n",
      "      8        0.0972  1.7181\n",
      "      9        \u001b[36m0.0509\u001b[0m  1.7294\n",
      "     10        \u001b[36m0.0382\u001b[0m  1.7193\n",
      "     11        \u001b[36m0.0309\u001b[0m  1.7148\n",
      "     12        0.0331  1.7081\n",
      "     13        \u001b[36m0.0225\u001b[0m  1.7171\n",
      "     14        0.1201  1.7132\n",
      "     15        0.0377  1.7071\n",
      "     16        0.0241  1.7058\n",
      "     17        \u001b[36m0.0199\u001b[0m  1.7139\n",
      "     18        \u001b[36m0.0196\u001b[0m  1.7038\n",
      "     19        0.0211  1.7085\n",
      "     20        \u001b[36m0.0144\u001b[0m  1.7350\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  34.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3234\u001b[0m  1.7023\n",
      "      2        \u001b[36m0.3011\u001b[0m  1.7025\n",
      "      3        \u001b[36m0.1746\u001b[0m  1.7121\n",
      "      4        \u001b[36m0.1543\u001b[0m  1.7153\n",
      "      5        \u001b[36m0.1073\u001b[0m  1.7190\n",
      "      6        \u001b[36m0.0751\u001b[0m  1.7103\n",
      "      7        \u001b[36m0.0525\u001b[0m  1.7227\n",
      "      8        0.0620  1.7198\n",
      "      9        \u001b[36m0.0320\u001b[0m  1.7161\n",
      "     10        0.0351  1.7140\n",
      "     11        0.1082  1.7185\n",
      "     12        0.0425  1.7463\n",
      "     13        \u001b[36m0.0278\u001b[0m  1.7259\n",
      "     14        \u001b[36m0.0270\u001b[0m  1.7207\n",
      "     15        0.1889  1.7043\n",
      "     16        0.2443  1.7080\n",
      "     17        0.1008  1.7328\n",
      "     18        0.0587  1.7425\n",
      "     19        0.0523  1.7332\n",
      "     20        0.0984  1.7199\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  34.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3020\u001b[0m  1.7478\n",
      "      2        \u001b[36m0.1927\u001b[0m  1.7177\n",
      "      3        \u001b[36m0.1116\u001b[0m  1.7456\n",
      "      4        \u001b[36m0.0658\u001b[0m  1.7101\n",
      "      5        \u001b[36m0.0339\u001b[0m  1.7371\n",
      "      6        \u001b[36m0.0272\u001b[0m  1.7148\n",
      "      7        \u001b[36m0.0210\u001b[0m  1.7219\n",
      "      8        0.0349  1.7144\n",
      "      9        0.0854  1.7206\n",
      "     10        0.0321  1.7086\n",
      "     11        0.0318  1.7226\n",
      "     12        0.0257  1.7271\n",
      "     13        \u001b[36m0.0190\u001b[0m  1.7279\n",
      "     14        0.0198  1.7212\n",
      "     15        0.0240  1.7263\n",
      "     16        \u001b[36m0.0162\u001b[0m  1.7134\n",
      "     17        0.0341  1.7305\n",
      "     18        0.0233  1.7272\n",
      "     19        0.0200  1.7109\n",
      "     20        0.0270  1.7404\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  34.9s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3247\u001b[0m  2.7293\n",
      "      2        \u001b[36m0.1646\u001b[0m  2.7281\n",
      "      3        0.2134  2.7298\n",
      "      4        \u001b[36m0.1046\u001b[0m  2.7344\n",
      "      5        \u001b[36m0.0667\u001b[0m  2.7265\n",
      "      6        \u001b[36m0.0587\u001b[0m  2.7300\n",
      "      7        0.0695  2.7322\n",
      "      8        0.0589  2.7250\n",
      "      9        0.3128  2.7207\n",
      "     10        0.1799  2.7250\n",
      "     11        0.1061  2.7297\n",
      "     12        0.0790  2.7261\n",
      "     13        0.0605  2.7238\n",
      "     14        \u001b[36m0.0552\u001b[0m  2.7175\n",
      "     15        0.1170  2.7305\n",
      "     16        \u001b[36m0.0510\u001b[0m  2.7299\n",
      "     17        \u001b[36m0.0417\u001b[0m  2.7217\n",
      "     18        \u001b[36m0.0331\u001b[0m  2.7299\n",
      "     19        0.0411  2.7283\n",
      "     20        0.0412  2.7119\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  55.0s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3991\u001b[0m  2.7332\n",
      "      2        \u001b[36m0.1041\u001b[0m  2.7388\n",
      "      3        \u001b[36m0.0498\u001b[0m  2.7450\n",
      "      4        \u001b[36m0.0297\u001b[0m  2.7465\n",
      "      5        0.0343  2.7463\n",
      "      6        \u001b[36m0.0264\u001b[0m  2.7472\n",
      "      7        \u001b[36m0.0216\u001b[0m  2.7477\n",
      "      8        \u001b[36m0.0213\u001b[0m  2.7374\n",
      "      9        \u001b[36m0.0186\u001b[0m  2.7499\n",
      "     10        0.0304  2.7512\n",
      "     11        0.0287  2.7482\n",
      "     12        \u001b[36m0.0164\u001b[0m  2.7312\n",
      "     13        0.0223  2.7443\n",
      "     14        0.0170  2.7392\n",
      "     15        \u001b[36m0.0157\u001b[0m  2.7395\n",
      "     16        \u001b[36m0.0153\u001b[0m  2.7361\n",
      "     17        \u001b[36m0.0151\u001b[0m  2.7419\n",
      "     18        0.0160  2.7426\n",
      "     19        \u001b[36m0.0149\u001b[0m  2.7409\n",
      "     20        0.0792  2.7454\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  55.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2653\u001b[0m  2.7524\n",
      "      2        \u001b[36m0.1319\u001b[0m  2.7411\n",
      "      3        \u001b[36m0.0823\u001b[0m  2.7553\n",
      "      4        0.1028  2.7582\n",
      "      5        \u001b[36m0.0484\u001b[0m  2.7561\n",
      "      6        \u001b[36m0.0342\u001b[0m  2.7530\n",
      "      7        \u001b[36m0.0269\u001b[0m  2.7560\n",
      "      8        \u001b[36m0.0215\u001b[0m  2.7625\n",
      "      9        0.0283  2.7520\n",
      "     10        \u001b[36m0.0172\u001b[0m  2.7613\n",
      "     11        \u001b[36m0.0139\u001b[0m  2.7458\n",
      "     12        0.0496  2.7581\n",
      "     13        0.0552  2.7563\n",
      "     14        0.0275  2.7436\n",
      "     15        0.0189  2.7583\n",
      "     16        0.0557  2.7586\n",
      "     17        0.4116  2.7551\n",
      "     18        0.6549  2.7521\n",
      "     19        0.6444  2.7531\n",
      "     20        0.6174  2.7561\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  55.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3472\u001b[0m  2.7488\n",
      "      2        \u001b[36m0.1975\u001b[0m  2.7550\n",
      "      3        0.2785  2.7601\n",
      "      4        0.4281  2.7397\n",
      "      5        \u001b[36m0.1868\u001b[0m  2.7406\n",
      "      6        \u001b[36m0.1311\u001b[0m  2.7374\n",
      "      7        0.1667  2.7398\n",
      "      8        0.1329  2.7531\n",
      "      9        \u001b[36m0.1148\u001b[0m  2.7534\n",
      "     10        0.1151  2.7580\n",
      "     11        \u001b[36m0.0863\u001b[0m  2.7569\n",
      "     12        0.0949  2.7566\n",
      "     13        \u001b[36m0.0679\u001b[0m  2.7740\n",
      "     14        0.1172  2.7492\n",
      "     15        0.0971  2.7457\n",
      "     16        0.1052  2.7483\n",
      "     17        0.0736  2.7563\n",
      "     18        0.0728  2.7566\n",
      "     19        0.3178  2.7538\n",
      "     20        0.1345  2.7549\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  55.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4859\u001b[0m  2.7378\n",
      "      2        \u001b[36m0.1416\u001b[0m  2.7579\n",
      "      3        \u001b[36m0.0635\u001b[0m  2.7459\n",
      "      4        \u001b[36m0.0520\u001b[0m  2.7527\n",
      "      5        \u001b[36m0.0330\u001b[0m  2.7503\n",
      "      6        0.0590  2.7518\n",
      "      7        0.0482  2.7561\n",
      "      8        \u001b[36m0.0310\u001b[0m  2.7512\n",
      "      9        \u001b[36m0.0282\u001b[0m  2.7503\n",
      "     10        \u001b[36m0.0191\u001b[0m  2.7554\n",
      "     11        0.0202  2.7539\n",
      "     12        \u001b[36m0.0181\u001b[0m  2.7483\n",
      "     13        0.0213  2.7539\n",
      "     14        0.0310  2.7507\n",
      "     15        0.0339  2.7535\n",
      "     16        0.0212  2.7537\n",
      "     17        0.0230  2.7432\n",
      "     18        \u001b[36m0.0160\u001b[0m  2.7584\n",
      "     19        0.0401  2.7606\n",
      "     20        0.0176  2.7513\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total=  55.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3234\u001b[0m  2.5257\n",
      "      2        \u001b[36m0.1654\u001b[0m  2.5287\n",
      "      3        \u001b[36m0.1434\u001b[0m  2.5325\n",
      "      4        0.1822  2.5359\n",
      "      5        0.2832  2.5344\n",
      "      6        0.3730  2.5387\n",
      "      7        0.2524  2.5360\n",
      "      8        \u001b[36m0.1215\u001b[0m  2.5296\n",
      "      9        0.1686  2.5292\n",
      "     10        \u001b[36m0.1152\u001b[0m  2.5243\n",
      "     11        \u001b[36m0.0642\u001b[0m  2.5266\n",
      "     12        \u001b[36m0.0423\u001b[0m  2.5405\n",
      "     13        \u001b[36m0.0349\u001b[0m  2.5341\n",
      "     14        0.0362  2.5301\n",
      "     15        \u001b[36m0.0310\u001b[0m  2.5362\n",
      "     16        \u001b[36m0.0297\u001b[0m  2.5231\n",
      "     17        0.0534  2.5435\n",
      "     18        0.0527  2.5434\n",
      "     19        0.0433  2.5373\n",
      "     20        0.0298  2.5320\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  51.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3508\u001b[0m  2.5350\n",
      "      2        \u001b[36m0.1526\u001b[0m  2.5210\n",
      "      3        \u001b[36m0.1032\u001b[0m  2.5215\n",
      "      4        \u001b[36m0.0690\u001b[0m  2.5227\n",
      "      5        \u001b[36m0.0452\u001b[0m  2.5336\n",
      "      6        \u001b[36m0.0326\u001b[0m  2.5367\n",
      "      7        0.0498  2.5426\n",
      "      8        0.0377  2.5387\n",
      "      9        \u001b[36m0.0227\u001b[0m  2.5447\n",
      "     10        0.0280  2.5474\n",
      "     11        0.1001  2.5441\n",
      "     12        0.0621  2.5454\n",
      "     13        0.0366  2.5441\n",
      "     14        0.0426  2.5484\n",
      "     15        0.0268  2.5474\n",
      "     16        \u001b[36m0.0212\u001b[0m  2.5481\n",
      "     17        \u001b[36m0.0203\u001b[0m  2.5545\n",
      "     18        0.0624  2.5397\n",
      "     19        0.3729  2.5536\n",
      "     20        0.1603  2.5468\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  51.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3144\u001b[0m  2.5095\n",
      "      2        \u001b[36m0.1810\u001b[0m  2.5078\n",
      "      3        \u001b[36m0.1025\u001b[0m  2.5033\n",
      "      4        \u001b[36m0.0616\u001b[0m  2.5170\n",
      "      5        \u001b[36m0.0564\u001b[0m  2.5061\n",
      "      6        \u001b[36m0.0454\u001b[0m  2.5087\n",
      "      7        \u001b[36m0.0404\u001b[0m  2.5006\n",
      "      8        \u001b[36m0.0272\u001b[0m  2.4941\n",
      "      9        0.0334  2.5105\n",
      "     10        \u001b[36m0.0188\u001b[0m  2.5064\n",
      "     11        \u001b[36m0.0167\u001b[0m  2.4965\n",
      "     12        0.0169  2.5054\n",
      "     13        0.2774  2.5064\n",
      "     14        0.5858  2.4923\n",
      "     15        0.4311  2.5138\n",
      "     16        0.2561  2.5039\n",
      "     17        0.1657  2.5078\n",
      "     18        0.1277  2.5083\n",
      "     19        0.1029  2.5140\n",
      "     20        0.0971  2.5131\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  50.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2962\u001b[0m  2.5521\n",
      "      2        \u001b[36m0.1353\u001b[0m  2.5370\n",
      "      3        \u001b[36m0.0895\u001b[0m  2.5546\n",
      "      4        \u001b[36m0.0518\u001b[0m  2.5610\n",
      "      5        0.0760  2.5572\n",
      "      6        0.0720  2.5502\n",
      "      7        \u001b[36m0.0360\u001b[0m  2.5604\n",
      "      8        \u001b[36m0.0328\u001b[0m  2.5534\n",
      "      9        0.3485  2.5472\n",
      "     10        0.0767  2.5417\n",
      "     11        0.0439  2.5561\n",
      "     12        0.0363  2.5529\n",
      "     13        0.6188  2.5520\n",
      "     14        0.3143  2.5476\n",
      "     15        0.1605  2.5445\n",
      "     16        0.1199  2.5518\n",
      "     17        0.0891  2.5502\n",
      "     18        0.0809  2.5451\n",
      "     19        0.0768  2.5550\n",
      "     20        0.0535  2.5494\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  51.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2992\u001b[0m  2.5426\n",
      "      2        \u001b[36m0.1226\u001b[0m  2.5367\n",
      "      3        \u001b[36m0.0777\u001b[0m  2.5556\n",
      "      4        \u001b[36m0.0588\u001b[0m  2.5522\n",
      "      5        \u001b[36m0.0474\u001b[0m  2.5507\n",
      "      6        \u001b[36m0.0329\u001b[0m  2.5379\n",
      "      7        0.0609  2.5449\n",
      "      8        0.0369  2.5566\n",
      "      9        \u001b[36m0.0275\u001b[0m  2.5456\n",
      "     10        0.2858  2.5431\n",
      "     11        0.0622  2.5413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12        0.0495  2.5510\n",
      "     13        0.0283  2.5479\n",
      "     14        \u001b[36m0.0210\u001b[0m  2.5446\n",
      "     15        0.0274  2.5389\n",
      "     16        0.0213  2.5396\n",
      "     17        0.0226  2.5405\n",
      "     18        \u001b[36m0.0178\u001b[0m  2.5474\n",
      "     19        \u001b[36m0.0176\u001b[0m  2.5478\n",
      "     20        0.0212  2.5513\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total=  51.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3683\u001b[0m  1.5841\n",
      "      2        \u001b[36m0.2679\u001b[0m  1.5959\n",
      "      3        \u001b[36m0.1918\u001b[0m  1.5754\n",
      "      4        \u001b[36m0.1808\u001b[0m  1.5906\n",
      "      5        0.2174  1.5965\n",
      "      6        0.2781  1.6057\n",
      "      7        0.1955  1.6003\n",
      "      8        \u001b[36m0.1569\u001b[0m  1.5807\n",
      "      9        \u001b[36m0.1524\u001b[0m  1.5772\n",
      "     10        \u001b[36m0.1483\u001b[0m  1.5881\n",
      "     11        \u001b[36m0.1316\u001b[0m  1.5907\n",
      "     12        \u001b[36m0.1244\u001b[0m  1.5955\n",
      "     13        \u001b[36m0.1124\u001b[0m  1.6055\n",
      "     14        \u001b[36m0.1048\u001b[0m  1.5967\n",
      "     15        0.1365  1.5924\n",
      "     16        0.1102  1.5843\n",
      "     17        \u001b[36m0.1009\u001b[0m  1.6216\n",
      "     18        \u001b[36m0.0895\u001b[0m  1.6213\n",
      "     19        \u001b[36m0.0833\u001b[0m  1.6144\n",
      "     20        0.0934  1.6051\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  32.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4055\u001b[0m  1.6116\n",
      "      2        \u001b[36m0.3420\u001b[0m  1.6031\n",
      "      3        \u001b[36m0.2706\u001b[0m  1.6093\n",
      "      4        \u001b[36m0.2144\u001b[0m  1.6109\n",
      "      5        \u001b[36m0.1896\u001b[0m  1.6080\n",
      "      6        \u001b[36m0.1435\u001b[0m  1.5862\n",
      "      7        0.1626  1.5885\n",
      "      8        \u001b[36m0.1422\u001b[0m  1.5880\n",
      "      9        \u001b[36m0.1324\u001b[0m  1.5990\n",
      "     10        \u001b[36m0.0922\u001b[0m  1.5847\n",
      "     11        \u001b[36m0.0742\u001b[0m  1.5974\n",
      "     12        0.0742  1.6103\n",
      "     13        0.0824  1.5978\n",
      "     14        0.0864  1.5884\n",
      "     15        0.1137  1.5941\n",
      "     16        \u001b[36m0.0732\u001b[0m  1.5946\n",
      "     17        0.3196  1.5934\n",
      "     18        0.1571  1.6072\n",
      "     19        0.1319  1.6130\n",
      "     20        0.0997  1.5832\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  32.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3647\u001b[0m  1.5863\n",
      "      2        \u001b[36m0.2393\u001b[0m  1.5949\n",
      "      3        \u001b[36m0.1724\u001b[0m  1.5870\n",
      "      4        0.1962  1.6073\n",
      "      5        0.2556  1.6047\n",
      "      6        0.2068  1.5854\n",
      "      7        0.1923  1.6021\n",
      "      8        \u001b[36m0.1629\u001b[0m  1.6051\n",
      "      9        \u001b[36m0.1084\u001b[0m  1.6075\n",
      "     10        0.1098  1.5936\n",
      "     11        \u001b[36m0.1022\u001b[0m  1.5786\n",
      "     12        \u001b[36m0.0795\u001b[0m  1.5698\n",
      "     13        0.0889  1.6139\n",
      "     14        \u001b[36m0.0653\u001b[0m  1.5969\n",
      "     15        0.1107  1.5976\n",
      "     16        0.0675  1.6149\n",
      "     17        \u001b[36m0.0522\u001b[0m  1.6149\n",
      "     18        \u001b[36m0.0520\u001b[0m  1.6166\n",
      "     19        \u001b[36m0.0425\u001b[0m  1.5950\n",
      "     20        0.0828  1.5965\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  32.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4506\u001b[0m  1.5826\n",
      "      2        \u001b[36m0.4259\u001b[0m  1.5770\n",
      "      3        \u001b[36m0.3698\u001b[0m  1.5966\n",
      "      4        \u001b[36m0.2362\u001b[0m  1.5929\n",
      "      5        \u001b[36m0.2190\u001b[0m  1.5854\n",
      "      6        \u001b[36m0.1925\u001b[0m  1.5931\n",
      "      7        \u001b[36m0.1596\u001b[0m  1.5814\n",
      "      8        \u001b[36m0.1424\u001b[0m  1.5907\n",
      "      9        0.2849  1.5806\n",
      "     10        0.3842  1.6048\n",
      "     11        0.2692  1.5918\n",
      "     12        0.2136  1.5808\n",
      "     13        0.1689  1.6089\n",
      "     14        0.1726  1.5980\n",
      "     15        0.1478  1.6093\n",
      "     16        \u001b[36m0.1238\u001b[0m  1.6006\n",
      "     17        0.1302  1.5800\n",
      "     18        \u001b[36m0.1059\u001b[0m  1.6109\n",
      "     19        \u001b[36m0.0947\u001b[0m  1.6072\n",
      "     20        \u001b[36m0.0917\u001b[0m  1.5980\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  32.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3982\u001b[0m  1.5927\n",
      "      2        \u001b[36m0.2733\u001b[0m  1.6103\n",
      "      3        \u001b[36m0.1778\u001b[0m  1.5864\n",
      "      4        0.2146  1.6008\n",
      "      5        \u001b[36m0.1778\u001b[0m  1.5884\n",
      "      6        0.2835  1.6154\n",
      "      7        0.1828  1.5828\n",
      "      8        0.1812  1.6004\n",
      "      9        \u001b[36m0.1100\u001b[0m  1.5827\n",
      "     10        \u001b[36m0.0957\u001b[0m  1.5931\n",
      "     11        0.0994  1.6086\n",
      "     12        0.1697  1.5848\n",
      "     13        0.1489  1.5902\n",
      "     14        \u001b[36m0.0926\u001b[0m  1.5806\n",
      "     15        \u001b[36m0.0754\u001b[0m  1.5992\n",
      "     16        \u001b[36m0.0660\u001b[0m  1.5898\n",
      "     17        \u001b[36m0.0592\u001b[0m  1.5969\n",
      "     18        0.0681  1.5945\n",
      "     19        0.0807  1.5815\n",
      "     20        0.3093  1.6066\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  32.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3123\u001b[0m  1.7149\n",
      "      2        \u001b[36m0.2045\u001b[0m  1.7248\n",
      "      3        \u001b[36m0.1606\u001b[0m  1.7078\n",
      "      4        \u001b[36m0.1192\u001b[0m  1.7272\n",
      "      5        \u001b[36m0.1019\u001b[0m  1.7055\n",
      "      6        \u001b[36m0.0725\u001b[0m  1.7149\n",
      "      7        \u001b[36m0.0558\u001b[0m  1.7307\n",
      "      8        \u001b[36m0.0436\u001b[0m  1.7357\n",
      "      9        \u001b[36m0.0371\u001b[0m  1.7252\n",
      "     10        0.0717  1.7077\n",
      "     11        0.0489  1.7060\n",
      "     12        0.0432  1.7200\n",
      "     13        0.0457  1.7110\n",
      "     14        0.0447  1.7237\n",
      "     15        \u001b[36m0.0280\u001b[0m  1.7283\n",
      "     16        0.0301  1.7129\n",
      "     17        0.0558  1.7076\n",
      "     18        0.0321  1.7409\n",
      "     19        0.0351  1.7393\n",
      "     20        \u001b[36m0.0259\u001b[0m  1.7143\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  34.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3679\u001b[0m  1.7216\n",
      "      2        \u001b[36m0.1724\u001b[0m  1.7144\n",
      "      3        \u001b[36m0.1344\u001b[0m  1.7318\n",
      "      4        \u001b[36m0.0847\u001b[0m  1.7260\n",
      "      5        \u001b[36m0.0558\u001b[0m  1.7232\n",
      "      6        \u001b[36m0.0436\u001b[0m  1.7180\n",
      "      7        \u001b[36m0.0299\u001b[0m  1.7296\n",
      "      8        \u001b[36m0.0282\u001b[0m  1.7123\n",
      "      9        0.0389  1.7395\n",
      "     10        0.0393  1.7212\n",
      "     11        0.0300  1.7450\n",
      "     12        \u001b[36m0.0224\u001b[0m  1.7145\n",
      "     13        \u001b[36m0.0199\u001b[0m  1.7264\n",
      "     14        0.0267  1.7184\n",
      "     15        \u001b[36m0.0184\u001b[0m  1.7469\n",
      "     16        0.0384  1.7241\n",
      "     17        0.0282  1.7215\n",
      "     18        0.0185  1.7178\n",
      "     19        \u001b[36m0.0148\u001b[0m  1.7246\n",
      "     20        0.0205  1.7246\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  34.9s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3260\u001b[0m  1.7308\n",
      "      2        \u001b[36m0.2702\u001b[0m  1.7275\n",
      "      3        \u001b[36m0.2490\u001b[0m  1.7189\n",
      "      4        \u001b[36m0.1609\u001b[0m  1.7381\n",
      "      5        \u001b[36m0.1326\u001b[0m  1.7531\n",
      "      6        \u001b[36m0.1000\u001b[0m  1.7309\n",
      "      7        \u001b[36m0.0834\u001b[0m  1.7432\n",
      "      8        0.0965  1.7310\n",
      "      9        0.1801  1.7372\n",
      "     10        0.0885  1.7187\n",
      "     11        \u001b[36m0.0721\u001b[0m  1.7157\n",
      "     12        \u001b[36m0.0602\u001b[0m  1.7419\n",
      "     13        \u001b[36m0.0464\u001b[0m  1.7378\n",
      "     14        \u001b[36m0.0381\u001b[0m  1.7126\n",
      "     15        \u001b[36m0.0356\u001b[0m  1.7048\n",
      "     16        0.2002  1.7351\n",
      "     17        0.1460  1.7104\n",
      "     18        0.2057  1.7204\n",
      "     19        0.0825  1.7183\n",
      "     20        0.0693  1.7190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  34.9s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3400\u001b[0m  1.7419\n",
      "      2        \u001b[36m0.1729\u001b[0m  1.7208\n",
      "      3        \u001b[36m0.1437\u001b[0m  1.7117\n",
      "      4        \u001b[36m0.1141\u001b[0m  1.7124\n",
      "      5        \u001b[36m0.0713\u001b[0m  1.7108\n",
      "      6        \u001b[36m0.0550\u001b[0m  1.7119\n",
      "      7        0.0693  1.7178\n",
      "      8        0.0692  1.7269\n",
      "      9        0.0616  1.7234\n",
      "     10        0.1242  1.7438\n",
      "     11        0.0638  1.7272\n",
      "     12        \u001b[36m0.0463\u001b[0m  1.7149\n",
      "     13        \u001b[36m0.0447\u001b[0m  1.7137\n",
      "     14        0.0648  1.7245\n",
      "     15        \u001b[36m0.0438\u001b[0m  1.7310\n",
      "     16        \u001b[36m0.0334\u001b[0m  1.7063\n",
      "     17        \u001b[36m0.0295\u001b[0m  1.7006\n",
      "     18        0.0505  1.7039\n",
      "     19        0.0480  1.7126\n",
      "     20        0.0313  1.7250\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  34.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3415\u001b[0m  1.7207\n",
      "      2        \u001b[36m0.1661\u001b[0m  1.7195\n",
      "      3        \u001b[36m0.1294\u001b[0m  1.7221\n",
      "      4        \u001b[36m0.0859\u001b[0m  1.7226\n",
      "      5        \u001b[36m0.0735\u001b[0m  1.7281\n",
      "      6        0.1090  1.7255\n",
      "      7        \u001b[36m0.0575\u001b[0m  1.7167\n",
      "      8        \u001b[36m0.0470\u001b[0m  1.7201\n",
      "      9        0.0474  1.7174\n",
      "     10        \u001b[36m0.0361\u001b[0m  1.7214\n",
      "     11        \u001b[36m0.0305\u001b[0m  1.7304\n",
      "     12        0.0342  1.7163\n",
      "     13        \u001b[36m0.0296\u001b[0m  1.7401\n",
      "     14        \u001b[36m0.0190\u001b[0m  1.7249\n",
      "     15        0.0198  1.7127\n",
      "     16        0.0193  1.7080\n",
      "     17        0.0255  1.7081\n",
      "     18        0.0226  1.7087\n",
      "     19        \u001b[36m0.0182\u001b[0m  1.7404\n",
      "     20        0.0197  1.7198\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  34.8s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3101\u001b[0m  2.7450\n",
      "      2        \u001b[36m0.1767\u001b[0m  2.7406\n",
      "      3        \u001b[36m0.1298\u001b[0m  2.7656\n",
      "      4        \u001b[36m0.0687\u001b[0m  2.7586\n",
      "      5        \u001b[36m0.0575\u001b[0m  2.7592\n",
      "      6        \u001b[36m0.0455\u001b[0m  2.7527\n",
      "      7        0.0792  2.7577\n",
      "      8        0.0747  2.7594\n",
      "      9        \u001b[36m0.0405\u001b[0m  2.7497\n",
      "     10        \u001b[36m0.0293\u001b[0m  2.7533\n",
      "     11        0.0315  2.7573\n",
      "     12        0.0353  2.7517\n",
      "     13        0.0385  2.7568\n",
      "     14        0.0342  2.7542\n",
      "     15        \u001b[36m0.0267\u001b[0m  2.7500\n",
      "     16        \u001b[36m0.0200\u001b[0m  2.7554\n",
      "     17        0.0227  2.7591\n",
      "     18        \u001b[36m0.0174\u001b[0m  2.7584\n",
      "     19        \u001b[36m0.0164\u001b[0m  2.7692\n",
      "     20        0.0165  2.7664\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  55.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3180\u001b[0m  2.7304\n",
      "      2        \u001b[36m0.1870\u001b[0m  2.7271\n",
      "      3        \u001b[36m0.1733\u001b[0m  2.7287\n",
      "      4        0.1808  2.7326\n",
      "      5        \u001b[36m0.0979\u001b[0m  2.7170\n",
      "      6        \u001b[36m0.0751\u001b[0m  2.7323\n",
      "      7        \u001b[36m0.0679\u001b[0m  2.7244\n",
      "      8        0.4565  2.7269\n",
      "      9        0.2093  2.7304\n",
      "     10        0.1219  2.7308\n",
      "     11        0.0829  2.7340\n",
      "     12        0.0731  2.7311\n",
      "     13        \u001b[36m0.0623\u001b[0m  2.7320\n",
      "     14        \u001b[36m0.0464\u001b[0m  2.7257\n",
      "     15        0.0540  2.7266\n",
      "     16        \u001b[36m0.0450\u001b[0m  2.7332\n",
      "     17        0.2502  2.7243\n",
      "     18        0.5068  2.7358\n",
      "     19        0.3033  2.7356\n",
      "     20        0.2280  2.7152\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  55.0s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3789\u001b[0m  2.7482\n",
      "      2        \u001b[36m0.1520\u001b[0m  2.7466\n",
      "      3        \u001b[36m0.0933\u001b[0m  2.7364\n",
      "      4        \u001b[36m0.0549\u001b[0m  2.7472\n",
      "      5        \u001b[36m0.0459\u001b[0m  2.7340\n",
      "      6        0.0579  2.7393\n",
      "      7        \u001b[36m0.0394\u001b[0m  2.7457\n",
      "      8        \u001b[36m0.0258\u001b[0m  2.7410\n",
      "      9        \u001b[36m0.0223\u001b[0m  2.7473\n",
      "     10        \u001b[36m0.0215\u001b[0m  2.7459\n",
      "     11        \u001b[36m0.0182\u001b[0m  2.7485\n",
      "     12        0.0185  2.7484\n",
      "     13        \u001b[36m0.0128\u001b[0m  2.7471\n",
      "     14        0.0159  2.7488\n",
      "     15        0.0301  2.7440\n",
      "     16        0.0192  2.7357\n",
      "     17        0.0144  2.7533\n",
      "     18        0.0133  2.7406\n",
      "     19        \u001b[36m0.0113\u001b[0m  2.7452\n",
      "     20        0.0131  2.7413\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  55.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3155\u001b[0m  2.7607\n",
      "      2        \u001b[36m0.1525\u001b[0m  2.7580\n",
      "      3        0.2582  2.7638\n",
      "      4        \u001b[36m0.0860\u001b[0m  2.7544\n",
      "      5        \u001b[36m0.0399\u001b[0m  2.7571\n",
      "      6        0.0421  2.7578\n",
      "      7        \u001b[36m0.0330\u001b[0m  2.7491\n",
      "      8        \u001b[36m0.0252\u001b[0m  2.7577\n",
      "      9        \u001b[36m0.0209\u001b[0m  2.7416\n",
      "     10        0.0570  2.7592\n",
      "     11        0.0230  2.7590\n",
      "     12        0.0227  2.7563\n",
      "     13        \u001b[36m0.0183\u001b[0m  2.7578\n",
      "     14        0.0226  2.7499\n",
      "     15        0.0193  2.7499\n",
      "     16        \u001b[36m0.0166\u001b[0m  2.7528\n",
      "     17        0.0228  2.7551\n",
      "     18        0.0319  2.7507\n",
      "     19        0.1458  2.7516\n",
      "     20        0.1997  2.7540\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  55.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3504\u001b[0m  2.7555\n",
      "      2        \u001b[36m0.1711\u001b[0m  2.7505\n",
      "      3        \u001b[36m0.1640\u001b[0m  2.7522\n",
      "      4        0.5269  2.7542\n",
      "      5        0.2396  2.7497\n",
      "      6        0.1857  2.7501\n",
      "      7        \u001b[36m0.1187\u001b[0m  2.7512\n",
      "      8        \u001b[36m0.0788\u001b[0m  2.7513\n",
      "      9        \u001b[36m0.0683\u001b[0m  2.7494\n",
      "     10        \u001b[36m0.0573\u001b[0m  2.7553\n",
      "     11        0.0647  2.7550\n",
      "     12        \u001b[36m0.0539\u001b[0m  2.7540\n",
      "     13        \u001b[36m0.0475\u001b[0m  2.7580\n",
      "     14        \u001b[36m0.0380\u001b[0m  2.7424\n",
      "     15        0.0407  2.7596\n",
      "     16        0.0481  2.7563\n",
      "     17        0.0557  2.7543\n",
      "     18        0.0383  2.7512\n",
      "     19        \u001b[36m0.0325\u001b[0m  2.7521\n",
      "     20        0.1117  2.7429\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total=  55.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3563\u001b[0m  2.5349\n",
      "      2        \u001b[36m0.1485\u001b[0m  2.5285\n",
      "      3        \u001b[36m0.0950\u001b[0m  2.5324\n",
      "      4        \u001b[36m0.0445\u001b[0m  2.5283\n",
      "      5        \u001b[36m0.0393\u001b[0m  2.5320\n",
      "      6        \u001b[36m0.0317\u001b[0m  2.5411\n",
      "      7        \u001b[36m0.0282\u001b[0m  2.5379\n",
      "      8        0.0365  2.5284\n",
      "      9        0.0311  2.5251\n",
      "     10        0.0288  2.5306\n",
      "     11        \u001b[36m0.0255\u001b[0m  2.5347\n",
      "     12        \u001b[36m0.0250\u001b[0m  2.5393\n",
      "     13        0.0259  2.5367\n",
      "     14        \u001b[36m0.0211\u001b[0m  2.5178\n",
      "     15        \u001b[36m0.0204\u001b[0m  2.5151\n",
      "     16        0.0206  2.5167\n",
      "     17        0.0226  2.5164\n",
      "     18        \u001b[36m0.0177\u001b[0m  2.5385\n",
      "     19        \u001b[36m0.0138\u001b[0m  2.5320\n",
      "     20        0.0246  2.5282\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  51.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3137\u001b[0m  2.5319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.2131\u001b[0m  2.5428\n",
      "      3        \u001b[36m0.1752\u001b[0m  2.5294\n",
      "      4        \u001b[36m0.1191\u001b[0m  2.5315\n",
      "      5        \u001b[36m0.0700\u001b[0m  2.5352\n",
      "      6        \u001b[36m0.0460\u001b[0m  2.5399\n",
      "      7        \u001b[36m0.0306\u001b[0m  2.5389\n",
      "      8        0.2773  2.5304\n",
      "      9        0.2389  2.5364\n",
      "     10        0.1281  2.5496\n",
      "     11        0.0863  2.5466\n",
      "     12        0.3607  2.5486\n",
      "     13        0.3787  2.5428\n",
      "     14        0.1669  2.5433\n",
      "     15        0.1054  2.5498\n",
      "     16        0.0885  2.5498\n",
      "     17        0.0701  2.5482\n",
      "     18        0.0731  2.5532\n",
      "     19        0.0559  2.5456\n",
      "     20        0.0418  2.5541\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  51.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3208\u001b[0m  2.5379\n",
      "      2        \u001b[36m0.1759\u001b[0m  2.5430\n",
      "      3        \u001b[36m0.1074\u001b[0m  2.5354\n",
      "      4        \u001b[36m0.0782\u001b[0m  2.5466\n",
      "      5        0.0983  2.5442\n",
      "      6        \u001b[36m0.0510\u001b[0m  2.5437\n",
      "      7        \u001b[36m0.0504\u001b[0m  2.5527\n",
      "      8        \u001b[36m0.0390\u001b[0m  2.5395\n",
      "      9        0.0816  2.5468\n",
      "     10        0.0404  2.5387\n",
      "     11        \u001b[36m0.0231\u001b[0m  2.5595\n",
      "     12        0.0236  2.5481\n",
      "     13        0.4516  2.5522\n",
      "     14        0.4416  2.5609\n",
      "     15        0.2144  2.5519\n",
      "     16        0.2968  2.5532\n",
      "     17        0.2236  2.5490\n",
      "     18        0.1481  2.5373\n",
      "     19        0.1117  2.5459\n",
      "     20        0.0770  2.5430\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  51.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2995\u001b[0m  2.5010\n",
      "      2        \u001b[36m0.1987\u001b[0m  2.5047\n",
      "      3        \u001b[36m0.1118\u001b[0m  2.5017\n",
      "      4        0.1172  2.5019\n",
      "      5        \u001b[36m0.0633\u001b[0m  2.5058\n",
      "      6        0.1265  2.5042\n",
      "      7        \u001b[36m0.0632\u001b[0m  2.5062\n",
      "      8        \u001b[36m0.0427\u001b[0m  2.5107\n",
      "      9        0.0431  2.5140\n",
      "     10        0.0600  2.5111\n",
      "     11        0.1195  2.4967\n",
      "     12        0.4544  2.5064\n",
      "     13        0.1263  2.5079\n",
      "     14        0.1028  2.5126\n",
      "     15        0.2085  2.5114\n",
      "     16        0.0986  2.5015\n",
      "     17        0.0531  2.5217\n",
      "     18        0.0799  2.5052\n",
      "     19        0.0535  2.5101\n",
      "     20        \u001b[36m0.0374\u001b[0m  2.4963\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  50.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3256\u001b[0m  2.5390\n",
      "      2        \u001b[36m0.1793\u001b[0m  2.5529\n",
      "      3        \u001b[36m0.0949\u001b[0m  2.5461\n",
      "      4        0.2772  2.5412\n",
      "      5        0.4378  2.5523\n",
      "      6        0.3008  2.5479\n",
      "      7        0.1975  2.5454\n",
      "      8        0.2012  2.5456\n",
      "      9        0.4019  2.5407\n",
      "     10        0.2641  2.5375\n",
      "     11        0.1781  2.5337\n",
      "     12        0.1292  2.5355\n",
      "     13        0.1108  2.5377\n",
      "     14        \u001b[36m0.0772\u001b[0m  2.5515\n",
      "     15        0.1197  2.5539\n",
      "     16        0.0946  2.5526\n",
      "     17        \u001b[36m0.0524\u001b[0m  2.5485\n",
      "     18        0.0527  2.5471\n",
      "     19        \u001b[36m0.0426\u001b[0m  2.5485\n",
      "     20        \u001b[36m0.0324\u001b[0m  2.5621\n",
      "[CV]  net__batch_size=128, net__max_epochs=20, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total=  51.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3790\u001b[0m  1.6089\n",
      "      2        \u001b[36m0.2810\u001b[0m  1.6046\n",
      "      3        \u001b[36m0.2473\u001b[0m  1.5788\n",
      "      4        \u001b[36m0.1654\u001b[0m  1.6068\n",
      "      5        \u001b[36m0.1270\u001b[0m  1.5957\n",
      "      6        0.1449  1.5977\n",
      "      7        0.1376  1.6083\n",
      "      8        \u001b[36m0.0898\u001b[0m  1.5743\n",
      "      9        \u001b[36m0.0704\u001b[0m  1.5756\n",
      "     10        \u001b[36m0.0650\u001b[0m  1.6088\n",
      "     11        \u001b[36m0.0554\u001b[0m  1.5748\n",
      "     12        \u001b[36m0.0456\u001b[0m  1.6101\n",
      "     13        0.0491  1.6128\n",
      "     14        0.0501  1.6026\n",
      "     15        \u001b[36m0.0449\u001b[0m  1.5910\n",
      "     16        0.0535  1.6088\n",
      "     17        0.0469  1.5840\n",
      "     18        \u001b[36m0.0344\u001b[0m  1.5871\n",
      "     19        \u001b[36m0.0302\u001b[0m  1.6097\n",
      "     20        0.0439  1.5960\n",
      "     21        0.0406  1.5801\n",
      "     22        0.0711  1.5867\n",
      "     23        0.0766  1.6094\n",
      "     24        0.0567  1.5827\n",
      "     25        0.0379  1.5781\n",
      "     26        0.0469  1.5775\n",
      "     27        0.0399  1.6147\n",
      "     28        0.0382  1.6050\n",
      "     29        0.0378  1.5841\n",
      "     30        0.0436  1.5888\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  48.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3598\u001b[0m  1.5982\n",
      "      2        \u001b[36m0.3289\u001b[0m  1.6154\n",
      "      3        \u001b[36m0.2287\u001b[0m  1.5985\n",
      "      4        \u001b[36m0.1694\u001b[0m  1.5928\n",
      "      5        \u001b[36m0.1394\u001b[0m  1.5993\n",
      "      6        0.1516  1.6047\n",
      "      7        \u001b[36m0.1110\u001b[0m  1.5913\n",
      "      8        \u001b[36m0.1014\u001b[0m  1.5957\n",
      "      9        \u001b[36m0.0766\u001b[0m  1.5777\n",
      "     10        \u001b[36m0.0714\u001b[0m  1.5931\n",
      "     11        \u001b[36m0.0590\u001b[0m  1.5991\n",
      "     12        0.0977  1.6167\n",
      "     13        \u001b[36m0.0527\u001b[0m  1.5908\n",
      "     14        \u001b[36m0.0467\u001b[0m  1.5825\n",
      "     15        0.0499  1.5990\n",
      "     16        0.0479  1.5978\n",
      "     17        \u001b[36m0.0392\u001b[0m  1.6032\n",
      "     18        0.0753  1.5884\n",
      "     19        0.0428  1.5894\n",
      "     20        \u001b[36m0.0390\u001b[0m  1.5964\n",
      "     21        \u001b[36m0.0339\u001b[0m  1.5776\n",
      "     22        \u001b[36m0.0327\u001b[0m  1.5891\n",
      "     23        0.0442  1.5956\n",
      "     24        0.0359  1.5858\n",
      "     25        0.0328  1.5734\n",
      "     26        0.0372  1.5975\n",
      "     27        \u001b[36m0.0322\u001b[0m  1.5762\n",
      "     28        0.0575  1.5859\n",
      "     29        \u001b[36m0.0307\u001b[0m  1.5884\n",
      "     30        \u001b[36m0.0290\u001b[0m  1.5781\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  48.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3516\u001b[0m  1.5931\n",
      "      2        \u001b[36m0.2107\u001b[0m  1.6113\n",
      "      3        0.2667  1.6021\n",
      "      4        0.2211  1.6050\n",
      "      5        0.2262  1.5902\n",
      "      6        \u001b[36m0.1468\u001b[0m  1.5939\n",
      "      7        \u001b[36m0.1101\u001b[0m  1.6045\n",
      "      8        0.2824  1.6035\n",
      "      9        0.1601  1.6057\n",
      "     10        0.1230  1.6160\n",
      "     11        \u001b[36m0.1038\u001b[0m  1.6159\n",
      "     12        \u001b[36m0.0962\u001b[0m  1.5995\n",
      "     13        0.0987  1.5826\n",
      "     14        0.0973  1.6088\n",
      "     15        \u001b[36m0.0760\u001b[0m  1.6196\n",
      "     16        \u001b[36m0.0708\u001b[0m  1.5892\n",
      "     17        \u001b[36m0.0660\u001b[0m  1.5953\n",
      "     18        \u001b[36m0.0589\u001b[0m  1.5973\n",
      "     19        0.0704  1.6070\n",
      "     20        0.0598  1.5789\n",
      "     21        \u001b[36m0.0564\u001b[0m  1.5799\n",
      "     22        0.1202  1.5893\n",
      "     23        0.0663  1.5994\n",
      "     24        \u001b[36m0.0560\u001b[0m  1.5969\n",
      "     25        \u001b[36m0.0473\u001b[0m  1.5964\n",
      "     26        0.0679  1.5849\n",
      "     27        0.0488  1.5931\n",
      "     28        \u001b[36m0.0432\u001b[0m  1.6006\n",
      "     29        0.0443  1.6004\n",
      "     30        \u001b[36m0.0371\u001b[0m  1.5957\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  48.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3844\u001b[0m  1.5954\n",
      "      2        \u001b[36m0.2730\u001b[0m  1.5866\n",
      "      3        \u001b[36m0.2252\u001b[0m  1.5924\n",
      "      4        \u001b[36m0.1686\u001b[0m  1.6018\n",
      "      5        \u001b[36m0.1462\u001b[0m  1.5836\n",
      "      6        0.1592  1.6111\n",
      "      7        \u001b[36m0.1408\u001b[0m  1.6033\n",
      "      8        \u001b[36m0.1149\u001b[0m  1.5823\n",
      "      9        \u001b[36m0.1116\u001b[0m  1.5843\n",
      "     10        \u001b[36m0.1106\u001b[0m  1.6039\n",
      "     11        \u001b[36m0.1041\u001b[0m  1.6134\n",
      "     12        \u001b[36m0.0776\u001b[0m  1.6046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13        \u001b[36m0.0765\u001b[0m  1.6052\n",
      "     14        0.1056  1.6044\n",
      "     15        0.1964  1.5867\n",
      "     16        0.1742  1.5925\n",
      "     17        0.1091  1.6070\n",
      "     18        0.0927  1.5989\n",
      "     19        0.0840  1.5731\n",
      "     20        0.1263  1.5712\n",
      "     21        0.0770  1.5836\n",
      "     22        \u001b[36m0.0569\u001b[0m  1.5925\n",
      "     23        0.1900  1.5886\n",
      "     24        0.1186  1.5813\n",
      "     25        0.1418  1.5769\n",
      "     26        0.0908  1.5775\n",
      "     27        0.0701  1.6014\n",
      "     28        0.1915  1.6059\n",
      "     29        0.1338  1.6009\n",
      "     30        0.0907  1.5740\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  48.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3303\u001b[0m  1.5733\n",
      "      2        \u001b[36m0.2197\u001b[0m  1.5696\n",
      "      3        0.2967  1.5854\n",
      "      4        \u001b[36m0.1657\u001b[0m  1.5776\n",
      "      5        \u001b[36m0.1566\u001b[0m  1.6015\n",
      "      6        \u001b[36m0.1179\u001b[0m  1.5888\n",
      "      7        0.1256  1.6069\n",
      "      8        \u001b[36m0.1132\u001b[0m  1.6014\n",
      "      9        \u001b[36m0.0918\u001b[0m  1.5976\n",
      "     10        \u001b[36m0.0818\u001b[0m  1.6017\n",
      "     11        \u001b[36m0.0634\u001b[0m  1.5770\n",
      "     12        \u001b[36m0.0598\u001b[0m  1.6030\n",
      "     13        0.2074  1.5905\n",
      "     14        0.1039  1.6087\n",
      "     15        0.0821  1.5780\n",
      "     16        0.0905  1.5768\n",
      "     17        0.0658  1.5844\n",
      "     18        0.0664  1.5795\n",
      "     19        0.0868  1.5803\n",
      "     20        0.0625  1.5966\n",
      "     21        \u001b[36m0.0561\u001b[0m  1.6014\n",
      "     22        \u001b[36m0.0516\u001b[0m  1.5817\n",
      "     23        \u001b[36m0.0486\u001b[0m  1.6026\n",
      "     24        0.0504  1.5953\n",
      "     25        \u001b[36m0.0454\u001b[0m  1.5844\n",
      "     26        0.0586  1.6088\n",
      "     27        0.0605  1.5819\n",
      "     28        0.0627  1.5875\n",
      "     29        0.0464  1.5830\n",
      "     30        0.0610  1.6061\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=10, total=  48.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3228\u001b[0m  1.7069\n",
      "      2        \u001b[36m0.1797\u001b[0m  1.7115\n",
      "      3        \u001b[36m0.1235\u001b[0m  1.7328\n",
      "      4        \u001b[36m0.1107\u001b[0m  1.7114\n",
      "      5        \u001b[36m0.0889\u001b[0m  1.7338\n",
      "      6        \u001b[36m0.0577\u001b[0m  1.7126\n",
      "      7        \u001b[36m0.0493\u001b[0m  1.7210\n",
      "      8        \u001b[36m0.0447\u001b[0m  1.7099\n",
      "      9        \u001b[36m0.0346\u001b[0m  1.7078\n",
      "     10        \u001b[36m0.0336\u001b[0m  1.7119\n",
      "     11        0.0367  1.7399\n",
      "     12        0.0485  1.7433\n",
      "     13        \u001b[36m0.0286\u001b[0m  1.7405\n",
      "     14        0.0867  1.7172\n",
      "     15        0.0440  1.7209\n",
      "     16        0.0348  1.7154\n",
      "     17        \u001b[36m0.0272\u001b[0m  1.7350\n",
      "     18        0.1514  1.7064\n",
      "     19        0.0576  1.7441\n",
      "     20        0.0445  1.7172\n",
      "     21        0.0374  1.7094\n",
      "     22        0.0317  1.7401\n",
      "     23        0.0377  1.7193\n",
      "     24        0.0272  1.7084\n",
      "     25        0.0305  1.7225\n",
      "     26        \u001b[36m0.0216\u001b[0m  1.7298\n",
      "     27        \u001b[36m0.0212\u001b[0m  1.7335\n",
      "     28        \u001b[36m0.0200\u001b[0m  1.7051\n",
      "     29        \u001b[36m0.0200\u001b[0m  1.7200\n",
      "     30        \u001b[36m0.0173\u001b[0m  1.7148\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  52.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3436\u001b[0m  1.7133\n",
      "      2        \u001b[36m0.1903\u001b[0m  1.7105\n",
      "      3        \u001b[36m0.1180\u001b[0m  1.7178\n",
      "      4        \u001b[36m0.0759\u001b[0m  1.7318\n",
      "      5        \u001b[36m0.0686\u001b[0m  1.7343\n",
      "      6        \u001b[36m0.0473\u001b[0m  1.7156\n",
      "      7        0.1793  1.7132\n",
      "      8        0.0760  1.7122\n",
      "      9        \u001b[36m0.0415\u001b[0m  1.7127\n",
      "     10        \u001b[36m0.0319\u001b[0m  1.7169\n",
      "     11        \u001b[36m0.0237\u001b[0m  1.7007\n",
      "     12        \u001b[36m0.0203\u001b[0m  1.7207\n",
      "     13        0.0287  1.6998\n",
      "     14        0.0220  1.7394\n",
      "     15        \u001b[36m0.0168\u001b[0m  1.7162\n",
      "     16        0.0171  1.7077\n",
      "     17        0.0225  1.7083\n",
      "     18        0.0190  1.7048\n",
      "     19        \u001b[36m0.0167\u001b[0m  1.7141\n",
      "     20        \u001b[36m0.0151\u001b[0m  1.7179\n",
      "     21        \u001b[36m0.0133\u001b[0m  1.7117\n",
      "     22        \u001b[36m0.0119\u001b[0m  1.7172\n",
      "     23        0.0195  1.7219\n",
      "     24        0.0129  1.7228\n",
      "     25        0.0121  1.7173\n",
      "     26        0.0123  1.7437\n",
      "     27        0.2857  1.7050\n",
      "     28        0.0635  1.7216\n",
      "     29        0.0384  1.7203\n",
      "     30        0.0307  1.7160\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  52.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2755\u001b[0m  1.7235\n",
      "      2        \u001b[36m0.1654\u001b[0m  1.7415\n",
      "      3        0.1682  1.7194\n",
      "      4        \u001b[36m0.1066\u001b[0m  1.7178\n",
      "      5        \u001b[36m0.0747\u001b[0m  1.7129\n",
      "      6        \u001b[36m0.0627\u001b[0m  1.7060\n",
      "      7        0.0634  1.7411\n",
      "      8        \u001b[36m0.0581\u001b[0m  1.7205\n",
      "      9        0.0629  1.7287\n",
      "     10        \u001b[36m0.0409\u001b[0m  1.7149\n",
      "     11        \u001b[36m0.0313\u001b[0m  1.7218\n",
      "     12        0.0422  1.7291\n",
      "     13        0.0440  1.7197\n",
      "     14        0.0468  1.7270\n",
      "     15        \u001b[36m0.0286\u001b[0m  1.7327\n",
      "     16        0.0322  1.7299\n",
      "     17        0.0286  1.7356\n",
      "     18        0.0443  1.7443\n",
      "     19        0.0860  1.7211\n",
      "     20        0.0477  1.7063\n",
      "     21        0.0389  1.7134\n",
      "     22        0.0359  1.7326\n",
      "     23        0.3594  1.7213\n",
      "     24        0.4798  1.7304\n",
      "     25        0.3209  1.7170\n",
      "     26        0.2289  1.7239\n",
      "     27        0.2731  1.7048\n",
      "     28        0.4538  1.7151\n",
      "     29        0.2573  1.7156\n",
      "     30        0.1967  1.7310\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  52.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3150\u001b[0m  1.7228\n",
      "      2        \u001b[36m0.1519\u001b[0m  1.7229\n",
      "      3        \u001b[36m0.1243\u001b[0m  1.7241\n",
      "      4        \u001b[36m0.0824\u001b[0m  1.7168\n",
      "      5        \u001b[36m0.0745\u001b[0m  1.7019\n",
      "      6        \u001b[36m0.0624\u001b[0m  1.7220\n",
      "      7        \u001b[36m0.0501\u001b[0m  1.7215\n",
      "      8        \u001b[36m0.0383\u001b[0m  1.7147\n",
      "      9        \u001b[36m0.0262\u001b[0m  1.7143\n",
      "     10        \u001b[36m0.0243\u001b[0m  1.7279\n",
      "     11        \u001b[36m0.0183\u001b[0m  1.7249\n",
      "     12        \u001b[36m0.0176\u001b[0m  1.7169\n",
      "     13        0.0202  1.7190\n",
      "     14        0.0249  1.7278\n",
      "     15        0.0353  1.7194\n",
      "     16        0.0215  1.7135\n",
      "     17        \u001b[36m0.0155\u001b[0m  1.7442\n",
      "     18        \u001b[36m0.0137\u001b[0m  1.7203\n",
      "     19        \u001b[36m0.0120\u001b[0m  1.7178\n",
      "     20        0.0150  1.7045\n",
      "     21        0.0157  1.7183\n",
      "     22        0.0202  1.7215\n",
      "     23        0.0144  1.7198\n",
      "     24        \u001b[36m0.0115\u001b[0m  1.7332\n",
      "     25        0.0136  1.7383\n",
      "     26        0.0155  1.7091\n",
      "     27        0.0133  1.7164\n",
      "     28        0.0211  1.7083\n",
      "     29        0.0159  1.7181\n",
      "     30        \u001b[36m0.0115\u001b[0m  1.7181\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  52.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3178\u001b[0m  1.7164\n",
      "      2        \u001b[36m0.1557\u001b[0m  1.7137\n",
      "      3        \u001b[36m0.1350\u001b[0m  1.7196\n",
      "      4        \u001b[36m0.0727\u001b[0m  1.7129\n",
      "      5        \u001b[36m0.0453\u001b[0m  1.7068\n",
      "      6        \u001b[36m0.0387\u001b[0m  1.7212\n",
      "      7        0.0420  1.7214\n",
      "      8        0.0512  1.7102\n",
      "      9        \u001b[36m0.0264\u001b[0m  1.7227\n",
      "     10        \u001b[36m0.0260\u001b[0m  1.7138\n",
      "     11        0.0397  1.7201\n",
      "     12        \u001b[36m0.0215\u001b[0m  1.7225\n",
      "     13        0.0223  1.7184\n",
      "     14        \u001b[36m0.0159\u001b[0m  1.7436\n",
      "     15        0.0383  1.7191\n",
      "     16        0.0280  1.7402\n",
      "     17        0.0191  1.7182\n",
      "     18        0.0169  1.7250\n",
      "     19        \u001b[36m0.0129\u001b[0m  1.7144\n",
      "     20        0.0314  1.7267\n",
      "     21        0.0363  1.7221\n",
      "     22        0.0215  1.7244\n",
      "     23        0.0170  1.7130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24        0.0155  1.7373\n",
      "     25        0.0185  1.7150\n",
      "     26        0.0159  1.7135\n",
      "     27        0.0166  1.7166\n",
      "     28        0.0132  1.7119\n",
      "     29        0.0272  1.7124\n",
      "     30        0.0153  1.7125\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=40, total=  52.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3013\u001b[0m  2.7474\n",
      "      2        \u001b[36m0.1865\u001b[0m  2.7543\n",
      "      3        \u001b[36m0.1111\u001b[0m  2.7917\n",
      "      4        \u001b[36m0.0654\u001b[0m  2.7392\n",
      "      5        0.3371  2.7464\n",
      "      6        0.3468  2.7474\n",
      "      7        0.2014  2.7536\n",
      "      8        0.1410  2.8296\n",
      "      9        0.1245  2.7911\n",
      "     10        0.0877  2.8098\n",
      "     11        0.0720  2.8380\n",
      "     12        0.0692  2.7759\n",
      "     13        \u001b[36m0.0644\u001b[0m  2.9106\n",
      "     14        \u001b[36m0.0551\u001b[0m  2.7629\n",
      "     15        \u001b[36m0.0476\u001b[0m  2.7555\n",
      "     16        0.0491  2.7544\n",
      "     17        \u001b[36m0.0412\u001b[0m  2.7755\n",
      "     18        0.0430  2.8052\n",
      "     19        0.0467  2.7724\n",
      "     20        \u001b[36m0.0308\u001b[0m  2.7981\n",
      "     21        0.0342  2.7556\n",
      "     22        0.0344  2.7782\n",
      "     23        \u001b[36m0.0296\u001b[0m  2.7523\n",
      "     24        \u001b[36m0.0272\u001b[0m  2.7844\n",
      "     25        \u001b[36m0.0250\u001b[0m  2.7462\n",
      "     26        \u001b[36m0.0245\u001b[0m  2.7694\n",
      "     27        \u001b[36m0.0207\u001b[0m  2.7461\n",
      "     28        0.0324  2.7836\n",
      "     29        0.0278  2.7390\n",
      "     30        0.0338  2.7567\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3338\u001b[0m  2.7742\n",
      "      2        \u001b[36m0.1402\u001b[0m  2.7551\n",
      "      3        \u001b[36m0.0988\u001b[0m  2.7574\n",
      "      4        \u001b[36m0.0591\u001b[0m  2.7609\n",
      "      5        \u001b[36m0.0352\u001b[0m  2.7622\n",
      "      6        \u001b[36m0.0333\u001b[0m  2.7577\n",
      "      7        \u001b[36m0.0311\u001b[0m  2.7572\n",
      "      8        0.0347  2.7553\n",
      "      9        \u001b[36m0.0197\u001b[0m  2.7582\n",
      "     10        \u001b[36m0.0191\u001b[0m  2.7491\n",
      "     11        \u001b[36m0.0142\u001b[0m  2.7514\n",
      "     12        \u001b[36m0.0131\u001b[0m  2.7634\n",
      "     13        0.0499  2.7538\n",
      "     14        0.4145  2.7506\n",
      "     15        0.3164  2.7554\n",
      "     16        0.6960  2.7596\n",
      "     17        0.5325  2.7553\n",
      "     18        0.4727  2.7502\n",
      "     19        0.4431  2.7552\n",
      "     20        0.4073  2.7514\n",
      "     21        0.3743  2.7569\n",
      "     22        0.3327  2.7496\n",
      "     23        0.3528  2.7616\n",
      "     24        0.3481  2.7442\n",
      "     25        0.2680  2.7431\n",
      "     26        0.2364  2.7649\n",
      "     27        0.2027  2.7490\n",
      "     28        0.1698  2.7583\n",
      "     29        0.1260  2.7557\n",
      "     30        0.0982  2.7535\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3145\u001b[0m  2.7204\n",
      "      2        \u001b[36m0.1491\u001b[0m  2.7338\n",
      "      3        0.3298  2.7171\n",
      "      4        0.3294  2.7182\n",
      "      5        0.1698  2.7167\n",
      "      6        0.1507  2.7290\n",
      "      7        0.5783  2.7326\n",
      "      8        0.5198  2.7361\n",
      "      9        0.4687  2.7269\n",
      "     10        0.4297  2.7230\n",
      "     11        0.3823  2.7232\n",
      "     12        0.3587  2.7303\n",
      "     13        0.2897  2.7305\n",
      "     14        0.2245  2.7320\n",
      "     15        0.1805  2.7375\n",
      "     16        0.1581  2.7326\n",
      "     17        0.2285  2.7306\n",
      "     18        0.1777  2.7453\n",
      "     19        0.1635  2.7317\n",
      "     20        \u001b[36m0.1478\u001b[0m  2.7160\n",
      "     21        \u001b[36m0.1181\u001b[0m  2.7126\n",
      "     22        0.1271  2.7289\n",
      "     23        \u001b[36m0.0952\u001b[0m  2.7183\n",
      "     24        0.0957  2.7174\n",
      "     25        0.1122  2.7203\n",
      "     26        \u001b[36m0.0950\u001b[0m  2.7335\n",
      "     27        \u001b[36m0.0660\u001b[0m  2.7262\n",
      "     28        0.0682  2.7325\n",
      "     29        \u001b[36m0.0521\u001b[0m  2.7270\n",
      "     30        \u001b[36m0.0460\u001b[0m  2.7277\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2816\u001b[0m  2.7438\n",
      "      2        \u001b[36m0.1315\u001b[0m  2.7490\n",
      "      3        \u001b[36m0.0713\u001b[0m  2.7495\n",
      "      4        \u001b[36m0.0670\u001b[0m  2.7518\n",
      "      5        \u001b[36m0.0589\u001b[0m  2.7326\n",
      "      6        \u001b[36m0.0276\u001b[0m  2.7437\n",
      "      7        0.0328  2.7439\n",
      "      8        0.0375  2.7419\n",
      "      9        \u001b[36m0.0259\u001b[0m  2.7396\n",
      "     10        \u001b[36m0.0226\u001b[0m  2.7407\n",
      "     11        \u001b[36m0.0197\u001b[0m  2.7468\n",
      "     12        \u001b[36m0.0186\u001b[0m  2.7463\n",
      "     13        \u001b[36m0.0156\u001b[0m  2.7325\n",
      "     14        0.0156  2.7518\n",
      "     15        0.0215  2.7491\n",
      "     16        0.0193  2.7497\n",
      "     17        \u001b[36m0.0130\u001b[0m  2.7416\n",
      "     18        0.0154  2.7458\n",
      "     19        0.0152  2.7346\n",
      "     20        0.0136  2.7434\n",
      "     21        \u001b[36m0.0122\u001b[0m  2.7485\n",
      "     22        0.4211  2.7425\n",
      "     23        0.2854  2.7439\n",
      "     24        0.0823  2.7410\n",
      "     25        0.0638  2.7428\n",
      "     26        0.0520  2.7433\n",
      "     27        0.0486  2.7413\n",
      "     28        0.0532  2.7405\n",
      "     29        0.0342  2.7452\n",
      "     30        0.0336  2.7538\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3597\u001b[0m  2.7570\n",
      "      2        \u001b[36m0.1613\u001b[0m  2.7577\n",
      "      3        \u001b[36m0.1462\u001b[0m  2.7455\n",
      "      4        \u001b[36m0.0886\u001b[0m  2.7459\n",
      "      5        \u001b[36m0.0701\u001b[0m  2.7539\n",
      "      6        \u001b[36m0.0541\u001b[0m  2.7567\n",
      "      7        \u001b[36m0.0353\u001b[0m  2.7596\n",
      "      8        \u001b[36m0.0286\u001b[0m  2.7481\n",
      "      9        \u001b[36m0.0212\u001b[0m  2.7816\n",
      "     10        0.0288  2.7675\n",
      "     11        0.0305  2.7508\n",
      "     12        0.0292  2.7523\n",
      "     13        0.0236  2.7565\n",
      "     14        \u001b[36m0.0131\u001b[0m  2.7593\n",
      "     15        0.0205  2.7432\n",
      "     16        0.0190  2.7616\n",
      "     17        0.0151  2.7598\n",
      "     18        0.0379  2.7546\n",
      "     19        0.3097  2.7469\n",
      "     20        0.5425  2.7571\n",
      "     21        0.3560  2.7555\n",
      "     22        0.2384  2.7519\n",
      "     23        0.1626  2.7510\n",
      "     24        0.5093  2.7389\n",
      "     25        0.4456  2.7538\n",
      "     26        0.2436  2.7556\n",
      "     27        0.1596  2.7575\n",
      "     28        0.1146  2.7507\n",
      "     29        0.1851  2.7384\n",
      "     30        0.2655  2.7694\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3152\u001b[0m  2.5197\n",
      "      2        \u001b[36m0.2060\u001b[0m  2.5319\n",
      "      3        0.2528  2.5313\n",
      "      4        0.3638  2.5422\n",
      "      5        0.3582  2.5227\n",
      "      6        \u001b[36m0.1365\u001b[0m  2.5206\n",
      "      7        \u001b[36m0.0783\u001b[0m  2.5398\n",
      "      8        \u001b[36m0.0690\u001b[0m  2.5376\n",
      "      9        \u001b[36m0.0486\u001b[0m  2.5302\n",
      "     10        0.1762  2.5312\n",
      "     11        0.0610  2.5320\n",
      "     12        \u001b[36m0.0421\u001b[0m  2.5459\n",
      "     13        0.0489  2.5395\n",
      "     14        \u001b[36m0.0332\u001b[0m  2.5390\n",
      "     15        \u001b[36m0.0277\u001b[0m  2.5364\n",
      "     16        0.0589  2.5478\n",
      "     17        0.0307  2.5419\n",
      "     18        0.0377  2.5336\n",
      "     19        \u001b[36m0.0272\u001b[0m  2.5331\n",
      "     20        0.0380  2.5297\n",
      "     21        \u001b[36m0.0239\u001b[0m  2.5278\n",
      "     22        \u001b[36m0.0183\u001b[0m  2.5315\n",
      "     23        \u001b[36m0.0174\u001b[0m  2.5216\n",
      "     24        0.0699  2.5381\n",
      "     25        0.0347  2.5428\n",
      "     26        0.0200  2.5401\n",
      "     27        0.0284  2.5359\n",
      "     28        0.0225  2.5327\n",
      "     29        \u001b[36m0.0173\u001b[0m  2.5380\n",
      "     30        0.0200  2.5307\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3127\u001b[0m  2.5240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.1636\u001b[0m  2.5268\n",
      "      3        \u001b[36m0.0921\u001b[0m  2.5377\n",
      "      4        \u001b[36m0.0623\u001b[0m  2.5486\n",
      "      5        \u001b[36m0.0313\u001b[0m  2.5487\n",
      "      6        \u001b[36m0.0252\u001b[0m  2.5423\n",
      "      7        0.0458  2.5454\n",
      "      8        \u001b[36m0.0244\u001b[0m  2.5490\n",
      "      9        \u001b[36m0.0193\u001b[0m  2.5484\n",
      "     10        \u001b[36m0.0187\u001b[0m  2.5464\n",
      "     11        \u001b[36m0.0168\u001b[0m  2.5406\n",
      "     12        \u001b[36m0.0154\u001b[0m  2.5444\n",
      "     13        0.0308  2.5412\n",
      "     14        0.0162  2.5467\n",
      "     15        \u001b[36m0.0130\u001b[0m  2.5349\n",
      "     16        \u001b[36m0.0122\u001b[0m  2.5468\n",
      "     17        0.0146  2.5431\n",
      "     18        0.0180  2.5448\n",
      "     19        0.0128  2.5491\n",
      "     20        0.0178  2.5499\n",
      "     21        \u001b[36m0.0113\u001b[0m  2.5367\n",
      "     22        0.0115  2.5450\n",
      "     23        0.3705  2.5412\n",
      "     24        0.1412  2.5355\n",
      "     25        0.0786  2.5474\n",
      "     26        0.1114  2.5452\n",
      "     27        0.0645  2.5424\n",
      "     28        0.0663  2.5433\n",
      "     29        0.0466  2.5423\n",
      "     30        0.0352  2.5449\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3993\u001b[0m  2.5425\n",
      "      2        \u001b[36m0.2189\u001b[0m  2.5665\n",
      "      3        \u001b[36m0.1114\u001b[0m  2.5415\n",
      "      4        \u001b[36m0.0741\u001b[0m  2.5469\n",
      "      5        0.4253  2.5505\n",
      "      6        0.1599  2.5532\n",
      "      7        0.0771  2.5487\n",
      "      8        \u001b[36m0.0599\u001b[0m  2.5492\n",
      "      9        \u001b[36m0.0568\u001b[0m  2.5344\n",
      "     10        \u001b[36m0.0449\u001b[0m  2.5414\n",
      "     11        \u001b[36m0.0426\u001b[0m  2.5474\n",
      "     12        \u001b[36m0.0414\u001b[0m  2.5541\n",
      "     13        \u001b[36m0.0305\u001b[0m  2.5546\n",
      "     14        \u001b[36m0.0255\u001b[0m  2.5538\n",
      "     15        \u001b[36m0.0191\u001b[0m  2.5350\n",
      "     16        0.0236  2.5426\n",
      "     17        0.0797  2.5465\n",
      "     18        0.0377  2.5452\n",
      "     19        0.0230  2.5503\n",
      "     20        \u001b[36m0.0165\u001b[0m  2.5352\n",
      "     21        0.0187  2.5478\n",
      "     22        0.0207  2.5491\n",
      "     23        \u001b[36m0.0126\u001b[0m  2.5477\n",
      "     24        0.0198  2.5441\n",
      "     25        0.0270  2.5482\n",
      "     26        0.2028  2.5407\n",
      "     27        0.1074  2.5423\n",
      "     28        0.0768  2.5420\n",
      "     29        0.0533  2.5458\n",
      "     30        0.0536  2.5501\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2920\u001b[0m  2.5458\n",
      "      2        \u001b[36m0.2673\u001b[0m  2.5518\n",
      "      3        0.5097  2.5415\n",
      "      4        \u001b[36m0.2241\u001b[0m  2.5344\n",
      "      5        \u001b[36m0.1581\u001b[0m  2.5312\n",
      "      6        0.1592  2.5469\n",
      "      7        \u001b[36m0.1130\u001b[0m  2.5454\n",
      "      8        0.1207  2.5464\n",
      "      9        0.1311  2.5433\n",
      "     10        \u001b[36m0.0885\u001b[0m  2.5519\n",
      "     11        0.1115  2.5497\n",
      "     12        \u001b[36m0.0817\u001b[0m  2.5516\n",
      "     13        0.0857  2.5439\n",
      "     14        \u001b[36m0.0675\u001b[0m  2.5533\n",
      "     15        \u001b[36m0.0489\u001b[0m  2.5545\n",
      "     16        0.0542  2.5598\n",
      "     17        0.1104  2.5444\n",
      "     18        0.0532  2.5449\n",
      "     19        \u001b[36m0.0431\u001b[0m  2.5592\n",
      "     20        \u001b[36m0.0328\u001b[0m  2.5540\n",
      "     21        \u001b[36m0.0320\u001b[0m  2.5550\n",
      "     22        0.0332  2.5556\n",
      "     23        0.0376  2.5465\n",
      "     24        \u001b[36m0.0291\u001b[0m  2.5470\n",
      "     25        0.0344  2.5451\n",
      "     26        \u001b[36m0.0219\u001b[0m  2.5367\n",
      "     27        0.0336  2.5526\n",
      "     28        0.0224  2.5455\n",
      "     29        0.0222  2.5343\n",
      "     30        0.0262  2.5371\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3431\u001b[0m  2.5032\n",
      "      2        \u001b[36m0.1635\u001b[0m  2.5107\n",
      "      3        \u001b[36m0.0842\u001b[0m  2.5093\n",
      "      4        \u001b[36m0.0516\u001b[0m  2.4992\n",
      "      5        \u001b[36m0.0366\u001b[0m  2.4973\n",
      "      6        0.1411  2.5072\n",
      "      7        0.1135  2.4965\n",
      "      8        0.0628  2.5007\n",
      "      9        0.0597  2.5079\n",
      "     10        0.3616  2.5022\n",
      "     11        0.0906  2.5011\n",
      "     12        0.0487  2.5067\n",
      "     13        \u001b[36m0.0327\u001b[0m  2.5101\n",
      "     14        \u001b[36m0.0264\u001b[0m  2.4988\n",
      "     15        0.3281  2.5060\n",
      "     16        0.1029  2.5135\n",
      "     17        0.0852  2.5011\n",
      "     18        0.4191  2.4999\n",
      "     19        0.2334  2.5005\n",
      "     20        0.1895  2.4989\n",
      "     21        0.1639  2.5125\n",
      "     22        0.1303  2.5055\n",
      "     23        0.0577  2.5075\n",
      "     24        0.0574  2.5053\n",
      "     25        0.0450  2.5183\n",
      "     26        0.0340  2.5148\n",
      "     27        0.0333  2.5163\n",
      "     28        0.1022  2.5146\n",
      "     29        0.1271  2.5067\n",
      "     30        0.0523  2.4950\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.4, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3405\u001b[0m  1.5817\n",
      "      2        \u001b[36m0.2779\u001b[0m  1.5793\n",
      "      3        \u001b[36m0.2678\u001b[0m  1.5834\n",
      "      4        \u001b[36m0.2249\u001b[0m  1.5969\n",
      "      5        \u001b[36m0.1542\u001b[0m  1.5899\n",
      "      6        \u001b[36m0.1278\u001b[0m  1.5807\n",
      "      7        0.1519  1.5974\n",
      "      8        \u001b[36m0.1130\u001b[0m  1.6126\n",
      "      9        \u001b[36m0.0910\u001b[0m  1.6076\n",
      "     10        \u001b[36m0.0784\u001b[0m  1.5938\n",
      "     11        0.0826  1.5847\n",
      "     12        0.0958  1.6102\n",
      "     13        0.0926  1.5900\n",
      "     14        \u001b[36m0.0713\u001b[0m  1.5923\n",
      "     15        \u001b[36m0.0650\u001b[0m  1.6124\n",
      "     16        \u001b[36m0.0552\u001b[0m  1.6026\n",
      "     17        0.0644  1.5793\n",
      "     18        \u001b[36m0.0543\u001b[0m  1.6038\n",
      "     19        \u001b[36m0.0464\u001b[0m  1.5856\n",
      "     20        \u001b[36m0.0457\u001b[0m  1.5983\n",
      "     21        0.0463  1.5733\n",
      "     22        0.0542  1.5725\n",
      "     23        0.0535  1.6094\n",
      "     24        0.0460  1.5898\n",
      "     25        0.0607  1.5800\n",
      "     26        0.0459  1.5893\n",
      "     27        \u001b[36m0.0377\u001b[0m  1.6020\n",
      "     28        0.0496  1.5863\n",
      "     29        0.0497  1.6003\n",
      "     30        0.0387  1.6063\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  48.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3404\u001b[0m  1.5703\n",
      "      2        \u001b[36m0.2363\u001b[0m  1.6033\n",
      "      3        0.3105  1.5987\n",
      "      4        0.2643  1.6049\n",
      "      5        \u001b[36m0.2019\u001b[0m  1.6083\n",
      "      6        0.2890  1.6053\n",
      "      7        0.2244  1.5941\n",
      "      8        0.2547  1.6049\n",
      "      9        \u001b[36m0.1766\u001b[0m  1.5782\n",
      "     10        \u001b[36m0.1505\u001b[0m  1.5934\n",
      "     11        \u001b[36m0.1300\u001b[0m  1.5992\n",
      "     12        \u001b[36m0.1127\u001b[0m  1.5925\n",
      "     13        \u001b[36m0.1003\u001b[0m  1.6010\n",
      "     14        \u001b[36m0.0897\u001b[0m  1.5866\n",
      "     15        0.2592  1.5698\n",
      "     16        0.2258  1.5906\n",
      "     17        0.1543  1.5730\n",
      "     18        0.1120  1.5884\n",
      "     19        0.0942  1.5984\n",
      "     20        \u001b[36m0.0798\u001b[0m  1.6129\n",
      "     21        0.1453  1.5987\n",
      "     22        0.0924  1.5928\n",
      "     23        0.0806  1.6001\n",
      "     24        \u001b[36m0.0716\u001b[0m  1.5996\n",
      "     25        \u001b[36m0.0674\u001b[0m  1.6012\n",
      "     26        \u001b[36m0.0615\u001b[0m  1.5756\n",
      "     27        \u001b[36m0.0577\u001b[0m  1.6013\n",
      "     28        0.0757  1.5843\n",
      "     29        \u001b[36m0.0562\u001b[0m  1.5848\n",
      "     30        0.1044  1.5957\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  48.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3450\u001b[0m  1.6066\n",
      "      2        \u001b[36m0.2090\u001b[0m  1.5952\n",
      "      3        \u001b[36m0.1911\u001b[0m  1.5943\n",
      "      4        \u001b[36m0.1565\u001b[0m  1.5917\n",
      "      5        \u001b[36m0.1372\u001b[0m  1.5909\n",
      "      6        \u001b[36m0.0997\u001b[0m  1.5903\n",
      "      7        0.1440  1.6087\n",
      "      8        0.1974  1.5893\n",
      "      9        0.1085  1.5825\n",
      "     10        \u001b[36m0.0750\u001b[0m  1.5982\n",
      "     11        \u001b[36m0.0629\u001b[0m  1.6021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12        0.0974  1.6052\n",
      "     13        0.1045  1.6031\n",
      "     14        0.0804  1.6076\n",
      "     15        \u001b[36m0.0621\u001b[0m  1.6076\n",
      "     16        0.0787  1.5980\n",
      "     17        0.0821  1.6008\n",
      "     18        0.3743  1.6092\n",
      "     19        0.4034  1.5723\n",
      "     20        0.3021  1.5720\n",
      "     21        0.2469  1.6008\n",
      "     22        0.1888  1.5765\n",
      "     23        0.1618  1.5989\n",
      "     24        0.1457  1.5830\n",
      "     25        0.1314  1.6058\n",
      "     26        0.1263  1.5822\n",
      "     27        0.1162  1.5659\n",
      "     28        0.1085  1.5890\n",
      "     29        0.0983  1.5973\n",
      "     30        0.0885  1.6010\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  48.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3725\u001b[0m  1.5839\n",
      "      2        \u001b[36m0.2426\u001b[0m  1.5899\n",
      "      3        \u001b[36m0.1741\u001b[0m  1.5723\n",
      "      4        0.1806  1.5862\n",
      "      5        \u001b[36m0.1658\u001b[0m  1.5804\n",
      "      6        0.1662  1.5968\n",
      "      7        0.1817  1.6015\n",
      "      8        \u001b[36m0.1254\u001b[0m  1.5849\n",
      "      9        \u001b[36m0.1020\u001b[0m  1.6043\n",
      "     10        0.1074  1.5794\n",
      "     11        \u001b[36m0.0792\u001b[0m  1.5912\n",
      "     12        0.1244  1.5981\n",
      "     13        0.1050  1.5866\n",
      "     14        0.0848  1.5897\n",
      "     15        \u001b[36m0.0666\u001b[0m  1.5862\n",
      "     16        0.1625  1.5878\n",
      "     17        0.1008  1.6074\n",
      "     18        0.0930  1.6085\n",
      "     19        0.1648  1.5982\n",
      "     20        0.1808  1.5723\n",
      "     21        0.1472  1.5707\n",
      "     22        0.1396  1.5712\n",
      "     23        0.2006  1.5791\n",
      "     24        0.1760  1.5855\n",
      "     25        0.2257  1.6006\n",
      "     26        0.1654  1.6015\n",
      "     27        0.1388  1.5772\n",
      "     28        0.1264  1.6141\n",
      "     29        0.1162  1.5848\n",
      "     30        0.1260  1.6043\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  48.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3891\u001b[0m  1.5906\n",
      "      2        \u001b[36m0.2183\u001b[0m  1.5857\n",
      "      3        \u001b[36m0.2179\u001b[0m  1.5741\n",
      "      4        \u001b[36m0.1436\u001b[0m  1.5835\n",
      "      5        0.1567  1.5903\n",
      "      6        0.1637  1.6038\n",
      "      7        \u001b[36m0.1019\u001b[0m  1.6004\n",
      "      8        \u001b[36m0.0825\u001b[0m  1.5998\n",
      "      9        \u001b[36m0.0675\u001b[0m  1.5945\n",
      "     10        0.0695  1.5834\n",
      "     11        0.0696  1.5762\n",
      "     12        0.1305  1.5996\n",
      "     13        0.1285  1.6009\n",
      "     14        0.0781  1.5942\n",
      "     15        0.0822  1.5907\n",
      "     16        \u001b[36m0.0561\u001b[0m  1.5782\n",
      "     17        0.1129  1.5976\n",
      "     18        0.0691  1.5903\n",
      "     19        \u001b[36m0.0483\u001b[0m  1.6037\n",
      "     20        0.0496  1.6069\n",
      "     21        \u001b[36m0.0472\u001b[0m  1.6005\n",
      "     22        \u001b[36m0.0412\u001b[0m  1.6145\n",
      "     23        0.0922  1.5834\n",
      "     24        0.0514  1.5969\n",
      "     25        0.0489  1.5862\n",
      "     26        \u001b[36m0.0400\u001b[0m  1.5994\n",
      "     27        0.0613  1.6011\n",
      "     28        \u001b[36m0.0394\u001b[0m  1.6052\n",
      "     29        \u001b[36m0.0369\u001b[0m  1.6125\n",
      "     30        0.0467  1.6058\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=10, total=  48.5s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3805\u001b[0m  1.7180\n",
      "      2        \u001b[36m0.2276\u001b[0m  1.7205\n",
      "      3        \u001b[36m0.1556\u001b[0m  1.7270\n",
      "      4        \u001b[36m0.1089\u001b[0m  1.7195\n",
      "      5        0.1824  1.7123\n",
      "      6        0.1685  1.7207\n",
      "      7        0.4469  1.7274\n",
      "      8        0.5157  1.7328\n",
      "      9        0.3525  1.7345\n",
      "     10        0.2336  1.7183\n",
      "     11        0.1673  1.7183\n",
      "     12        0.1184  1.7303\n",
      "     13        \u001b[36m0.0997\u001b[0m  1.7125\n",
      "     14        \u001b[36m0.0784\u001b[0m  1.7318\n",
      "     15        0.0801  1.7215\n",
      "     16        \u001b[36m0.0659\u001b[0m  1.7223\n",
      "     17        \u001b[36m0.0534\u001b[0m  1.7182\n",
      "     18        0.0650  1.7263\n",
      "     19        \u001b[36m0.0418\u001b[0m  1.7144\n",
      "     20        0.1729  1.7206\n",
      "     21        0.0662  1.7157\n",
      "     22        0.0590  1.7192\n",
      "     23        0.1175  1.7208\n",
      "     24        0.0450  1.7286\n",
      "     25        0.0474  1.7262\n",
      "     26        \u001b[36m0.0375\u001b[0m  1.7393\n",
      "     27        \u001b[36m0.0327\u001b[0m  1.7181\n",
      "     28        0.0400  1.7109\n",
      "     29        \u001b[36m0.0291\u001b[0m  1.7112\n",
      "     30        0.0432  1.7102\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  52.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3488\u001b[0m  1.7234\n",
      "      2        \u001b[36m0.1573\u001b[0m  1.7304\n",
      "      3        \u001b[36m0.0936\u001b[0m  1.7224\n",
      "      4        \u001b[36m0.0687\u001b[0m  1.7174\n",
      "      5        \u001b[36m0.0441\u001b[0m  1.7344\n",
      "      6        \u001b[36m0.0372\u001b[0m  1.7408\n",
      "      7        \u001b[36m0.0365\u001b[0m  1.7115\n",
      "      8        \u001b[36m0.0304\u001b[0m  1.7076\n",
      "      9        \u001b[36m0.0227\u001b[0m  1.7192\n",
      "     10        \u001b[36m0.0194\u001b[0m  1.7185\n",
      "     11        0.0279  1.7055\n",
      "     12        0.0241  1.7215\n",
      "     13        0.0198  1.7214\n",
      "     14        0.0234  1.7208\n",
      "     15        0.0251  1.7121\n",
      "     16        0.0199  1.7141\n",
      "     17        \u001b[36m0.0169\u001b[0m  1.7192\n",
      "     18        \u001b[36m0.0136\u001b[0m  1.7140\n",
      "     19        0.0155  1.7356\n",
      "     20        0.0301  1.7197\n",
      "     21        0.0573  1.7209\n",
      "     22        0.0501  1.7114\n",
      "     23        0.0379  1.7093\n",
      "     24        0.0270  1.7248\n",
      "     25        0.0223  1.7146\n",
      "     26        0.0191  1.7144\n",
      "     27        0.1354  1.7193\n",
      "     28        0.0538  1.7186\n",
      "     29        0.0943  1.7349\n",
      "     30        0.0570  1.7255\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  52.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3201\u001b[0m  1.7219\n",
      "      2        \u001b[36m0.1594\u001b[0m  1.7070\n",
      "      3        \u001b[36m0.0965\u001b[0m  1.7094\n",
      "      4        0.1514  1.7158\n",
      "      5        0.4806  1.7303\n",
      "      6        0.3828  1.7270\n",
      "      7        0.2348  1.7170\n",
      "      8        0.1732  1.7203\n",
      "      9        0.1018  1.7036\n",
      "     10        \u001b[36m0.0944\u001b[0m  1.7103\n",
      "     11        \u001b[36m0.0700\u001b[0m  1.7143\n",
      "     12        \u001b[36m0.0558\u001b[0m  1.7263\n",
      "     13        0.0896  1.7053\n",
      "     14        0.1218  1.7208\n",
      "     15        0.2319  1.7171\n",
      "     16        0.1970  1.7222\n",
      "     17        0.1116  1.7466\n",
      "     18        0.0803  1.7020\n",
      "     19        0.0670  1.7024\n",
      "     20        0.0679  1.7024\n",
      "     21        \u001b[36m0.0519\u001b[0m  1.7064\n",
      "     22        \u001b[36m0.0401\u001b[0m  1.7057\n",
      "     23        0.0405  1.7198\n",
      "     24        \u001b[36m0.0355\u001b[0m  1.7140\n",
      "     25        \u001b[36m0.0307\u001b[0m  1.7102\n",
      "     26        0.0325  1.7129\n",
      "     27        0.0374  1.7108\n",
      "     28        \u001b[36m0.0260\u001b[0m  1.7118\n",
      "     29        0.0266  1.7059\n",
      "     30        0.0442  1.7064\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  52.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3455\u001b[0m  1.7116\n",
      "      2        \u001b[36m0.1851\u001b[0m  1.7082\n",
      "      3        0.1942  1.7243\n",
      "      4        \u001b[36m0.1246\u001b[0m  1.7548\n",
      "      5        \u001b[36m0.0886\u001b[0m  1.7416\n",
      "      6        \u001b[36m0.0689\u001b[0m  1.7470\n",
      "      7        \u001b[36m0.0476\u001b[0m  1.7728\n",
      "      8        \u001b[36m0.0388\u001b[0m  1.7334\n",
      "      9        \u001b[36m0.0311\u001b[0m  1.7405\n",
      "     10        0.0379  1.7363\n",
      "     11        0.0405  1.7292\n",
      "     12        0.0540  1.7216\n",
      "     13        0.0650  1.7313\n",
      "     14        0.0352  1.7442\n",
      "     15        \u001b[36m0.0271\u001b[0m  1.8219\n",
      "     16        0.0405  1.7918\n",
      "     17        \u001b[36m0.0258\u001b[0m  1.8068\n",
      "     18        \u001b[36m0.0200\u001b[0m  1.7350\n",
      "     19        \u001b[36m0.0197\u001b[0m  1.7918\n",
      "     20        0.0208  1.7378\n",
      "     21        0.0266  1.7429\n",
      "     22        0.0208  1.7355\n",
      "     23        0.0218  1.7171\n",
      "     24        \u001b[36m0.0195\u001b[0m  1.7409\n",
      "     25        \u001b[36m0.0159\u001b[0m  1.7222\n",
      "     26        0.0211  1.7321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27        0.0177  1.7327\n",
      "     28        0.0305  1.7289\n",
      "     29        0.0305  1.7414\n",
      "     30        0.0306  1.7733\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  53.1s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3587\u001b[0m  1.7716\n",
      "      2        \u001b[36m0.2098\u001b[0m  1.7427\n",
      "      3        \u001b[36m0.1244\u001b[0m  1.7399\n",
      "      4        \u001b[36m0.0881\u001b[0m  1.7147\n",
      "      5        \u001b[36m0.0606\u001b[0m  1.7665\n",
      "      6        0.0888  1.7264\n",
      "      7        0.0659  1.7234\n",
      "      8        \u001b[36m0.0478\u001b[0m  1.7306\n",
      "      9        0.3567  1.7498\n",
      "     10        0.6233  1.7121\n",
      "     11        0.5526  1.7167\n",
      "     12        0.5101  1.7469\n",
      "     13        0.4803  1.7099\n",
      "     14        0.4592  1.7181\n",
      "     15        0.4346  1.7394\n",
      "     16        0.4258  1.7428\n",
      "     17        0.3963  1.7165\n",
      "     18        0.3764  1.7265\n",
      "     19        0.4233  1.7355\n",
      "     20        0.6762  1.7395\n",
      "     21        0.4755  1.7309\n",
      "     22        0.4292  1.7417\n",
      "     23        0.3834  1.7115\n",
      "     24        0.3160  1.7279\n",
      "     25        0.2821  1.7212\n",
      "     26        0.2477  1.7266\n",
      "     27        0.2185  1.7179\n",
      "     28        0.2043  1.7132\n",
      "     29        0.1478  1.7174\n",
      "     30        0.1492  1.7233\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=40, total=  52.6s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4056\u001b[0m  2.7517\n",
      "      2        \u001b[36m0.1825\u001b[0m  2.7482\n",
      "      3        \u001b[36m0.1255\u001b[0m  2.7458\n",
      "      4        0.1359  2.7516\n",
      "      5        \u001b[36m0.0991\u001b[0m  2.7524\n",
      "      6        \u001b[36m0.0694\u001b[0m  2.7540\n",
      "      7        \u001b[36m0.0671\u001b[0m  2.7476\n",
      "      8        \u001b[36m0.0550\u001b[0m  2.7553\n",
      "      9        0.1030  2.7494\n",
      "     10        0.0832  2.7475\n",
      "     11        0.0643  2.7485\n",
      "     12        0.0691  2.7468\n",
      "     13        \u001b[36m0.0395\u001b[0m  2.7502\n",
      "     14        0.1064  2.7586\n",
      "     15        0.3431  2.7453\n",
      "     16        0.1467  2.7521\n",
      "     17        0.3790  2.7477\n",
      "     18        0.2063  2.7508\n",
      "     19        0.1186  2.7519\n",
      "     20        0.0954  2.7600\n",
      "     21        0.0699  2.7530\n",
      "     22        0.0922  2.7552\n",
      "     23        0.0782  2.7381\n",
      "     24        0.0651  2.7437\n",
      "     25        0.0718  2.7479\n",
      "     26        0.0538  2.7479\n",
      "     27        \u001b[36m0.0387\u001b[0m  2.7484\n",
      "     28        0.0470  2.7521\n",
      "     29        0.0462  2.7499\n",
      "     30        0.0399  2.7423\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3584\u001b[0m  2.7481\n",
      "      2        \u001b[36m0.1438\u001b[0m  2.7566\n",
      "      3        \u001b[36m0.0691\u001b[0m  2.7467\n",
      "      4        \u001b[36m0.0548\u001b[0m  2.7491\n",
      "      5        \u001b[36m0.0444\u001b[0m  2.7505\n",
      "      6        \u001b[36m0.0315\u001b[0m  2.7504\n",
      "      7        \u001b[36m0.0260\u001b[0m  2.7522\n",
      "      8        \u001b[36m0.0247\u001b[0m  2.7528\n",
      "      9        0.0301  2.7478\n",
      "     10        0.0258  2.7587\n",
      "     11        \u001b[36m0.0175\u001b[0m  2.7520\n",
      "     12        0.0253  2.7473\n",
      "     13        0.0311  2.7537\n",
      "     14        0.7504  2.7540\n",
      "     15        0.5637  2.7362\n",
      "     16        0.3166  2.7369\n",
      "     17        0.3460  2.7496\n",
      "     18        0.2489  2.7388\n",
      "     19        0.1837  2.7546\n",
      "     20        0.1402  2.7484\n",
      "     21        0.2202  2.7492\n",
      "     22        0.3462  2.7513\n",
      "     23        0.3634  2.7488\n",
      "     24        0.2314  2.7538\n",
      "     25        0.0886  2.7375\n",
      "     26        0.0821  2.7528\n",
      "     27        0.0670  2.7520\n",
      "     28        0.0569  2.7543\n",
      "     29        0.0483  2.7548\n",
      "     30        0.0498  2.7565\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3384\u001b[0m  2.7584\n",
      "      2        \u001b[36m0.1642\u001b[0m  2.7662\n",
      "      3        \u001b[36m0.0778\u001b[0m  2.7558\n",
      "      4        \u001b[36m0.0566\u001b[0m  2.7570\n",
      "      5        \u001b[36m0.0422\u001b[0m  2.7584\n",
      "      6        \u001b[36m0.0311\u001b[0m  2.7616\n",
      "      7        \u001b[36m0.0307\u001b[0m  2.7549\n",
      "      8        0.0309  2.7552\n",
      "      9        \u001b[36m0.0208\u001b[0m  2.7544\n",
      "     10        \u001b[36m0.0184\u001b[0m  2.7609\n",
      "     11        0.0432  2.7447\n",
      "     12        0.4283  2.7428\n",
      "     13        0.3922  2.7412\n",
      "     14        0.2193  2.7528\n",
      "     15        0.0979  2.7607\n",
      "     16        0.0631  2.7472\n",
      "     17        0.0519  2.7661\n",
      "     18        0.0399  2.7441\n",
      "     19        0.0445  2.7616\n",
      "     20        0.0325  2.7571\n",
      "     21        0.0325  2.7620\n",
      "     22        0.0591  2.7515\n",
      "     23        0.0429  2.7604\n",
      "     24        0.1630  2.7635\n",
      "     25        0.2532  2.7569\n",
      "     26        0.0824  2.7528\n",
      "     27        0.0744  2.7530\n",
      "     28        0.0672  2.7540\n",
      "     29        0.0754  2.7538\n",
      "     30        0.0468  2.7533\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3227\u001b[0m  2.7255\n",
      "      2        \u001b[36m0.2211\u001b[0m  2.7254\n",
      "      3        0.3019  2.7326\n",
      "      4        \u001b[36m0.1285\u001b[0m  2.7396\n",
      "      5        \u001b[36m0.0652\u001b[0m  2.7362\n",
      "      6        \u001b[36m0.0631\u001b[0m  2.7390\n",
      "      7        \u001b[36m0.0354\u001b[0m  2.7310\n",
      "      8        0.0363  2.7150\n",
      "      9        \u001b[36m0.0325\u001b[0m  2.7286\n",
      "     10        0.4588  2.7577\n",
      "     11        0.2126  2.7276\n",
      "     12        0.1053  2.7400\n",
      "     13        0.0899  2.7315\n",
      "     14        0.0561  2.7481\n",
      "     15        0.0487  2.7603\n",
      "     16        0.0408  2.7237\n",
      "     17        0.0520  2.7708\n",
      "     18        0.0329  2.7336\n",
      "     19        0.1123  2.7616\n",
      "     20        0.5836  2.7367\n",
      "     21        0.5545  2.7611\n",
      "     22        0.4921  2.7318\n",
      "     23        0.5139  2.7271\n",
      "     24        0.4442  2.7336\n",
      "     25        0.3607  2.7323\n",
      "     26        0.2911  2.7312\n",
      "     27        0.2033  2.7305\n",
      "     28        0.1940  2.7175\n",
      "     29        0.1666  2.7366\n",
      "     30        0.1483  2.7301\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3150\u001b[0m  2.7506\n",
      "      2        \u001b[36m0.1508\u001b[0m  2.7442\n",
      "      3        \u001b[36m0.1218\u001b[0m  2.7522\n",
      "      4        \u001b[36m0.1074\u001b[0m  2.7497\n",
      "      5        \u001b[36m0.0576\u001b[0m  2.7451\n",
      "      6        \u001b[36m0.0388\u001b[0m  2.7522\n",
      "      7        0.1363  2.7500\n",
      "      8        0.0866  2.7344\n",
      "      9        0.1039  2.7338\n",
      "     10        0.0716  2.7330\n",
      "     11        \u001b[36m0.0341\u001b[0m  2.7435\n",
      "     12        \u001b[36m0.0245\u001b[0m  2.7369\n",
      "     13        0.0564  2.7447\n",
      "     14        0.6512  2.7338\n",
      "     15        0.6326  2.7434\n",
      "     16        0.5380  2.7466\n",
      "     17        0.3130  2.7430\n",
      "     18        0.2221  2.7491\n",
      "     19        0.1877  2.7383\n",
      "     20        0.1469  2.7496\n",
      "     21        0.1235  2.7436\n",
      "     22        0.1134  2.7414\n",
      "     23        0.1023  2.7434\n",
      "     24        0.0820  2.7410\n",
      "     25        0.0893  2.7436\n",
      "     26        0.0758  2.7455\n",
      "     27        0.1056  2.7307\n",
      "     28        0.0820  2.7480\n",
      "     29        0.0629  2.7509\n",
      "     30        0.1428  2.7507\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3077\u001b[0m  2.5265\n",
      "      2        \u001b[36m0.2365\u001b[0m  2.5275\n",
      "      3        \u001b[36m0.1307\u001b[0m  2.5341\n",
      "      4        \u001b[36m0.0777\u001b[0m  2.5377\n",
      "      5        \u001b[36m0.0715\u001b[0m  2.5474\n",
      "      6        \u001b[36m0.0441\u001b[0m  2.5491\n",
      "      7        \u001b[36m0.0367\u001b[0m  2.5404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        \u001b[36m0.0239\u001b[0m  2.5444\n",
      "      9        0.0458  2.5465\n",
      "     10        0.0269  2.5577\n",
      "     11        0.0255  2.5517\n",
      "     12        0.0369  2.5536\n",
      "     13        0.1688  2.5452\n",
      "     14        0.1514  2.5529\n",
      "     15        0.0530  2.5511\n",
      "     16        0.0418  2.5511\n",
      "     17        0.0905  2.5461\n",
      "     18        0.5826  2.5567\n",
      "     19        0.4908  2.5354\n",
      "     20        0.3633  2.5439\n",
      "     21        0.5064  2.5552\n",
      "     22        0.5052  2.5537\n",
      "     23        0.5550  2.5451\n",
      "     24        0.4485  2.5452\n",
      "     25        0.3569  2.5512\n",
      "     26        0.2823  2.5456\n",
      "     27        0.2227  2.5418\n",
      "     28        0.1786  2.5338\n",
      "     29        0.1539  2.5443\n",
      "     30        0.1212  2.5422\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3302\u001b[0m  2.5456\n",
      "      2        \u001b[36m0.1637\u001b[0m  2.5543\n",
      "      3        \u001b[36m0.0962\u001b[0m  2.5431\n",
      "      4        \u001b[36m0.0794\u001b[0m  2.5357\n",
      "      5        \u001b[36m0.0410\u001b[0m  2.5446\n",
      "      6        \u001b[36m0.0328\u001b[0m  2.5456\n",
      "      7        0.0489  2.5507\n",
      "      8        0.0403  2.5452\n",
      "      9        0.0809  2.5576\n",
      "     10        0.0735  2.5502\n",
      "     11        0.0510  2.5520\n",
      "     12        \u001b[36m0.0290\u001b[0m  2.5525\n",
      "     13        \u001b[36m0.0222\u001b[0m  2.5431\n",
      "     14        \u001b[36m0.0181\u001b[0m  2.5430\n",
      "     15        0.0251  2.5403\n",
      "     16        \u001b[36m0.0159\u001b[0m  2.5421\n",
      "     17        0.0206  2.5433\n",
      "     18        0.0173  2.5478\n",
      "     19        \u001b[36m0.0149\u001b[0m  2.5540\n",
      "     20        0.0191  2.5528\n",
      "     21        0.0292  2.5537\n",
      "     22        0.0325  2.5407\n",
      "     23        0.0529  2.5455\n",
      "     24        0.0240  2.5429\n",
      "     25        0.0275  2.5395\n",
      "     26        0.0169  2.5425\n",
      "     27        0.0151  2.5454\n",
      "     28        0.0159  2.5589\n",
      "     29        0.0164  2.5504\n",
      "     30        0.6503  2.5536\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2850\u001b[0m  2.5475\n",
      "      2        \u001b[36m0.1592\u001b[0m  2.5476\n",
      "      3        \u001b[36m0.0957\u001b[0m  2.5473\n",
      "      4        0.1725  2.5512\n",
      "      5        \u001b[36m0.0651\u001b[0m  2.5480\n",
      "      6        0.1967  2.5482\n",
      "      7        0.2064  2.5588\n",
      "      8        0.0991  2.5583\n",
      "      9        0.0694  2.5502\n",
      "     10        \u001b[36m0.0583\u001b[0m  2.5446\n",
      "     11        \u001b[36m0.0397\u001b[0m  2.5472\n",
      "     12        \u001b[36m0.0343\u001b[0m  2.5376\n",
      "     13        \u001b[36m0.0239\u001b[0m  2.5492\n",
      "     14        0.0374  2.5338\n",
      "     15        0.0332  2.5486\n",
      "     16        0.0320  2.5548\n",
      "     17        0.0286  2.5411\n",
      "     18        \u001b[36m0.0192\u001b[0m  2.5390\n",
      "     19        \u001b[36m0.0155\u001b[0m  2.5443\n",
      "     20        \u001b[36m0.0108\u001b[0m  2.5462\n",
      "     21        0.0666  2.5471\n",
      "     22        0.0257  2.5418\n",
      "     23        0.0296  2.5463\n",
      "     24        0.0325  2.5536\n",
      "     25        0.0285  2.5434\n",
      "     26        0.0168  2.5449\n",
      "     27        0.0486  2.5425\n",
      "     28        0.0341  2.5531\n",
      "     29        0.0272  2.5512\n",
      "     30        0.0290  2.5469\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3647\u001b[0m  2.5404\n",
      "      2        \u001b[36m0.2406\u001b[0m  2.5504\n",
      "      3        \u001b[36m0.1522\u001b[0m  2.5434\n",
      "      4        \u001b[36m0.1320\u001b[0m  2.5451\n",
      "      5        \u001b[36m0.1207\u001b[0m  2.5502\n",
      "      6        \u001b[36m0.0825\u001b[0m  2.5564\n",
      "      7        0.0849  2.5515\n",
      "      8        \u001b[36m0.0634\u001b[0m  2.5469\n",
      "      9        0.1158  2.5480\n",
      "     10        \u001b[36m0.0631\u001b[0m  2.5411\n",
      "     11        \u001b[36m0.0436\u001b[0m  2.5530\n",
      "     12        0.0449  2.5510\n",
      "     13        \u001b[36m0.0293\u001b[0m  2.5491\n",
      "     14        \u001b[36m0.0271\u001b[0m  2.5485\n",
      "     15        \u001b[36m0.0241\u001b[0m  2.5485\n",
      "     16        \u001b[36m0.0178\u001b[0m  2.5401\n",
      "     17        0.0322  2.5498\n",
      "     18        0.0310  2.5541\n",
      "     19        0.0232  2.5472\n",
      "     20        \u001b[36m0.0171\u001b[0m  2.5453\n",
      "     21        \u001b[36m0.0156\u001b[0m  2.5497\n",
      "     22        0.0160  2.5511\n",
      "     23        0.0310  2.5434\n",
      "     24        0.2476  2.5457\n",
      "     25        0.1409  2.5551\n",
      "     26        0.3253  2.5540\n",
      "     27        0.3550  2.5501\n",
      "     28        0.2241  2.5524\n",
      "     29        0.1200  2.5352\n",
      "     30        0.1014  2.5556\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3091\u001b[0m  2.5442\n",
      "      2        \u001b[36m0.1200\u001b[0m  2.5475\n",
      "      3        \u001b[36m0.0812\u001b[0m  2.5467\n",
      "      4        \u001b[36m0.0633\u001b[0m  2.5515\n",
      "      5        0.0724  2.5387\n",
      "      6        \u001b[36m0.0378\u001b[0m  2.5490\n",
      "      7        0.5425  2.5506\n",
      "      8        0.2664  2.5557\n",
      "      9        0.1942  2.5527\n",
      "     10        0.1170  2.5516\n",
      "     11        0.0881  2.5453\n",
      "     12        0.0669  2.5468\n",
      "     13        0.0702  2.5528\n",
      "     14        0.0552  2.5568\n",
      "     15        0.0510  2.5486\n",
      "     16        0.0591  2.5529\n",
      "     17        0.0489  2.5514\n",
      "     18        0.0387  2.5476\n",
      "     19        0.0410  2.5508\n",
      "     20        0.0439  2.5460\n",
      "     21        0.0633  2.5462\n",
      "     22        \u001b[36m0.0349\u001b[0m  2.5483\n",
      "     23        \u001b[36m0.0274\u001b[0m  2.5486\n",
      "     24        \u001b[36m0.0256\u001b[0m  2.5894\n",
      "     25        0.0263  2.5557\n",
      "     26        \u001b[36m0.0203\u001b[0m  2.5489\n",
      "     27        0.0681  2.5836\n",
      "     28        0.0599  2.5373\n",
      "     29        0.0417  2.5774\n",
      "     30        0.0301  2.5508\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.5, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3802\u001b[0m  1.5978\n",
      "      2        \u001b[36m0.2238\u001b[0m  1.6186\n",
      "      3        0.2563  1.5966\n",
      "      4        \u001b[36m0.2001\u001b[0m  1.5915\n",
      "      5        \u001b[36m0.1664\u001b[0m  1.6194\n",
      "      6        \u001b[36m0.1359\u001b[0m  1.5928\n",
      "      7        \u001b[36m0.1257\u001b[0m  1.6162\n",
      "      8        \u001b[36m0.1101\u001b[0m  1.6011\n",
      "      9        \u001b[36m0.1028\u001b[0m  1.6253\n",
      "     10        0.1322  1.5828\n",
      "     11        \u001b[36m0.0864\u001b[0m  1.5829\n",
      "     12        0.0991  1.5848\n",
      "     13        0.1189  1.5812\n",
      "     14        \u001b[36m0.0771\u001b[0m  1.6038\n",
      "     15        \u001b[36m0.0675\u001b[0m  1.5972\n",
      "     16        \u001b[36m0.0597\u001b[0m  1.5813\n",
      "     17        \u001b[36m0.0589\u001b[0m  1.5881\n",
      "     18        0.0606  1.6150\n",
      "     19        0.0676  1.6075\n",
      "     20        0.0593  1.6038\n",
      "     21        0.0828  1.6149\n",
      "     22        0.0765  1.6085\n",
      "     23        0.0628  1.5980\n",
      "     24        0.0944  1.5855\n",
      "     25        0.0888  1.6026\n",
      "     26        \u001b[36m0.0546\u001b[0m  1.6066\n",
      "     27        \u001b[36m0.0469\u001b[0m  1.6039\n",
      "     28        \u001b[36m0.0447\u001b[0m  1.6025\n",
      "     29        0.0539  1.5934\n",
      "     30        0.0546  1.6005\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  48.7s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3948\u001b[0m  1.6124\n",
      "      2        \u001b[36m0.3201\u001b[0m  1.5851\n",
      "      3        \u001b[36m0.2308\u001b[0m  1.5808\n",
      "      4        \u001b[36m0.2056\u001b[0m  1.5848\n",
      "      5        \u001b[36m0.1914\u001b[0m  1.6154\n",
      "      6        0.2322  1.5993\n",
      "      7        \u001b[36m0.1652\u001b[0m  1.5749\n",
      "      8        \u001b[36m0.1175\u001b[0m  1.6116\n",
      "      9        \u001b[36m0.1034\u001b[0m  1.5816\n",
      "     10        0.2454  1.5778\n",
      "     11        0.1819  1.5889\n",
      "     12        0.1386  1.5946\n",
      "     13        0.1164  1.5989\n",
      "     14        \u001b[36m0.0892\u001b[0m  1.5904\n",
      "     15        0.1246  1.6007\n",
      "     16        0.0978  1.5965\n",
      "     17        \u001b[36m0.0815\u001b[0m  1.5786\n",
      "     18        0.1011  1.5934\n",
      "     19        0.0904  1.6154\n",
      "     20        0.2914  1.5843\n",
      "     21        0.1965  1.5911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22        0.1517  1.5880\n",
      "     23        0.1212  1.5934\n",
      "     24        0.1042  1.5821\n",
      "     25        0.1005  1.5815\n",
      "     26        0.0917  1.5761\n",
      "     27        0.0852  1.5762\n",
      "     28        \u001b[36m0.0796\u001b[0m  1.5783\n",
      "     29        0.0834  1.6052\n",
      "     30        0.0815  1.5836\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  48.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4065\u001b[0m  1.5781\n",
      "      2        \u001b[36m0.2575\u001b[0m  1.6039\n",
      "      3        0.2864  1.5868\n",
      "      4        0.3197  1.5834\n",
      "      5        0.4293  1.5905\n",
      "      6        0.3115  1.5800\n",
      "      7        0.2727  1.5910\n",
      "      8        \u001b[36m0.2333\u001b[0m  1.5718\n",
      "      9        \u001b[36m0.1994\u001b[0m  1.5713\n",
      "     10        0.2784  1.6092\n",
      "     11        0.2018  1.5915\n",
      "     12        0.2317  1.5720\n",
      "     13        \u001b[36m0.1729\u001b[0m  1.5837\n",
      "     14        \u001b[36m0.1608\u001b[0m  1.5762\n",
      "     15        \u001b[36m0.1523\u001b[0m  1.5877\n",
      "     16        \u001b[36m0.1425\u001b[0m  1.5746\n",
      "     17        0.2798  1.5908\n",
      "     18        0.1468  1.5954\n",
      "     19        \u001b[36m0.1304\u001b[0m  1.5847\n",
      "     20        \u001b[36m0.1243\u001b[0m  1.5724\n",
      "     21        \u001b[36m0.1124\u001b[0m  1.5992\n",
      "     22        \u001b[36m0.1063\u001b[0m  1.5826\n",
      "     23        \u001b[36m0.0970\u001b[0m  1.6075\n",
      "     24        \u001b[36m0.0960\u001b[0m  1.5925\n",
      "     25        \u001b[36m0.0902\u001b[0m  1.6099\n",
      "     26        \u001b[36m0.0894\u001b[0m  1.5950\n",
      "     27        \u001b[36m0.0888\u001b[0m  1.6084\n",
      "     28        \u001b[36m0.0826\u001b[0m  1.6159\n",
      "     29        \u001b[36m0.0776\u001b[0m  1.5865\n",
      "     30        0.0817  1.5973\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  48.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4085\u001b[0m  1.5925\n",
      "      2        \u001b[36m0.2433\u001b[0m  1.6178\n",
      "      3        \u001b[36m0.2228\u001b[0m  1.5850\n",
      "      4        \u001b[36m0.1394\u001b[0m  1.5937\n",
      "      5        \u001b[36m0.1143\u001b[0m  1.5950\n",
      "      6        0.1386  1.5709\n",
      "      7        0.1790  1.5892\n",
      "      8        0.1356  1.6081\n",
      "      9        0.1289  1.5713\n",
      "     10        \u001b[36m0.1069\u001b[0m  1.5721\n",
      "     11        0.1492  1.5746\n",
      "     12        \u001b[36m0.0940\u001b[0m  1.5873\n",
      "     13        0.1233  1.6002\n",
      "     14        \u001b[36m0.0767\u001b[0m  1.5907\n",
      "     15        \u001b[36m0.0644\u001b[0m  1.5794\n",
      "     16        0.0707  1.5899\n",
      "     17        \u001b[36m0.0587\u001b[0m  1.5853\n",
      "     18        0.0637  1.5816\n",
      "     19        \u001b[36m0.0550\u001b[0m  1.5779\n",
      "     20        \u001b[36m0.0524\u001b[0m  1.5777\n",
      "     21        0.0773  1.5948\n",
      "     22        0.0767  1.5850\n",
      "     23        0.0549  1.5712\n",
      "     24        0.0667  1.5851\n",
      "     25        0.0695  1.5969\n",
      "     26        0.0666  1.5923\n",
      "     27        0.0537  1.5735\n",
      "     28        0.0846  1.5863\n",
      "     29        0.2342  1.6037\n",
      "     30        0.2795  1.6042\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  48.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4231\u001b[0m  1.6038\n",
      "      2        \u001b[36m0.2684\u001b[0m  1.5969\n",
      "      3        \u001b[36m0.2069\u001b[0m  1.5924\n",
      "      4        \u001b[36m0.1963\u001b[0m  1.5962\n",
      "      5        0.2631  1.6081\n",
      "      6        \u001b[36m0.1861\u001b[0m  1.5811\n",
      "      7        \u001b[36m0.1472\u001b[0m  1.5736\n",
      "      8        \u001b[36m0.1160\u001b[0m  1.5829\n",
      "      9        \u001b[36m0.0990\u001b[0m  1.5782\n",
      "     10        \u001b[36m0.0988\u001b[0m  1.5858\n",
      "     11        0.2377  1.5974\n",
      "     12        0.1489  1.5850\n",
      "     13        0.1075  1.6055\n",
      "     14        \u001b[36m0.0901\u001b[0m  1.5977\n",
      "     15        \u001b[36m0.0739\u001b[0m  1.5820\n",
      "     16        0.1444  1.5881\n",
      "     17        0.0818  1.5743\n",
      "     18        \u001b[36m0.0695\u001b[0m  1.5953\n",
      "     19        \u001b[36m0.0561\u001b[0m  1.5881\n",
      "     20        \u001b[36m0.0550\u001b[0m  1.5894\n",
      "     21        \u001b[36m0.0520\u001b[0m  1.5865\n",
      "     22        \u001b[36m0.0439\u001b[0m  1.5995\n",
      "     23        0.0793  1.5827\n",
      "     24        0.0754  1.6053\n",
      "     25        0.0604  1.6014\n",
      "     26        0.0495  1.6004\n",
      "     27        0.0451  1.6019\n",
      "     28        0.0492  1.5757\n",
      "     29        \u001b[36m0.0388\u001b[0m  1.6021\n",
      "     30        0.0792  1.6000\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=10, total=  48.4s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4834\u001b[0m  1.7279\n",
      "      2        \u001b[36m0.4006\u001b[0m  1.7284\n",
      "      3        \u001b[36m0.1854\u001b[0m  1.7427\n",
      "      4        \u001b[36m0.1369\u001b[0m  1.7387\n",
      "      5        \u001b[36m0.1014\u001b[0m  1.7261\n",
      "      6        \u001b[36m0.0824\u001b[0m  1.7330\n",
      "      7        \u001b[36m0.0586\u001b[0m  1.7121\n",
      "      8        \u001b[36m0.0547\u001b[0m  1.7119\n",
      "      9        0.0731  1.7120\n",
      "     10        \u001b[36m0.0516\u001b[0m  1.7429\n",
      "     11        \u001b[36m0.0351\u001b[0m  1.7333\n",
      "     12        \u001b[36m0.0333\u001b[0m  1.7267\n",
      "     13        \u001b[36m0.0327\u001b[0m  1.7284\n",
      "     14        0.0372  1.7209\n",
      "     15        \u001b[36m0.0311\u001b[0m  1.7285\n",
      "     16        0.0770  1.7275\n",
      "     17        0.0404  1.7161\n",
      "     18        \u001b[36m0.0293\u001b[0m  1.7215\n",
      "     19        \u001b[36m0.0208\u001b[0m  1.7061\n",
      "     20        \u001b[36m0.0192\u001b[0m  1.7024\n",
      "     21        0.0274  1.7117\n",
      "     22        0.0325  1.7202\n",
      "     23        0.0195  1.7280\n",
      "     24        \u001b[36m0.0175\u001b[0m  1.7200\n",
      "     25        0.0208  1.7129\n",
      "     26        0.0202  1.7213\n",
      "     27        0.0264  1.7219\n",
      "     28        0.0274  1.7201\n",
      "     29        0.0185  1.7088\n",
      "     30        0.0349  1.7123\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  52.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3469\u001b[0m  1.7267\n",
      "      2        \u001b[36m0.1725\u001b[0m  1.7150\n",
      "      3        \u001b[36m0.1475\u001b[0m  1.7174\n",
      "      4        \u001b[36m0.1267\u001b[0m  1.7153\n",
      "      5        \u001b[36m0.0981\u001b[0m  1.7152\n",
      "      6        \u001b[36m0.0624\u001b[0m  1.7157\n",
      "      7        \u001b[36m0.0557\u001b[0m  1.7177\n",
      "      8        \u001b[36m0.0387\u001b[0m  1.7239\n",
      "      9        0.0471  1.7128\n",
      "     10        \u001b[36m0.0374\u001b[0m  1.7291\n",
      "     11        0.0478  1.7449\n",
      "     12        \u001b[36m0.0283\u001b[0m  1.7330\n",
      "     13        \u001b[36m0.0227\u001b[0m  1.7170\n",
      "     14        0.0330  1.7269\n",
      "     15        0.0541  1.7179\n",
      "     16        0.0372  1.7208\n",
      "     17        0.0260  1.7229\n",
      "     18        0.0300  1.7117\n",
      "     19        \u001b[36m0.0201\u001b[0m  1.7162\n",
      "     20        \u001b[36m0.0187\u001b[0m  1.7249\n",
      "     21        0.0215  1.7156\n",
      "     22        0.0280  1.7152\n",
      "     23        0.0226  1.7201\n",
      "     24        0.0239  1.7322\n",
      "     25        \u001b[36m0.0176\u001b[0m  1.7141\n",
      "     26        \u001b[36m0.0176\u001b[0m  1.7265\n",
      "     27        0.0177  1.7194\n",
      "     28        0.0192  1.7163\n",
      "     29        \u001b[36m0.0157\u001b[0m  1.7189\n",
      "     30        0.0418  1.7064\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  52.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3183\u001b[0m  1.7225\n",
      "      2        \u001b[36m0.1760\u001b[0m  1.7083\n",
      "      3        0.1930  1.7032\n",
      "      4        \u001b[36m0.1405\u001b[0m  1.7056\n",
      "      5        \u001b[36m0.1178\u001b[0m  1.7198\n",
      "      6        \u001b[36m0.0900\u001b[0m  1.7145\n",
      "      7        \u001b[36m0.0724\u001b[0m  1.7092\n",
      "      8        \u001b[36m0.0708\u001b[0m  1.7135\n",
      "      9        \u001b[36m0.0455\u001b[0m  1.7173\n",
      "     10        0.3292  1.7295\n",
      "     11        0.1880  1.7233\n",
      "     12        0.1412  1.7124\n",
      "     13        0.0999  1.7155\n",
      "     14        0.0727  1.7231\n",
      "     15        0.0590  1.7262\n",
      "     16        0.0525  1.7204\n",
      "     17        0.1167  1.7235\n",
      "     18        0.0708  1.7204\n",
      "     19        \u001b[36m0.0389\u001b[0m  1.7361\n",
      "     20        \u001b[36m0.0368\u001b[0m  1.7329\n",
      "     21        0.0472  1.7438\n",
      "     22        \u001b[36m0.0356\u001b[0m  1.7369\n",
      "     23        0.0409  1.7120\n",
      "     24        \u001b[36m0.0306\u001b[0m  1.7182\n",
      "     25        \u001b[36m0.0255\u001b[0m  1.7489\n",
      "     26        \u001b[36m0.0248\u001b[0m  1.7211\n",
      "     27        0.0293  1.7216\n",
      "     28        0.0322  1.7181\n",
      "     29        0.0329  1.7245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     30        0.0360  1.7210\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  52.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3116\u001b[0m  1.7075\n",
      "      2        \u001b[36m0.1922\u001b[0m  1.7400\n",
      "      3        \u001b[36m0.1366\u001b[0m  1.7266\n",
      "      4        0.2328  1.7117\n",
      "      5        0.1573  1.7119\n",
      "      6        0.2078  1.7120\n",
      "      7        0.1401  1.7196\n",
      "      8        \u001b[36m0.1241\u001b[0m  1.7194\n",
      "      9        \u001b[36m0.0621\u001b[0m  1.7108\n",
      "     10        0.0706  1.7336\n",
      "     11        \u001b[36m0.0473\u001b[0m  1.7146\n",
      "     12        \u001b[36m0.0381\u001b[0m  1.7188\n",
      "     13        \u001b[36m0.0286\u001b[0m  1.7135\n",
      "     14        0.0347  1.7160\n",
      "     15        \u001b[36m0.0264\u001b[0m  1.7101\n",
      "     16        \u001b[36m0.0257\u001b[0m  1.7156\n",
      "     17        0.0262  1.6997\n",
      "     18        \u001b[36m0.0245\u001b[0m  1.7272\n",
      "     19        0.0275  1.7252\n",
      "     20        \u001b[36m0.0212\u001b[0m  1.7123\n",
      "     21        0.0567  1.7158\n",
      "     22        0.0480  1.7174\n",
      "     23        0.0296  1.7249\n",
      "     24        0.0250  1.7157\n",
      "     25        \u001b[36m0.0200\u001b[0m  1.7231\n",
      "     26        0.0247  1.7230\n",
      "     27        0.0457  1.7290\n",
      "     28        0.0324  1.7161\n",
      "     29        0.0272  1.7272\n",
      "     30        0.0350  1.7136\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  52.2s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3429\u001b[0m  1.7168\n",
      "      2        \u001b[36m0.2193\u001b[0m  1.7130\n",
      "      3        \u001b[36m0.1195\u001b[0m  1.7086\n",
      "      4        \u001b[36m0.0684\u001b[0m  1.7363\n",
      "      5        0.0831  1.7118\n",
      "      6        0.0795  1.7074\n",
      "      7        \u001b[36m0.0475\u001b[0m  1.7050\n",
      "      8        \u001b[36m0.0324\u001b[0m  1.7233\n",
      "      9        \u001b[36m0.0315\u001b[0m  1.7415\n",
      "     10        \u001b[36m0.0272\u001b[0m  1.7129\n",
      "     11        0.0286  1.7340\n",
      "     12        0.0451  1.7188\n",
      "     13        0.0272  1.7147\n",
      "     14        \u001b[36m0.0203\u001b[0m  1.7144\n",
      "     15        \u001b[36m0.0187\u001b[0m  1.7147\n",
      "     16        0.0283  1.7297\n",
      "     17        0.0189  1.7357\n",
      "     18        \u001b[36m0.0164\u001b[0m  1.7329\n",
      "     19        \u001b[36m0.0143\u001b[0m  1.7191\n",
      "     20        0.0186  1.7271\n",
      "     21        0.0185  1.7113\n",
      "     22        0.0209  1.7308\n",
      "     23        0.0148  1.7280\n",
      "     24        \u001b[36m0.0104\u001b[0m  1.7157\n",
      "     25        0.0405  1.7295\n",
      "     26        0.0145  1.7193\n",
      "     27        0.0126  1.7172\n",
      "     28        0.0337  1.7076\n",
      "     29        0.0896  1.7078\n",
      "     30        0.0948  1.7339\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=40, total=  52.3s\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2987\u001b[0m  2.7535\n",
      "      2        \u001b[36m0.1668\u001b[0m  2.7521\n",
      "      3        \u001b[36m0.0819\u001b[0m  2.7451\n",
      "      4        0.1395  2.7484\n",
      "      5        \u001b[36m0.0614\u001b[0m  2.7441\n",
      "      6        \u001b[36m0.0467\u001b[0m  2.7432\n",
      "      7        \u001b[36m0.0312\u001b[0m  2.7522\n",
      "      8        \u001b[36m0.0251\u001b[0m  2.7588\n",
      "      9        \u001b[36m0.0244\u001b[0m  2.7836\n",
      "     10        \u001b[36m0.0218\u001b[0m  2.7473\n",
      "     11        0.4165  2.7490\n",
      "     12        0.3818  2.7476\n",
      "     13        0.1996  2.7552\n",
      "     14        0.1355  2.7462\n",
      "     15        0.1096  2.7542\n",
      "     16        0.0921  2.7593\n",
      "     17        0.0940  2.7541\n",
      "     18        0.0722  2.7489\n",
      "     19        0.0680  2.7588\n",
      "     20        0.0604  2.7526\n",
      "     21        0.0659  2.7433\n",
      "     22        0.0965  2.7566\n",
      "     23        0.0633  2.7613\n",
      "     24        0.1229  2.7547\n",
      "     25        0.1050  2.7485\n",
      "     26        0.0561  2.7484\n",
      "     27        0.0569  2.7457\n",
      "     28        0.0356  2.7573\n",
      "     29        0.0519  2.7469\n",
      "     30        0.0399  2.7445\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3446\u001b[0m  2.7551\n",
      "      2        \u001b[36m0.1810\u001b[0m  2.7495\n",
      "      3        \u001b[36m0.1301\u001b[0m  2.7473\n",
      "      4        \u001b[36m0.0824\u001b[0m  2.7515\n",
      "      5        \u001b[36m0.0632\u001b[0m  2.7534\n",
      "      6        0.4164  2.7415\n",
      "      7        0.1799  2.7571\n",
      "      8        0.0947  2.7467\n",
      "      9        0.0774  2.7426\n",
      "     10        0.0764  2.7370\n",
      "     11        0.0809  2.7437\n",
      "     12        0.0654  2.7519\n",
      "     13        0.2547  2.7468\n",
      "     14        0.0980  2.7454\n",
      "     15        0.1457  2.7610\n",
      "     16        \u001b[36m0.0627\u001b[0m  2.7581\n",
      "     17        \u001b[36m0.0498\u001b[0m  2.7511\n",
      "     18        \u001b[36m0.0459\u001b[0m  2.7354\n",
      "     19        \u001b[36m0.0381\u001b[0m  2.7525\n",
      "     20        \u001b[36m0.0296\u001b[0m  2.7494\n",
      "     21        0.0378  2.7509\n",
      "     22        \u001b[36m0.0255\u001b[0m  2.7526\n",
      "     23        0.0301  2.7511\n",
      "     24        0.0264  2.7463\n",
      "     25        \u001b[36m0.0244\u001b[0m  2.7561\n",
      "     26        \u001b[36m0.0198\u001b[0m  2.7543\n",
      "     27        0.0236  2.7486\n",
      "     28        0.0585  2.7583\n",
      "     29        0.0265  2.7547\n",
      "     30        \u001b[36m0.0191\u001b[0m  2.7561\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3307\u001b[0m  2.7407\n",
      "      2        \u001b[36m0.1611\u001b[0m  2.7443\n",
      "      3        \u001b[36m0.1189\u001b[0m  2.7524\n",
      "      4        \u001b[36m0.0779\u001b[0m  2.7474\n",
      "      5        \u001b[36m0.0705\u001b[0m  2.7491\n",
      "      6        0.1045  2.7509\n",
      "      7        \u001b[36m0.0477\u001b[0m  2.7508\n",
      "      8        0.0588  2.7499\n",
      "      9        \u001b[36m0.0391\u001b[0m  2.7425\n",
      "     10        0.0937  2.7370\n",
      "     11        0.0537  2.7556\n",
      "     12        \u001b[36m0.0293\u001b[0m  2.7429\n",
      "     13        \u001b[36m0.0228\u001b[0m  2.7334\n",
      "     14        \u001b[36m0.0221\u001b[0m  2.7316\n",
      "     15        0.0258  2.7503\n",
      "     16        0.0234  2.7481\n",
      "     17        0.6859  2.7443\n",
      "     18        0.4748  2.7532\n",
      "     19        0.3690  2.7364\n",
      "     20        0.2743  2.7341\n",
      "     21        0.2131  2.7386\n",
      "     22        0.1811  2.7448\n",
      "     23        0.1679  2.7463\n",
      "     24        0.1962  2.7491\n",
      "     25        0.1407  2.7469\n",
      "     26        0.1142  2.7446\n",
      "     27        0.0976  2.7457\n",
      "     28        0.2298  2.7557\n",
      "     29        0.3451  2.7510\n",
      "     30        0.1868  2.7519\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3023\u001b[0m  2.7465\n",
      "      2        \u001b[36m0.1775\u001b[0m  2.7551\n",
      "      3        \u001b[36m0.1316\u001b[0m  2.7570\n",
      "      4        \u001b[36m0.0920\u001b[0m  2.7586\n",
      "      5        \u001b[36m0.0560\u001b[0m  2.7622\n",
      "      6        0.1702  2.7581\n",
      "      7        0.3552  2.7535\n",
      "      8        0.1245  2.7675\n",
      "      9        0.1935  2.7570\n",
      "     10        0.1044  2.7539\n",
      "     11        0.0919  2.7434\n",
      "     12        \u001b[36m0.0518\u001b[0m  2.7544\n",
      "     13        \u001b[36m0.0482\u001b[0m  2.7490\n",
      "     14        \u001b[36m0.0365\u001b[0m  2.7528\n",
      "     15        0.0391  2.7613\n",
      "     16        \u001b[36m0.0279\u001b[0m  2.7470\n",
      "     17        0.0293  2.7603\n",
      "     18        0.0400  2.7601\n",
      "     19        0.0375  2.7522\n",
      "     20        0.0459  2.7607\n",
      "     21        0.0368  2.7422\n",
      "     22        0.0423  2.7576\n",
      "     23        0.0335  2.7554\n",
      "     24        \u001b[36m0.0238\u001b[0m  2.7431\n",
      "     25        \u001b[36m0.0206\u001b[0m  2.7518\n",
      "     26        0.0300  2.7592\n",
      "     27        0.0401  2.7581\n",
      "     28        0.0319  2.7565\n",
      "     29        0.0243  2.7537\n",
      "     30        0.0219  2.7421\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3438\u001b[0m  2.7159\n",
      "      2        \u001b[36m0.1413\u001b[0m  2.7324\n",
      "      3        \u001b[36m0.1188\u001b[0m  2.7284\n",
      "      4        \u001b[36m0.0553\u001b[0m  2.7334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        \u001b[36m0.0437\u001b[0m  2.7314\n",
      "      6        \u001b[36m0.0308\u001b[0m  2.7281\n",
      "      7        \u001b[36m0.0257\u001b[0m  2.7318\n",
      "      8        \u001b[36m0.0232\u001b[0m  2.7347\n",
      "      9        0.0254  2.7316\n",
      "     10        0.0676  2.7311\n",
      "     11        0.3700  2.7400\n",
      "     12        0.6333  2.7474\n",
      "     13        0.5410  2.7322\n",
      "     14        0.4349  2.7285\n",
      "     15        0.3600  2.7267\n",
      "     16        0.4186  2.7271\n",
      "     17        0.3580  2.7291\n",
      "     18        0.3335  2.7328\n",
      "     19        0.3423  2.7233\n",
      "     20        0.4002  2.7265\n",
      "     21        0.2968  2.7205\n",
      "     22        0.3621  2.7301\n",
      "     23        0.2717  2.7307\n",
      "     24        0.2085  2.7326\n",
      "     25        0.6302  2.7255\n",
      "     26        0.3271  2.7413\n",
      "     27        0.2112  2.7318\n",
      "     28        0.1395  2.7343\n",
      "     29        0.4875  2.7341\n",
      "     30        0.4804  2.7362\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=70, total= 1.4min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3204\u001b[0m  2.5333\n",
      "      2        \u001b[36m0.2387\u001b[0m  2.5375\n",
      "      3        \u001b[36m0.1405\u001b[0m  2.5323\n",
      "      4        \u001b[36m0.0495\u001b[0m  2.5298\n",
      "      5        0.1113  2.5336\n",
      "      6        0.6110  2.5399\n",
      "      7        0.3942  2.5289\n",
      "      8        0.3176  2.5259\n",
      "      9        0.2758  2.5291\n",
      "     10        0.2469  2.5275\n",
      "     11        0.1987  2.5287\n",
      "     12        0.1669  2.5253\n",
      "     13        0.1496  2.5321\n",
      "     14        0.1380  2.5306\n",
      "     15        0.1190  2.5328\n",
      "     16        0.1129  2.5341\n",
      "     17        0.0933  2.5342\n",
      "     18        0.0975  2.5459\n",
      "     19        0.0882  2.5284\n",
      "     20        0.0866  2.5326\n",
      "     21        0.0774  2.5241\n",
      "     22        0.0786  2.5369\n",
      "     23        0.0814  2.5458\n",
      "     24        0.0976  2.5411\n",
      "     25        0.0950  2.5348\n",
      "     26        0.0696  2.5435\n",
      "     27        0.0651  2.5509\n",
      "     28        \u001b[36m0.0478\u001b[0m  2.5473\n",
      "     29        0.0517  2.5528\n",
      "     30        0.0510  2.5533\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3182\u001b[0m  2.5567\n",
      "      2        \u001b[36m0.1440\u001b[0m  2.5452\n",
      "      3        \u001b[36m0.0564\u001b[0m  2.5427\n",
      "      4        \u001b[36m0.0363\u001b[0m  2.5384\n",
      "      5        \u001b[36m0.0272\u001b[0m  2.5483\n",
      "      6        \u001b[36m0.0230\u001b[0m  2.5319\n",
      "      7        0.0451  2.5595\n",
      "      8        0.0538  2.5404\n",
      "      9        0.6793  2.5519\n",
      "     10        0.6203  2.5459\n",
      "     11        0.6554  2.5342\n",
      "     12        0.6275  2.5544\n",
      "     13        0.6574  2.5486\n",
      "     14        0.6515  2.5508\n",
      "     15        0.5224  2.5401\n",
      "     16        0.3561  2.5482\n",
      "     17        0.2655  2.5536\n",
      "     18        0.1790  2.5483\n",
      "     19        0.1253  2.5528\n",
      "     20        0.1203  2.5480\n",
      "     21        0.0762  2.5337\n",
      "     22        0.4606  2.5510\n",
      "     23        0.6077  2.5534\n",
      "     24        0.5168  2.5423\n",
      "     25        0.3598  2.5402\n",
      "     26        0.2685  2.5442\n",
      "     27        0.2163  2.5462\n",
      "     28        0.1898  2.5437\n",
      "     29        0.1645  2.5423\n",
      "     30        0.1116  2.5466\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3026\u001b[0m  2.5391\n",
      "      2        \u001b[36m0.1673\u001b[0m  2.5570\n",
      "      3        \u001b[36m0.1052\u001b[0m  2.5421\n",
      "      4        \u001b[36m0.0565\u001b[0m  2.5353\n",
      "      5        \u001b[36m0.0419\u001b[0m  2.5502\n",
      "      6        0.0722  2.5460\n",
      "      7        \u001b[36m0.0383\u001b[0m  2.5593\n",
      "      8        \u001b[36m0.0243\u001b[0m  2.5446\n",
      "      9        \u001b[36m0.0182\u001b[0m  2.5509\n",
      "     10        0.0207  2.5462\n",
      "     11        0.0254  2.5488\n",
      "     12        0.0486  2.5514\n",
      "     13        0.0344  2.5436\n",
      "     14        \u001b[36m0.0175\u001b[0m  2.5500\n",
      "     15        0.0278  2.5544\n",
      "     16        0.0250  2.5369\n",
      "     17        0.0211  2.5373\n",
      "     18        0.0201  2.5357\n",
      "     19        0.0585  2.5391\n",
      "     20        0.4247  2.5504\n",
      "     21        0.6219  2.5528\n",
      "     22        0.6425  2.5555\n",
      "     23        0.6254  2.5577\n",
      "     24        0.5864  2.5524\n",
      "     25        0.5536  2.5458\n",
      "     26        0.5018  2.5612\n",
      "     27        0.4424  2.5526\n",
      "     28        0.3550  2.5544\n",
      "     29        0.2479  2.5541\n",
      "     30        0.1892  2.5554\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3842\u001b[0m  2.5524\n",
      "      2        \u001b[36m0.1256\u001b[0m  2.5391\n",
      "      3        \u001b[36m0.0629\u001b[0m  2.5507\n",
      "      4        \u001b[36m0.0390\u001b[0m  2.5359\n",
      "      5        \u001b[36m0.0327\u001b[0m  2.5362\n",
      "      6        \u001b[36m0.0252\u001b[0m  2.5443\n",
      "      7        \u001b[36m0.0192\u001b[0m  2.5498\n",
      "      8        0.0288  2.5520\n",
      "      9        0.1782  2.5423\n",
      "     10        0.1662  2.5429\n",
      "     11        0.0734  2.5328\n",
      "     12        0.0539  2.5374\n",
      "     13        0.0472  2.5507\n",
      "     14        0.0301  2.5413\n",
      "     15        0.0265  2.5433\n",
      "     16        0.0239  2.5514\n",
      "     17        0.0247  2.5512\n",
      "     18        0.0444  2.5600\n",
      "     19        0.0270  2.5560\n",
      "     20        0.0346  2.5534\n",
      "     21        0.0235  2.5565\n",
      "     22        0.0238  2.5564\n",
      "     23        0.0287  2.5535\n",
      "     24        \u001b[36m0.0174\u001b[0m  2.5397\n",
      "     25        \u001b[36m0.0171\u001b[0m  2.5493\n",
      "     26        0.0178  2.5445\n",
      "     27        0.0274  2.5403\n",
      "     28        0.0193  2.5334\n",
      "     29        0.0193  2.5503\n",
      "     30        \u001b[36m0.0155\u001b[0m  2.5594\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.3min\n",
      "[CV] net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100 \n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.3988\u001b[0m  2.5571\n",
      "      2        \u001b[36m0.2904\u001b[0m  2.5552\n",
      "      3        \u001b[36m0.1632\u001b[0m  2.5504\n",
      "      4        0.3455  2.5387\n",
      "      5        \u001b[36m0.1430\u001b[0m  2.5524\n",
      "      6        \u001b[36m0.0811\u001b[0m  2.5536\n",
      "      7        0.1993  2.5527\n",
      "      8        0.1538  2.5475\n",
      "      9        0.0833  2.5461\n",
      "     10        \u001b[36m0.0443\u001b[0m  2.5439\n",
      "     11        \u001b[36m0.0309\u001b[0m  2.5448\n",
      "     12        0.0488  2.5507\n",
      "     13        0.0365  2.5559\n",
      "     14        \u001b[36m0.0225\u001b[0m  2.5455\n",
      "     15        0.1438  2.5538\n",
      "     16        0.7041  2.5609\n",
      "     17        0.5231  2.5432\n",
      "     18        0.4553  2.5385\n",
      "     19        0.3646  2.5534\n",
      "     20        0.2976  2.5592\n",
      "     21        0.2470  2.5519\n",
      "     22        0.1979  2.5448\n",
      "     23        0.1610  2.5487\n",
      "     24        0.1931  2.5540\n",
      "     25        0.1585  2.5545\n",
      "     26        0.2467  2.5473\n",
      "     27        0.1836  2.5450\n",
      "     28        0.2745  2.5439\n",
      "     29        0.2182  2.5442\n",
      "     30        0.1603  2.5468\n",
      "[CV]  net__batch_size=128, net__max_epochs=30, net__module__dropout_rate=0.6, net__module__hidden_dim=100, total= 1.3min\n",
      "0.9760087365212534 {'net__batch_size': 64, 'net__max_epochs': 20, 'net__module__dropout_rate': 0.5, 'net__module__hidden_dim': 10}\n",
      "\n",
      "Done! Time: 757.46 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed: 757.5min finished\n"
     ]
    }
   ],
   "source": [
    "start_training = time.time()\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "input_dim = 307\n",
    "\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    LSTM_network,\n",
    "    module__input_dim = input_dim,\n",
    "    module__hidden_dim = 10,\n",
    "    module__dropout_rate = 0.4,\n",
    "    batch_size = 32,\n",
    "    max_epochs = 10,\n",
    "    train_split = None,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    iterator_train__shuffle = True,\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "ros = RandomOverSampler(random_state = SEED)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ros', ros),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'net__module__hidden_dim' : [10, 40, 70, 100],\n",
    "    'net__module__dropout_rate' : [0.4, 0.5, 0.6],\n",
    "    'net__batch_size' : [32, 64, 128],\n",
    "    'net__max_epochs' : [10, 20, 30]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    refit = False,\n",
    "    cv = StratifiedKFold(n_splits = 5, random_state = SEED, shuffle = True),\n",
    "    scoring = lambda net_gs, X_gs, y_gs : roc_auc_score(y_gs, net_gs.predict_proba(X_gs)),\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train.astype(np.float))\n",
    "\n",
    "print(gs.best_score_, gs.best_params_)\n",
    "\n",
    "end_training = (time.time() - start_training) / 60\n",
    "\n",
    "print(f'\\nDone! Time: {end_training:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Configuration:\n",
    "\n",
    "0.9760087365212534 {'net__batch_size': 64, 'net__max_epochs': 20, 'net__module__dropout_rate': 0.5, 'net__module__hidden_dim': 10}\n",
    "\n",
    "Done! Time: 757.46 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.2988\u001b[0m  3.9138\n",
      "      2        \u001b[36m0.1538\u001b[0m  3.7618\n",
      "      3        \u001b[36m0.1111\u001b[0m  3.5495\n",
      "      4        \u001b[36m0.1051\u001b[0m  3.5489\n",
      "      5        \u001b[36m0.0787\u001b[0m  3.7537\n",
      "      6        \u001b[36m0.0678\u001b[0m  3.7538\n",
      "      7        0.0727  3.6880\n",
      "      8        0.0742  3.7890\n",
      "      9        \u001b[36m0.0507\u001b[0m  3.5029\n",
      "     10        \u001b[36m0.0476\u001b[0m  3.6287\n",
      "     11        0.0518  3.4410\n",
      "     12        0.0555  3.4792\n",
      "     13        \u001b[36m0.0414\u001b[0m  3.5584\n",
      "     14        0.0680  3.6025\n",
      "     15        0.0704  3.7988\n",
      "     16        0.0472  3.7248\n",
      "     17        0.0491  3.5063\n",
      "     18        0.0444  3.5038\n",
      "     19        0.0577  3.4682\n",
      "     20        \u001b[36m0.0376\u001b[0m  3.4734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ros',\n",
       "                 RandomOverSampler(random_state=137, ratio=None,\n",
       "                                   return_indices=False,\n",
       "                                   sampling_strategy='auto')),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetBinaryClassifier'>[initialized](\n",
       "  module_=LSTM_network(\n",
       "    (lstm): LSTM(307, 10, batch_first=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Linear(in_features=10, out_features=1, bias=True)\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "\n",
    "# hidden_dim = gs.best_params_['net__module__hidden_dim']\n",
    "# dropout_rate = gs.best_params_['net__module__dropout_rate']\n",
    "# batch_size = gs.best_params_['net__batch_size']\n",
    "# max_epochs = gs.best_params_['net__max_epochs']\n",
    "\n",
    "input_dim = 307\n",
    "hidden_dim = 10\n",
    "dropout_rate = 0.5\n",
    "batch_size = 64\n",
    "max_epochs = 20\n",
    "\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    LSTM_network,\n",
    "    module__input_dim = input_dim,\n",
    "    module__hidden_dim = hidden_dim,\n",
    "    module__dropout_rate = dropout_rate,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs,\n",
    "    train_split = None,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    iterator_train__shuffle = True,\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "ros = RandomOverSampler(random_state = SEED)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ros', ros),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train.astype(np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(y, pred):\n",
    "    print('Confusion matrix\\n[TN FP]\\n[FN TP]')\n",
    "    print(confusion_matrix(y >= 0.5, pred >= 0.5))\n",
    "    print(f'Precision: {precision_score(y >= 0.5, pred >= 0.5):.4f}')\n",
    "    print(f'Recall: {recall_score(y >= 0.5, pred >= 0.5):.4f}')    \n",
    "    print(f'F1-score: {f1_score(y >= 0.5, pred >= 0.5):.4f}')\n",
    "    print(f'ROC AUC: {roc_auc_score(y, pred):.4f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[TN FP]\n",
      "[FN TP]\n",
      "[[    0 12815]\n",
      " [    0   348]]\n",
      "Precision: 0.0264\n",
      "Recall: 1.0000\n",
      "F1-score: 0.0515\n",
      "ROC AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(y_test, np.ones(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[TN FP]\n",
      "[FN TP]\n",
      "[[12651   164]\n",
      " [   48   300]]\n",
      "Precision: 0.6466\n",
      "Recall: 0.8621\n",
      "F1-score: 0.7389\n",
      "ROC AUC: 0.9761\n"
     ]
    }
   ],
   "source": [
    "model_evaluate(y_test, pipe.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
